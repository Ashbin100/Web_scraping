Moderately Hard, Memory-bound Functions
Mart´ınAbadi MikeBurrows, MarkManasse,andTedWobber
UniversityofCaliforniaatSantaCruz MicrosoftResearch,Silicon Valley
Abstract
Aresourcemaybeabusedifitsusersincurlittleorno
cost. Forexample,e-mailabuseisrampantbecausesend-
ing an e-mail has negligible cost for the sender. It has
beensuggestedthatsuchabusemaybediscouragedbyin-
troducinganartificialcostintheformofamoderatelyex-
pensivecomputation. Thus,thesenderofane-mailmight
berequiredtopaybycomputingforafewsecondsbefore
the e-mail is accepted. Unfortunately, because of sharp
disparities across computer systems, this approach may
be ineffective against malicious users with high-end sys-
tems,prohibitivelyslowforlegitimateuserswithlow-end
systems, or both. Starting from this observation, we re-
searchmoderatelyhardfunctionsthatmostrecentsystems
will evaluate at about the same speed. For this purpose,
we rely on memory-bound computations. We describe
andanalyzeafamilyofmoderatelyhard,memory-bound
functions,andweexplainhowtousethemforprotecting
againstabuses.
1. Introduction
With the increase in the number of e-mail users and
theproliferationofjunke-mail(spam),severaltechniques
for discouraging or filtering spam have been proposed
(e.g., [5]). In particular, Dwork and Naor suggested in
their seminal paper that a way to discourage spam is to
force senders of e-mail to pay by performing a moder-
atelyexpensivecomputation[7]. Morerecently,Backre-
discoveredthisideaandimplementeditintheHashCash
system[3](seealso[4]).
Theirbasicschemegoesasfollows.Assumethatsender
S is sending an e-mail
(cid:0)
to recipient R. If R has previ-
ously agreed to receive e-mail from S, then
(cid:0)
is sent in
thenormalway. Otherwise,theyproceed:
(cid:1) S computes some moderately-hard function (cid:2)(cid:4) (cid:3) (cid:0)(cid:6) (cid:5)
andsends (cid:3)
(cid:0)(cid:8) (cid:7)
(cid:2)(cid:4) (cid:3)
(cid:0)(cid:6) (cid:5)(cid:9) (cid:5)
toR.
(cid:1) R verifies that what it receives from S is of the
form (cid:3)
(cid:0)(cid:8) (cid:7)
(cid:2)(cid:4) (cid:3)
(cid:0)(cid:6) (cid:5)(cid:9) (cid:5)
. If so, R accepts
(cid:0)
. If not, R
bounces
(cid:0)
, possibly indicating in the bounce mes-
sagewhereScanobtainsoftwareforcomputing (cid:2)(cid:4) (cid:3)
(cid:5)
The function
.
(cid:2)(cid:4) (cid:3)
(cid:5)
is chosen so that the verification by R
is fast, taking a millisecond, say, and so that the compu-
tation byS is fairlyslow, taking atleast severalseconds.
Therefore,Scouldbe(somewhat)discouragedfromsend-
ing
(cid:0)
. Foraspammerthatwishestosendmanymillions
of messages, the cost of computing (cid:2)(cid:4) (cid:3)
(cid:5)
repeatedly can
becomeprohibitive.
Such schemes, with refinements and extensions, have
a variety of interesting applications. For example, mod-
erately expensive computations also play a role in an-
otherschemeforcurbingspam,secureclassification[10].
Beyondcombatingspam,requiringmoderatelyexpensive
computationscanhelpinprotectingagainstotherabuses.
For example, Web indexes could require a computation
eachtimeausertriestoaddaURLtotheindex,thereby
limiting additions; a server could require a computation
eachtimea clienttriestoestablisha connection, thereby
counteringconnection-depletionattacks[13]. Apaperby
Jakobsson and Juels discusses several other applications
and develops a formalization of the concept of proof of
work[12].
Insomecases,itispreferablethatSapplyamoderately
hardfunctiontoachallengeprovidedbyR(ratherthanto
aparticularmessageorrequest):
(cid:1) ScontactsR,requestingpermissiontousesomeser-
vice.
(cid:1) Rreturnsafreshchallenge (cid:10) toS.
(cid:1) Scomputes (cid:2)(cid:4) (cid:3)(cid:11) (cid:10) (cid:5) andreturnsittoR.
(cid:1) R verifiesthat what it receivesis a correct response
to (cid:10) . Ifso,RallowsStousetheservice.
ThisvariantenablesStocompute (cid:2)(cid:4) (cid:3)(cid:12) (cid:10)
(cid:5)
wellbeforeactu-
allyusingtheserviceinquestion.
Inpreviousworkinthisarea,theemphasisisonCPU-
intensive computations. In particular, Dwork and Naor
suggest CPU-intensive candidates for the function (cid:2)(cid:4) (cid:3)
(cid:5)
such as breaking the Fiat-Shamir signature scheme with
alowsecurityparameter. Back’sHashCashschemerelies
on the brute-force search for partial collisions in a hash
function.Thestartingpointforthepresentpaperisasimple,new memories may grow as fast as caches over the next few
observation about a problematic feature of such moder- years.
atelyhardcomputations. FastCPUsrunmuchfasterthan The next section, section 2, further describes our ap-
slowCPUs—considera2.5GHzPCversusa33MHzPalm proach; it explores a particular class of memory-bound
PDA. Moreover, in addition to high clock rates, higher- computations related to inverting functions. Section 3
end computer systems also have sophisticated pipelines develops this approach into a complete method. Sec-
and other advantageous features. If a computation takes tions 4 and 5 present some refinements and variants of
a few seconds on a new PC, it may take a minute on an themethod. Section6theninvestigatesspecificinstances
old PC, and several minutes on a PDA. That seems un- ofthemethod. Section7givesexperimentalresults. Sec-
fortunateforusersofoldPCs,andprobablyunacceptable tion8concludes,mentioningsomeotherrelatedworkand
for users of PDAs. While it is conceivable that service someopenquestions.
providers may (for a fee) perform computations on be- In our presentation, we emphasize the application of
halfofusersoflow-endmachines,sucharrangementsare memory-bound functions to discouraging spam. How-
notideal. Thesearrangementswouldconflictwithfreee- ever, memory-bound functions are immediately appli-
mail, and may be unstable: service providerscould save cable in protecting against other abuses (for example,
moneyandtroublebymakingcontractstopasse-mailbe- against abusive additions of URLs to Web indexes and
tween themselves without actually performing the com- againstconnection-depletionattacks). Inparticular,afu-
putations. Somoderatelyhardcomputationsmaybemost ture release of Microsoft’s Passport system may use our
appropriatewhenperformedbyclients. Therefore,webe- functions as one of the mechanisms for controlling ac-
lievethatthedisparityinclientCPUspeedconstitutesone count creation. Memory-bound functions are also appli-
ofthesignificantobstaclestowidespreadadoptionofany cableforstrengtheningpasswords. Weexplainthisappli-
schemebasedonaCPU-boundmoderatelyhardfunction. cation,whichislessstraightforward,insection5.
Inthispaper,weareconcernedwithfindingmoderately
hard functions that most computer systems will evaluate 2.Memory-boundcomputations: initialideas
at about the same speed. We envisionthat high-end sys-
Our approach is to force the senderS to access an un-
temsmightevaluatethesefunctionssomewhatfasterthan
predictable sequence of locations in a large array. The
low-endsystems,perhapseven2–10timesfaster(butnot
sizeof thisarrayis chosento besignificantlylargerthan
10–100 faster, as CPU disparities might imply). More-
thelargestcacheavailable;atpresent,thesizeofthearray
over,thebestachievableprice-performanceshouldnotbe
couldbe16MB,say.
significantlybetterthanthatofatypicallegitimateclient.
One possibility is to prescribe a computation on some
Webelievethattheseratiosareegalitarianenoughforthe
largedatastructure,forexamplealargegraph,thatwould
intended applications: the functions should be effective
force the desired memory accesses. Unfortunately, with
in discouraging abuses and should not introduce a pro-
this strategy, the definition of the function may itself be-
hibitive delay on legitimate interactions, across a wide
come rather large and hard to communicate, and check-
rangeofsystems.
ingS’sanswermaybecostly. Nevertheless,thisstrategy
Our approach is to rely on memory-bound functions.
mightbeviable.
The ratios of memory latencies of machines built in the
An alternative, which we adopt, is to prescribe a com-
lastfiveyearsistypicallynogreaterthantwo,andalmost
putation that could be done with very little memory but
always less than four. (Memory throughput tends to be
which is immensely helped by memory accesses. More
lessuniform, sowe focusonlatency.) Amemory-bound
specifically,let functionshouldaccesslocationsinalargeregionofmem-
ory in an unpredictable way, in such a way that caches
areineffective. Thisstrategycanworkonlyifthelargest
caches are significantly smaller than the smallest memo-
ries across the machines of interest. Unfortunately, one
cannowbuymachineswith8MBcaches,andsomePDAs
haveonly8MBofmemoryorless,soperhapsthereislit-
tle or no room to manœuvre. On the other hand, at the
time of this writing, machines with 8MB caches are still
expensiverarities,whilePDAswith64MBofmemoryare
fairlycommon.Soweproceedbyrestrictingourattention
tomachineswithatleast32MBofavailablememory. In
light of technology commonalities, we expect that PDA
(cid:4) (cid:0) (cid:3)
(cid:5)
beafunctionwhosedomainandrange
areintegersin (cid:1)(cid:3) (cid:3) (cid:2)(cid:4)(cid:2)(cid:6) (cid:5)(cid:8) (cid:7)(cid:10) (cid:9)(cid:12) (cid:11)
(cid:5)
,where (cid:5)(cid:8) (cid:7) isthenumberofen-
triesinthearray.Supposethat (cid:4)
(cid:0)
(cid:3)
(cid:5)
’sinverse
(cid:0)(cid:14) (cid:13)(cid:16) (cid:15)
(cid:3)
(cid:5)
cannot
beevaluatedinlesstimethanamemoryaccess. Ifweask
Stocompute (cid:0) (cid:13)(cid:16) (cid:15) (cid:3)
(cid:5)
manytimes, thenitbecomesworth-
while for S to build a table for
(cid:0) (cid:13)(cid:16) (cid:15)
(cid:3)
(cid:5)
and to rely on the
tablethereafter.
The table can be computed by
(cid:5)(cid:17) (cid:7)
applications of (cid:4)
(cid:0)
(cid:3)
(cid:5)
.
Buildingthetablealsorequiresmemoryaccesses,forstor-
ingthetableentries.However,thesememoryaccessescan
benefitfrombatching,andtheircost(likethatofapplying
(cid:4)
(cid:0)
(cid:3)
(cid:5)
) is not necessarily uniform across machines. There-
fore,thecostofbuildingthetableshouldnotbedominant
in S’s work in responding to R’s challenge. Rather, thedominant cost should be that of performing many table
lookups.
Inordertodeveloptheseinitialideas,wefirstdescribe
a naive embodiment and list some of its problems (sec-
tion2.1). Thenwemakeaninterestingbutimperfectim-
provement(section2.2). Wedesignandstudyacomplete
methodlaterinthispaper.
2.1.Anaiveembodiment
A naive embodiment of our ideas consists in letting
R challenge S with (cid:0) values (cid:10)(cid:2) (cid:1) , ..., (cid:10)(cid:4) (cid:3)
(cid:13) (cid:15)
, and requir-
ing S to respond with their immediate pre-images, that
is, with values (cid:5)(cid:6) (cid:1) , ..., (cid:5)(cid:7) (cid:3) (cid:13)(cid:16) (cid:15) such that (cid:4) (cid:0) (cid:3)(cid:8) (cid:5)(cid:6) (cid:1) (cid:5)(cid:10) (cid:9) (cid:10)(cid:11) (cid:1) , ..., (cid:4) (cid:0) (cid:3)(cid:8) (cid:5) (cid:3) (cid:13)(cid:16) (cid:15) (cid:5)(cid:12) (cid:9) (cid:10) (cid:3) (cid:13)(cid:16) (cid:15) . Thisnaiveschemeisflawed,inatleastfourrespects:
1. The size of the challenge is (cid:13)(cid:15) (cid:14)(cid:16) (cid:0) . While (cid:13) will
not be very large, because
(cid:5) (cid:7)
will be smaller than
thememorysize, (cid:0) willneedtobequitelargesoas
todetermineasufficientlydifficultproblem. There-
sultingsizeofthechallengecouldbeontheorderof
megabytes. Therefore, the challenge would be hard
totransmittoS.
2. Ifthevalues (cid:10) (cid:1) ,..., (cid:10) (cid:3)
(cid:13)(cid:16) (cid:15)
areallpresentedatonce,a
brute-forcesearchcanattempttofindpre-imagesfor
allofthematonce,bycomputing
(cid:0)
(cid:3) (cid:5) forward.This
searchwillrequireatmost
(cid:5)(cid:17) (cid:7)
computationsof (cid:4)
(cid:0)
(cid:3) (cid:5) —
a largenumber,but probablynotlargeenough. If (cid:0)
issmallenough, (cid:10)(cid:2) (cid:1) , ..., (cid:10)(cid:4) (cid:3)
(cid:13) (cid:15)
willbecachedrather
thanstoredinmemory,sothisbrute-forcesearchwill
beCPU-boundanditwillbefasterthantheexpected
memory-boundcomputation.If (cid:0) islarge,so (cid:10) (cid:1) ,...,
(cid:10) (cid:3)
(cid:13)(cid:16) (cid:15)
are stored in memory, the brute-force search
will require memory accesses, but these can be or-
ganized in such a way that their cost is not uniform
acrossmachines.
On the other hand, if R presents (cid:10)(cid:17) (cid:1) , ..., (cid:10)(cid:4) (cid:3)
(cid:13)(cid:16) (cid:15)
se-
quentially,waitingforS’sresponseto (cid:10)(cid:4) (cid:18) beforegiv-
ing (cid:10)(cid:17) (cid:18)(cid:20)(cid:19) (cid:15) ,thenaiveapproachrequiresaprohibitively largenumber( (cid:0)
of
)ofroundsofcommunication.
3. If R must present the challenge to S, then S is un-
abletoprepareamessagetobesenttoRwithoutfirst
contacting R. While this interaction may be accept-
able in some circumstances, we would like to have
the option of avoiding it. One technique for avoid-
ingit, whichwe exploitin asystem currentlyunder development,consistsinlettingatrustedthirdparty
present the challenge to S; but, in some settings, a
suitabletrustedthirdpartymaynotbeeasytofind.
4. The ratio of the work done at S and R is the ratio intimebetweenamemoryaccessandacomputation
(cid:4)
(cid:0)
(cid:3)
(cid:5)
. This ratio is unlikely to be more than 10,
andcannotbemorethan100orsowithpresentma-
chines. (Herewe ignorethecost ofbuildinga table
atS,sinceitshouldbedominatedbythecostofthe
laterlookupsinthetable,asindicatedabove.)
2.2.Animprovement: chains
Chaining the applications of (cid:4)
(cid:0)
(cid:3)
(cid:5)
helps in addressing
shortcomings 1 and 2 of the naive scheme. (We return
to shortcomings 3 and 4 in later sections.) The chaining
maygoasfollows:
(cid:1) Rpicksavalue (cid:10)(cid:2) (cid:1) . (cid:1) Rcomputes (cid:10)(cid:4) (cid:3) byletting,forall (cid:21)(cid:23) (cid:22) (cid:1) (cid:3)(cid:24)(cid:2)(cid:2) (cid:0) (cid:9)(cid:12) (cid:11) (cid:5) ,
(cid:1)
(cid:10)(cid:2) (cid:18)(cid:20)(cid:19)
(cid:15)
(cid:9)
(cid:4) (cid:0) (cid:3)(cid:12) (cid:10)(cid:17) (cid:18)
(cid:5)
Rgives (cid:10) (cid:3) toSandchallengesStofind (cid:10) (cid:1) .
The hope is that, as long as
(cid:5)(cid:17) (cid:7)
and
(cid:0)
are large enough,
thefastestapproachforSwouldbetoperform
(cid:0)
accesses
into a table to evaluate
(cid:0) (cid:13) (cid:15)
(cid:3)
(cid:5)
as many times. S should
perform these accesses in sequence, not because of in-
teraction with R but because each access dependson the
previous one. The function (cid:4)
(cid:0)
(cid:3)
(cid:5)
should be such that the
sequenceofaccesseshaspoorlocalityandishardtopre-
dict,soSshouldnotbenefitfromcaches. Finally,thesize
of the challenge (cid:10) (cid:3) ( (cid:13) bits) is smaller than in the naive
scheme.
This straightforwarduse of chains is however unsatis-
factory. In particular,if thesequence ofvaluesproduced
by successive invocationsof (cid:4) (cid:0) (cid:3)
(cid:5)
containscycles smaller
than (cid:5) (cid:7) ,thenSmightbeabletousethosecyclesasshort-
cuts. On the other hand, if (cid:4)
(cid:0)
(cid:3)
(cid:5)
is a permutation with a
single cycle of length (cid:5)(cid:17) (cid:7) , then S may find (cid:10) (cid:1) from (cid:10) (cid:3)
withatmost (cid:0)(cid:26) (cid:25) (cid:5) (cid:7) (cid:19) (cid:15) forwardcomputationsof (cid:4) (cid:0) (cid:3)
(cid:5)
and
hardlyusingmemory:
(cid:10) :=anarbitraryvalue;
(cid:5) := (cid:0) (cid:3) (cid:3)(cid:28) (cid:27)
(cid:5)
; while (cid:5)(cid:30) (cid:9) (cid:29) (cid:10) (cid:3) do( (cid:10) , (cid:5) ):=( (cid:4) (cid:0) (cid:3)(cid:12) (cid:10) (cid:5) , (cid:4) (cid:0) (cid:3)(cid:28) (cid:5) (cid:5) );
return (cid:10)
InordertodefeatthisCPU-basedsolutionandtoeliminate
cycles, we change the recurrence to depend on the step
number by introducing a permutation. In what follows,
weuse:
(cid:10) (cid:18)(cid:20)(cid:19) (cid:15) (cid:9) (cid:4) (cid:0) (cid:3)(cid:11) (cid:10) (cid:18) (cid:5) xor (cid:21)
Evenafterthiscorrection,thedesignofaschemebased
onchainsrequiresfurtherelaboration. Inparticular,when
thefunction (cid:4)
(cid:0)
(cid:3)
(cid:5)
isnotapermutation,theremaybemany
valid responses to the challenge (cid:10) (cid:3) : there may be many (cid:10)(cid:17) (cid:31)(cid:1) such that the recurrence (cid:10)(cid:4) (cid:31)(cid:18)(cid:20)(cid:19)
(cid:15)
(cid:9) (cid:4) (cid:0) (cid:3)(cid:12) (cid:10)(cid:17) (cid:31)(cid:18) (cid:5) xor (cid:21) yields(cid:10)(cid:2) (cid:31)(cid:3) (cid:9) (cid:10) (cid:3) . We should specify which of these (cid:10)(cid:4) (cid:31)(cid:1) are ac-
ceptableresponses.
This difficulty can be addressed by generalizing from
chains to trees, as we do next. The generalization also
allows us to avoid the other shortcomings of the naive
schemeofsection2.1.
3. Acompletemethod: trees
Buildingontheideasoftheprevioussection,wedesign
andstudyamethodthatreliesontrees.
3.1.Themethod
In trying to address the shortcomings of chains, we
workwithfunctionsthatarenotpermutations,soweneed
to specify which are the acceptable responses to a chal-
lenge (cid:10) (cid:3) . Atleasttwoapproachesareviable:
(cid:1) One approach is to accept not only (cid:10) (cid:1) but all (cid:10) (cid:31)(cid:1) suchthattherecurrence (cid:10)(cid:4) (cid:31)(cid:18)(cid:20)(cid:19) (cid:15) (cid:9) (cid:4) (cid:0) (cid:3)(cid:11) (cid:10)(cid:2) (cid:31)(cid:18) (cid:5) xor (cid:21) yields (cid:10)(cid:17) (cid:31)(cid:3) (cid:9) (cid:10) (cid:3) . It is still usefultoconstruct (cid:10) (cid:3) from (cid:10) (cid:1) ,
ratherthancompletelyatrandom,inordertoensure thatatleastoneacceptableresponseexists. Thisap-
proach obviously adds to the cost of verifying a re-
sponse.
(cid:1) Anotherapproach,whichweprefer,istoacceptonly
(cid:10)(cid:2) (cid:1) , forcing S to explore a tree of pre-images rather
thanachainofpre-images. Thetreehasroot (cid:10) (cid:3) and
depth
(cid:0)
. Thenodesofthetreeare(immediateorit-
erated)pre-imagesof (cid:10) (cid:3) . Oneoftheleavesatdepth
(cid:0) is (cid:10) (cid:1) .
This presentsa furtherproblem, namely thatSdoes
notknowwhichofthemanypossibleleavesatdepth
(cid:0)
isR’schosenone.Scouldperhapssendallofthese
leavestoR,butthiswouldaddconsiderablecommu-
nication cost. (The number of these leaves can be
fairlylarge.)
AsolutionisforRtoprovideSwithacheapcheck-
sumofthepathfrom (cid:10)(cid:4) (cid:3) to (cid:10)(cid:11) (cid:1) .Thischecksumshould
besuchthatScantellwhenithasfound (cid:10)(cid:17) (cid:1) , yetthe
checksum should not allow S to prune the space of
possibilitiesinadvanceofasearch.
Insummary,theresultingmethodisasfollows:
(cid:1) Let (cid:0) and (cid:13) betwointegers,andlet (cid:4) (cid:0) (cid:3) (cid:5) beafunction
whosedomainandrangeareintegersin
(cid:1)(cid:3)
(cid:3)
(cid:2)(cid:4)(cid:2) (cid:5)(cid:17) (cid:7) (cid:9) (cid:11)
(cid:5)
.
Wesupposethat (cid:4)
(cid:0)
(cid:3)
(cid:5)
’sinverse
(cid:0) (cid:13)(cid:16) (cid:15)
(cid:3)
(cid:5)
cannotbeeval-
uatedinlesstimethanamemoryaccess.Weassume
that (cid:0) , (cid:13) , and (cid:4) (cid:0) (cid:3)
(cid:5)
are knownto both R and S, pos-
siblybecauseRhaschosenthemandcommunicated
themtoS.
(cid:1) R picks an integer (cid:10) (cid:1) in (cid:1)(cid:3) (cid:3) (cid:2)(cid:4)(cid:2)(cid:6) (cid:5) (cid:7) (cid:9) (cid:11) (cid:5) and computes,
for (cid:21) (cid:22) (cid:1)(cid:3) (cid:3)(cid:24)(cid:2)(cid:4)(cid:2) (cid:0) (cid:9) (cid:11)
(cid:5)
:
(cid:10)(cid:17) (cid:18)(cid:19)
(cid:15)
(cid:9) (cid:4) (cid:0) (cid:3)(cid:12) (cid:10)(cid:17) (cid:18) (cid:5) xor (cid:21)
andachecksumofthesequence (cid:10)(cid:17) (cid:1) ,..., (cid:10)(cid:4) (cid:3) . Rsends
(cid:10)(cid:17) (cid:3) andthischecksumtoS.
(cid:1) Withthisinformation,Sshouldfind (cid:10) (cid:1) andreturnit
toR.
(cid:1) WhenRreceivesaresponsefromS,itsimplychecks
thatitis (cid:10) (cid:1) .
WeexpectStoproceedasfollowsinordertofind (cid:10)(cid:4) (cid:1) :
(cid:1) Construct a table for
(cid:0) (cid:13) (cid:15)
(cid:3) (cid:5) by applying (cid:4)
(cid:0)
(cid:3) (cid:5) to all
integersin
(cid:1)(cid:3)
(cid:3)
(cid:2)(cid:4)(cid:2)(cid:6) (cid:5)(cid:8) (cid:7)(cid:10) (cid:9)(cid:12) (cid:11)
(cid:5)
.
(cid:1) Build sequences (cid:5) (cid:3) , ..., (cid:5) (cid:1) starting with (cid:5) (cid:3) (cid:9) (cid:10) (cid:3)
andsuchthat (cid:5) (cid:18) (cid:22) (cid:0) (cid:13) (cid:15) (cid:3)(cid:28) (cid:5)(cid:6) (cid:18)(cid:19)
(cid:15)
xor (cid:21) (cid:5)
(sothat (cid:5)(cid:6) (cid:18)(cid:20)(cid:19)
(cid:15)
(cid:9) (cid:4) (cid:0) (cid:3)(cid:8) (cid:5)(cid:6) (cid:18) (cid:5) xor (cid:21) ).
(cid:1) Given such a sequence, return
(cid:5) (cid:1)
if the checksum
matches.
Smaybuildthesequences
(cid:5) (cid:3)
,...,
(cid:5) (cid:1)
depth-first(hoping
tofindamatchearly,muchbeforebuildingallsequences);
orSmaybuildthembreadth-first(tryingtohidesomeof
the memory latency). In either case, S should perform
manyaccessestothetablefor
(cid:0) (cid:13) (cid:15)
(cid:3)
(cid:5)
.
Of course, S may instead adopt alternative, CPU-
intensive algorithms. However, when (cid:4) (cid:0) (cid:3)
(cid:5)
, (cid:13) , and (cid:0) are
chosenappropriately,webelievethatS’staskismemory-
bound. In other words, those CPU-intensive algorithms
willbeslowerthanamemory-boundsolution. Wedonot
unfortunatelyhaveaformalproofofthisconjecture. Be-
low, we give calculationsthat support this conjecturefo-
cusingonparticularCPU-intensivealgorithms.
3.2.Treesandwork
The ratio of the work done at S and R is greatly im-
proved when we force S to explore a tree as explained
above. Thus,theuseoftreesalsoaddressesproblem4of
section2.1.Inthissectionweanalyzethatworkratio.We
also calculatethe expectedperformanceofSusingalter-
native, CPU-intensive algorithms. We obtain some con-
straintson
(cid:13)
,
(cid:0)
,andotherparameters.
Aquadraticfactor
In orderto characterize thework ratio, itis helpfulto be
more specific on the basic function (cid:4)
(cid:0)
(cid:3)
(cid:5)
. An interestingpossibility, which we discuss further in section 6.1, is to
let (cid:4)
(cid:0)
(cid:3)
(cid:5)
bearandomfunction. (Here,andintherestofthis
paper,wesaythat (cid:4)
(cid:0)
(cid:3)
(cid:5)
isarandomfunctionifandonlyif
(cid:4)
(cid:0)
(cid:3)(cid:12) (cid:10)
(cid:5)
isuniformlydistributedover
(cid:1)(cid:3)
(cid:3)
(cid:2)(cid:4)(cid:2)(cid:6) (cid:5)(cid:8) (cid:7) (cid:9) (cid:11)
(cid:5)
,foreach (cid:10) ,
andindependentofall (cid:4) (cid:0) (cid:3)(cid:8) (cid:5) (cid:5) for (cid:5) (cid:9) (cid:29) (cid:10) .)
When (cid:4) (cid:0) (cid:3)
(cid:5)
is random and (cid:0) (cid:0) (cid:5)(cid:8) (cid:7) , the size of the tree
exploredbySisquadraticin
(cid:0)
,soSisforcedtoperform
farmorework thanRevenif ittakesaslongtocompute
(cid:4)
(cid:0)
(cid:3)
(cid:5)
as
(cid:0) (cid:13) (cid:15)
(cid:3)
(cid:5)
. Basically, the size of the tree is approx-
imately
(cid:0)
(cid:1)(cid:3) (cid:2)
(cid:5)
, and S needs to explore half of the tree on
average (with depth-first search), so S needs to evaluate
(cid:0) (cid:13)(cid:16) (cid:15) (cid:3) (cid:5) roughly (cid:0) (cid:1)(cid:4) (cid:2)(cid:3) (cid:5) timesonaverage. Incontrast,Rap-
plies (cid:4) (cid:0) (cid:3)
(cid:5)
only (cid:0) times.
More precisely, we have made the following observa-
tion. Supposethatthefunction (cid:4)
(cid:0)
(cid:3)
(cid:5)
on
(cid:1)
(cid:3)
(cid:2)(cid:2) (cid:5)(cid:17) (cid:7) (cid:9)(cid:12) (cid:11)
(cid:5)
isran-
domand (cid:0) (cid:0) (cid:5)(cid:8) (cid:7) . Let (cid:10)(cid:11) (cid:1) bearandomvalueandlet (cid:10)(cid:4) (cid:3) be
definedbytherecurrence:
(cid:10) (cid:18)(cid:20)(cid:19) (cid:15) (cid:9) (cid:4) (cid:0) (cid:3)(cid:12) (cid:10) (cid:18) (cid:5) xor (cid:21)
Constructatreewithroot (cid:10)(cid:4) (cid:3) andinwhich,if (cid:5) isatdepth
(cid:6) (cid:0) (cid:0) fromtheroot,then (cid:27) isachildof (cid:5) ifandonlyif
(cid:5) (cid:9) (cid:4) (cid:0) (cid:3)(cid:24) (cid:27) (cid:5) xor (cid:3) (cid:0) (cid:9) (cid:6) (cid:9) (cid:11) (cid:5)
The expected number of leaves of this tree at depth
(cid:0)
is
approximately
(cid:0) (cid:25) (cid:11)
. Theexpectedsizeofthistreeisap-
proximately (cid:3) (cid:0) (cid:25) (cid:11) (cid:5) (cid:3)(cid:24) (cid:0) (cid:25) (cid:5) (cid:5) (cid:2) (cid:5) .Thesenumbersrequirethat the tree in question be constructed from some (cid:10) (cid:1) , rather
thangrownfromarandom (cid:10) (cid:3) : theexpectedsizeofatree
grownfromarandom (cid:10)(cid:4) (cid:3) isconsiderablysmaller.
We have noticed the quadratic size of trees in experi-
ments, letting (cid:4)
(cid:0)
(cid:3)
(cid:5)
be various practical (not exactly ran-
dom) functions. Section 7 discusses these experiments
further. A posteriori, we have sketched a proof of the
quadratic size, there assuming an independent random
function at each tree level. A more sophisticated analy-
sis might be possible using tools from research on ran-
dom functions, a rich field with many theorems (see for
instance[9]).
In light of the quadratic size of trees, it is tempting to use very deep trees, so as to increase the work ratio be-
tweenSandR.Thereare,however,importantlimitations
on tree depth. At each level in a tree, S may try to in-
vertalltheleavessimultaneously,somehow. Whenthere
are enough leaves, S may benefit from cache behaviour.
Specifically, when several leaves land in the same cache
line,thecostofinvertingallofthemisessentiallythecost
ofjustonememoryaccess. These issuesare particularly
clear when
(cid:0)
nears the size of the space,
(cid:5)(cid:17) (cid:7)
. We must
thereforekeep
(cid:0)
muchsmallerthan
(cid:5) (cid:7)
(say,below
(cid:5) (cid:7) (cid:8)(cid:13) (cid:7)
algorithms—atS.Weobtainsomeconstraintson
).
Somecalculations
Next we derive a few simple formulas that (roughly)
characterize the work at R and—using several different
(cid:13)
,
(cid:0)
,and
otherparameters.Weindicatesomeprecisevaluesforpa-
rametersinsection6.2.
For simplicity, we assume that R has chosen (cid:4)
(cid:0)
(cid:3)
(cid:5)
and
communicatedittoS;section6.1saysmoreonthechoice
of (cid:4) (cid:0) (cid:3)
(cid:5)
. We also rely on the quadratic ratio established
above. We assume that
(cid:0)
is “small enough” (in partic-
ular, so that this ratio applies). Finally, we assume that
checksumming is essentially free (partly because we do
not require a strong cryptographic checksum). We write
(cid:9) forthecostofoneapplicationof (cid:4)
(cid:0)
(cid:3)
(cid:5)
,
(cid:10)
forthecostof
onememoryread(withacachemiss),and (cid:11) forthecost
ofonememorywrite.
(cid:1) R’scostinmakingachallengewillessentiallybethat
of (cid:0) applicationsof (cid:4) (cid:0) (cid:3)
(cid:5)
,thatis, (cid:0) (cid:14) (cid:9) .
(cid:1) S’scostforbuildingatablefor
(cid:0) (cid:13)(cid:16) (cid:15)
(cid:3) (cid:5) willbethatof:
–
(cid:5)(cid:8) (cid:7)
applicationsof (cid:4)
(cid:0)
(cid:3) (cid:5) ;
–
(cid:5)(cid:8) (cid:7)
insertionsintothetable.
Naively,thiscostappearstobe (cid:5)(cid:17) (cid:7) (cid:14) (cid:3) (cid:9) (cid:25)(cid:12) (cid:11) (cid:5) . How-
ever,forsomefunctions (cid:4)
(cid:0)
(cid:3)
(cid:5)
,thecostof
(cid:5) (cid:7)
applica-
tionsof (cid:4) (cid:0) (cid:3)
(cid:5)
maybesubstantiallysmallerthan (cid:5)(cid:17) (cid:7) (cid:14) (cid:9) .
Similarly,thecostofinserting (cid:5)(cid:8) (cid:7) entriesmaybesub- stantiallysmallerthan (cid:5)(cid:17) (cid:7) (cid:14)(cid:13) (cid:11) ,becausethenecessary writescanbebatchedandcompletedasynchronously
bythehardware.Ontheotherhand,ifthetablestruc-
tureissimilartothatofahashtable, thentheinser-
tionswillrequirereadsinordertoresolvecollisions.
Thesereadsmaymakethecostofbuildingthetable
closerto (cid:5)(cid:8) (cid:7) (cid:14) (cid:3) (cid:9) (cid:25)(cid:14) (cid:10)
(cid:5)
. Inthecalculationsbelow,we
assume that the cost is (cid:5)(cid:8) (cid:7) (cid:14) (cid:3) (cid:9) (cid:25)(cid:15) (cid:11)
(cid:5)
and we often assumethat
(cid:11)
(cid:9)
(cid:10)
.
(cid:1) S’s cost for solving a challenge using a table for
(cid:0) (cid:13)(cid:16) (cid:15)
(cid:3) (cid:5) and depth-first search will be approximately
that of
(cid:0)
(cid:1)(cid:4) (cid:2)(cid:3) (cid:5) memory accesses without significant
helpfromcaches,thatis, (cid:3)(cid:24) (cid:0) (cid:1)(cid:3) (cid:2)(cid:16) (cid:5) (cid:5) (cid:14)(cid:17) (cid:10) .
(cid:1) IfSprefersnottouseatablefor
(cid:0) (cid:13) (cid:15)
(cid:3) (cid:5) ,itmaystill
followthesamesearchstrategybypretendingthatit
hasatableandbyinverting (cid:4)
(cid:0)
(cid:3)
(cid:5)
onthefly(bybrute
force) whenever necessary. Provided that an inver-
sionof (cid:4)
(cid:0)
(cid:3)
(cid:5)
requires
(cid:5)(cid:8) (cid:7)
applicationsof (cid:4)
(cid:0)
(cid:3)
(cid:5)
,thecost
ofthisCPU-intensiveapproachwillbe
(cid:0)
(cid:1)
(cid:14) (cid:5) (cid:7) (cid:14)
(cid:9) .
With a little more trouble, a CPU-intensive search
may be done only once for each level in the tree of
pre-images,withtotalcost
(cid:0) (cid:14) (cid:5)(cid:17) (cid:7) (cid:14)
(cid:9) .
(cid:1) If S prefers not to use a table for
(cid:0)(cid:14) (cid:13)(cid:16) (cid:15)
(cid:3) (cid:5) , S may
also guess (cid:10) (cid:1) and check its guess by applying (cid:4) (cid:0) (cid:3)
(cid:5)
.
For each guess, it has to apply (cid:4) (cid:0) (cid:3)
(cid:5)
(cid:0) times, so the
expected cost of this CPU-intensive approach willbe that of (cid:5)(cid:8) (cid:7) (cid:13)(cid:16) (cid:15) (cid:14) (cid:0) applications of (cid:4) (cid:0) (cid:3)
(cid:5)
, that is,
(cid:0) (cid:14) (cid:5) (cid:7) (cid:13) (cid:15) (cid:14)
(cid:9) .
(cid:1) Alongsimilarlines,Smayapply (cid:4) (cid:0) (cid:3) (cid:5) only (cid:0) (cid:0) times toeachofthevaluesin
(cid:1)
(cid:3)
(cid:2)(cid:2) (cid:5)(cid:17) (cid:7) (cid:9) (cid:11)
(cid:5) ;becauseofcolli-
sions, roughly
(cid:5) (cid:7)
(cid:19)
(cid:15)
(cid:2)
(cid:0) (cid:0)
distinct values will remain
afterthis,andSmaythenapply (cid:4) (cid:0) (cid:3)
(cid:5)
tothem (cid:3)(cid:24) (cid:0) (cid:9) (cid:0) (cid:0)
(cid:5)
times (terminating half way through these applica-
tions, on average). The expected cost of this more
sophisticated(butrealistic) CPU-intensiveapproach willbe (cid:3) (cid:0) (cid:0) (cid:14) (cid:5)(cid:8) (cid:7) (cid:25) (cid:5)(cid:8) (cid:7) (cid:19) (cid:15) (cid:2) (cid:0) (cid:0) (cid:14) (cid:3)(cid:24) (cid:0) (cid:9) (cid:0) (cid:0) (cid:5) (cid:2) (cid:5) (cid:5) (cid:14) (cid:9) , thatis, (cid:3) (cid:6) (cid:26)(cid:5) (cid:14)(cid:1) (cid:0) (cid:0)(cid:10) (cid:9)(cid:12) (cid:11) (cid:5) (cid:14) (cid:5) (cid:7) (cid:14) (cid:9) .
(cid:1) S may be able to find other optimizations of the
brute-force,CPU-intensivesearchfor (cid:10) (cid:1) . Inparticu- lar,inordertominimizeapplicationsof (cid:4)
(cid:0)
(cid:3) (cid:5) , Smay
try to notice collisions after each round of applica- tionsof (cid:4) (cid:0) (cid:3) (cid:5) (ratherthanonlyonceafter (cid:0) (cid:0) rounds). Thus, S would apply (cid:4)
(cid:0)
(cid:3) (cid:5) to each of the
(cid:5)(cid:17) (cid:7)
values
justonce, thenapply (cid:4) (cid:0) (cid:3) (cid:5) only oncetoeachoftheir images,andsoon.Smaythusrequire (cid:2) (cid:3)(cid:24) (cid:0) (cid:5) (cid:14) (cid:5)(cid:17) (cid:7) ap- plicationsof (cid:4) (cid:0) (cid:3) (cid:5) ,where (cid:2) (cid:3) (cid:0) (cid:5) isanaffinefunctionof
the logarithm of (cid:0) . Conceivably, this and other op- timizations can lead to a cost of (cid:10)(cid:2) (cid:14) (cid:5)(cid:17) (cid:7) (cid:14) (cid:9) , where
(cid:2)
is a small integer (say, below 10). Note however
thatthisisacoarseboundonambitious,speculative
ideas, not a measurement of an actual efficient im- plementation: we do not knowhowto realize these
ideaswithoutsubstantialoverhead.
Wearriveatthefollowingconstraints:
1. Asindicatedinsection2,thecostofbuildingtheta-
ble for (cid:0) (cid:13) (cid:15) (cid:3) (cid:5) should not be dominant in the table-
basedsolution.SupposethatSamortizesatableover
(cid:3) problems.Thenweshouldhave
(cid:3) (cid:14) (cid:3)(cid:24) (cid:0) (cid:1) (cid:2)(cid:16) (cid:5) (cid:5) (cid:14)(cid:17) (cid:5)(cid:10) (cid:4) (cid:5) (cid:7) (cid:14) (cid:3) (cid:9) (cid:25) (cid:11) (cid:5)
thatis,
(cid:0)(cid:6) (cid:4) (cid:8)(cid:5) (cid:10)(cid:7)(cid:7) (cid:9) (cid:12)(cid:1) (cid:11) (cid:19) (cid:15) (cid:14)(cid:14) (cid:13) (cid:11) (cid:2) (cid:3) (cid:14)(cid:15) (cid:13) (cid:3) (cid:9) (cid:25)(cid:12) (cid:11) (cid:5) (cid:2) (cid:10)
Thislowerboundcanbereducedwhen,assuggested above, the cost of (cid:5)(cid:17) (cid:7) applications of (cid:4) (cid:0) (cid:3) (cid:5) and (cid:5)(cid:17) (cid:7) storesissmallerthan (cid:5)(cid:8) (cid:7) (cid:14) (cid:3) (cid:9) (cid:25)(cid:12) (cid:11) (cid:5) .
2. We would like the table-based solution to be faster
than the CPU-intensive solutions. With the sim-
pler CPU-intensive solutions, this condition means
roughlythat
(cid:0)(cid:17) (cid:16) (cid:5) (cid:7) (cid:19) (cid:15) (cid:14) (cid:3) (cid:9) (cid:2) (cid:10) (cid:5)
With the moresophisticatedCPU-intensivesolution
describedabove,however,weshouldhavethat
(cid:0)(cid:17) (cid:16) (cid:3) (cid:5) (cid:7) (cid:19)(cid:19) (cid:18) (cid:14) (cid:3) (cid:9) (cid:2) (cid:10) (cid:5)(cid:9) (cid:5) (cid:1) (cid:9) (cid:18)
Finally,fearingthatonecouldeventuallyimplement
a CPU-intensive solution with cost
(cid:2) (cid:14) (cid:5)(cid:17) (cid:7) (cid:14)
(cid:9) , we
wouldwant
(cid:0)(cid:17) (cid:16) (cid:5) (cid:10)(cid:7)(cid:7) (cid:9)
(cid:20)(cid:1) (cid:11) (cid:19)
(cid:15) (cid:14)(cid:15) (cid:13)
(cid:9) (cid:2)
(cid:10) (cid:14) (cid:0) (cid:2)
(Here we simply ignore the cost of building a table
for
(cid:0) (cid:13)(cid:16) (cid:15)
(cid:3) (cid:5) ,sinceitwillbedominatedbyothercosts.)
3. We would also like that setting a challenge is much
cheaper thansolving it. Inother words, (cid:3) (cid:0) (cid:1)(cid:4) (cid:2)(cid:3) (cid:5) (cid:5) (cid:14) (cid:10) should be much larger than (cid:0) (cid:14) (cid:9) , so (cid:0) should be muchlargerthan (cid:5) (cid:14) (cid:3) (cid:9) (cid:2) (cid:10) (cid:5) . Thisconstraintiseasily
satisfiedwhen (cid:0) islarge.
4. Anotherconstraintfollowsfromourrequirementthat
(cid:0) (cid:13)(cid:16) (cid:15)
(cid:3) (cid:5) cannotbeevaluatedinlesstimethanamem-
ory access. Obviously, (cid:0) (cid:13)(cid:16) (cid:15) (cid:3) (cid:5) can be evaluated with (cid:5)(cid:8) (cid:7) applications of (cid:4) (cid:0) (cid:3) (cid:5) , so we must have that (cid:9)
(cid:4) (cid:10)
(cid:2)
(cid:5) (cid:7)
, but
(cid:10)
(cid:2)
(cid:5)(cid:8) (cid:7)
will be tiny. A more sophisti-
cated construction permits evaluating (cid:0) (cid:13) (cid:15) (cid:3) (cid:5) with a muchsmallernumberofapplicationsof (cid:4) (cid:0) (cid:3) (cid:5) ,asfol- lows[11,8].
For (cid:6) (cid:9) (cid:11)(cid:8) (cid:21)(cid:2)(cid:4)(cid:2) ,Swouldprecompute (cid:22) pairs (cid:3)(cid:12) (cid:10) (cid:7) (cid:20) (cid:23)(cid:25) (cid:24) (cid:26) (cid:3)(cid:11) (cid:10) (cid:5)(cid:9) (cid:5) where (cid:23) (cid:26) (cid:3)(cid:12) (cid:10) (cid:5) (cid:9)(cid:28) (cid:27) (cid:26) (cid:3) (cid:4)
(cid:0)
(cid:3)(cid:11) (cid:10) (cid:5) (cid:5) and each (cid:27) (cid:26) (cid:3) (cid:5) is an aux-
iliary function. The integers
(cid:22)
and
(cid:21)
should be
such that
(cid:21)
(cid:1)
(cid:14)(cid:14) (cid:22)
is around
(cid:5)(cid:8) (cid:7)
and such that
(cid:23)(cid:21) (cid:14)(cid:14) (cid:22) pairs (cid:3)(cid:12) (cid:10) (cid:7) (cid:20) (cid:23)(cid:29) (cid:24) (cid:26) (cid:3)(cid:12) (cid:10) (cid:5)(cid:9) (cid:5) canbecached. Therefore, (cid:21) willbe
at least 2; we can force it to be larger (at least 3,
perhaps 6) by increasing the size ratio between the
smallestmemoryandthelargestcacheunderconsid-
eration. In order to find one immediate pre-image
of (cid:5) , S would apply each function (cid:23) (cid:26) (cid:3)
(cid:5)
to (cid:5) up to (cid:21) times,hopingtohitsomeprecomputed (cid:23)(cid:25) (cid:24) (cid:26) (cid:3)(cid:11) (cid:10) (cid:5) ,thenS
would reachan immediate pre-imageof
(cid:5)
bywork-
ingforwardfromtheassociated (cid:10) . Thisprocesscan
be repeated to find all immediate pre-images of (cid:5) , withsomeprobability[16]. Makingtheconservative
assumptionthattheapplicationsofthefunctions (cid:27) (cid:9)(cid:18) (cid:3)
(cid:5)
are free and that there is no other overhead, S may evaluate (cid:0) (cid:13)(cid:16) (cid:15) (cid:3) (cid:5) intime (cid:21) (cid:1) (cid:14) (cid:9) .IfShasahugecache,
then (cid:21) could conceivably be 2, so S could evaluate (cid:0) (cid:13)(cid:16) (cid:15) (cid:3) (cid:5) intime (cid:5) (cid:14) (cid:9) . Onthe otherhand, naively,S maykeephalfofatablefor (cid:0) (cid:13) (cid:15) (cid:3) (cid:5) inacacheofthe same size, and thus S may evaluate
(cid:0) (cid:13)(cid:16) (cid:15)
(cid:3) (cid:5) in time
(cid:10)
(cid:2)
(cid:5)
onaverage.Undertheseassumptions,weshould
requirethat (cid:5)
(cid:14)
(cid:9)
(cid:4) (cid:10)
(cid:2)
(cid:5)
,thatis, (cid:9)
(cid:4) (cid:10)
(cid:31)(cid:2) (cid:30) .
Although these assumptions may appear fairly ex-
treme, we believe that it is safer to keep (cid:9)
(cid:4) (cid:10)
(cid:2) (cid:30) ,
and we may have to raise this bound in the future. Fortunately, this bound is not particularly problem-
atic,aswedemonstratebelow.
5. On the other hand, (cid:9) cannot be very large (or else
someoftheCPU-intensivesolutionscanbespedup).If applying (cid:4)
(cid:0)
(cid:3)
(cid:5)
naively is slower than a memory
read,thenSmaybuildatablefor (cid:4)
(cid:0)
(cid:3)
(cid:5)
. Manyofthe
accessestothetablemightbeorganizedinbiglinear
scansandmightthereforeberelativelycheap. More-
over, part of the table might be cached, even across
problemsthatusethesameorrelated (cid:4) (cid:0) (cid:3)
(cid:5)
’s,thusfur-
ther reducing the effective cost of calculating (cid:4)
(cid:0)
(cid:3)
(cid:5)
.
Therefore,weconsider (cid:9)
(cid:16) (cid:10)
.
In the lower bound on
(cid:0)
(constraint 1), the value of (cid:9)
shouldcorrespondtoaslowmachine;intheupperbound
(constraint 2) and in the other constraints, to a fast ma-
chine. (We assume, pessimistically, that attackers have
fastmachines;wecanalsoassumethatthechallengesare
set at fast servers.) In order to avoid ambiguities, let us
callthevaluesof (cid:9) onslowandfastmachines (cid:9)
(cid:1)
and (cid:9)
(cid:15)
,
respectively.
Thereexistsasatisfactoryvalueof
(cid:0)
providedthat:
(cid:5) (cid:10)(cid:7)(cid:7) (cid:9) (cid:12)(cid:1) (cid:11) (cid:19) (cid:15) (cid:14) (cid:0) (cid:11) (cid:3) (cid:14) (cid:0) (cid:3) (cid:9) (cid:1) (cid:25) (cid:10) (cid:11) (cid:5) (cid:16) (cid:5) (cid:7)(cid:7) (cid:9) (cid:20)(cid:1) (cid:11) (cid:19) (cid:15) (cid:14) (cid:0) (cid:9) (cid:15) (cid:10) (cid:14) (cid:0) (cid:2)
Inotherwords,weshouldhave:
(cid:3) (cid:11) (cid:2) (cid:3) (cid:5) (cid:14) (cid:3) (cid:3) (cid:9) (cid:1) (cid:25)(cid:12) (cid:11) (cid:5) (cid:2) (cid:10) (cid:5) (cid:16) (cid:3) (cid:9)
(cid:15)
(cid:2) (cid:10) (cid:5) (cid:14) (cid:2)
thatis,
(cid:3) (cid:4) (cid:3) (cid:9) (cid:1) (cid:25) (cid:11)
(cid:5)
(cid:2) (cid:3) (cid:9)
(cid:15)
(cid:14) (cid:2)
(cid:5)
Forinstance,when
(cid:2)
(cid:9) (cid:5) ,
(cid:11)
(cid:9) (cid:9)
(cid:15)
,and (cid:9)
(cid:1)
(cid:9)
(cid:11) (cid:1)(cid:8) (cid:26)(cid:1) (cid:14)
(cid:9)
(cid:15)
,
werequireroughly (cid:3) (cid:4) (cid:5)(cid:2) (cid:1) .Withthesevalues, (cid:10) (cid:9) (cid:11) ,and
(cid:13)
(cid:9)
(cid:5)(cid:17) (cid:5)
(forarealisticmemorysize),wemaylet
(cid:0)
be
(cid:5) (cid:15)
(cid:18) .
Thecorrespondingcostisthatof
(cid:5)
(cid:1)(cid:4) (cid:3) memoryaccessesfor
eachof (cid:3) problems. Section6.2saysmoreonthesetting
ofparametersandtheirconsequences.
Theconstraints
(cid:10)
(cid:31)(cid:2) (cid:30)
(cid:16)
(cid:9)
(cid:15)
(cid:16) (cid:10)
areeasytosatisfy. Inparticular,asCPUspeedsincrease,
we can modify or replace (cid:4)
(cid:0)
(cid:3)
(cid:5)
in order to slow it down
and to preserve
(cid:10)
(cid:2) (cid:30)
(cid:16)
(cid:9)
(cid:15)
. If slow machines are never
upgraded,thischangewillresultinalarger (cid:9)
(cid:1)
,soitmay
affect both the setting and the solving of challenges on
thosemachines,thoughintolerableways:
(cid:1) Because of the quadratic factor in the work ratio,
setting challenges will remain efficient even on a
fairlyslowmachine. Moreover,itseemsreasonable
to assume, as we do above, that setting challenges
willnormallybedoneatfastmachinessuchasmail
servers.
(cid:1) Themodifiedfunction (cid:4)
(cid:0)
(cid:3) (cid:5)
of a table for
maycomputetheimages
of a variable number of inputs at the same time, as
wedescribeinsection6.1. Inthiscase,thebuilding
(cid:0) (cid:13) (cid:15)
(cid:3)
(cid:5)
need not be penalized by the
modification: it can be as fast as with the original,
fasterfunction.
Even without this technique, we can easily accom-
modatelargedisparitiesbetweenthespeedsatwhich
clients may build the table. The example settings
in which (cid:9)
(cid:1)
(cid:9)
(cid:11) (cid:1)(cid:17) (cid:1) (cid:14)
(cid:9)
(cid:15)
show that we can support
clients that are much slower than those accepted by
mostusersandcurrentapplications.
4. Refinements
Severalrefinementsofourtree-basedmethodareattrac-
tive. We describe five in this section. The first three are
clearlyimportant;theremainingtwoaremorespeculative.
Forgettingthechallenge
Relyingonastandardtechnique,wecansaveRfromre- membering (cid:10) (cid:1) after it sends it to S. Specifically, R can produce a keyed hash
(cid:5)
(cid:3)
(cid:7) (cid:6)
(cid:7) (cid:10) (cid:1) (cid:5) of (cid:10) (cid:1) , using a crypto-
graphicallystrongkeyedhashfunction
(cid:5)
[15]andakey
(cid:6) knownonly to R, and give (cid:5) (cid:3) (cid:7) (cid:6)
(cid:7)
(cid:10) (cid:1)
(cid:5)
to S along with thechallenge. Sshouldreturnboth (cid:10)(cid:17) (cid:1) and (cid:5) (cid:3) (cid:7) (cid:6) (cid:7) (cid:10)(cid:11) (cid:1) (cid:5) , so R can check that S’s response is correct by recomputing
(cid:5) (cid:3) (cid:7) (cid:6)
(cid:7)
(cid:10)(cid:11) (cid:1)
(cid:5)
from (cid:6) and (cid:10)(cid:2) (cid:1) .
Varyingthefunction (cid:4)
(cid:0)
(cid:3)
(cid:5)
We expect that the function (cid:4) (cid:0) (cid:3) (cid:5) will vary from time
to time, and even from challenge to challenge. It may
be freshly generated for each challenge, at random from
somefamily.
The variation may simply consist in xoring a different
quantityforeachchallenge.Thus,givenamasterfunction
(cid:8)(cid:10) (cid:9) (cid:3)
(cid:5)
andaninteger (cid:6) (cid:22) (cid:1)(cid:3) (cid:3) (cid:2)(cid:4)(cid:2)(cid:6) (cid:5)(cid:8) (cid:7) (cid:9) (cid:11)
(cid:5)
,Rmaydefineanew
function (cid:4)
(cid:0)
(cid:3)
(cid:5)
simplyby:
(cid:4)
(cid:0)
(cid:3)(cid:12) (cid:10) (cid:5) (cid:9)(cid:11) (cid:8)(cid:12) (cid:9) (cid:3)(cid:11) (cid:10) (cid:5) xor (cid:6)
Theinteger (cid:6) maybeachallengeindex(acounter)ormay
begeneratedatrandom.Ineithercase,ifRandSknowthe
masterfunction (cid:8)(cid:10) (cid:9) (cid:3)
(cid:5)
inadvance,thenRneedstotrans-
mitonly (cid:6) toSinordertoconvey (cid:4)
(cid:0)
(cid:3)
(cid:5)
. Moreover,aslong
as (cid:8)(cid:10) (cid:9) (cid:3)
(cid:5)
remains fixed, S may use a table for (cid:8)(cid:12) (cid:9)
(cid:13) (cid:15)
(cid:3)
(cid:5)
instead of a table for each derived function
(cid:0) (cid:13) (cid:15)
(cid:3)
(cid:5)
, thus
amortizingthecostofbuildingthetablefor (cid:8)(cid:12) (cid:9)
(cid:13) (cid:15)
(cid:3)
(cid:5)
. The
masterfunctionitselfshouldchangefromtimetotime—
wemaynottrustanyonefunctionforlong.
Of course, there are manyother ways of defining suit-
ablefamiliesoffunctions.WereturntothismatterinSec-
tion6.1.
Using multiple functions requires conventions for de-
scribingthem,forexamplesothatRcantellSaboutanewfunction. If (cid:4)
(cid:0)
(cid:3)
(cid:5)
isderivedfromamasterfunctionandan
integerparameter(asin (cid:4)
(cid:0)
(cid:3)(cid:11) (cid:10) (cid:5) (cid:9) (cid:8)(cid:10) (cid:9) (cid:3)(cid:12) (cid:10) (cid:5) xor (cid:6) ),thenthe
description of (cid:4)
(cid:0)
(cid:3)
(cid:5)
might be a description of the master
functionplustheparameter.Thedescriptionofthemaster
functionmightsimplybeashortname,ifitiswellknown,
oritmightbecodeoratableforthefunction. Theinteger parameter can be omitted when it is clear from context,
forinstancewhenitisacounter.
Usingseveralproblemsasachallenge
R may ask S to solve several problems of the sort de-
scribed above, so that S has more work to do, without
increasingtheexpecteddifficultyofeachproblem. Inad-
ditiontorequiringmorework,theuseofseveralproblems
also givessomevaluableprotectionagainstvariabilityin
problemhardness.
WemaybeconcernedthatScouldamortizesomework
acrossseveralproblemsandsolvethemallinparallelwith
a CPU-intensiveapproach. Indeed, someflawedvariants
ofour method allowsuchdangerous amortizations. Two
twiststhwartsuchamortization:
(cid:1) Asdescribedabove,thefunction (cid:4)
(cid:0)
(cid:3) (cid:5) mayvaryfrom
problemtoproblem.Alltheproblemsinagroupmay
shareamasterfunction. Forinstance,withfunctions
oftheform (cid:4)
(cid:0)
(cid:3)(cid:12) (cid:10) (cid:5) (cid:9) (cid:8)(cid:10) (cid:9) (cid:3)(cid:12) (cid:10) (cid:5) xor (cid:6) , theproblemsin
a group may all share (cid:8)(cid:12) (cid:9) (cid:3)
(cid:5)
but each may have a
different (cid:6) .
(cid:1) Each problem’s challenge and function description
(exceptthefirst)maybepresentedencryptedundera
key derivedfrom the path to the solution of the im-
mediatelyprecedingproblem.
Omittingbitsfromproblems
One can often make problems harder by omitting some
bits from them. In particular, R could omit some bits of
thechallenge (cid:10)(cid:4) (cid:3) ,ofthedescriptionofthefunction (cid:4) (cid:0) (cid:3)
(cid:5)
,or
both,andSwouldneedtoguessorreconstructthemissing
bits in finding (cid:10)(cid:2) (cid:1) . For instance, R could present the full (cid:10)(cid:17) (cid:3) andachecksumofthepathfrom (cid:10) (cid:3) to (cid:10)(cid:2) (cid:1) ,andRcould
tellSthat (cid:4)
(cid:0)
(cid:3)
(cid:5)
hasadefinitionoftheform
(cid:4)
(cid:0)
(cid:3)(cid:12) (cid:10) (cid:5)(cid:23) (cid:9) (cid:8)(cid:10) (cid:9) (cid:3)(cid:12) (cid:10) (cid:5) xor (cid:6)
where S knows (cid:8)(cid:12) (cid:9) (cid:3) (cid:5) but not the integer (cid:6) ; then S may needtotrymanypossiblevaluesof (cid:6) inordertofind (cid:10)(cid:17) (cid:1) .
Omitting bits slows down S’s memory-bound search.
On the other hand, omitting bits does not always slow
down CPU-intensive alternatives. For example, CPU-
intensiveforwardsearchesarenotaffectedwhenRomits
bitsfrom (cid:10) (cid:3) butnot (cid:4) (cid:0) (cid:3)
(cid:5)
Mixingfunctions
Anotherwaytomakeproblemsharderistointerleaveap-
plicationsofmultiplefunctions
. Therefore,suchvariantsshould
beusedwithcaution.
(cid:0) (cid:1) (cid:3)
(cid:5)
,..., (cid:0) (cid:1) (cid:3)
(cid:5)
. WhenR
constructsthechallenge (cid:10) (cid:3) from (cid:10) (cid:1) , ateachstep, itmay
applyanyofthosefunctions. Thus,forall (cid:21)(cid:23) (cid:22) (cid:1) (cid:3)(cid:24)(cid:2)(cid:2) (cid:0) (cid:9)(cid:12) (cid:11)
(cid:5)
, we have (cid:10)(cid:17) (cid:18)(cid:20)(cid:19)
(cid:15)
(cid:9) (cid:0) (cid:26) (cid:3)(cid:11) (cid:10)(cid:2) (cid:18) (cid:5) xor (cid:21) for some (cid:6) (cid:22) (cid:1)(cid:3) (cid:22)(cid:2)(cid:4)(cid:2) . S
knows (cid:0) (cid:1) (cid:3)
(cid:5)
, ..., (cid:0) (cid:1) (cid:3)
(cid:5)
, but notin whichsequence R ap-
pliesthem,ornotentirely. Forinstance,Smayknowthat
R always applies (cid:0) (cid:1) (cid:3)
(cid:5)
except that every 10 steps R ap-
plies either (cid:0) (cid:1) (cid:3)
(cid:5)
or (cid:0)
(cid:15)
(cid:3)
(cid:5)
. Therefore, S basically has to
guess (part of) the sequence of function choices when it
triestofind (cid:10) (cid:1) .
Thistechniqueseemsviable. Ithelpsinthwartingcer-
tain CPU-intensive attacks and it may yield an improve-
mentinworkratios,atthecostofsomecomplexity.
5. Variants
Thetree-basedmethodcanalsobeadaptedtoscenarios
in which interaction between S and R is somehow con-
strained. Nextwedescribetwovariantsofthetree-based
methodthataddresssuchconstraints.
5.1.Anon-interactivevariant
Wereturntoproblem3ofsection2.1,thatis,weshow
howto avoid requiring R to interact with S before S can
senditsmessage
(cid:0)
.
IfR(oratrustedthirdparty)cannotpresentachallenge
toS,thenthechallengecanbedefinedbythemessage
(cid:0)
,
asfollows.
(cid:1) S is required to apply a checksum to (cid:0) (or certain
partsof
(cid:0)
).
(cid:1) Using the result as the seed to a cryptographic ran-
dom number generator, S then generates a function
(cid:4) (cid:0) (cid:3)
(cid:5)
andastartposition (cid:10)(cid:2) (cid:1) foritstreesearch.
(IfRoratrustedthirdpartycanprovideasmall,par-
tialchallengetoS,thenSshoulduseitinthechoice
of (cid:4) (cid:0) (cid:3)
(cid:5)
and (cid:10)(cid:2) (cid:1) .)
(cid:1) S computes (cid:10)(cid:4) (cid:3) by evaluating (cid:4) (cid:0) (cid:3) (cid:5) (cid:0) times, with the recurrence:
(cid:10) (cid:18)(cid:19)
(cid:15)
(cid:9) (cid:4) (cid:0) (cid:3)(cid:12) (cid:10) (cid:18) (cid:5) xor
(cid:1)
(cid:21)
S must supply a value (cid:10)(cid:17) (cid:31)(cid:1) other than (cid:10)(cid:2) (cid:1) such that (cid:10)(cid:2) (cid:31)(cid:18)(cid:20)(cid:19)
(cid:15)
(cid:9) (cid:4) (cid:0) (cid:3)(cid:12) (cid:10)(cid:2) (cid:31)(cid:18) (cid:5) xor (cid:21) yields (cid:10)(cid:17) (cid:31)(cid:3) (cid:9) (cid:10)(cid:4) (cid:3) ,andthatsome
otherpropertyholds.
An example of such a property might be that the
checksum of the path from (cid:10) (cid:3) to (cid:10) (cid:31)(cid:1) be 0 mod (cid:5) (cid:1)
forsome
(cid:22)
. When
(cid:5)
(cid:1) issmallerthan
(cid:0)
,itislikely
thatsuchan (cid:10)(cid:17) (cid:31)(cid:1) exists.Whennosuch (cid:10)(cid:17) (cid:31)(cid:1) exists,Scan
pickanew (cid:10) (cid:1) and (cid:4)
(cid:0)
(cid:3)
(cid:5)
andtryagain.IfRverifiesthatthe (cid:10)(cid:17) (cid:31)(cid:1) presentedbyShastheprop-
erty, and that S did not discard too many functions,
thenRcanbereasonablycertainthatShadtosearch
asubstantialfractionofthetreerootedat (cid:10) (cid:3) .
We maychoose apropertythat isquitehardtosatisfy,
so as to increase the work that S has to do in finding a
suitable (cid:10)(cid:17) (cid:31)(cid:1) . DespiteS’sadditionaleffort,itsresponsecan
remainsmall.
Alternatively,shouldSneedtodomoreworkthanthat
representedbysolvingasingleproblem,Smaysolvesev-
eral problems. The problems may all be independently
derivedfrom
(cid:0)
(each with its own function (cid:4) (cid:0) (cid:3)
(cid:5)
and its own (cid:10) (cid:1) and (cid:10)(cid:17) (cid:31)(cid:1) ),ortheycanbelinkedtogether(sothean- swer (cid:10) (cid:31)(cid:1) for one problem may be used in computing the
function (cid:4) (cid:0) (cid:3)
(cid:5)
and the start position (cid:10) (cid:1) for the next prob- lem). Ineithercase,Sshouldsupplyallthevalues (cid:10) (cid:31)(cid:1) .
5.2.Strengtheningpasswords
Interestingly, some of the same ideas can be used for
strengtheningpasswords. Inthisapplication,SandRin-
teractbeforeSdoesitswork,butSneednotrespondtoR.
In outline, a method for strengthening passwords goes
asfollows[14,1]. Supposethattwoparties,SandR,ini-
tiallyshareapassword (cid:0) (possiblyaweakpassword). In
ordertosupplement (cid:0) ,Rpicksan
(cid:13)
-bitpasswordexten-
sion
(cid:1)
, where
(cid:13)
isanintegerparameter. ThenRposesa
problemwithsolution
(cid:1)
toS.Theproblemshouldbesuch
thatScansolveit, withmoderateeffort, byusing (cid:0) , but
suchthat
(cid:1)
ishardtofindwithout (cid:0) . Afterwards,Sand
Rsharenotonly (cid:0) butalso
(cid:1)
. Inparticular,Smayuse (cid:0)
and
(cid:1)
without further interaction with R, for instance in
ordertodecryptfilesthatRhaspreviouslyencrypted.For
password extensions longer than (cid:13) bits, each (cid:13) -bit frag-
ment may be communicated separately, with (cid:0) as base
password,orsequentially,with (cid:0) andpreviousfragments
asbasepassword;thelatterchoicelimitsparallelattacks,
soitseemspreferable.
The previous instances of this method require a CPU-
intensivecomputationfromS.Unfortunately,thiscompu-
tation may need to be long in order for (cid:0) and
(cid:1)
to be
secureagainstattackerswithfasterCPUs.
Nextwedescribeanalternativeinstanceofthemethod
in which S performs a memory-bound computation in-
stead.
(cid:1) Rderivesa function (cid:4)
(cid:0)
(cid:3) (cid:5) fromthepassword (cid:0) (and
possiblyasaltandsomeother,publicdata),chooses
an (cid:13) -bitpasswordextension (cid:1) ,andlets (cid:10) (cid:1) be (cid:1) .
(cid:1) R computes (cid:10) (cid:3) by evaluating (cid:4) (cid:0) (cid:3) (cid:5) (cid:0) times, with the recurrence:
(cid:10) (cid:18)(cid:20)(cid:19)
(cid:15)
(cid:9) (cid:4) (cid:0) (cid:3)(cid:12) (cid:10) (cid:18) (cid:5) xor (cid:21)
Ralsofindssome (cid:10)(cid:17) (cid:31)(cid:1) otherthan (cid:10) (cid:1) thatalsomapsto
(cid:10) (cid:3) inthisway.
(cid:1) RthengivestoSachecksumofthepathfrom (cid:10) (cid:3) to
(cid:10) (cid:1) (butneither (cid:10) (cid:1) nor (cid:10) (cid:3) ),and (cid:10) (cid:31)(cid:1) .
(cid:1) Using (cid:0) , S derives (cid:4)
(cid:0)
(cid:3) (cid:5) , builds a table for
(cid:0) (cid:13) (cid:15)
(cid:3) (cid:5) ,
uses (cid:10)(cid:17) (cid:31)(cid:1) and (cid:4) (cid:0) (cid:3)
(cid:5)
tocompute (cid:10)(cid:4) (cid:3) ,thenuses (cid:10)(cid:4) (cid:3) andthe
tabletofind (cid:10)(cid:2) (cid:1) ,thatis, (cid:1) .
An attackerthattriesto find
(cid:1)
byguessingpossibleval-
ues of (cid:0) will have to do a memory-bound computation
foreachsuchvalue. Had (cid:4)
(cid:0)
(cid:3)
(cid:5)
beenindependentof (cid:0) ,this
propertywouldofcoursenothold. HadRtransmitted (cid:10) (cid:3) rather than (cid:10)(cid:17) (cid:31)(cid:1) , thispropertywould probablynothold ei- ther: an attacker with a wrong guess of (cid:0) would use a
wrong (cid:4) (cid:0) (cid:3) (cid:5) in constructing a tree of pre-images for (cid:10) (cid:3) , andwouldprobablygetstuckratherquickly. Thatiswhy
Rshouldprovide (cid:10)(cid:4) (cid:31)(cid:1) . Althoughfinding (cid:10)(cid:17) (cid:31)(cid:1) isanon-trivial
burden, R mayexploreonlya fractionof thetree ofpre-
images of (cid:10)(cid:4) (cid:3) for this purpose. Alternatively, R may be
able toguess (cid:10)(cid:17) (cid:31)(cid:1) andverifythatitmapsto (cid:10) (cid:3) ; if thetree
that contains (cid:10)(cid:2) (cid:1) has (cid:21) leavesatdepth (cid:0) , then R willsuc-
ceedafterapproximately
(cid:5)(cid:17) (cid:7)
(cid:2)
(cid:21)
guesses.
An attackerthat guesses (cid:0) incorrectlymay detect that
thisguessisincorrect,withsomeprobability,whenitfails
to find a path with the expected checksum. This possi-
bilitymaybeundesirable,althoughtheattackermayhave
other, cheaper ways of detecting that its guess is incor-
rect.Soitisattractivetouseonlyweakchecksums,sothat
pathswiththeexpectedchecksumswillalwaysbefound,
ortodropchecksumsentirelyasinthefollowingalterna-
tiveprotocol:
(cid:1) SandRderiveafunction (cid:4)
(cid:0)
(cid:3) (cid:5) fromthepassword (cid:0)
(andpossiblyasaltandsomeother,publicdata),and
bothbuildatablefor
(cid:0) (cid:13)(cid:16) (cid:15)
(cid:3)
(cid:5)
.
(cid:1) S and R choose random values (cid:10)
(cid:3) (cid:2)
and (cid:10)
(cid:5) (cid:4)
, respec-
tively,exchangethem,andlet (cid:10) (cid:1) (cid:9) (cid:3)(cid:11) (cid:10)
(cid:6) (cid:2)
xor (cid:10)
(cid:6) (cid:4)
(cid:5) .
(cid:1) SandRcompute (cid:10) (cid:3) byevaluating (cid:4) (cid:0) (cid:3) (cid:5) (cid:0) times,again
withtherecurrence:
(cid:10) (cid:18)(cid:19)
(cid:15)
(cid:9) (cid:4) (cid:0) (cid:3)(cid:12) (cid:10) (cid:18) (cid:5) xor (cid:21)
Theythenfindall (cid:10)(cid:17) (cid:31)(cid:1) thatmapto (cid:10) (cid:3) inthisway. The
password extension (cid:1) is a function of all these (cid:10) (cid:31)(cid:1) (forexample,ahashofallofthemexcept (cid:10) (cid:1) ).
Here,bothSandRperformthesame(expensive)stepsto
computeapasswordextension.Undoubtedly,otherproto-
colsofthisformareviable. As usual, the cost of building tables can be amortized
over multiple searches. The multiple searches might be
unrelated to oneanother; or theymightallbe part ofthesamesearchforan
(cid:13)
-bitpasswordextension(forinstance,
if some bits are omitted from problems); or each search
mightservetofindan
(cid:13)
-bitfragmentofalongerpassword
extension.
6. Instantiatingthemethod
In this section, we describe a concrete instantiation of
our method of section 3.1. We discuss the choice of a
basicfunction (cid:4)
(cid:0)
(cid:3)
(cid:5)
. Wealsodiscusssettingsforotherpa-
rameters,andtheirmotivationsandeffects.
6.1.Choosingthefunction (cid:4)
(cid:0)
(cid:3)
(cid:5)
Wewouldlikeafunction (cid:4) (cid:0) (cid:3) (cid:5) thatcanbeevaluatedef- ficiently,butwhichneverthelesscannotbeinvertedinless
time than a memory cache miss. These two constraints
arenottoohardtosatisfy;nextweexploresomeparticu-
larchoicesof (cid:4)
(cid:0)
(cid:3)
(cid:5)
andtheirfeatures.
Randomfunctions
Wewouldlike (cid:4)
(cid:0)
(cid:3)
(cid:5)
toapproximatearandomfunction,in
order to defeat caches and to obtain reasonable work ra- tios. An appealing possibility is to let (cid:4) (cid:0) (cid:3) (cid:5) be a random function. Inthiscase,weenvisionthat (cid:4)
(cid:0)
(cid:3) (cid:5) couldsimply
begivenbyatable(withoutmuchattentiontotherandom
processthatgeneratedthetable).
Theuseofa randomfunction (cid:4) (cid:0) (cid:3) (cid:5) givesriseto perfor- manceissues. Specifically,evaluatingarandomfunction
maynotalways be cheap enough. Ingeneral, eachcom-
putation of (cid:4) (cid:0) (cid:3) (cid:5) may require a memory access, just like eachcomputationof (cid:0) (cid:13)(cid:16) (cid:15) (cid:3) (cid:5) . Theratiobetweenthework doneatSandRwillstillbequadraticin
(cid:0)
,butwithoutthe
constantfactorthatrepresentsthedifferencebetweenthe
respective costs of evaluating (cid:4)
(cid:0)
(cid:3)
(cid:5)
and
(cid:0) (cid:13)(cid:16) (cid:15)
(cid:3)
(cid:5)
. Although
the tree search performed by S forces S to perform sub-
stantiallymoreworkthanR,wemaywanttoincreasethis
differencebyourchoiceofthefunction (cid:4)
(cid:0)
(cid:3) (cid:5) . Ontheother
hand, we may also increase this difference by raising
(cid:0)
:
theupperboundon (cid:0) insection3.2isgreaterwhen (cid:4) (cid:0) (cid:3) (cid:5) is slower.
The use of a random function (cid:4) (cid:0) (cid:3) (cid:5) also gives rise to a
storage problem. In general, R will need to have a table
for (cid:4) (cid:0) (cid:3)
(cid:5)
. Thisrequirementmaybeinconvenient.
Finally,theuseofarandomfunction (cid:4)
(cid:0)
(cid:3)
(cid:5)
givesrisetoa
communicationproblem. Ifthechoiceoffunctionshould
changefromtimetotime,thenitishelpfulforthefunction
tohaveasuccinctdescription,sothatitcanbecommuni-
catedefficiently. Truerandomfunctionsdonotingeneral
have such succinct descriptions. Therefore, we may not
generate andtransmit a brand new, random (cid:4)
(cid:0)
(cid:3)
(cid:5)
for each
challenge. Instead, we may derive a challenge-specific
function (cid:4) (cid:0) (cid:3)
(cid:5)
fromarandommasterfunction (cid:8)(cid:10) (cid:9) (cid:3)
(cid:5)
adefinitionlike
,with
(cid:4)
(cid:0)
(cid:3)(cid:12) (cid:10) (cid:5) (cid:9)(cid:11) (cid:8)(cid:12) (cid:9) (cid:3)(cid:11) (cid:10) (cid:5) xor (cid:6)
(as discussed in section 4). In this case, assuming that
(cid:8)(cid:10) (cid:9) (cid:3)
(cid:5)
isknowninadvance,only (cid:6) needstobetransmitted.
Approximations
Moregenerally,wemaydefine:
(cid:4)
(cid:0)
(cid:3)(cid:12) (cid:10)
(cid:5)(cid:23) (cid:9)
(cid:2)(cid:4) (cid:3)
(cid:1) (cid:0)
(cid:7)
(cid:10)
(cid:5)
where (cid:2)(cid:4) (cid:3)
(cid:5)
is a suitablemaster function(random, orran-
dom enough), and
(cid:0)
is a parameter. For such functions,
describing (cid:4) (cid:0) (cid:3) (cid:5) amounts to giving the corresponding (cid:0) if
(cid:2)(cid:4) (cid:3)
(cid:5)
isknowninadvance. Inaddition,evaluating (cid:2)(cid:4) (cid:3)
(cid:5)
and
therefore (cid:4)
(cid:0)
(cid:3) (cid:5) may well be cheap. These functions (cid:4)
(cid:0)
(cid:3) (cid:5)
may share many of the advantages of true random func-
tions. However,theycomplicateanalysis.
We have investigated several candidate functions (cid:4)
(cid:0)
(cid:3)
(cid:5)
of this form. Some are based on functions (cid:2)(cid:4) (cid:3)
(cid:5)
from the
cryptography literature: one-way hash functions such as
MD5 andSHA,or variantsof fastencryption algorithms
suchasTEA[15]. Forinstance,givenavalue (cid:10) ,wemay applySHAtoakeyandto (cid:10) ,thenextract (cid:4) (cid:0) (cid:3)(cid:12) (cid:10) (cid:5) fromthe result.
Sinceourintendedapplicationsdonotactuallyrequire
much cryptographic strength, we have also investigated
some faster functions (cid:4) (cid:0) (cid:3) (cid:5) of the same form. One is as follows:
(cid:1) Assumingthat (cid:13) iseven,let (cid:0) (cid:1) and (cid:0) (cid:15) be twotables of (cid:5)(cid:8) (cid:10)(cid:7) (cid:9) (cid:1) random32-bitnumbers. Together, (cid:0) (cid:1) and (cid:0) (cid:15) playtheroleof
(cid:0)
above.
(cid:1) Let the bitstring representing (cid:10) be formed from the
concatenation of the bitstrings (cid:2) (cid:1) and (cid:2) (cid:15) , each of length
(cid:13)
(cid:2)
(cid:5)
bits.
(cid:1) Thenlet (cid:4)
(cid:0)
(cid:3)(cid:12) (cid:10) (cid:5) bethemiddlebitsofthe64-bitproduct
of the two 32-bit numbers indexed by
(cid:2) (cid:1)
and
(cid:2) (cid:15)
in
tables (cid:0) (cid:1) and (cid:0) (cid:15) :
(cid:4) (cid:0) (cid:3)(cid:11) (cid:10) (cid:5) (cid:9) middle-bits (cid:3) (cid:3) (cid:0) (cid:1)(cid:5) (cid:4)(cid:2) (cid:1)(cid:7) (cid:6)(cid:9) (cid:8) (cid:0)
(cid:15)
(cid:4)(cid:2)
(cid:15)
(cid:5) (cid:6)
The tables (cid:0) (cid:1) and (cid:0)
(cid:15)
have only (cid:5)(cid:8) (cid:10)(cid:7) (cid:9) (cid:1) entries, so they will
fitinthecacheonmostmachines. Thus,theevaluationof
(cid:4)
(cid:0)
(cid:3)
(cid:5)
will take only a few cycles. In fact, this function is
sofastthatitconflictswiththecondition (cid:9)
(cid:4) (cid:10)
(cid:31)(cid:2) (cid:30) ofsec-
tion3.2;itiseasytodefineslowervariantsofthisfunction
thatsatisfythecondition.
In an early version of our work, the two tables
(cid:0) (cid:1)
and
(cid:0) (cid:15)
were identical. That saves space for R, but enables S
to use a smaller table for (cid:0) (cid:13) (cid:15) (cid:3) (cid:5) because
(cid:4) (cid:0) (cid:3) (cid:12) (cid:2)
(cid:15)
(cid:10) (cid:2) (cid:1)
(cid:5) (cid:4) (cid:0) (cid:3) (cid:1) (cid:2) (cid:1)(cid:11) (cid:10) (cid:2)
(cid:15)
(cid:5) (cid:9)
. (Here,wewrite (cid:2) (cid:1)(cid:13) (cid:10) (cid:2)
(cid:15)
fortheconcatenationof
(cid:2) (cid:1)
and
(cid:2)
(cid:15)
.) So letting
(cid:0) (cid:1)
and
(cid:0)
(cid:15)
be identicalis not at-
tractive. In that early version of our work, we also used
tablesof32-bitprimes,ratherthantablesofarbitrary32-
bitnumbers.Primesseemtoyieldasomewhatbetter (cid:4)
(cid:0)
(cid:3)
(cid:5)
,
but the tables are a little harder to compute. These and
othervariationsmaybeworthexploringfurther.
Assuming that we define (cid:4)
(cid:0)
(cid:3) (cid:5) by letting
(cid:2)(cid:4) (cid:3) (cid:3) (cid:0) (cid:7) (cid:10) (cid:5)
(cid:4)
(cid:0)
(cid:3)(cid:12) (cid:10) (cid:5) (cid:9)
for some function (cid:2)(cid:4) (cid:3) (cid:5) (either by letting (cid:2) (cid:15) (cid:5)(cid:12) (cid:9) (cid:4) (cid:0) (cid:3) (cid:1) (cid:2) (cid:1) (cid:10) middle-bits (cid:3) (cid:3) (cid:0) (cid:1) (cid:4)(cid:2) (cid:1) (cid:6) (cid:8) (cid:0) (cid:15) (cid:4)(cid:2) (cid:15) (cid:5) (cid:6) orinsomeotherway), we may still use a trivial definition such as
(cid:4) (cid:0) (cid:3)(cid:12) (cid:10)
(cid:5) (cid:0) (cid:31) (cid:3)(cid:11) (cid:10) (cid:5) (cid:9)
xor (cid:6) togenerateotherfunctions,orwemaygener-
ateotherfunctionsbyvarying
(cid:0)
.
The definition (cid:4)
(cid:0)
(cid:3)(cid:12) (cid:10) (cid:5)(cid:30) (cid:9) (cid:2)(cid:4) (cid:3)
(cid:3) (cid:0)
(cid:7) (cid:10) (cid:5) can be generalized in
usefulways. If (cid:2)(cid:4) (cid:3)
(cid:5)
yields (cid:13) (cid:14) (cid:5) (cid:1) bits,where (cid:2) isasmall
integer,wemayapply (cid:2)(cid:4) (cid:3)
(cid:5)
toaparameter (cid:0) andtothe (cid:13) (cid:9) (cid:2)
high-orderbitsof (cid:10) ,thenextract (cid:4) (cid:0) (cid:3)(cid:11) (cid:10)
(cid:5)
fromtheresult,as
wellas (cid:4) (cid:0) (cid:3)(cid:12) (cid:10)(cid:17)
(cid:5)
(cid:31) forevery (cid:10)(cid:17) (cid:31) thatdiffersfrom (cid:10) onlyinthe (cid:2)
low-orderbits. Interestingly,thisdefinitionmakesthecost
ofapplying (cid:4) (cid:0) (cid:3)
(cid:5)
toallvaluesin (cid:1) (cid:3) (cid:2)(cid:2) (cid:5)(cid:17) (cid:7)(cid:10) (cid:9) (cid:11)
(cid:5)
bethecostof
(cid:5) (cid:7)
single applications divided by
(cid:5)
(cid:1) ; this cost reduction
helpsinbuildingatablefor
(cid:0) (cid:13)(cid:16) (cid:15)
(cid:3)
(cid:5)
.
6.2.Settingparameters
Inordertoinstantiateourmethod,weneedtopickval-
uesforvariousparameters(
(cid:13)
,
(cid:0)
, (cid:9) , (cid:3) ,...). Thesechoices
areconstrainedbythe availabletechnology,andtheyare
informedby severalpreferencesandgoals. Nextwe dis-
cuss some settings for these parameters and their conse-
quences; many other similar settings are possible. All
these settings are viablewith current machines, and they
all lead to seconds or minutes of memory-bound work
forS,asintended.
Supposethatwewantthetablefor
(cid:0) (cid:13) (cid:15)
(cid:3)
(cid:5)
tofitin32MB
memories, butnotin 8MBcaches. Theseconstraintsde-
terminethepossiblevaluesof
(cid:13)
tobe22or23.Onemight
imaginethateachentryinthetablewilltakeonly3bytes,
but such a compact encoding may be impractical. It is
more realistic to allocate 4 or 6 bytes per entry to allow
forcollisions.With (cid:13) (cid:9) (cid:5)(cid:17) (cid:5) ,atablefor (cid:0) (cid:13) (cid:15) (cid:3) (cid:5) willoccupy
around 16MB (with 4 bytes per entry) or 24MB (more
comfortably, with 6 bytes per entry). With
(cid:13)
(cid:9)
(cid:5)(cid:4) (cid:3)
, a
table for
(cid:0) (cid:13)(cid:16) (cid:15)
(cid:3)
(cid:5)
will occupyaround 32MB (with 4 bytes
per entry) or 48MB (more comfortably,with 6 bytes per
entry), so
(cid:13)
(cid:9)
(cid:5)(cid:4) (cid:3)
may not be viable. In what follows,
we proceed with
(cid:13)
(cid:9)
(cid:5)(cid:8) (cid:5)
because that appears to be the
appropriate value for current machines. We recommend
increasing
(cid:13)
assoonascachesizesrequireit.
We have some choice in the cost (cid:9) of applying (cid:4)
(cid:0)
(cid:3)
(cid:5)
,
within the constraints of section 3.2. A largervalue will
result in more work for R if it sets problems or checks
solutionsbyapplying (cid:4) (cid:0) (cid:3) (cid:5)
memory-bound solution (through a larger
. Alargervalueshouldalsore- sultinmoreworkforSifitadoptsaCPU-intensivealgo-
rithm,soalargervalueleavesroomforamoreexpensive
(cid:0)
). However,
these effects cease when (cid:9) reaches the cost
(cid:10)
of a mem-
oryreadonafastmachine,becauseScouldreplacemany
applications of (cid:4)
(cid:0)
(cid:3)
(cid:5)
with lookups at that point. Thus S
will pay at most
(cid:10)
for applying (cid:4)
(cid:0)
(cid:3)
(cid:5)
on average, perhaps
muchlesswithcachingandotheroptimizations. Inwhat
follows,weconsiderthreepossiblevaluesfor (cid:9) onafast
machine: (cid:9) (cid:9) (cid:10) , (cid:9) (cid:9) (cid:10) (cid:2) (cid:5) ,and (cid:9) (cid:9) (cid:10) (cid:31)(cid:2) (cid:30) . Inlightofconstraints1and2ofsection3.2,weshould setthenumber (cid:0) ofiterationsaround (cid:5) (cid:15) (cid:1) . Wehavesome
freedomin thesettingof (cid:0) . Alarger (cid:0) willlead tomore
work per problem, for both parties S and R, but with a
better (larger) ratio between the work of S and the work
ofR.Conversely,a smaller (cid:0) willresult inlesswork per
problem, with a smaller work ratio. Therefore, we tend
to prefer larger values for (cid:0) . When (cid:0) is too large, CPU-
intensive solutions become competitive with the table-
based approach, andtheircost is notuniform across ma-
chines. When (cid:0) is too small, the cost ofbuilding a table
for
(cid:0) (cid:13) (cid:15)
(cid:3)
(cid:5)
becomesdominantinthetable-basedapproach,
andthiscost isnot necessarilyuniform acrossmachines.
Inwhatfollows,weproceedwith
(cid:0)
(cid:9)
(cid:5) (cid:15)
(cid:18) if (cid:9) (cid:9)
(cid:10)
,with
(cid:0)
(cid:9)
(cid:5) (cid:15)
(cid:1) if (cid:9) (cid:9)
(cid:10)
(cid:2)
(cid:5)
,andwith
(cid:0)
(cid:9)
(cid:5) (cid:15) (cid:15)
if (cid:9) (cid:9)
(cid:10)
(cid:2) (cid:30) .
Finally,wehavesomechoiceinthenumber (cid:3) ofprob-
lems over which a table for
(cid:0) (cid:13)(cid:16) (cid:15)
(cid:3)
(cid:5)
should be amortized.
Generally, a larger (cid:3) is better, primarily because it gives
us more freedom in setting other parameters. The num-
ber (cid:3) couldbehugeifweusedafixedfunction(orafixed
master function) forever. However, we believe that it is
prudenttouse adifferentfunctionforeachproblem, and
alsotochangemasterfunctionsatleastfromtimetotime.
Anobviouspossibilityistogroupproblemsandtoadopt
anewmasterfunctionforeachgroup(seesection4). We
can usually describe the master function concisely, by a
short name plus the seed to a random number generator
or a cryptographic key, in approximately 20 bytes. We
can usually describe each derived function in 0–2 bytes.
We can present each problem in 6 bytes (including the
required checksum), and each solution in 3 bytes. For (cid:3) (cid:9)
(cid:11) (cid:5)
(cid:30) , each group of problems occupies up to 1KB,
givingrisetoavisiblebutreasonablecommunicationcost.
The communication cost can be drastically reduced with
thenon-interactivevariantofsection5,ifwesowish. For
the sake of definiteness, we proceed with (cid:3) (cid:9)
(cid:3) (cid:5)
. Each
group of 32 problems occupies only 192 bytes without
functiondescriptions,andalittlemorewiththem.
Weexpectthatamachinecandoroughly
(cid:5)
(cid:1) (cid:18) readsper
second frommemory(withina smallfactor). Onthe ba-
sis of this data, we can calculate the cost of setting and
solvingproblems:
(cid:1) With (cid:9) (cid:9) (cid:10) and (cid:0) (cid:9) (cid:5) (cid:15) (cid:18) , we intend thatSperform
(cid:5)
(cid:1)(cid:4) (cid:3) reads per problem, so S should take 2 seconds
perproblem.(cid:22)(cid:17)
(cid:5)
(cid:11)
(cid:8)(cid:5) (cid:23)(cid:2) (cid:24)(cid:25)
(cid:4) (cid:3)(cid:2) (cid:0)(cid:1) (cid:5)
(cid:1) (cid:5)
(cid:2) (cid:0)(cid:5) (cid:1) (cid:5) (cid:0)
(cid:1) (cid:0)(cid:11)
(cid:5)
(cid:11)
(cid:8)
(cid:11)
(cid:24)(cid:27) (cid:26)(cid:29)
(cid:28)(
(cid:28)(cid:31)
(cid:8)(cid:5)
(cid:8)
(cid:30)
(cid:23)(cid:4)
(cid:8)(cid:5) (cid:20)! (cid:16)(cid:6)
’) (cid:26)* (cid:20)(cid:21) (cid:8)(cid:1)
(cid:8)
(cid:8)
(cid:5)
(cid:18)#
+,
"$(cid:8)(cid:1) (cid:23)& %(cid:2) (cid:8)(cid:1) ’
(cid:0) (cid:25) (cid:11)%- (cid:23)(cid:6) ".(cid:26)(cid:29) (cid:8)(cid:5) ’
(cid:8)
(cid:8) (cid:8)
(cid:5)
(cid:5) (cid:0) (cid:0)(cid:11)
(cid:7)(cid:9) (cid:8)(cid:11) (cid:10)(cid:13) (cid:12)(cid:15) (cid:14)(cid:17) (cid:16)(cid:6) (cid:18)(cid:19)
(cid:8)
(cid:12)(cid:21)
(cid:8)
(cid:20)(cid:15)
(cid:5)
(cid:8)(cid:11)
(cid:8)
(cid:6)(cid:1)
(cid:8)
(cid:0)
(cid:3)(cid:24)
(cid:8)
(cid:0)
(cid:11)(cid:5)
(cid:8)
(cid:1)(cid:17) (cid:5)
(cid:5)
(cid:8)
(cid:5)
(cid:8)
(cid:2) (cid:3)(cid:4)(cid:1) (cid:0)
(cid:8)
(cid:22)(cid:17) (cid:8)(cid:1) (cid:23)(cid:6) (cid:24)2
(cid:8)
(cid:25)(cid:11) (cid:1)(cid:8) (cid:25) 0(cid:11) (cid:1)(cid:8)
(cid:25) (cid:2)(cid:11) (cid:1)
(cid:11) (cid:1)(cid:8) (cid:1)(cid:17) (cid:1)(cid:8) (cid:1)(cid:17) (cid:11) (cid:1)(cid:17) (cid:1)(cid:8) (cid:1)(cid:17)
(cid:11) (cid:1)(cid:8) (cid:1)(cid:8)
(cid:11) (cid:1)(cid:8)
(cid:11)
(cid:24)(cid:27)
(cid:30)
/
(cid:0)
(cid:1) (cid:1)
(cid:1)
(cid:1)
(cid:1)
(cid:11)
(cid:26)(cid:29)
(cid:8)
(cid:11)
(cid:28)3
(cid:3)(cid:24) (cid:28)6
(cid:30)4
(cid:0)
(cid:8)
(cid:8)(cid:11) (cid:20)5
(cid:25) (cid:8)(cid:1) (cid:23)(cid:2) ’(cid:21)
(cid:8)
(cid:5)
(cid:16)(cid:2)
(cid:11)(cid:26)(cid:29)
(cid:18)# (cid:24)* (cid:16)(cid:27) +(cid:29) (cid:8)(cid:5) ’
(cid:5) (cid:5) (cid:3) (cid:0) (cid:25)(cid:12) (cid:5)(cid:20)(cid:15) (cid:8)(cid:5) +(cid:25) %& (cid:23)(cid:2) "$(cid:26)*
(cid:8)
(cid:8)
(cid:8)
(cid:1) (cid:0)(cid:11)
(cid:7)1 (cid:8)(cid:5) (cid:10)(cid:13) (cid:12)(cid:21) (cid:14)(cid:17)
(cid:2) (cid:5)(cid:8)(cid:5) ’
(cid:8)
(cid:5)
(cid:0)
(cid:16)(cid:2) (cid:18)(cid:19)
(cid:8)
(cid:12)(cid:15)
(cid:8)
(cid:5)(cid:2)
(cid:20)(cid:21) (cid:8)(cid:5)
(cid:8)
(cid:6)(cid:1)
(cid:8)
(cid:0)
(cid:3)
(cid:8)
(cid:0)
(cid:11)(cid:5)
(cid:8)
(cid:1)(cid:17) (cid:5)
(cid:5)
(cid:8)
(cid:5)
(cid:8)
(cid:4) (cid:3)(cid:2)(cid:1) (cid:0)
(cid:8)
Figure1.Meannumbersofleavesandnodesintreesofdepth
(cid:0)
.
Thesettingofaproblemwillrequire
(cid:5) (cid:15)
(cid:18) applications
of (cid:4)
(cid:0)
(cid:3) (cid:5) ,whichwilltakeonemillisecondonafastma-
chine.
(cid:1) With (cid:9) (cid:9)
(cid:10)
(cid:2)
(cid:5)
and
(cid:0)
(cid:9)
(cid:5) (cid:15)
(cid:1) ,weintendthatSperform
(cid:5)
(cid:1) (cid:1) reads per problem, so S should take .5 seconds
perproblem.
Thesettingofaproblemwillrequire (cid:5) (cid:15) (cid:1) applications of (cid:4)
(cid:0)
(cid:3) (cid:5) , which will take .25 milliseconds on a fast
machine.
(cid:1) With (cid:9) (cid:9) (cid:10) (cid:2) (cid:30) and (cid:0) (cid:9) (cid:5) (cid:15) (cid:15) ,weintendthatSperform
(cid:5)
(cid:1) (cid:1) readsperproblem,soSshouldtake.125seconds
perproblem.
Thesettingofaproblemwillrequire
(cid:5) (cid:15) (cid:15)
applications
of (cid:4)
(cid:0)
(cid:3)
(cid:5)
, which will take 32 microseconds on a fast
machine.
When we multiply these costs by the number of prob-
lems (32), we obtain costs for solving groups of prob-
lems: 64,16,and4seconds,respectively. Wenowcheck
that these costs dominate the cost of building a table for
(cid:0) (cid:13)(cid:16) (cid:15)
(cid:3)
(cid:5)
. The cost of building a table is roughly that of
(cid:5)
(cid:1) (cid:1) applications of (cid:4)
(cid:0)
(cid:3) (cid:5) and writes. On a fast machine,
the writes account for a substantial part of the cost; the
costshouldbeunderonesecond,inanycase. Onaslow
machine, theapplicationsof (cid:4)
(cid:0)
(cid:3)
(cid:5)
accountformostofthe
cost;thecostmaygoupconsiderably,butnohigherthan
the cost of solving a group of problems. Even if each
application of (cid:4) (cid:0) (cid:3)
(cid:5)
were to cost as much as (cid:5)(cid:11) (cid:0) (cid:14) (cid:10) on a
slow machine, building a table would take under 10 sec-
onds. Thus,thetotalcostforbuildingatableandsolving
agroupofproblemsremainswithinasmallfactoracross
machines.
These costs compare favourably to those of solving
problems with a CPU-intensive algorithm. Suppose that
someCPU-intensivealgorithmcouldsolveeachproblem
withjust (cid:5) (cid:14) (cid:5)(cid:8) (cid:7) applicationsof (cid:4) (cid:0) (cid:3) (cid:5) ,thatis,withjust (cid:5) (cid:1) (cid:3) applicationsof (cid:4) (cid:0) (cid:3) (cid:5) (letting (cid:2) (cid:9) (cid:5) ,inthenotationofsec- tion 3.2). Depending on whether (cid:9) (cid:9)
(cid:10)
, (cid:9) (cid:9)
(cid:10)
(cid:2)
(cid:5)
, or
(cid:9) (cid:9)
(cid:10)
(cid:2) (cid:30) ,thoseapplicationswillcostasmuchas
(cid:5)
(cid:1)(cid:4) (cid:3) ,
(cid:5)
(cid:1) (cid:18) ,
or
(cid:5)
(cid:1)
(cid:15)
reads, respectively. In comparison, the memory-
bound approachrequires
(cid:5)
(cid:1) (cid:3) ,
(cid:5)
(cid:1) (cid:1) , and
(cid:5)
(cid:1) (cid:1) reads, respec-
tively.
Relying on an 8MB cache and a compact encoding, S
mightbeabletoevaluate
(cid:0) (cid:13) (cid:15)
(cid:3)
(cid:5)
withonly4applications
of (cid:4)
(cid:0)
(cid:3)
(cid:5)
[11, 8] (see section 3.2). Thus, S might replace
each read with 4 applications of (cid:4) (cid:0) (cid:3) (cid:5) and otherwise per- formthesamesearchasinthememory-boundapproach.
When (cid:9) (cid:9)
(cid:10)
or (cid:9) (cid:9)
(cid:10)
(cid:2)
(cid:5)
, this strategy does not beat a
CPU-intensive algorithm that could solve each problem with
(cid:5)
(cid:1)(cid:4) (cid:3) applicationsof (cid:4)
(cid:0)
(cid:3) (cid:5) ,andafortioriitdoesnotbeat
thememory-boundalgorithm. When (cid:9) (cid:9)
(cid:10)
(cid:31)(cid:2) (cid:30) ,thisstrat-
egymayproduceasolutionatthesamecostas
(cid:5) 8(cid:15) 7
reads,
so it might appear to be faster than the memory-bound
algorithm. However, the memory-bound algorithm will
havethatsamecostifShasan8MBcacheandholdsthere
halfofatablefor
(cid:0) (cid:13)(cid:16) (cid:15)
(cid:3)
(cid:5)
withacompactencoding.
7. Experiments
Inthissectionwereportonseveralexperimentsrelated
to our method. First, we give evidence for the claims
about tree sizes made in section 3.2. Then we showthat
memorylatenciesvaryfarlessthanCPUspeeds. Finally
we show that the speed of our memory-bound functions
variessignificantlylessacrossmachinesthanthespeedof
CPU-boundfunctionsproposedforsimilarpurposes.
Treesizes
For two functions on22-bit integers, we foundthe mean
number of leaves and nodes in trees formed using the
procedure given in section 3.2. One of the functions
was derivedby calling the system (UNIX) randomnum-
ber generator
(cid:5)
(cid:1) (cid:1) times. The other was the function
(cid:4) (cid:0) (cid:3) (cid:12) (cid:2) (cid:1) (cid:10) (cid:2) (cid:15) (cid:5)(cid:26) (cid:9) middle-bits (cid:3) (cid:3) (cid:0) (cid:1)(cid:5) (cid:4)(cid:2) (cid:1)(cid:7) (cid:6) (cid:8) (cid:0) (cid:15) (cid:4)(cid:2) (cid:15) (cid:5) (cid:6) discussed in section6.1,wheretheelementsof (cid:0) (cid:1) and (cid:0) (cid:15) wereobtained fromthesystemrandomnumbergenerator.machine model processortype
server DellPowerEdge2650 IntelPentium4
desktop CompaqDeskProEN IntelPentium3
laptop SonyPCG-C1VN TransmetaCrusoe
settop GCT-AllWell Nat. Semi.
STB3036N GeodeGX1
PDA SharpSL-5500 IntelSA-1110
Table1.Themachinesusedinourexperiments.
machine CPUclock memoryread approximate
frequency time price(US$)
server 2.4GHz 0.19
(cid:0)
s $3000
desktop 1GHz 0.14
(cid:0)
s $600
laptop 600MHz 0.25
(cid:0)
s $1000
settop 233MHz 0.23
(cid:0)
s $300
PDA 206MHz 0.59
(cid:0)
s $500
Table2.Machinecharacteristics.
Theresultsareindistinguishableforthetwo functions.
We expectsimilar results for other pseudo-randomfunc-
tions.
We averaged over all possible starting points (cid:10) (cid:1) , and
varied the depth
(cid:0)
of the trees. Figure 1 shows that the
meannumberofleavesinsuchtreescloselymatches
(cid:0)(cid:17) (cid:25)(cid:14) (cid:11)
,
and that the mean number of nodes in such trees closely
matches (cid:3) (cid:0) (cid:25) (cid:11)
(cid:5)
(cid:3)(cid:24) (cid:0) (cid:25) (cid:5)
(cid:5)
(cid:2) (cid:5)
machine CPU-bound memory-bound
(HashCash) (trees)
seconds ratio seconds ratio
server=1 desktop=1
server 110 1.0 24 1.1
desktop 140 1.3 22 1.0
laptop 330 3.0 42 1.9
settop 1430 13.0 91 4.1
PDA 1920 17.5 100 4.5
Table 3. The performance of HashCash and of our
treesearchesonthemachineslistedinTable1. The
absolutetimesareoflessinterestthantherangeof
timesforagivenfunction.
machine tablebuildtime
seconds
server 0.9
desktop 1.1
laptop 3.2
settop 6.1
PDA 5.6
Table4.Timestobuildtheinversetableusedinthe
memory-boundfunctions.
. Althoughthesettopboxmightappeartohaveanattrac- tiveperformanceforitsprice,itisactuallyslowerthanits
clockspeedandmemoryaccesstimemightsuggest,partly
Timings
becauseithasafairlysimplepipeline.Atthehighend,the
Next we give experimental results for five modern ma- serverhaslowerperformancethanonemightexpect, be-
chines that were boughtin the last two years, andwhich causeofacomplexpipelinethatpenalizesbranchingcode.
coverarangeofperformancecharacteristics. Allofthese Ingeneral,higherclockspeedscorrelatewithhigherper-
machines are sometimes used to send e-mail—even the formance,butthecorrelationisfarfromperfect.
settop box, which is employed as a quiet machine in a Table 3 shows the performance of a CPU-bound task
home. Table1liststhemachines;Table2givestheirCPU (HashCash [3]) and of our memory-bound computations
clock frequencies, memory read times, and approximate onthemachineslistedinTable1. Thetimesarerounded
prices. to two significant figures. The HashCash times are for
We obtained the memory read times by measuring the minting 100 20-bit HashCash tokens—that is, finding
timetakentofollowalonglinkedlist;thelistentrieswere 100 independent 20-bit partial collisions in SHA-1. The
scatteredwidelythroughmemory,andpositionedsoasto memory-bound times are the means over 10 runs, each
ensurethat each accessmissed in the cache. Thus, these consisting of 128 depth-first tree searches, using the pa-
timesincludeTLBmissoverhead. Thisoverheadissub- rameters
stantialonourPDAanditexplainsthehighlatencyonthat
machine, where there seems to be an additional memory
reference for most reads from the list. None of the ma-
chines have huge caches—the largest was on the server
machine, whichhas a 512KBcache. Althoughthe clock
speeds ofthe machines varyby a factor of12, the mem-
ory read times vary by a factor of only 4.2. This mea-
surement confirms our premise that memory read laten-
ciesvarymuchlessthanCPUspeeds.
(cid:13)
(cid:9)
(cid:5)(cid:17) (cid:5)
and
(cid:0)
(cid:9)
(cid:5) (cid:15) (cid:15)
. These results do not in-
clude the time taken to build the table for
(cid:0) (cid:13)(cid:16) (cid:15)
(cid:3)
(cid:5)
, which
weconsidernext.
Table 4 shows the time taken to build the table for
(cid:0) (cid:13) (cid:15)
(cid:3)
(cid:5)
. We used a straightforward implementation in
which each insertion of an entry into the table requires
at least one read for resolving collisions, followed by
a write to store the entry. We let (cid:4) (cid:0) (cid:3) (cid:1) (cid:2) (cid:1) (cid:10) (cid:2)
(cid:15)
(cid:5) (cid:9)
middle-bits (cid:3) (cid:1) (cid:0) (cid:1) (cid:4)(cid:2) (cid:1) (cid:6) (cid:8) (cid:0)
(cid:15)
(cid:4)(cid:2)
(cid:15)
(cid:6)
(cid:5)
. Evaluating (cid:4) (cid:0) (cid:3)
(cid:5)
is cheap
compared to a memory access; thus, most of the cost ofbuilding the table is due to the memory accesses needed
for insertions into the table. For this function, the cost
(cid:9) isunder
(cid:10)
(cid:2) (cid:30) ,butincreasingitto
(cid:10)
(cid:2) (cid:30) doesnotsubstan-
tiallyaffecttheseresults.Oneachmachine,thetimetaken
to build the table is insignificant when compared with
the corresponding numberin Table 3. Thelatter number
corresponds to 128 problems. If instead each table were
amortizedoverjust32problems,buildingthetablewould
contributenomorethan25%ofthetotaltimeofsolvinga
groupofproblems. Inanycase,theratioacrossmachines
remainsunder5.
The same executables were used on the desktop, lap-
top, and settop machines. The code was compiled with
the Intel C compiler. The executablesfor the serverma-
chinewerecompiledwithoptimizationforthePentium4;
performance without this specialized optimization was
poor. The executables for the PDA were compiled with
gcc. We used less memory (20MB) for the inverse table
on the PDA, in order to make it fit in the limited space
available—theSharpSL-5500providesonly32MBofits
memorytoapplicationsandtheoperatingsystem. Onthe
othermachines,weused24MB.
These experiments demonstrate several points. First,
the effective performance of the machines varies more
than clock speed alone might indicate. This variation is
theresultofthefaster,moreexpensiveprocessorshaving
more elaborate pipelines. Second, the desktop machine
is the most cost-effective one for both CPU-bound and
memory-bound computations; memory-bound computa-
tionsdonotappeartoallowattackerstobenefitfromthe
lower-cost machines. Finally, the memory-bound func-
tionssucceedinmaintainingaperformanceratiobetween
theslowestandfastestmachinesthatisnotmuchgreater
thantheratioofmemoryreadtimes.
Theexperimentsalsoprovidevalidationoftheapprox-
imate calculations of section 6.2 in which we discuss
settings for our parameters. In that section, we assume
a machine with a memory read time of
(cid:5) (cid:13)
(cid:1) (cid:18)
much more egalitarian across machine types than CPU-
boundfunctions.
Itispossiblethattechnologychangeswillresultinmore
diversememorysystemsinthefuture,andthenmemory-
boundfunctionsmaynolongerprovideanegalitarianpro-
tection againstabuses. However,we haveidentified sev-
eralparameters(
seconds,
while these real machineshave somewhatslowermemo-
ries.Oncethisdifferenceistakenintoaccount,theexperi-
mentalresultsarelargelyconsistentwiththecalculations.
8. Conclusionsand open issues
This paper is concerned with finding moderately hard
functions that most recent computer systems will evalu-
ate at about the same speed. Such functions can help in
protectingagainsta varietyofabuses. Theuniformityof
theircostacrosssystemsmeansthattheyneednotincon-
veniencelow-end,legitimateusersinordertodeterhigh-
endattackers.Wedefineandstudyafamilyofmoderately
hard functions whose computation can benefit crucially
fromaccessestoalargetableinmemory.Ourexperimen-
talresultsindicatethatthesememory-boundfunctionsare
(cid:13)
,
(cid:0)
, (cid:9) , (cid:3) ,...) thatcanbetunedastech-
nology evolves. We have also found a number of ideas
and tricks that should help in adapting our approach to
differentcircumstancesandapplications.
Theliteraturecontainsmanypapersthattreatthespace
requirements of particular algorithms, cache-miss rates,
andtradeoffsbetweentimeandspace. Someofthatwork
hasbeenasourceofinspirationforusinseekingmemory-
bound functions. In particular, we remembered the clas-
sicmeet-in-the-middleattacksondoubleDES;usinglarge
tables, these attacks are much faster than naive CPU-
intensivealgorithms[15]. However,these attacks canbe
implementedwithmultiplepassesoverthekeyspaceand
smallertables,sotheyarenotnecessarilylimitedbymem-
orylatency.Wehavenotcomeacrossanypreviousresults
thatwecoulddirectlyexploitforourpurposes,thoughwe
maystillfindsome. Moregenerally,itisdesirableto in-
vestigate alternative memory-bound computations; some
arebeingconsidered[6].
The literature also contains some models of memory
hierarchies (e.g., [2]). An interesting subject for further
workistousesuchmodelsinordertodevelopafounda-
tionformemory-boundcomputations,ifpossibleproving
thatparticularcomputations(suchasours)areinherently
memory-bound.
Manyconsiderationsmayaffecttheacceptanceofmod-
eratelyhardfunctions,andofmemory-boundfunctionsin
particular. Theproblemsoflarge-scaledeployment,such
assoftwaredistributionandhandlinglegacysystems,may
bethemostchallenging. Inaddition,asthepriceofcom-
puter time falls, one must prescribe longer computations
inordertoimposeagivencost. Forexample,inorderto
imposea cost of onecent(well underthecurrent cost of
physical bulk mail in the US), a computation of at least
several minutes is required today; half an hour may be
neededinthenot-too-distantfuture.Inaddition,memory-
bound functions can interfere with concurrently running
applicationsina multitaskingenvironment,bothbecause
theyconsumememoryandbecausetheycandisplacethe
applications’ code and data from caches. For these rea-
sons, users may not tolerate moderately hard functions,
not even egalitarian ones. On the other hand, even costs
below one cent might be effective against some abuses,
such as spam. Cache interference can be reduced by ar-
rangingthattheinversetablemaptoasubsetofthecache
lines,anditcanbeavoidedbyaccessingmemorywithin-
structionsthatbypassthecaches. Futhermore,usersmaytolerate, and perhaps not even notice, long computations
done asynchronously when their machines are otherwise
idle. We rely on such asynchronous computations in an
ongoingproject.
Acknowledgments
We aregratefultoDanSimonforsuggestingthefunc-
tion
(cid:4) (cid:0) (cid:3) (cid:12) (cid:2) (cid:1) (cid:10) (cid:2)
(cid:15)
(cid:5) (cid:9) middle-bits (cid:3) (cid:1) (cid:0) (cid:4)(cid:2) (cid:1) (cid:6)(cid:9) (cid:8) (cid:0) (cid:4)(cid:2)
(cid:15)
(cid:6) (cid:5)
where
(cid:0)
[12] M.JakobssonandA.Juels.Proofsofworkandbreadpud-
dingprotocols. InProceedingsoftheIFIPTC6andTC11
JointWorkingConferenceonCommunicationsandMulti-
mediaSecurity(CMS’99).Kluwer,1999.
[13] A.JuelsandJ.Brainard. Clientpuzzles: Acryptographic
defense against connection depletion. In Proceedingsof
NDSS ’99 (Networks and Distributed Systems Security),
pages151–165,1999.
[14] U. Manber. A simple scheme to make passwords based
onone-wayfunctionsmuchhardertocrack.Computers&
Security,15(2):171–176,1996. [15] A. J. Menezes, P. C. van Oorschot, and S. A. Vanstone.
isatableofrandom32-bitprimes. Wealsowish HandbookofAppliedCryptography. CRCPress,1996.
[16] M.Naor. Privatecommunication. 2002.
to thank Dave Conroy and Chuck Thacker for informa-
tiononmemorysystems;MoniNaor,forexplainingprior
workoninvertingfunctions;andAndrewBirrell,Cynthia
Dwork, Andrew Goldberg, Michael Isard, Anna Karlin,
andAdamSmith,formanyinterestingdiscussions. Most
ofMart´ınAbadi’sworkwasdoneatMicrosoftResearch,
Silicon Valley,with Microsoft’ssupport. Mart´ınAbadi’s
work was also partly supported by the National Science
FoundationunderGrantCCR-0208800.
References
[1] M.Abadi, T.M.A. Lomas, and R.Needham. Strength-
eningpasswords. SRCTechnicalNote1997–033,Dig-
ital Equipment Corporation, Systems Research Center,
September/December1997.
[2] A. Aggarwal, B. Alpern, A. Chandra, and M. Snir. A
model for hierarchical memory. In Proceedings of the
Nineteenth Annual ACM Symposium on Theory of Com-
puting,pages305–314,1987.
[3] A. Back. HashCash. Available on the web at URL
www.cypherspace.org/˜adam/hashcash,1997.
[4] camram. camram. Available on the web at URL
www.camram.org,2002.
[5] L.F.CranorandB.A.LaMacchia. Spam! Communica-
tionsoftheACM,41(8):74–83,Aug.1998.
[6] C.Dwork,A.Goldberg,andM.Naor. Onmemory-bound
functionsforfightingspam. Draft,2002.
[7] C.DworkandM.Naor. Pricingviaprocessingorcombat-
tingjunkmail.InAdvancesinCryptology—CRYPTO’92,
pages139–147.Springer,1999.
[8] A. Fiat and M. Naor. Rigorous time/space trade-offs
for inverting functions. SIAM Journal on Computing,
29(3):790–803,June2000.
[9] P. Flajolet and A. Odlyzko. Random mapping statistics.
In J.-J. Quisquater and J. Vandewalle, editors, Advances
in Cryptology – EUROCRYPT’ 89, volume 434 of Lec-
tureNotesinComputerScience,pages329–354.Springer,
1990.
[10] E. Gabber, M. Jakobsson, Y. Matias, and A. J. Mayer.
Curbing junk e-mail via secure classification. In Finan-
cialCryptography,pages198–213,1998.
[11] M. E. Hellman. A cryptanalytic time-memorytrade off.
IEEETransactionsonInformationTheory,IT-26(4):401–
406,1980.