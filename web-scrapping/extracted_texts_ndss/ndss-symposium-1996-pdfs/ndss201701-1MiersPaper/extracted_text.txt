IO-DSSE: Scaling Dynamic Searchable Encryption
to Millions of Indexes By Improving Locality
Ian Miers Payman Mohassel
The Johns Hopkins University Department of Computer Science Visa Research∗
imiers@cs.jhu.edu pmohasse@visa.com
Abstract—Free cloud-based services are powerful candidates typically allow for some information leakage on search/access
fordeployingubiquitousencryptionformessaging.Inthecaseof patterns which is captured using a leakage function. The
email and increasingly chat, users expect the ability to store and dynamic variants of SSE (DSSE) [4,13,14,20] also allow
searchtheirmessagespersistently.Usingdatafromamajormail for efficient updates to the encrypted database. The question is
provider, we confirm that for a searchable encryption scheme
whether dynamic SSE can be used efficiently in a cloud-scale
to scale to millions of users, it should be highly IO-efficient
application?
(locality) and handle a very dynamic message corpi. We observe
that existing solutions fail to achieve both properties simulta-
Several works [4,5] have addressed scaling SSE schemes
neously. We then design, build, and evaluate a provably secure
to a very large index—terabytes of data—but to the best of our
DynamicSearchableSymmetricEncryption(DSSE)schemewith
knowledge, none have examined deploying millions of small
significant reduction in IO cost compared to preceding works
indexes on shared hardware. This is the exact problem faced
when used for email or other highly dynamic material.
by a cloud provider wishing to deploy search for encrypted
messaging or email without deploying large amounts of new
I. INTRODUCTION
hardware.
The last few years have seen incredible success in deploy-
Since SSE schemes typically use fast symmetric cryp-
ing seamless end-to-end encryption for messaging. Between
tography, the primary performance issue for SSE is IO and
iMessage, WhatsApp, and SRTP for video, over 2 billion
specificallypoorlocality:unlikeastandardinvertedindexwhere
users routinely encrypt their messages without necessarily even
thelistofdocumentIDsforagivenkeywordk canbestoredin
noticing. Unfortunately, this trend has been largely limited to
a single location, SSE schemes typically place each document
ephemeral or semi-ephemeral communication mediums. Where
ID for a given keyword in a distinct random location in order
users expect messages to be available for later recall, we have
to hide the index structure. This results in a large increase in
seen little progress.
IO usage, since searching for a keyword found in, e.g., 500
Thequintessentialexampleofthisisemail,wheremessages documents results in 500 random reads, rather than one single
aresearchedformonthsoryearsafterbeingreceived.Butemail read retrieving a list of 500 document IDs. Similarly, inserting
isnottheonlymediumfillingthisrole:GoogleHangouts,Slack, a batch of, e.g., 100 documents containing some 150 total
and Facebook Messenger all operate in an archive and search keywords requires 100×150=15,000 writes, rather than 150
paradigm—indeed the latter two are to some extent used as writes, one per keyword.
an email substitute because of this. In this setting, end-to-end
While the same locality issues arise in SSE schemes for
encryption is not seamless: by using it, users lose the ability
very large indexes, the solution space is far more constrained
to store messages in the cloud and search. Since users are
in our setting and the main techniques introduced in the
unwilling to sacrifice features for security, this is a major
most promising approaches [4,5] are not applicable for purely
impediment to deploying end-to-end encryption.
dynamic indexes (i.e. indexes that are initially empty). As a
Symmetric Searchable Encryption (SSE) [5,7,8,10,15,19] result, deploying existing SSE schemes for search for mail or
providesapotentialsolutiontothisproblemasitallowsaclient messaging—where every entry is inserted dynamically into an
to outsource an encrypted index of documents (e.g. emails) initially empty index—-would result in an order of magnitude
to an untrusted server and efficiently search the index for increase in IO usage. Since existing mail search is already IO
specific keywords. The efficiency of SSE stems from its use bound, the cost of doing so is prohibitive. This is a marked
of fast symmetric-key operations and its privacy guarantees departure from the cost of deploying end-to-end encryption for
ephemeral communication, which comes at little operational
∗ WorkdonewhileatYahooLabs. cost.
Unfortunately, this increased cost cannot be handled by
Permission to freely reproduce all or part of this paper for noncommercial simply using better hardware. First, high performance storage
purposes is granted provided that copies bear this notice and the full citation
systems are prohibitively expensive relative to profit from
on the first page. Reproduction for commercial purposes is strictly prohibited
without the prior written consent of the Internet Society, the first-named author free communications services. Second, caching is relatively
(for reproduction of an entire paper only), and the author’s employer if the ineffective as each individual index is used infrequently. Third,
paper was prepared within the scope of employment. even given cost effective storage (e.g. much cheaper SSDs)
NDSS ’17, 26 February - 1 March 2017, San Diego, CA, USA
and the willingness of providers to upgrade infrastructure, any
Copyright 2017 Internet Society, ISBN 1-891562-46-0
http://dx.doi.org/10.14722/ndss.2017.23394 infrastructure-related improvement yields similar cost savingsIOtoinsertndocuments IOforasearch
supportsdeletes
withkkeywords returningndocuments
indextype Static Dynamic Static Dynamic
UnencryptedIndex O(k) O(k) O(1) O(1) yes
Cashet.al[4] O(k) O(nk) O(1) O(nk) dynamiconly
Stefanovet.al[20] O(nk) O(nk) O(nk) O(nk) yes
Thiswork1 O(k) O(k) O(1) O(1) partialdynamic
TABLE I: Informal description of IO costs of SSE schemes assuming n, the number of documents mapped to a given keyword,
is smaller that the block size used for storage. When inserting n documents containing k keywords into an existing index, all
existing SSE schemes write each posting (i.e. keyword, document ID pair) to a distinct random location. As a result, when adding
n documents to the index entry for a given keyword, there are n writes to distinct random locations. This is repeated for each
of the k keywords. For search, returning the complete entry in the index for a given keyword requires each of the n random
locations be read. When used for messaging or email, all insertions and searches are done against the dynamic index and any
savings in the static case do not apply.
fornon-encryptedsearch.ExistingSSEschemessimplyrequire isinmanywayseasierthanwhatistypicallyaskedofencrypted
considerably more resources than unencrypted search. search.WeanalyzedetailedusagenumbersfurnishedbyYahoo
Webmail. We conclude that searchable encryption for cloud-
We now examine in detail the specific challenges for email
based email is surprisingly plausible in terms of functionality
and then detail our proposed solution.
if cost is disregarded: the size of the datasets are manageable,
search is not frequently used, and most queries are exceedingly
A. Why Email is Different
simple. In particular, the combination of single keyword plus
Cloud-basedmailoffersauniquesetting.First,whilestorage intersectiononpublicmetadata(date,sender,“hasattachment”),
at this scale is cheap, access to it is not: existing mail search is seemstocoverthevastmajorityofsearches.Whileconjunctive
already IO bound. As a result, we must minimize the IO cost querieswouldofcoursebeanimprovement,theyarenotstrictly
of maintaining the index. As we will see, this is the driving necessary. Moreover the availability of cheap storage coupled
design constraint behind our work. with the fact that search is infrequent, means the cost of index
entries for deleted files is relatively small. This allows us to
Second, unlike traditional settings for SSE, there is no
eschew many of the complexities of fully dynamic searchable
initial corpus of documents to index. Instead all documents
encryption because we can afford to delete entries on a best-
(i.e. sent and received emails) are added after database creation
effort basis. The scalability issues become even easier when
via updates2—the typical user receives between 30 and 200
one considers that end-to-end encrypted mail is likely personal
messages a day.3 This exacerbates the IO problem, since all
and the majority of email is not. As a result, only a small
existing schemes end up performing one random write to the
fraction of mail will need to be encrypted or indexed using
disk per keyword for each new email and one random read per
SSE.
document ID returned in a search. This is in marked contrast
to a standard index wherein multiple entries are packed into
Why existing schemes fail Encrypted databases such as Blind
one block and read/written in one shot, resulting in efficient
Seer [16], Cryptdb [17] and others aim to provide complex
IO usage.
privatequeriesasaprivacy-preservingreplacementtotraditional
Third,thequeryrateisexceedinglylow.ForYahoowebmail, large database applications. Just as those database clusters are
we see on the order of 250 searches per second total across unsuited for mail search, so too are their privacy-preserving
all users on mail content from on the order of a few hundred counterparts.
millionmonthlyactiveusers.Searchesonpublicmetadatasuch
The DSSE scheme of Stefanov et al. [20] provides impres-
assender,datesent,“hasattachment”,etc.arefarmorefrequent,
sive privacy protections including efficient deletion of entries,
but searches on mail content, i.e., what would be stored in an
but as each individual index entry (i.e. a mapping from a word
encryptedindex,aresurprisinglyrare.Manyschemes(e.g.[20])
to a single document) is stored in a random location, the IO
assume hundreds of queries per second, where it is economical
expansion relative to standard search is very large. This is not
to load the index into memory. At an average two queries per
scalable in the context of deploying hundreds of millions of
inbox per month, storing the index in memory is neither cost
indexes on a few thousand servers.
effectivenorremotelypracticalgiventhesheernumberofusers
each needing their own separate index. This problem is not isolated to Stefanov et al.’s scheme.
Indeed, Cash et al. [4] note “One critical source of inefficiency
If the IO problems are resolved, however, the prospects for
in practice (often ignored in theory) is a complete lack of
encrypted mail search are actually fairly good: search for email
locality and parallelism: To execute a search, most prior
1Weassumetheobliviouslyupdatableindexisoffixedsizeandthusthe SSE schemes sequentially read each result from storage at
overheaditimposesisconstant.Thisisthecaseifthekeywordlistisfixed a pseudorandom position, and the only known way to avoid
ortheserverhaslimitedspace.Otherwisethereisacostthatislogarithmicin thiswhilemaintainingprivacyinvolvespaddingtheserverindex
thesizeoftheOUIbutindependentoftotalindexsizeorsearchfrequency.
to a prohibitively large size.” [4]. Although one can arrive at
2Sincetheserverknowsthecontentsofexisting(unencrypted)email,adding
this from varying perspectives (disk IO, latency, or memory
existingunencryptedemailtotheindexisunnecessaryandforsomeschemes
ill-advised. requirements), it is a central problem that renders all previous
3Themeanis30withastandarddeviationof148. schemes unusable in this context.
2overflow: f3 f3 f5 f7 f9 f 1, f 5 ,f 8,f 9
k f k f f k f f f f
1 3 1 4 9 1 1, 5 , 8, 12
k f k f f f f
keyword k f f 2 4 4 4, 1 , 3, 9
7 4 1
queries
…
k f f f
k f f 3 1 8 9 k
3 1 8 1 f f f f
2, 3 , 8, 11
Obliviously Updatable Index Full Block Index
Local Device Data center
Fig. 1: IO-DSSE logical architecture: an index mapping keywords to document IDs is stored locally, then the largest entries
overflow into the obliviously updatable index. When the entry for a keyword in the OUI is full, index entries are inserted into the
Full Block Index in chunks. Keyword searches query all three indexes. Note: encryption and the obliviously updatable index
construction hide this view from the server.
While Cash and Tessaro [6] show there is a fundamental ORAM, however, is not an ideal choice. First, in most
trade-off between locality and index size, in many settings SSE schemes, access patterns for search are already leaked,
a large increase in overall performance can be obtained by yet in ORAM we must pay for the full ORAM overhead not
allowing a small blow-up in index size. Cash et al. [4] offer just for reads and writes associated with index updates, but
such an improvement: instead of storing each index entry at for searches as well.4 Second, ORAM must remain secure
a random location on disk, they store entries sequentially in for arbitrary access patterns, while we only need to obscure
fixed-size blocks, drastically reducing the number of disk reads batched updates to the index (many emails/keywords can be
by allowing many index entries for a given keyword to be batched and inserted in the index at the same time).
retrieved at once. Unfortunately, this technique cannot readily
Thus, in Section III, we construct an obliviously updatable
be used to handle updates. The act of appending a new index
index (OUI), which provides for ORAM-like properties for
entry to an existing (partially-filled) block leaks significant
updates to the index (both reads and writes) but allows simple
information on updates (which are frequent). This means these
non-oblivious reads for search. An overview of this approach
techniques are not applicable to entries inserted into the index
is given in Figure 1. This is accomplished by using a weaker
after the initial index creation.
security requirement tailored to the SSE leakage function.
Asaresult,whileCashetal.makeuseofanefficienton-disk Through optimizations and batching, we achieve a 94% IO
index for the starting document corpus, all updates to the index savings vs. the generic approach using Path ORAM [21].
are stored in memory because each index entry is written to a
To summarize our contributions:
distinct random location. The scheme is not designed to deal
with frequent updates in an IO-efficient manner and assumes
1) We examine the requirements and feasibility of search on
that most of the corpus is indexed statically, at initialization.
encryptedemailandmoregenerally,theclassofIO-bound
Thus, when the scheme is used for dynamic updates, it incurs
DSSE schemes that exhibit a low query rate and high
the very same locality issues the authors identify. Bridging this
update rate. This examination is supported with realistic
gap between locality and privacy for highly dynamic indexes
data from a large webmail provider.
is the goal of our construction. See Table I for details.
2) Motivated by IO-efficient SSE for highly dynamic corpi,
we introduce the concept of an Obliviously Updatable
Index (OUI). As a proof of concept, we provide a new
B. Our Contribution
construction for an OUI, with proof of security, which
offers a 94% savings compared to a naive implementation
A logical extension of Cash et al.’s scheme is to buffer
using ORAM. We obtain our final solution by combining
partialblockslocally(client-side)andonlyuploadtotheserver
this with the state-of-the-art IO-efficient SSE that indexes
oncetheblockisfull.HoweverourexperimentsinSectionIV-C
the full blocks.
indicate that a storage-limited client (e.g. a mobile device) will
3) We evaluate our solution using real-world data from
overflow its local storage in less than 100 days even for the
100,000 mail users, showing we achieve a 99% reduction
average user. A second approach is to offload this buffer to the
in the IO cost vs. the state-of-the-art in SSE schemes such
serverinawaythathideswhenitisupdatedbutstillallowsthe
buffertobesearched.ObliviousRAM(ORAM)[2,9,11,12,18]
4Becauseweneedtoknowthecontentofanindexentrytoupdateitand
is a natural choice. Index entries would be buffered in a small
mustreadthatfromaserver,wecannotuse“write-only”[1]ORAMwhich
ORAM cache and then written to the full index. assumesreadsarenotobservable.
3asthatofCashetal.which,forpurelydynamicinsertions, an updated encrypted memory EM(cid:48) where M[y] = v, if
write each document-keyword pair to a random location. v (cid:54)=null.
We also report the storage required for a typical mail user
both on the client side and the server side.
Correctness Consider the following correctness experiment.
Adversary A chooses memory M. Consider the encrypted
C. No free lunch database EM generated with SETUP (i.e., (cid:104)σ,EM(cid:105)↔ SETUP(cid:104)
(1λ,M),⊥(cid:105)). The adversary then adaptively chooses mem-
These improvements are, of course, not free. First, we must
ory locations to read and write. Denote the adversary’s
allowforslightlymoreleakageinsearchthantheschemeof[4],
read/write queries by (y ,v ),...,(y ,v ) where v = null
1 1 q q i
since we leak when an entry in the OUI is full and needs to be
for read operations. A wins in the correctness game if
pushed to the full-block index. Second, we can only deal with (cid:104)(M [y ],σ ),EM(cid:48)(cid:105) are not the final outputs of the protocol
i i i
deletes from the OUI: once an entry is written to the static
OBLIVIOUSACCESS(cid:104)(σ i−1,y i,v i),EM i−1(cid:105) for any 1≤i≤q,
index, it is stored until the index is rebuilt. Thus we do not
whereM ,EM ,σ arethememoryarray,theencryptedmemory
i i i
provide a fully dynamic index. Given the low cost of storage
array and the secret state, respectively, after the i-th access
relative to the size of emails and the fact that for the average
operation, and OBLIVIOUSACCESS is run between an honest
user emails are contained fully within the partial index for at
clientandserver.TheORAMschemeiscorrectiftheprobability
least 11 days, we believe this is an acceptable trade-off.
of A in winning the game is negligible in λ.
II. BACKGROUND Security An ORAM scheme is secure if for any adversary
A, there exists a simulator S such that the following two
A. Hash Tables
distributions are computationally indistinguishable.
Ahashtableisadatastructurecommonlyusedformapping
keys to values. It often uses a hash function h that maps a key • Real A(λ): A chooses M. The experiment then runs
to an index (or a set of indexes) in a memory array M where (cid:104)σ,EM(cid:105)↔ SETUP(cid:104)(1λ,M),⊥(cid:105). A then adaptively makes
the value associated with the key may be found. The keyword read/write queries (y i,v) where v = null on reads, for
is not in the table if it is not in one of those locations. More whichtheexperimentrunstheprotocol(cid:104)(M[y i],σ i),EM i(cid:105)
formally,wedefineahashtableH =(hsetup,hlookup,hwrite) ↔ OBLIVIOUSACCESS(cid:104)(σ i−1,y i,v),EM i−1(cid:105). Denote
using a tuple of algorithms. the full transcript of the protocol by t i. Eventually, the
experiment outputs (EM,t ,...,t ) where q is the total
1 q
• (h,M)←hsetup(S): hsetup takes as input an initial set number of read/write queries.
S of keyword-value pairs and outputs a hash function h • Ideal (λ): The experiment outputs (EM,t(cid:48),...,t(cid:48))↔
A,S 1 q
and a memory array M storing the key-value pairs. S(q,|M|,1λ).
• M(cid:48) ← hwrite(key,value,M,h): If (key,value) al-
ready exists in the table it does nothing, else it stores
C. Path ORAM
(key,value) in the table. If M and h are known from the
context, we use the shorter notation hwrite(key,value). Path ORAM [21] is a tree-based ORAM construction with
• value ← hlookup(key,M,h): hlookup returns value if high practical efficiency. We use Path ORAM as a component
(key,value) is in the table. Else it returns ⊥. If M and h in our SSE construction. We only review the non-recursive
are known from the context, we use the shorter notation version of Path ORAM where the client stores the position
hlookup(key). map locally and hence only a single binary tree T is needed
to store the data on the server.
B. Oblivious RAM
Notations Let M be a memory array of size at most N =2L
We recall Oblivious RAM (ORAM), a notion introduced that we want to obliviously store on the server. We use M[i]
and first studied in the seminal paper of Goldreich and to denote the ith block in M. Let T denote a binary tree of
Ostrovsky [12]. ORAM can be thought of as a compiler that depth L on the server side that will be used to store M. The
encodes the memory into a special format such that accesses client stores a position map position where x=position[i] is
on the compiled memory do not reveal the underlying access the index of a uniformly random leaf in T. The invariant Path
patterns on the original memory. An ORAM scheme consists ORAM maintains is that M[i] is stored in a node on the path
of protocols (SETUP,OBLIVIOUSACCESS). from the root to leaf x which we denote by P(x). We also
use P(x,(cid:96)) to denote the node at level (cid:96) on path P(x), i.e.
• (cid:104)σ,EM(cid:105)↔ SETUP(cid:104)(1λ,M),⊥(cid:105): SETUP takesasinputthe
the node that has distance (cid:96) from the root. There is a bucket
security parameter λ and a memory array M and outputs
associated with each node of the tree T, and each bucket can
a secret state σ (for the client), and an encrypted memory
at most fit Z memory blocks.
EM (for the server).
• (cid:104)(M[y],σ(cid:48)),EM(cid:48)(cid:105) ↔ OBLIVIOUSACCESS(cid:104)(σ,y,v),EM(cid:105): The client holds a small local stash denoted by S, which
OBLIVIOUSACCESS is a protocol between the client and containsasetofblocksthatneedtobepushedintotheserver’s
the server, where the client’s input is the secret state σ, tree.
an index y and a value v which is set to null in case the
access is a read operation (not a write). Server’s input ORAM Setup We assume that memory array M is initially
is the encrypted memory EM. Client’s output is M[y] empty. Client’s stash S is empty. All the buckets in the tree
and an updated secret state σ(cid:48), and the server’s output is T are filled with encryptions of dummy data. The position
4OBLIVIOUSACCESS(cid:104)(σ,y,v),EM(cid:105): Moreprecisely,adatabaseisasetofdocument/keyword-set
pair DB=(d ,W )N . Let W =∪N W be the universe of
i i i=1 i=1 i
1: x←position[y] keywords. A keyword search query for w should return all d i
2: position[y]←R {0,...,2L} where w ∈W i. We denote this subset of DB by DB(w).
3: for (cid:96)∈{0,...,L} do A searchable symmetric encryption scheme Π consists of
4: S ←S∪READBUCKET(P(x,(cid:96))) protocols SSESETUP, SSESEARCH and SSEADD.
5: end for
6: data← Read block y from S • (cid:104)EDB,σ(cid:105)← SSESETUP(cid:104)(1λ,DB),⊥(cid:105): SSESETUP takes
7: if v (cid:54)= then as client’s input a database DB and outputs a secret state
8: S ←(S−{(y,data)})∪{(y,v)} σ (for the client) and an encrypted database EDB which
9: end if is outsourced to the server.
10: for (cid:96)∈{L,...,0} do • (cid:104)(DB(w),σ(cid:48)),EDB(cid:48)(cid:105)← SSESEARCH(cid:104)(σ,w),EDB(cid:105):
11: S(cid:48) ← {(y(cid:48),data(cid:48)) ∈ S : P(x,(cid:96)) = SSESEARCH is a protocol between the client and the
P(position[y(cid:48)],(cid:96))} server, where the client’s input is the secret state σ and
12: S(cid:48) ← Select min(|S(cid:48)|,Z) blocks from S(cid:48). the keyword w he is searching for. The server’s input is
13: S ←S−S(cid:48) the encrypted database EDB. The client’s output is the
14: WRITEBUCKET(P(x,(cid:96)),S(cid:48)) set of documents containing w, i.e., DB(w) as well an
15: end for updated secret state σ(cid:48), and the server obtains an updated
encrypted database EDB(cid:48).
Fig. 2: Read/Write Ops in path ORAM • (cid:104)σ(cid:48),EDB(cid:48)(cid:105) ← SSEADD(cid:104)(σ,d),EDB(cid:105): SSEADD is a
protocol between the client and the server, where the
client’s input is the secret state σ and a document d to
be inserted into the database. The server’s input is the
map position is initialized with uniformly random values in
encrypteddatabaseEDB.Theclient’soutputisanupdated
{0,...,2L}. This encrypted tree is denoted by EM. secret state σ(cid:48), and the server’s output is an updated
encrypted database EDB(cid:48) which now contains the new
Read/Write Operations To read M[y] or to write a value v document d.
at M[y], the client first looks up the leaf position x from the
position map and reads all the buckets along the path P(x). It
Correctness Consider the following correctness experiment.
thenupdatesposition[y]toafreshrandomvaluein{0,...,2L}.
An adversary A chooses a database DB. Consider the en-
If it is a read operation, the encryption of (y,v) will be found
crypted database EDB generated using SSESETUP (i.e. (cid:104)EDB,
in one of the buckets on P(x), which the client decypts to
K(cid:105) ← SSESETUP(cid:104)(1λ,DB),⊥(cid:105)). The adversary then adap-
output v. It also adds all the buckets on P(x) to its local stash.
tively chooses keywords to search and documents to add to
If it is a write operation, the client also adds (y,v) to its local
the database. Denote the searched keywords by w ,...,w .
stash. 1 t
A wins in the correctness game if (cid:104)(DB (w ),σ ),EDB (cid:105) (cid:54)=
i i i i
The client encrypts all the blocks in the stash and inserts SSESEARCH(cid:104)(σ i−1,w i),EDB i−1(cid:105) for any 1 ≤ i ≤ t, where
as many as possible into the buckets along P(x), inserting DB i,EDB i are the database and encrypted database, respec-
each block into the lowest bucket in the path possible while tively, after the ith search, and SSESEARCH and SSEADD are
maintaining the invariant that each block y(cid:48) remains on the run between an honest client and server. The SSE scheme is
path P(position[y(cid:48)]). correctiftheprobabilityofAinwinningthegameisnegligible
in λ.
Figure 2 describes the read/write operations in more detail.
The READBUCKET protocol has the server return the bucket
SecuritySecurityofSSEschemesisparametrizedbyaleakage
being read to the client who decrypts and outputs the blocks in
functionL,whichexplainswhattheadversary(theserver)learns
thebucket.The WRITEBUCKET protocolhastheclientencrypt
about the database and the search queries, while interacting
and insert all the blocks in its input set into a bucket and send
with a secure SSE scheme.
it to the server.
An SSE Scheme Π is L-secure if for any PPT adversary
A, there exists a simulator S such that the following two
D. Searchable Symmetric Encryption
distributions are computationally indistinguishable.
A database D is a collection of documents d each of
i
which consist of a set of keywords W . A document can be a • RealΠ(λ): A chooses DB. The experiment then runs
i A
webpage,anemail,orarecordinadatabase,andthekeywords (cid:104)EDB,σ(cid:105) ← SSESETUP(cid:104)(1λ,DB),⊥(cid:105). A then adap-
can represent the words in the document, or the attributes tively makes search queries w i, which the experiment
associated with it. A symmetric searchable encryption (SSE) answers by running the protocol (cid:104)DB i−1(w i),σ i(cid:105) ←
scheme allows a client to outsource a database to an untrusted SSESEARCH(cid:104)(σ i−1,w i),EDB i−1(cid:105). Denote the full tran-
server in an encrypted format and have the server perform scripts of the protocol by t i. Add queries are handled
keyword searches that return a set of documents containing the in a similar way. Eventually, the experiment outputs
keyword. For practical reasons, SSE schemes often return a (EDB,t 1,...,t q)whereqisthetotalnumberofsearch/add
set of identifiers that point to the actual documents. The client queries made by A.
can then present these identifiers to retrieve the documents and • IdealΠ (λ): A choose DB. The experiment runs
A,S,L
decrypt them locally. (EDB(cid:48),st )←S(L(DB)). On any search query w from
0 i
5A, the experiment adds (w ,search) to the history H, This is stronger than the typical protection provided by SSE
i
and on an add query d it adds (d ,add) to H. It then schemes (which leak the “search pattern”), and in our case
i i
runs (t(cid:48),st ) ← S(st ,L(DB ,H)). Eventually, the (similar to prior work) this information is already revealed via
i i i−1 i−1
experiment outputs (EDB(cid:48),t ,...,t(cid:48)) where q is the total searches against the full-block index. So we gain no additional
1 q
number of search/add queries made bt A. privacy by hiding the search pattern only in the OUI and will
realize considerable efficiency gains by not doing so.
III. OURCONSTRUCTION
As a concrete starting point, consider a basic construction
As discussed earlier, three important security/efficiency of Path ORAM [21]. In Path ORAM, entries (called blocks
requirements for any searchable symmetric scheme for email in our construction) are stored as leaves in a full binary tree.
to be practical are (1) dynamic updatability, (2) low latency Each time an entry is read or written, the entire path from its
on search and hence high IO efficiency, and (3) no leakage on leaf to root is read, the entry is remapped to a random leaf
updates (send/received email). in the tree, and the original path is rewritten with the entry
placed at as close to the lowest common ancestor of the old
TheSSEconstructionof[5]accommodatesdynamicupdates
and new paths as possible.
and does not leak keyword patterns on updates as each new
keyword-document pair is added to the index using a freshly The position map which keeps track of the current leaf
random key generated by a PRF that takes a counter as input. position for each entry is typically stored on the server side in
This meets requirements (1) and (3). They also address the its own ORAM. This leads to many round trips of interaction
IO efficiency issue by storing document IDs in larger blocks for each read/update which is a non-starter for a real-time
and hence retrieving many documents IDs using a single disk applicationsuchasemail.Wenotethatforemail,itisfeasibleto
access. This provides a partial solution to the IO efficiency and storethepositionmapclientside.Asshownintheexperiments
fastsearch,butthesolutionisnotsuitableforahighly-dynamic in Section IV-C, this storage will not exceed 70MB in 10 years
application such as mail. for the 95th percentile user and for most users is closer to
35MB.
Inparticular,themainchallengeistopackmultipleupdates
(i.e. a set of new keyword-document pairs) into a large block, Even with the position map stored on the client side, a
before pushing them into the encrypted index. The naive read or write entails reading everything on the path from a leaf
solution of storing the partial blocks in the same index and to the root, performing some client side operations, and then
adding new keyword-document pairs on each update leaks the writing back along that path. In other words, in Path ORAM
update pattern which is a major drawback for an update-heavy (and ORAM in general), entries are shuffled both in case of
application such as email. reads and writes.
Our construction consists of two pieces: the obliviously At first glance, in the case of a lookup in the oblivious
updatable index (OUI), a small dynamic encrypted index for index, we can simply omit the complicated machinery for a
partial blocks, and the full-blocks index (FBI), a large append- read of the ORAM (which we only need for reads and writes
only encrypted index for full blocks. for index updates) and directly access a single entry in the tree.
We do not care if repeated index accesses to the same location
The full-block index holds a mapping from an encrypted
are identifiable. However, there are two issues with this. First,
keyword to a fixed-size block containing document IDs. New
the position map only stores what leaf an entry was mapped to,
entries can be added to this index only when we have a
not the particular point along the path from leaf to root where
full block. This is the basic approach taken by [5] for static
it is stored. This can be fixed by storing, for each keyword,
encrypted search, though they expand on it to deal with far
additional information to locate the entry.
larger data sets than we wish to.
The larger issue is that the reshuffling that occurs on a
The main technical challenge in our construction is the
read provides privacy protections not just for the read (which
design of OUI for managing partially-filled blocks until they
is not important for us) but for subsequent reads and writes.
are full and can be pushed to the FBI. In particular, note that
If reads are not shuffled, then an observer can identify when
the blocks in OUI need not be full and are instead padded
frequently looked up index entries are updated. As a result,
to some fixed size. When a block is full of real data (i.e. no
we cannot simply have a “half-ORAM”: to get completely
padding) its contents are transferred to the full-block index.
oblivious writes, we must at some point reshuffle the locations
This allows messages to be added and deleted from the OUI
we read from.
by updating the requisite block. Of course, we must do so in
a way that does not leak which blocks are being updated, or Crucially, in our obliviously updatable index, we need not
else we fail to meet the basic requirements for secure search do this on every read (as in ORAM), rather we can defer the
by leaking update patterns. shuffling induced by a non-oblivious read to the beginning of
an update. We call these deferred reads.
A. An Obliviously Updatable Index
This enables considerable savings. First, since updates can
ORAM forms a generic starting point for our obliviously bebatched(i.e.,wecollectabunchofupdatestovariousentries
updatable index. In particular, storing partial blocks in ORAM locally and only commit them to the server later), we can shift
would allow us to update them privately. However, as a generic the computational and bandwidth load to idle time (e.g. when
approach, ORAM is an overkill. An index built on top of a mobile device is plugged in and connected to wifi) at the
ORAM would hide not only reads and writes resulting from cost of temporary client storage. Second, repeated searches for
an index update, but also reads resulting from an index lookup. the same term only result in one deferred read. Third, searches
6for terms that are mapped to the same leaf also only result in (cid:104)σ,EDB(cid:105)↔ SSESETUP(cid:104)(1λ,⊥),⊥(cid:105):
one shuffle operation. Finally, because paths overlap even for
distinct leaves, we will realize considerable savings: e.g. for 1: Client runs (h c,M c) ← hsetup() to setup a local
10 deferred read shuffles, we will end up transmitting the root hash table.
of the tree once instead of 10 times, the children of root twice 2: Serverruns(h s,M s)←hsetup()tosetupanappend-
instead of 5 times, etc. Looking forward to our evaluation, this only hash table.
results in over 90% savings in accesses compared to the simple 3: for w ∈|W| do
Path ORAM. 4: pos w ←R {0,...,2L}
We note that write-only ORAM constructions [1] do not 5: count w,r w,(cid:96) w ←0, B w ←∅
solveourproblem.Write-onlyORAMisusedinsettingswhere 6: Client runs M c ←hwrite(w,[pos w,(cid:96) w,count w,
reads leave no record (e.g. where an adversary only has access r ,B ],M )
w w c
tosnapshotsofanencrypteddisk,whichrevealschangesdueto 7: end for
writes but not reads.). In these settings, the initial read needed 8: k f ←K(1λ), k e ←KG(1λ), k a ←KG(1λ)
to determine the contents of the block being appended to can 9: Client and server run the setup for a non-recursive
be done in the clear. We cannot do that here since we must Path ORAM. Server stores the tree T, and client
request the partial bock from the server before appending to it. stores the stash S.
Tosummarize,ourobliviouslyupdatableindexisamodified
10: Client outputs σ =(M c,S,k f,k a,k e)
Path ORAM scheme with the following changes:
11: Server outputs EDB=(M s,T)
• We keep the position map on the client slide and augment Fig. 3: Setup for our DSSE scheme
the position map to allow us to locate index entries inside
a given path from leaf to the root.
• Onnon-obliviousreads:welookuptheentrydirectlyfrom
The client generates three random keys k , k , and k , one
its position in the tree (i.e. one disk access), but add the f e a
forthePRFF,andtheothertwofortheCPA-secureencryption
leaf to the list of deferred reads.
scheme.
• On batched reads and updates: we read all paths in the
set of deferred reads since the last batch updated and all The client and server initialize the obliviously updatable
the paths associated with the updates themselves. We then index, i.e., a non-recursive Path ORAM for a memory of size
remap and edit the entries on these paths as in standard |W|. We denote the tree stored at the server by T, and the
Path ORAM and write them back to the ORAM at once. correspondingstash storedat theclient byS.For allreferences
to Path ORAM we use the notation introduced in Section II-C.
Security Intuition Deferred shuffling for reads ensures that The server also sets up an initially empty full-block index, i.e.,
when a non-deferred read/write happens, the system is in the an append-only hash table that will be used to store full blocks
exact same state as it would be in full Path ORAM. Intuitively, of document IDs.
this models the effect of shuffling a deck of cards: no matter
what the previous state was and how the deck was rigged, the For every w ∈W, the client stores in a local hash table the
shuffle is still good. key-valuepair(w,[pos w,(cid:96) w,count w,r w,B w]),whereB w isa
block storing IDs of documents containing w (initially empty),
More formally, our approach means that after the deferred pos stores the leaf position in {0,...,2L} corresponding to
w
read, the position map entries are statistically independent of w(chosenuniformlyatrandom),(cid:96) storesthelevelofthenode
w
eachother,andweretainthesecurityconditionforPathORAM on path P(pos ) that would store the block for documents
that (cid:81)M Pr(position(a ))=( 1 M ) for non-deferred oper- containingw(inw itiallyempty),count storesthenumberoffull
j=1 j 2L w
ations.Ofcourse,wehaveleakedsubstantialinformationabout blocks for keyword w already stored in the append-only hash
the prior state of the index, but that leakage is allowed in SSE! table (initially 0), and r is a bit indicating whether keyword
w
Rather than proving this separately, we will capture it in the w is searched since the last push of the client’s block to Path
proof of security for the SSE scheme itself. ORAM (initially 0).
The client’s state σ will be the hash table M , the stash S
B. The Full Protocol c
for the Path ORAM, and the keys k ,k ,k .
e f a
Next, we describe our full DSSE scheme for email which
is a combination of the OUI described above and a separate Search.(Figure4)Theclientwillstorethematchingdocuments
index for full blocks. A detailed description follows. in the initially empty set R = ∅. To search locally, the
client first looks up w in its local hash table to obtain
Let H =(hsetup,hlookup,hwrite) be a hash table imple- [pos ,(cid:96) ,count ,r ,B ], and lets R=R∪B .
w w w w w w
mentation, E =(KG,Enc,Dec) be a CPA-secure encryption
scheme and F : K ×M → C be a pseudorandom function. It then asks the server for the bucket in the tree T at node
Let W be the universe of all keywords, and L=log(|W|). level (cid:96) w and on path P(pos w), i.e., P(pos w,(cid:96) w). It decrypts
the blocks in the bucket using k . If it finds a tuple (w,O ) in
Setup. (Figure 3) For simplicity, we assume that the DB e w
the bucket, it lets R=R∪O . If r is not yet set, the client
w w
is initially empty, and documents are dynamically added. If
lets r =1 to indicate that w was searched for.
w
not, one can run the SSEADD protocol we describe shortly
multiple times to populate the client and server storages with For i = 1,...,count , the client sends F (w||i) to the
w kf
the documents in DB. server, who looks it up in the append-only hash table and
7SSESEARCH(cid:104)(σ,w),EDB=(T,M s)(cid:105): SSEADD(cid:104)(σ,id d),EDB(cid:105):
1: R←∅ 1: for w ∈d do
2: [pos w,(cid:96) w,count w,r w,B w]←hlookup(w,M c) 2: [pos w,(cid:96) w,count w,r w,B w]←hlookup(w,M c)
3: R←R∪B w 3: B w ←B w∪{id d}
4: U ← READBUCKET(P(pos w,(cid:96) w) 4: hwrite(w,[pos w,(cid:96) w,count w,r w,B w],M c)
5: Read (w,O w) from U 5: size c ←size c+1
6: R←R∪O w 6: end for
7: r w ←1 7: if size c <max c then
8: hwrite(w,[pos w,(cid:96) w,count w,r w,B w],M c) 8: return
9: for i∈{1,...,count w} do 9: else
10: Client sends F kf(w||i) to server 10: U ←{w ∈|W|:r w ==1}
11: Server returns C wi ←hlookup(F kf(w||i),M s) 11: for w ∈U do
1 12 3:
:
A Ri w ←← RD ∪e Ac k
i
wa(C wi) 12:
M c)
[pos w,(cid:96) w,count w,r w,B w] ← hlookup(w,
14: end for 13: for (cid:96)∈{0,...,L} do
15: Client outputs R 14: S ←S∪READBUCKET(P(pos w,(cid:96)))
15: end for
Fig. 4: Search for our DSSE scheme 16: end for
17: for (w,O w)∈S do
18: O w(cid:48) ←O w∪B w
returns the encrypted full block Ai w. The client decrypts using
1 29 0:
:
if |O cow(cid:48) u| n>
t
wm ←ax cb ot uh ne tn
w+1
k a and lets R = R ∪ Ai w. The client then outputs R. See 21: O w(cid:48)(cid:48) ← first max b items in O w(cid:48)
Figure 4 for details. 22: hwrite(F kf(w||count w),O w(cid:48)(cid:48),M s)
Update. (Figure 5) Let id
d
be the document identifier associ- 23: O w(cid:48) ←O w(cid:48)(cid:48) −O w(cid:48)
ated with d. For every keyword w in d, the client looks up w 24: end if
in its local hash and adds id
d
to B w. It then checks whether its 25: S ←(S−{(w,O w)})∪{(w,O w(cid:48) )}
local storage has reached the maximum limit max or not. If 26: end for
c
not,theupdateis done.Else,weneedtopushallthe document 27: for (cid:96)∈{L,...,0} do
blocks to the server. 28: S(cid:48) ← {(w(cid:48),O w(cid:48)) ∈ S : P(x,(cid:96)) =
P(pos ,(cid:96))}
w(cid:48)
But before doing so, we need to finish the ORAM access 29: S(cid:48) ← Select min(|S(cid:48)|,Z) blocks from S(cid:48).
for all reads done since the last push. In particular, for all non- 30: S ←S−S(cid:48)
zero r w’s, the client needs to read the whole path P(pos w), 31: WRITEBUCKET(P(x,(cid:96)),S(cid:48))
re-encrypt allthe buckets usingfresh randomness,update pos w 32: for (w,O w)∈S(cid:48) do
to a fresh random leaf, and write the buckets back to the tree 33: (cid:96) w ←(cid:96)
using the Path ORAM approach. 34: r w ←0
Then, for every non-empty block B in its local hash, the 35: B w ←∅
client performs a full ORAM write tow add the documents in 36: pos w ←R {0,...,2L}
B
w
to the ORAM block O
w
for the same keyword. If O
w
37: hwrite(w,[pos w,(cid:96) w,count w,r w,B w],
becomes full as a result, max
b
documents IDs in the block M c)
are removed and inserted into Acountw+1, and inserted to the 38: end for
w
append-only hash table using a keyword F (w||count +1). 39: end for
See Figure 5 for details.
kf w
40: size c ←0
41: end if
C. Security Analysis Fig. 5: Update for our DSSE scheme
As noted in Section II, security of an SSE scheme is
defined with respect to a leakage function L on the database of
documentsDBaswellasthehistoryofsearch/updateoperations
the pattern of searches for w in the history H. Note that this
in the index. We first specify the leakage function for our i
doesnotleakw itself,butonlythelocationofallsearch/update
construction. i
queries for w in the sequence all previous read/updates. On
i
an update query d , the leakage function L(DB ,H) leaks
The Leakage Function Recall that DB = (d ,W )N is the i i−1
i i i=1 the total number of keywords in d , and also the total number
database of document-keyword pairs and W =∪N W is the i
i=1 i of keywords in d for which the number of documents in the
universe of keywords. i
index has reached the multiple of our designated block-size.
During the setup, L(DB) outputs the size of database |DB|, Again, this does not leak what the actual keywords are and
i.e., the total number of initial document-keyword pairs in the how they are related to previous searches/updates (no leakage
database.Forsimplicitywecanassumethisiszeroinitially.On of patterns). This leakage on updates simply captures the fact
eachsearchqueryw ,theleakagefunctionL(DB ,H),leaks that the server learns when full-blocks are pushed from the
i i−1
8partial-block index to the full-block index. Section. We consider adversary’s view for the search queries
and update queries separately. On update queries, both in the
Theorem 1: Our SSE Scheme is L-secure (see definition
real protocol and in H , the location to be updated in the OUI
in Section II-D), if F is a pseudorandom function, and E is a 2
isgeneratedusingaPRFasdescribedintheprotocol,andsois
CPA-secure encryption scheme.
thelocationtobeaddedtothefull-blockindexforallkeywords
Proof Sketch: First, we need to describe a simulator S that that have reached a full block during this update. Similarly, in
given access to the leakage function describe above, simulates both cases, the real document keywords used for generating
the adversary A (i.e. untrusted server’s) view in the real world. locations and the real document identifiers are encrypted. So
the two views are identical.
Description of the Simulator: The simulator initializes a
local position map that it uses for bookkeeping, just as the In case of read queries, if the keyword is being searched
honest client would. for the first time, again the leaf location to be looked up in
both the real protocol and H are generated using a PRF, and
2
On each update query d (or many updates if they are
i for repeated reads, in both cases, the exact same locations in
batched), the simulator learns the number of keywords in d ,
i the OUI and the full-block index are looked up. Hence the two
n. It also learns the total number of keywords in d that just
i views are identical. This concludes the proof sketch.
reachedafullblock(m)andneedtobepushedtothefull-block
index. It also knows (from the state it is keeping) the location
of the leaf for all deferred reads since the last update. The
IV. EVALUATION
simulator behaves similar to the honest client, except that he In this section we assess the feasibility and performance of
generates the leaf location for each keyword being updated our SSE scheme for email, using experiments that are based on
uniformly at random and the m locations in the full-block real data. The two important requirements we focus on in our
index where the newly filled blocks will go also uniformly at evaluation are (1) storage usage both on the server side and
random. It keeps record of all these locations in its position the client side, (2) IO performance on the server side. Again,
map. Also, for all encrypted blocks it needs to send, it simply as existing (non-encrypted) mail search is already IO bound,
generates fresh encryptions of dummy values using a random our primary concern is the second criteria.
encryption key it generates.
On each search query for w , S learns (from the leakage A. Real World Data
i
function) all previous occurrences of search/update for w . If
i Note that the performance of any SSE scheme critically
this is the first occurrence, it chooses a random entry on the
dependsontwomainpiecesofinformation:(1)thedistribution
ORAM tree for the OUI, a sequence of random locations that
and frequency of updates to the index, i.e., new keyword-
have not yet been looked up in the full-block index, and also
document pairs added to the search index, and (2) distribution
stored these locations for bookkeeping. But if it is not the first
and frequency of the keywords being searched.
occurrence, S has previously stored the locations in the partial-
block and full-block index it had sent to the server. It simply
Data on Index Updates for Email Our email data comes
sends the same locations to the server again. This completes
from Yahoo Webmail. Yahoo mail has hundreds of millions of
the description of the simulator.
monthly active users and maintains a 30 day rolling window of
We need to show that the simulated view above is indistin- customer email for research. This dataset consists of the sent
guishable from the view of the adversary in the real execution. and received emails of over one hundred thousand users who
We do so using a sequence of hybrids. opted into email collection for research. For privacy reasons,
weextractonlythefrequencyofkeywords,nottheactualwords
H : In the first hybrid, the adversary is interacting with the
0 themselves and all analysis of the data itself was performed
simulator described above. In other words, all ”random”
directly on the map-reduce cluster containing the dataset: only
locations are generated uniformly at random and indepen-
the counts of each token, not the tokens themselves, were
dently, and all encrypted values are dummy values.
exported. On average, users receive 30 emails per day with a
H : In the second hybrid, all locations that were generated
1 standard deviation of 148. Furthermore, each message contains
uniformly at random are instead generated by the client
an average of 143 (unstemmed) keywords in it with a standard
using a PRF with a random key k not known to the
f deviation of 140.
adversary.
Note that the advantage of an adversary in distinguishing For all keyword data, we strip HTML from the messages
these two hybrids is bounded by the advantage of an and use the standard tokenizer and stopword list from Apache
adversary in breaking the PRF security. Lucene.5 No stemming or other filtering was applied. Between
H : Inthethirdhybrid,alldummyencryptionsarereplacedby thisandthefactthatthedatasetspannedmorethanjustEnglish,
2
the encryption of actual document identifiers (chosen by our data represents an upper bound for the “index everything”
the adversary) using a semantically secure symmetric-key approach. We identified a total of 62,131,942 keywords in our
encryption as prescribed in the real protocol. dataset across all 100K users’ email. As the estimated number
The advantage of the adversary in distinguishing the two of words in the English language is in the order of one million,
games is bounded by the security of the CPA-secure there is ample room for stemming and filtering to drastically
encryption scheme used to encrypt document identifiers. reduce this. Nevertheless, we stick with this number for our
experiments as an empirical worst case measurement.
It only remains to show that the view of the adversary in
H
2
is identical to the real protocols described earlier in this 5WeusedthelistStopAnalyzer.ENGLISH_STOP_WORDS_SET.
9Approximating query data For two reasons, we do not have sents the state of the art schemes under purely dynamic
access to comprehensive query data. First, there is no such insertion [5,20], which perform identically.
dataset of users’ queries for which users explicitly opted in. • Our solution but with a naive implementation of an
Second,existingmailsearchsupportsmorethansinglekeyword Obliviously Updatable Index built with Path ORAM.
queries and as such queries are often in natural language. It is
Because we are mainly concerned with the IO cost, it was
unclear how to appropriately generate keyword searches from
not necessary to implement the comparison systems. For the
such data. As such, for the sake of experiments, we assume
current state of the art encrypted index, the number of random
search terms are selected uniformly at random from the set of
writeswillsimplybeequaltothenumberofinsertedkeywords,
all indexed words.
and the number of random reads equal to the number of search
Given the low number of queries, we anticipate that the results.Thisprovidesalowerboundonthenumberofaccesses
overall effect of this is minimal. The primary concern in our required for all of the DSSE schemes we compare with.
evaluation is the effect of the large number of updates on
ForasolutionthatusesthePathORAMschemeastheOUI,
storage and performance requirements.
the cost of a search is dominated by one ORAM read and one
ORAM write. An ORAM “read” would be recorded as many
B. IO Performance of IO-DSSE reads by our code as each level in the path generates a distinct
access.Thus,insteadofonenon-deferredreadasinourscheme,
We now examine the IO performance of IO-DSSE relative
we charge oramHeight reads and oramHeight writes. By
to the operating conditions we observe at Yahoo. Our goal is
read or write, we mean the access of a single key-value pair
to measure the ability of our scheme to scale out to millions of
in the underlying server-side data structure.
concurrent instances on arbitrary (and likely proprietary) cloud
infrastructure. As a result, we model such an system abstractly A third approach we could compare against is a variant
as a key value store and measure the number of reads and of Cash et al. scheme [4] where full-blocks are stored on the
writes against it. We implement our scheme in Python against server-side, and partial blocks are stored locally on the client
this abstraction. side. This would exhibit better performance than our scheme
in the short term, because it reduces IO costs compared to an
Our measurements are taken over 30 days of traffic
OUI. However, when the client-side storage becomes full, the
generatedusingthesampleddistributionofkeywordsdiscussed
blocks need to be pushed to the index even if they are only
above and is repeated for 50 iterations. We assume that the
partially full and indeed maybe almost empty. As we will see
system pushes all client-side email messages to the server
in the storage discussion, this does not work in practice as
every day. This models a mobile device that has access to a
the client would need to regularly push partially-filled blocks
free Internet connection when at home. Given that we fix the
to the static index, hence defeating the IO efficiency gains of
distribution of keywords, we are left with three variables: the
packing many documents identifiers into one block.
number of searches, the number of emails per day, and the
number of keywords per email. Using our implementation, we measure:
Forsimplicity,wefixthenumberofkeywordsat350(thisis Total IO savings: The total amount of IO saved compared to
twostandarddeviationsabovetheaverage),andvarythenumber the existing approach of SSE schemes (including [5,20]
of email messages starting with the average and incrementing underpurelydynamicinsertion).Thisincludesbothsearch
by the standard deviation. This has the net effect of changing and update.
the total number of updates per day which (along with the IO savings for search: The amount of savings on read due
distribution of keywords) is the actual controlling variable for to search, ignoring deferred reads. This represents the
performance. Similarly, we fix the number of searches at one immediate cost of a search and also the associated latency
per day, modeling an active user (at Yahoo the average user savings.
searches message content once per month.). IO savings vs. ORAM: Total IO savings when using an OUI
vs. ORAM. This is the savings due to our optimized
Finally, we somewhat arbitrarily fix the Path ORAM obliviously updatable index that does not require full
parameters, assuming a height of 17 at 4 buckets per level ORAM security.
with each ORAM entry containing a block of 500 identifiers
(at 64 bits per file ID, this gives us blocks that approximately The results show (see Figure 6) a 99% percent reduction
fit in a 4KB disk block). Real deployments should tune these in the IO cost of our scheme compared to a scheme that does
parameters dependent on system architecture and testing. We one random read per search result and one random write per
stress again that our goal is not to see how our system handles keyword-documentpair.Thisisslightlydifferentfromthenaive
large indexes—individual mail inboxes are at most tens of estimate for the savings of simply batching IO into contiguous
x− x
gigabytes—but to measure the resources used by a small index. blocks of 500 (our chosen block size), i.e., 500 =0.998 due
x
Thisallowsustoseehowcostlyitistodeployinasettingwith to both the overhead of access to our obliviously updatable
hundreds of millions of inboxes and thus indexes supported by index and the fact that entries will not be packed perfectly,
a minimal number of servers. instead being added in smaller groups as they arrive. However,
some entries will still be in the stash locally and therefore will
Our experiment measures the actual IO savings of our
not be read from the index. These two issues appear to roughly
scheme against:
cancel out.
• An encrypted index which, for updates, stores each We show a 94% percent reduction in the reads required
keyword-document pair at a random location. This repre- by the server for a search query for our scheme vs. simply
10Fig. 6: Experimental and simulated results. IO savings for IO-DSSE vs existing approach and vs an obliviously updatable index
constructed with PATH ORAM.
construction an obliviously updatable index with ORAM. This difference if all of the storage is used holding an entry for a
shows that optimizations stemming from the relaxation of single keyword appearing in two million emails or one million
ORAM’s security properties are effective. keywords each in one email. To a first approximation, client
storage is directly proportional to the number of documents
This is both an important cost saving and a large reduction
keyword pairs (as we store less than 8 bytes per unique
in the latency of serving the first page results. These results
keyword). As shown in Figure 6, we use 62.7MB±13.2KB
are exactly as predicted, since we do one read instead of 17
for a 95th percentile user and 33.4MB±11.8KB for a 50th
(the length of a full path for the chosen parameters) and save
percentile user.
17−1 = .941. Finally, our experiments show a 20% to 82%
17
reductionintheIOneededtoreturnasearchresult.Sincesearch
Server storage for partial-block index Of course, once the
terms are selected uniformly at random from the set of results,
client’sstorageisfull,wemustevictentriesintotheobliviously
manysearcheshaveonly1or2documentsassociatedwiththem,
updatable index, starting with the most full. For OUI, keyword
needingonlythesmallcorrespondingnumberofreadsfromthe
distribution comes into play. At some point the index will be
naive index vs. one read from the obliviously updatable index
full of infrequent words and we will be forced to evict partial
inourscheme.Forthose,ourschemeofferslittleadvantage.As
blocks into the full-block index. The main questions we need
we increase the number of received messages, the total number
to answer are 1) how often does this happen and 2) how large
of indexed documents and therefore the expected number of
of a partial-block index we need to ensure it does not happen
results per search increases and our scheme becomes more
too soon.
efficient. The variance in the number of results per search term
alsoaccountsforthevarianceinthemeasuredresults.Weagain
To measure this directly would involve experiments span-
note that, given the relative infrequence of searches against the
ning the expected lifetime of a user’s mail account, which
index compared to updates, this is not the crucial metric to
is prohibitive to evaluate with a real implementation. Instead,
optimize for.
we conduct a Monte Carlo style simulation. We draw words
at random, according to the measured distribution of tokens
C. Simulated Long-term Storage Usage described in the previous section and measure how long it
takes before we are forced to evict a partially full block from
We now examine the storage requirements for IO-DSSE
the OUI. Our simulator merely keeps track of how space is
bothontheserverside(i.e.howlargetheobliviouslyupdatable
allocated locally (client-side) and in the OUI and at what point
index needs to be) and on the client side in terms of stored
each becomes full and forces an eviction. The simulator does
metadata.Thenecessarysizeoftheobliviouslyupdatableindex
not provide actual search results as the intention here is to
is a function of the distribution of keywords, the rate of arrival
assess storage requirements.
of keywords, and the amount of available local storage that
can be used to buffer results on the client. We assume a local store of 128MB and 64-bit email
identifiers. We assume the cost of adding a new keyword
Client storageBecausethelocalclientistrusted,weareunder to the index is 100 bits. Rather than specifying a fixed size
no constraints as to how the storage is laid out and need not for the OUI, we simply measure how many blocks would be
obscure its access pattern. As a result, it does not make a needed to fit the entire index.
11Fig. 7: Simulated long term storage for IO-DSSE. Left: the size of the obliviously updatable index needed (i.e. server side storage)
as time goes on for users of different activity levels. Right: the size of the client’s storage under the same conditions.
Our simulation validates that the general approach of techniques insert each document ID associated with a given
splitting the index into a partial-block and full-block index keyword into a random location in the index.
is viable, showing that even for a 95th percentile user, 2GB
of partial-block index is sufficient to hold ten years worth of
B. Attacks
email or nearly 100 years of email for the average user.
Recently Zang et al. [22] construct a highly effective query
As the graph in Figure 6 shows, however, there appears
recovery attack on SSE schemes. The attack leverages the
to be no upper bound on the size of the index, short of the
fact that an attacker who can insert entries into the index can
total number of observed words. This validates the following
construct them such that the subset of attacker files returned
intuition:evictingfrequentwordsfromtheOUIwhentheblock
uniquely identifies the queried keyword. Effectively, this is a
is full ultimately does not free enough space for infrequent
more efficient version of the attacker inserting one unique file
words. That space will immediately be occupied by (in many
per possible keyword which contains only that single keyword.
cases the same) frequent word. The long tail of keywords
Asthisattackrequiresanadversarytoinsertfilesintotheindex,
causes problems. To accommodate this, providers must either
it cannot be mounted by an adversary who wishes to passively
(1) limit the number of indexed words (e.g. to English words),
surveil many users. None-the-less, our scheme is subject to the
or (2) limit the amount of indexed email. In the case of a
attack, and indeed if used for email, highly susceptible due to
limited set of keywords, the obliviously updatable index would
the ease with which an attacker can insert files. This makes
have a fixed size.
the scheme useful for end-to-end encryption settings which
protect against dragnet surveillance. However, it should not be
Deletes Recall, we can only delete emails from the obliviously used in scenarios where greater protection against an actively
updatable index, so any index entries that have been evicted malicious mail server is needed. Also, as the attack depends
from the OUI are permanent. How long does this give us to only on observing retrieved files, there appears to be no simple
fully delete a message (i.e. all index entries resulting from countermeasures. Forward private SSE schemes [3] do thwart
that message’s arrival)? For a 95th percentile user, the most the adaptive version of the attack that requires injecting fewer
frequent word is evicted 6724.8±3.22490 times in 3650 days files, but again at a large locality cost. Moreover as Zang et
or 2 evictions per day. For such a user, all index entries for an al. make clear, the non-adaptive attack still works even with
email can only be deleted within a day of arrival. For the 50th forward privacy and that attack is readily mountable in the
percentile user, on the other hand, where the most frequent setting of email.
word is evicted 319.4±0.843274 times in 3650 days, all index
Wearehopefulthatsomemethodofinjectingnoiseintothe
entries for an email can be removed if the email is deleted
results or merely detecting when this attack has been mounted
within an expected 11 days of arrival.
will be developed. As these techniques likely operate over
the logical structure of the index, our scheme should be fully
V. RELATEDWORKANDATTACKS
compatible with them. But absent such countermeasures, SSE
in the email setting is only secure against passive adversaries
A. Related work on searchable encryption
regardless of its IO efficiency.
Searchable encryption has been studied in an extensive line
of works [5,7,8,10,15,19]. Very few works have focused
VI. EXTENSIONSANDCONCLUSIONS
on efficiency or locality. Cash et al. [5] provide the best
such approach. As we stressed in the introduction, however, Encrypted search for email or similar messaging systems
this approach does not help in the dynamic case: all existing represents a major obstacle for E2E encrypted applications. All
12existing built solutions place a prohibitively high IO cost on [2] BONEH, D., MAZIERES, D., AND POPA, R. A. Remote oblivious
updating the index on message arrival: requiring one random storage:Makingobliviousrampractical.
write per document-keyword pair and one random read per [3] BOST,R. Sophos-forwardsecuresearchableencryption. Cryptology
search. Using a hybrid approach where updates are done to ePrintArchive,Report2016/728,2016. http://eprint.iacr.org/2016/728.
a dynamic ORAM-like index and then evicted to a chunked [4] CASH, D., JAEGER, J., JARECKI, S., JUTLA, C., KRAWCZYK, H.,
index typically used for static searchable encryption, we are
ROSU,M.-C.,ANDSTEINER,M. Dynamicsearchableencryptionin
very-largedatabases:Datastructuresandimplementation. InNetwork
able to reduce the total IO usage by 99%, and by building a
andDistributedSystemSecuritySymposium(NDSS’14)(2014).
dynamic index that does not protect read privacy, we are able
[5] CASH,D.,JARECKI,S.,JUTLA,C.,KRAWCZYK,H.,ROS¸U,M.-C.,
to achieve a 94% reduction in the upfront costs of search. ANDSTEINER,M. Highly-scalable searchable symmetric encryption
withsupportforbooleanqueries. InAdvancesinCryptology–CRYPTO
Our approach, of course, is still more expensive than non-
2013.Springer,2013,pp.353–373.
encrypted search, and deploying for email is, in the end, a cost-
[6] CASH,D.,ANDTESSARO,S. The locality of searchable symmetric
benefit analysis between the value of protecting user privacy encryption. InAdvancesinCryptology–EUROCRYPT2014.Springer,
andtheoperatingcost.Butthisisatleastnowatrade-offthatis 2014,pp.351–368.
fareasiertomakegivenourperformanceimprovements.Indeed, [7] CHASE,M.,ANDKAMARA,S. Structuredencryptionandcontrolled
withoutsuchareductioninIOcost,thecostofencryptedsearch disclosure.InAdvancesinCryptology-ASIACRYPT2010.Springer,2010,
pp.577–594.
for email is too high.
[8] CURTMOLA, R., GARAY, J., KAMARA, S., AND OSTROVSKY, R.
Achieving this comes at some cost. First, we must slightly Searchable symmetric encryption: improved definitions and efficient
relaxtheleakagefunctionforsearchableencryption:anattacker constructions. InProceedingsofthe13thACMconferenceonComputer
andcommunicationssecurity(2006),ACM,pp.79–88.
learns when entries are moved from the partial to full-block
index,andweleakslightlymoretoanactiveattacker.Second,at [9] DAMGA˚RD,I.,MELDGAARD,S.,ANDNIELSEN,J.B. Perfectlysecure
oblivious ram without random oracles. In Theory of Cryptography.
present,weonlysupportdeletesfromtheobliviouslyupdatable
Springer,2011,pp.144–163.
index, and third, we only provide single keyword search.
[10] GOH,E.-J.,ETAL. Secureindexes. IACRCryptologyePrintArchive
2003(2003),216.
FutureworkandextensionsThetechniquesofCashet.al [5]
[11] GOLDREICH,O. Towardsatheoryofsoftwareprotectionandsimulation
canreadilybeappliedtoourapproachtogetconjunctivesearch. by oblivious rams. In Proceedings of the nineteenth annual ACM
We can simply use their (or any other similar) scheme directly symposiumonTheoryofcomputing(1987),ACM,pp.182–194.
forthefull-blockindex.Intheirscheme,akeywordisassociated [12] GOLDREICH, O., AND OSTROVSKY, R. Software protection and
with a key used specifically for computing intersection tags simulation on oblivious rams. Journal of the ACM (JACM) 43, 3
xtag based on indexes and set of all such tags xSET is stored (1996),431–473.
by the server. Because no additional data is associated with [13] KAMARA,S.,ANDPAPAMANTHOU,C.Parallelanddynamicsearchable
symmetric encryption. In Financial cryptography and data security.
the index entries on the server, and tags can safely be added
Springer,2013,pp.258–274.
to xSET without additional leakage, this technique can be
[14] KAMARA, S., PAPAMANTHOU, C., AND ROEDER, T. Dynamic
applied to our approach simply by having the server store the searchable symmetric encryption. In Proceedings of the 2012 ACM
tag set. conferenceonComputerandcommunicationssecurity(2012),ACM,
pp.965–976.
To deal with deletes, it is possible to incrementally rebuild
[15] NAVEED,M.,PRABHAKARAN,M.,ANDGUNTER,C.A. Dynamic
the index. Instead of appending to the full index on eviction,
searchable encryption via blind storage. Cryptology ePrint Archive,
we can with some small probability overwrite a block in the Report2014/219,2014. http://eprint.iacr.org/.
full index with one evicted from the partial index, storing [16] PAPPAS,V.,KRELL,F.,VO,B.,KOLESNIKOV,V.,MALKIN,T.,CHOI,
the overwritten block locally and then incrementally feeding S.G.,GEORGE,W.,KEROMYTIS,A.,ANDBELLOVIN,S. Blindseer:
the non-deleted entries back. Thus the entire index would A scalable private dbms. In Security and Privacy (SP), 2014 IEEE
Symposiumon(2014),IEEE,pp.359–374.
periodically be refreshed. However, careful analysis of the
specific rate of deletion is needed to check if this approach
[17] POPA,R.A.,REDFIELD,C.,ZELDOVICH,N.,ANDBALAKRISHNAN,
H. Cryptdb:protectingconfidentialitywithencryptedqueryprocessing.
provides any practical benefit. In Proceedings of the Twenty-Third ACM Symposium on Operating
SystemsPrinciples(2011),ACM,pp.85–100.
Finally, it is an interesting question whether similar relax-
ations to ORAM security can be used to build an obliviously [18] SHI, E., CHAN, T.-H. H., STEFANOV, E., AND LI, M. Oblivious
ram with o ((logn) 3) worst-case cost. In Advances in Cryptology–
updatable index with something other than Path ORAM and
ASIACRYPT2011.Springer,2011,pp.197–214.
with even better efficiency.
[19] SONG,D.X.,WAGNER,D.,ANDPERRIG,A. Practicaltechniquesfor
searchesonencrypteddata. InSecurityandPrivacy,2000.S&P2000.
ACKNOWLEDGMENTS Proceedings.2000IEEESymposiumon(2000),IEEE,pp.44–55.
[20] STEFANOV,E.,PAPAMANTHOU,C.,ANDSHI,E. Practicaldynamic
This work was supported in part by The National Science
searchable encryption with small leakage. IACR Cryptology ePrint
Foundation under award CNS-1228443. We would also like to Archive2013(2013),832.
thank David Cash, Seny Kamara, Charalampos Papamanthou [21] STEFANOV,E.,VANDIJK,M.,SHI,E.,FLETCHER,C.,REN,L.,YU,
and the anonymous reviewers for discussions and helpful X.,ANDDEVADAS,S. Pathoram:Anextremelysimpleobliviousram
comments. protocol. In Proceedings of the 2013 ACM SIGSAC conference on
Computer&communicationssecurity(2013),ACM,pp.299–310.
REFERENCES [22] ZHANG, Y., KATZ, J., AND PAPAMANTHOU, C. All your queries
are belong to us: The power of file-injection attacks on searchable
[1] BLASS,E.-O.,MAYBERRY,T.,NOUBIR,G.,ANDONARLIOGLU,K. encryption. CryptologyePrintArchive,Report2016/172,2016. http:
Toward robust hidden volumes using write-only oblivious ram. In //eprint.iacr.org/2016/172.
Proceedingsofthe2014ACMSIGSACConferenceonComputerand
CommunicationsSecurity(2014),ACM,pp.203–214.
13