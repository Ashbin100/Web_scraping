Large-Scale Automatic Classification of Phishing Pages
ColinWhittaker Brian Ryner MarriaNazif
GoogleInc. GoogleInc. GoogleInc.
cwhittak@google.com bryner@google.com marria@google.com
Abstract mustbecomprehensive,error-free,andtimely. Ablacklist
that is not comprehensive fails to protect a portion of its
Phishing websites, fraudulent sites that impersonate a users. Onethatisnoterror-freesubjectsusersto unneces-
trustedthirdpartyto gainaccesstoprivatedata,continue sary warnings and ultimately trains its users to ignore the
to cost Internet users over a billion dollars each year. In warnings. Ablacklistthatisnottimelymayfailtowarnits
this paper, we describe the design and performance char- usersabouta phishingpage in time to protectthem. Con-
acteristicsofascalablemachinelearningclassifierwede- sideringthatphishingpagesonlyremainactiveforanaver-
veloped to detect phishing websites. We use this classifier ageofapproximatelythreedays,withthemajorityofpages
tomaintainGoogle’sphishingblacklistautomatically. Our lastinglessthanaday,adelayofonlyafewhourscansig-
classifier analyzes millions of pages a day, examining the nificantlydegradethequalityofablacklist[2],[30].
URL and the contents of a page to determine whether or Currently, human reviewers maintain some blacklists,
nota page is phishing. Unlike previouswork in this field, like the one published by PhishTank [25]. With Phish-
wetraintheclassifieronanoisydatasetconsistingofmil- Tank,theusercommunitymanuallyverifiespotentialphish-
lionsofsamplesfrompreviouslycollectedliveclassification ing pagessubmittedby communitymembersto keeptheir
data. Despite the noise in the training data, our classifier blacklistmostlyerror-free. Unfortunately,thisreviewpro-
learnsarobustmodelforidentifyingphishingpageswhich cess takes a considerable amount of time, ranging from a
correctly classifies more than 90% of phishing pages sev- median of over ten hours in March, 2009 to a median of
eralweeksaftertrainingconcludes. over fifty hours in June, 2009, according to PhishTank’s
statistics. Omitting verification to improve the timeliness
ofthedataisnotagoodoptionforPhishTank.Withoutver-
1 Introduction ification, the list would have many false positives coming
fromeitherinnocentconfusionormaliciousabuse.
Phishingisasocialengineeringcrimegenerallydefined An automatic classifier could handle this verification
asimpersonatingatrustedthirdpartytogainaccesstopri- task. Previously published efforts have shown that a clas-
vatedata. Forexample,anadversarymightsendthevictim sification system couldexaminethe same signalsa human
an email directing him to a fraudulent website that looks reviewer uses to evaluate whether a page is phishing [13],
like a page belonging to a bank. The adversary can use [16], [20], [21], [35]. Such a system could add verified
anyinformationthevictimentersintothephishingpageto phishingpages to the blacklist automatically, substantially
drainthevictim’sbankaccountorstealthevictim’sidentity. reducing the verification time and improving the through-
Despiteincreasingpublicawareness,phishingcontinuesto put. Withhigherthroughput,thesystemcouldevenexam-
be a major threat to Internet users. Gartner estimates that ine largenumbersof questionable,automaticallycollected
phishers stole $1.7 billion in 2008, and the Anti-Phishing URLstolookforotherwisemissedphishingpages.
WorkingGroupidentifiedroughlytwentythousandunique This paper describes such an automatic phishing clas-
new phishing sites each month between July and Decem- sifier that we built and currently use to evaluate phishing
ber of 2008 [3], [17]. To help combat phishing, Google pages and maintain our blacklist. Since its activation in
publishesa blacklist of phishing URLs and phishingURL November, 2008, this system evaluates millions of poten-
patterns[7], [29]. The anti-phishingfeaturesin Firefox 3, tial phishing pages every day. To evaluate each page, the
Google Chrome, and Apple Safari use this blacklist. We classifierconsidersfeaturesregardingthepage’sURL,con-
provideaccesstothelisttootherclientsthroughourpublic tent,andhostinginformation.Weretrainthisclassifierdaily
API[18]. using approximately ten million samples from classifica-
In order foran anti-phishingblacklistto be effective, it tion data collected over the last three months. To providetraininglabelsforthisdata,weuseourpublishedblacklist, claiming to unblock an email or chat account when given
themostcompletelistingofknownphishingpageswehave thelogincredentialsfallunderthislastcategory. Notethat
available. Since the coverageof our publishedblacklist is ifoneofthesesitesissanctionedbythethirdparty,thenit
notperfect,thetraininglabelscontainanumberofmisclas- wouldbe properlyauthorizedand thereforenota phishing
sifications. Nevertheless, our process develops classifica- page.
tionmodelsthatdemonstrateexcellentperformance,main-
taining a false positive rate well below 0.1% while main- 2.2 RelatedWork
taininghighrecall. Duringthefirstsixmonthsof2009,our
classifierevaluatedhundredsofmillionsofpages,automat-
Garera et al. described an early prototype of our cur-
ically blacklisting 165,382 phishing pages. For compari-
rentsystem,usingbothGoogle’sinternaldata,likePageR-
son,PhishTankevaluated139,340potentialphishingpages,
ank [26], and features extracted from the URL to classify
findingonly47,203actualphishingpages,duringthesame
pages [16]. Our system continuesto use some of the fea-
timespan[25].
turestheydescribewhileexpandingthefeaturesetconsid-
Thecontributionsofthispaperare: 1)Ademonstration
erably.However,theoriginalpreparationofthetrainingset
that a scalable machine learning classifier can be used to
involvedmanuallabeling,whichisnotfeasiblefortraining
automaticallymaintaina blacklistofphishingpages. 2)A
sets as large as the ones we use now. We designed a new
demonstrationthata machinelearningclassifier for phish-
trainingsystemforthispaper.
ingpagescanachieveaveryhighaccuracydespiteanoisy
Other papers have also examined the problem of auto-
trainingset. 3)Anexaminationofthevalueofcertainfea-
maticallyclassifyingphishingwebpages,buttheyhavede-
turesofawebpageintheevaluationofwhetherthatpageis
scribed experimental systems, not systems in active use.
phishing.
Also, none of these efforts used a noisy training dataset.
InSection2,wepreciselydefine“phishing”andreview
Oursystem,ontheotherhand,providesclassificationstoan
previousworkregardinganti-phishingtoolsandclassifiers.
audienceofovera hundredmillionwebusersinrealtime.
Section3 describesthe classifier’s design andhow we op-
Wecanpublishtheseclassificationswithoutfurtherreview
erateitinourproductionenvironment.Weprovideananal-
becauseourclassifiermakesfewerfalsepositiveclassifica-
ysisoftheperformanceoftheclassifierinSection4before
tionsthantheothersystemsdespiteournoisytrainingdata.
concludinginSection5.
Zhang et al. presented a system for using Google web
searchasafilterforphishingpagesbutusedonly2519ac-
2 Background
tive URLs in their most realistic dataset [35]. Also, their
conservativeclassifierdemonstratedafalsepositiverateof
2.1 DefinitionofPhishing 3%, too high to be viable without further review. Fette et
al. describeda system forclassifyingphishingemailsthat
PhishTank defines phishing as “a fraudulent attempt, sharesmanysimilaritieswithoursystem,despitenotclassi-
usually made throughemail, to steal ... personalinforma- fyingwebpages[13]. Infact,weextractmanyofthesame
tion”[25]. Inordertoprotectendusersagainstthebroadest featuresregardingpagecontentastheyextractedregarding
setofphishingscams,weuseasomewhatmoregeneraldef- emailcontent. Ludletal. alsodiscussedasystemforclas-
initionofphishingthanthis. Wedefineaphishingpageas sifyingphishingpagesbasedonfeaturesofthepagewhich
anywebpagethat,withoutpermission,allegestoactonbe- inspiredsomeofourpagefeatures[20]. Maetal. published
halfofathirdpartywiththeintentionofconfusingviewers a pair of papers describing another system for identifying
intoperforminganactionwithwhichtheviewerwouldonly maliciousURLsbyexamininglexicalfeaturesoftheURLs
trustatrueagentofthethirdparty. Notethattheseactions andfeaturesofthesites’hostinginformation[21],[22]. We
include, but are not limited to, submitting personal infor- useverysimilarfeaturesinoursystem,thoughwealsouse
mationtothepage. Inasense,ourdefinitionofphishingis a large number of features describing page content. Also,
closerto“webforgery,”thephraseusedintheFirefoxuser theydo notassign labelsfor their URLs dynamicallywith
interface, than the traditional definition of phishing. This theirclassifieraswedo.
definitioncertainlycoversthetypicalcaseofphishingpages Besidesourpublishedblacklist,anumberofotheranti-
displayinggraphicsrelatingtoafinancialcompanyandre- phishing solutions exist. For example, several vendors
questing a viewer’s login credentials. This definition also provide a blacklist similar to ours. PhishTank, described
covers phishing pages which display a trusted company’s in Section 1, makes its data available in the form of a
logosandrequestthattheviewerdownloadandexecutean downloadable feed [25]. Netcraft also makes a feed of
unknownbinary.Siteswhichclaimtobeabletoperformac- its blacklist data available to service providers and host-
tionsthroughathirdpartyonceprovidedwiththeviewer’s ingcompanies[24]. Additionally,Netcraftsuppliesatool-
logincredentialsmeetthisbroaderdefinitionaswell. Sites bar that blocks the user from browsing to phishing pagesand displays additional data, like websites’ hosting coun- sifier makes the final determination of whether a page is
tries. Otheranti-phishingtoolbars,like SpoofGuard,high- phishing on the basis of these features [5]. The classifi-
light suspicious website characteristics based on a set of cation model used by the classifier is developed in an of-
heuristics [9]. Microsoft combines a manually compiled fline training process. The training process uses features
blacklist with heuristic analysis in its latest version of In- collected by the classification system over the past three
ternetExplorer[23]. monthslabeledaccordingtoourpublishedblacklist.
Wuetal. examinedthevalueofanumberofthesetools Using ourpublishedblacklist in this fashion introduces
in the context of a series of simulated phishing attacks, theriskoffeedbackloops,whereanerrorinourpublished
though they did not examine any clients using Google’s datapropagatestoclassificationmodelsusedtogeneratead-
blacklist[33]. Theyalsoquestiontheeffectivenessofthese ditionalpublisheddata. Tominimizethisrisk,we alsoex-
toolbars from a user interface perspective, though recent aminetherelativelysmallnumberofusersubmittedphish-
studies have found that the Firefox anti-phishing feature ingpagesandreportederrorsmanually,allowingustobreak
isindeedeffectiveatprotectinguserswhentriggered[12]. any such loops. Note that we must manuallyreview these
Zhang et al. looked at the coverage of the anti-phishing submissionsanywaytopromptlycorrectanyuserreported
toolsincludingthebuilt-inphishingprotectionofFirefox2, errors in our blacklist. However, less than one percent of
atthetimepoweredbyourblacklist,alongwithmanyother the input to our system receives a manual review, leaving
similartools[34]. Theyfoundthatourblacklistwas com- ourautomaticsystemtohandlethebulkoftheanalysis.
petitivewithotherproducts,althoughtheirsamplesizewas
Since we use our published blacklist to label the train-
relativelysmall,consistingofonly100phishingURLsand
ing data, the resulting classifier effectively generalizesthe
516legitimateURLs. A recentstudy bySheng etal. also
blacklist. We find that this works well in practice, since
comparedtoolsbasedonGoogle’sblacklistwithotheranti-
manyofthephishingpagesnotonourblacklistaresimilar
phishingtoolsintwoexperiments,oneinOctober,2008and
topagesonourblacklist.Byexpandingonthecommonfea-
oneinDecember,2008[30]. Incidentally,theirtwoexperi-
tures of knownphishingpages, the classifier can correctly
mentscomparethequalityofourblacklistbeforeandafter
identifynewphishingpages.
we enabledourautomaticclassification system in Novem-
ber, 2008. We discuss the findings of this paper in Sec-
tion4.3. 3.1.1 Design Goals. First, the classifier must prioritize
Highlightingtheneedforananti-phishingsolution,sev- precisionover recallto minimize the numberof published
eralpapershavestudiedwhyInternetusersfallforphishing falsepositives1. Inordertofindasmanyphishingpagesas
attacksin the first place. Dhamija et al. concludethat the possible,weexaminealargesetofpages,mostofwhichare
average unaided user lacks the knowledge to properly in- notphishing. Giventherelativescarcityofactualphishing
terpretthesecuritysignalsbuiltintowebbrowsers,leaving pagesinthesetofpagesexamined,thefalsepositiverateof
themvulnerabletophishing[10]. Downsetal. explorethe theclassifiermustbeextremelylow.
mentalmodelsused by Internetusers to evaluate potential Second, the classifier must achieve high recall. If the
phishingpages[11]. Someoftheirsubjectsusedincorrect classifierfailstoidentifymostofthephishingpages,itdoes
strategiesto analyzepotentialscams, leaving them at risk. notadequatelyreplaceamanualsystem.
At a more fundamental level, Fogg et al. studied the at-
Third, the classifier must tolerate noisy training data.
tributesofawebpagethatmakeitcredible[14]. Theyfind
Since we must train on the data and classifications we al-
thatmanyfeaturesofa page’sappearanceenhanceitsper-
readyhaveavailable,weneedtheclassifiertopickupcon-
ceivedcredibility,afactthatphishersroutinelyexploitand
sistentpatternsdespiteanyexistingmisclassifications.
thatwe,inturn,usetomotivatepartsofourfeatureset.
Finally,theclassifiermustprocessalargenumberofweb
pageswithlowlatency.OurURLcollectionsystemobtains
3 Phishing ClassifierInfrastructure
millionsofnewpagestoexamineeveryday,sotheclassifier
mustkeepupwiththeload.Theclassifiermayneedtodrop
3.1 OverallSystemDesign some likely non-phishing URLs early in the classification
processtoreducetheloadonbottlenecksinthesystemand
Oursystemclassifieswebpagessubmittedbyendusers improveoveralllatency.
and collected from Gmail’s spam filters. To successfully
identify a wide variety of phishing pages, our system ex- 1Precision=numberoftruepositiveclassifications/numberofpositive
tracts and analyzes a number of features regarding these classifications.
Recall =Truepositive rate =numberoftruepositive classifications /
pages. Thesefeaturesdescribethecompositionoftheweb
numberofpositiveexamples.
page’sURL,thehostingofthepage,andthepage’sHTML
Falsepositiverate=numberoffalsepositiveclassifications/numberof
contentascollectedbyacrawler.Alogisticregressionclas- negativeexamples.[15]3.2 ClassificationWorkflow requiringthat each site both have high traffic and nothost
arbitrary user-generated content. Sites on this list include
Theworkflowforclassifyingawebpageasphishingdi- citibank.comandcnn.com.
vides the work into a number of separate processes, each One feature this process extracts is whether the URL
handled by a pool of workers. The first process extracts contains an IP address for its hostname. Using an IP ad-
features about the URL of the page. The second process dress in this fashion effectivelydisguises the ownerof the
obtainsdomaininformationaboutthepageandcrawlsit. If site from a casual viewer. It also prevents administrators
thecrawlsucceeds,thethirdprocessextractsfeaturesfrom fromshuttingdownthesitebydisablingthedomainname.
thepagecontents.Thefinalprocessassignsthepageascore However,theURLwillbreakifthehostcomputerchanges
basedonthecollectedfeaturesrepresentingtheprobability itsIPaddress. Fortunately,staticIPaddresshostingiseasy
thatthe page is phishing. If the score is high enough,this to detect. Since a few legitimate services, like the Google
process automatically adds the page to the blacklist pub- webcache, use an IP addressas the URL host, this feature
lishedbyourservingsystem. Tosavebandwidth,ourserv- cannotbeusedinisolation.
ingsystemcombinessimilarblacklistedURLsintoblacklist Anotherfeaturethisprocessextractsiswhetherthepage
patterns. hasmanyhostcomponents. Phisherscommonlyusealong
To help run this workflow, we create tasks to represent hostname, prepending an authentic-sounding host to their
units of work for each workflow process. A task manage- fixed domain name, to confuse viewers into believing that
ment system buffers these tasks for the various processes, thepageislegitimate[33]. Anexampleofthisis9794.my-
assignstaskstoworkers,andretriesanytasksthatfail.After onlineaccounts2.abbeynational.co.uk.syrialand.com. This
aworkerfinisheswithatask,itstoresanygenerateddatain is also easy to detect automatically by counting the num-
aBigtabledatabaseandaddsanewtasktothequeueforthe berofhostsegmentsintheURLbeforethedomain(e.g.,5
nextprocessintheworkflow[8]. Ifataskfailsortimesout, inthepreviousexample.)
thetaskisreturnedtoitsqueueandretried.Sinceeachtask
BesidesmanipulatingthestructureoftheirURLs,phish-
is an independentunit of work, no inter-worker coordina-
ers often include characteristic strings in their URLs to
tionisnecessary. Therefore,iftheworkflowcannothandle
mislead viewers. These can include the trademarksof the
thevolumeofcollectedURLs,wecanincreasethenumber
phishingtarget,like“abbeynational”intheexampleabove,
ofworkers,andtheoverallthroughputofoursystemscales
or more general phrases associated with phishing targets,
linearly.
like“login”. TheURLFeatureExtractorextractsallstring
Adetaileddescriptionofeachoftheworkflowprocesses tokensseparatedbynon-alphanumericcharactersoutofthe
follows.RefertoSection4.2forasummaryofthedescribed URLtouseasfeaturesratherthanlookingforspecificchar-
featureswithstatisticsregardingtheirvaluetotheclassifier. acter strings as in Garera et al. [16]. By including all
of these tokens, our models can respond automatically to
3.2.1 Candidate URL Collection. We receive new po- phishing attacks that use a common string in their URLs.
tentialphishingURLsinreportsfromusersofourblacklist Thefeatureextractortransformseachofthesetokensintoa
and from spam messages collected by Gmail. We receive booleanfeature, such as “The path containsthe token ‘lo-
approximately one thousand user reports and five million gin.’”AlthougheachURLdoesnothavemanyofthesefea-
URLs from spam emails each day. For URLs from spam tures, the number of these sparse, boolean features in the
emails,wetakeprecautionstomakesurethatwedonotac- dataset increases the overall size of the feature space sig-
cidentally fetch user-identifiable URLs. Primarily, we en- nificantly. When combined with similar boolean features
surethatseveraluniqueGmailusersreceivedaURLbefore regarding the hosting and page content described in Sec-
weaddthatURLtooursystem. tion 3.2.4, the total number of features seen in one month
canexceedonemillion. Werelyonfeatureselectionmeth-
3.2.2 URL Feature Extraction. We can often tell odsbuiltinto ourmachinelearningframeworkto incorpo-
whether or not a web page is phishing simply by looking rateonlythemostusefulofthesefeaturesintoourclassifi-
at the URL. Phishers commonly construct their URLs to cationmodels[5].
confusetheviewerintobelievingthattheURLsbelongtoa TheURLFeatureExtractoralsocollectsURLmetadata,
trustedparty. To identifythetelltale signsofthese efforts, including PageRank, from Google proprietary infrastruc-
thefirstprocessintheworkflow,theURLFeatureExtractor, ture and constructs corresponding features [26]. We also
looksonlyattheURLofthepagetodeterminefeatures. useadomainreputationscorecomputedbytheGmailanti-
First, if the URL is improperly constructed or if it spam system as a feature. This score is roughly the per-
matchesawhitelistofhighprofile,safesites,thentheURL centageofemailsfromadomainwhicharenotspam. Do-
Feature Extractor drops the URL from the workflow en- mains that send lots of non-spam email earn high reputa-
tirely. We manually compile this whitelist of 2778 sites, tionscoresandarelesslikelytohostphishingsites. Taylordescribestheexactmethodforcalculatingthesereputation functioncorrectlyforthephishingpagetolooklegitimate.
scores[32]. Inthecaseoftheimages,thephishersdonotneedtocopy
allofthetarget’simagestotheirshort-livedphishingpages
3.2.3 Fetching Page Content. After the URL Feature iftheylinktotheappropriatetargetimagesdirectly. These
Extractor analyzes the URL, the Content Fetcher process featuresaresimilartoonesusedbytheclassifierconstructed
crawlsthe page and gathersits hosting information. First, inLudletal. [20].
the Content Fetcher resolves the host and records the re- Whilewecouldconstructfeaturesoutofeverytermap-
turned IPs, nameservers, and nameserver IPs. It also ge- pearing in the text of a page, this many features per page
olocatesthese IPs, recordingthe city, region, and country. wouldoverburdenourmachinelearningsoftware. Instead,
Next,theContentFetchersendstheURLtoapoolofhead- thefeatureextractoronlymakesfeaturesofthetermswith
less web browsers to render the page content. Rendering the highest term frequency-inverse document frequency
the page in a browser ensures that we mimic the environ- (TF-IDF) values [28]. The TF-IDF value of a term on a
ment that the user would experience as much as possible. page is the frequency of the term in the given page (term
Afterthebrowserrendersthepage,theContentFetcherre- frequency,)dividedbythelogofthefrequencyoftheterm
ceives and records the page HTML, as well as all iframe, in all pages (documentfrequency.) In this case, the docu-
image,andjavascriptcontentembeddedinthepage. mentfrequencyiscalculatedbasedontermsfoundonpages
The Content Fetcher rate limits fetchesto each website in the same language as the evaluated page in the Google
as an extra safeguard against generating a high volume of search index. Phishing pages often use terms from their
trafficto popularsites. Based onthe rate ofrecentfetches targetsprominently,andtheirhighestvaluedTF-IDFterms
totherequesteddomain,theContentFetchermaydeferthe reflectthis. Non-phishingpagesdonotcontainthesetarget-
task until later or drop the task to avoid creating a large related terms often enough to give them a high TF-IDF
backlogoffetches. value. Zhang et al. also used terms with the highest TF-
IDFvaluesasakeycomponentoftheiranalysis[35].
Finally, the Page Feature Extractor constructs a feature
3.2.4 HostingandPageFeatureExtraction. Whilethe
indicatingwhetherthepagehasapasswordfield.Moststan-
URLofaphishingpagemaybemanipulatedbyaphisher,
dardphishingsitesuseaformwithapasswordfieldtosteal
thesameisnottrueforthepage’shostinginformation.The
a viewer’s login credentials, though nontraditional phish-
DNSentriesforaphishingpagemustbeaccurate,otherwise
ingpagesmayrequestthattheviewerdownloadavirusor
potentialvictims cannotview the page. While the hosting
keyloggerinstead.Non-phishingpagesthathavepassword
informationalonecannotproveconclusivelythatapageis
fields are usually easy to distinguish on the basis of their
phishing, this data can establish whether a page is hosted
otherfeatures.
like other phishing sites. The Page Feature Extractoruses
the page hosting data gathered by the Content Fetcher to
3.2.5 Page Classification. With all of the features col-
generatefeaturesforthispurpose.
lected, the classifier process scores the page on a scale of
To start, the Page Feature Extractor constructs features
0.0 being not at all phishing to 1.0 being definitely phish-
outoftheautonomoussystemnumberstowhichthepage’s
ing. The score translates to the computed probability that
hosts and nameservers correspond using the routing data
thepageisphishing.Aseparatetrainingprocess,described
from the University of Oregon Route Views project [1].
inSection3.3,computesmodelswhichtheclassifierreloads
Autonomoussystemnumbersgiveamoreaccuratepicture
dailyandusestocalculatethesescores.
ofIPaddressassociationthansimplylookingatIPaddress
Tocomputethisscore,theclassifierfirstcreatesasetof
subnets. Also, theypresenta smaller rangeoffeaturesfor
feature values for the page. For boolean features, “true”
themachinelearningalgorithms.Thefeatureextractoralso
becomesavalueof1.0,and“false”becomesavalueof0.0.
computesfeatures based on the geolocationsof the page’s
All continuous features are scaled to be between 0.0 and
hosts and nameservers, taking into account their city, re-
1.0.Anyfeaturesabsentfromthepageareassumedtohave
gion,andcountry.
a value of 0.0. To compute the score for the page in log
EvenwithalegitimatelookingURLandreputablehost-
odds, the classifier combines these values using a logistic
ing, we can still tell when a page is phishing by looking
regressiondefinedbythe classificationmodel[5]. Finally,
atthepagecontents. Tothisend,thePageFeatureExtrac-
the classifier transforms the score in log odds to the final
tor also extracts featuresfrom the HTML collected by the
outputscore:
ContentFetcher.
One of these features is the extent to which pages link
elogodds
to other domains in terms of both HTML hyperlinks and score=
1+elogodds
images. Links and images on phishing pages often point
directly to the target website. For the links, they need to If the score is greater than 0.5, the page is more likelythannotphishing,andtheclassifiermarksitassuchwithin sumethatpagesnotinourblacklistarenotphishing.Aswe
our review system. Before the classifier automatically discovermorephishingpagesoridentifyerrorsinourpub-
blacklists the page, it checks to make sure that the page lishedblacklist,weupdateourtrainingdataforsubsequent
does not have a high PageRank [26]. If it does, the page trainingruns.
ispopular,unlikelytobephishing,andthereforeapossible
When we train classification models, we build six sep-
classification error. Popular pages require a final manual
arate models: five cross-validation models, each leaving
review before being added to the blacklist to preventhigh
out a different part of the training data, and a candidate
impactfalsepositiveclassifications.
modeltrainedonallofthedata.Eachofthecross-validation
modelsexcludesadifferentsetofURLsaccordingtoeach
3.2.6 AggregationandServing. Thefinalprocessinthe URL’s first entry time in our database. The first model
workflow, the Blacklist Aggregator, prepares the blacklist excludes the earliest data, the last model excludes the lat-
to be served to clients. The Blacklist Aggregatorreads in est, etc. This sharding scheme aims to have one of the
the set of blacklisted URLs and transformsthem into host validation models entirely exclude each individual phish-
suffix/pathprefixexpressionsrequiredbytheSafeBrowsing ing attack, possibly consisting of a large number of simi-
protocolspecification[7]. larURLs. Thisseparatesattacksquitewell,sincephishing
TheBlacklistAggregatornextappliesabroadeningalgo- attacks rarely last more than a few days while our shards
rithmtotheexpressions,toreducethenumberofpatternson each span almost three weeks [2], [30]. Without this type
ourblacklist. IfanumberofblacklistedURLsmatchsome of separation, each cross-validation model would train on
broaderexpression,theBlacklistAggregatormayblacklist samplesofeveryattack, leadingustobelievethatthecan-
the broaderexpression instead. Phishing attacks often use didate would perform better than it would in reality. We
URLs that vary only by a portion of the host or path, so train the models using a proprietary, but general purpose,
broadeningreduces these URLs to a single blacklist entry implementation of the online gradient descent logistic re-
per attack. This reduction minimizes the size of the list gression learning algorithm, which we run over the entire
servedtoourclients.Italsoimprovesourblacklistcoverage datasetduringtraining[5]. Thisimplementationexamines
byblockingURLsthatarepartofaphishingattackbutwere blocks of the training data serially to find potentially use-
missed by our classification system. To avoid acting too fulfeaturestoincludeintheclassificationmodel. Features
aggressively,thebroadeningalgorithmavoidspatternsthat which do not contribute to the model are simply omitted.
match sites with a high PageRank [26]. For example, this Thissystemcanhandlemillionsoftraininginstances,each
safeguard prevents it from blacklisting the top-level URL withdozensoffeaturesandasparsefeaturespacecontain-
of a hosting site even though the site may contain several ingoveramillionuniquefeatures. Sinceweuseanonline
phishingpages. learningalgorithm,trainingonlargerdatasetsmeanstakes
Once pattern broadening finishes, the Blacklist Aggre- longer but does not require significantly more computing
gator removesany overlappingexpressionsand assembles resources.
theremainingexpressionsintothe binaryformatservedto
We chose to use this proprietarymachine learning sys-
clientsusingtheSafeBrowsingprotocol.
tem because it is convenient to operate in our computing
environment,notbecauseitperformsunusuallywell. Ma-
3.3 TrainingProcess
chinelearningsystemswhichcanhandlenoisytrainingdata
andaverylargefeaturesetshouldperformsimilarlytoour
Trainingtheclassifierisanofflineprocessthatrunsonce proprietarysystem. Forexample,weexperimentedwithus-
per day to pick up new phishing trends. As a training ingaclassifierbasedonrandomforests[6]. Sincerandom
dataset, we use a sample of roughlyten million URLs an- forests do not dynamically select features, we preselected
alyzed by the classification workflow over the past three 3000features from the trainingset using informationgain
months along with the features obtained at the time. We anddocumentfrequencyfeatureselectionalgorithms[15].
includeeachURLonlyonceinourtrainingset,evenifwe Withthesefeatures,wefoundthatarandomforestclassifier
receiveditbothfromauserreportandfromaGmailspam consistingof100treeseachtrainedonarandomquarterof
message. WealsolimitthenumberofURLsfromanysin- thetrainingsetperformedsimilarlytoourproprietaryclas-
gledomainto150perweektopreventasingledomainfrom sifier. Demonstratinganotherapproach,Ma et al. showed
having too much weight in determining our classification thatgenericonlinelearningalgorithmsperformedwellona
models. We find this limit preventsconcentratedphishing datasetsimilartoourswithtwomillioninstancesandhun-
attacksfromdominatingourtrainingdatawhilestillallow- dredsof thousandsof sparse features[22]. These findings
ingustoincludea representativesample oflargewebsites suggestthatbothrandomforestsandotheronlinelearning
withmanylegitimatepages.Weuseourpublishedblacklist implementations would adequately substitute for our pro-
as a noisy source of true phishing classifications. We as- prietarylearningsystem.Oncethetrainingfinishes, wetesteachcross-validation this,weusealargetrainingsetcollectedoveralongperiod
modelagainstthetrainingdataleftoutduringitsconstruc- of time and limit the numberof times a givendomaincan
tion. Because the last model excluded the latest training appearinthetrainingsetasdescribedinSection3.3. Since
data, it only trained on older data. Therefore, the perfor- weweightalldataequally,phishersdonothaveanopportu-
manceofthismodelprovidesanestimateofhowthecandi- nitytotargethigherweightedsegmentsofourtrainingset.
datemodelwillperformonnew,livedata. Wealsotestthe Despiteoursafeguards,westillseephishingcampaignsthat
candidatemodelonallofthetrainingdatatomakesurethat makeupasignificantportionofourtrainingdata(seeSec-
themodelcontainsnoobviousflaws. tion 4.1.) However, setting up similar campaigns of non-
Forourtargetmodelperformance,werequirethatmod- phishingpagestopossiblyinfluenceourclassificationmod-
els exhibit better than 90% precision and 90% recall. If elswouldbeexpensive,againreducingthephisher’sgains.
the cross-validation models average above this level, the Phisherscouldattempttousetheratelimitingdescribed
cross-validationfoldtestedonthelastpartoftrainingdata in Section 3.2.3to preventour system fromcrawlingtheir
isabovethislevel,andthecandidatemodelperformsabove pages by putting many phishing pages on one domain.
thislevelonthe fulltrainingset, thenthecandidatemodel However, if they put enough different pages on the same
ispushedtotheliveclassifiers. domaintoslowdownourfetches,ourURLaggregational-
gorithmwillblocktheirentiredomain(seeSection3.2.6.)
3.4 PotentialAdversarialAttacks Finally, phishers can try to bypass our system by hid-
ingtheirphishingpagesfromus. Theycouldavoidsending
phishingemailstoGmailuserstoavoidourautomaticURL
Phisherscanattempttobypassoursysteminafewways.
collection system. However, many users forward email
The following attacks represent real vulnerabilities in our
fromotheraccountsintoGmail,sothistacticwouldnotal-
classifier, which we expect phishers to attempt to exploit.
wayswork.Instead,phisherscouldexploitourprivacysafe-
However,webelievethatthepossibleattacksonoursystem
guards, describedin Section 3.2.1,to keeptheir URLsout
areeitherlimitedorexpensive.
ofoursystem. Phisherscouldalsotrytoserveourcrawlers
Phisherscantrytobypassoursystembydisguisingtheir
non-phishing content different from what they serve their
pagesasnon-phishingpages. However,inorderforphish-
intended victims to escape automatic phishing classifica-
ingpagestooperatecorrectly,theymustbothappearvisu-
tions.
ally like a third party and request that the victim perform
Evenifaphishingpagedefeatsourautomaticclassifica-
some action. Both of these characteristics are possible to
tionsystem,themorepeopleitreaches,thehigherthelike-
identify automatically. To make these features less suspi-
lihoodthatavictimwillreportthepagetous. Thisallows
cious, the phishers could try to trick our classifier by giv-
ustocorrectlyclassifythephishingpagemanually,regard-
ing their page a high PageRank. However, PageRank is
less of how the page appears to our classification system.
designed to make manipulation of the ranking scores dif-
Becauseofthis,defeatingourautomaticclassifierdoesnot
ficult[26].Consequently,alteringthePageRankofaphish-
mean that the page will never appear on our blacklist. In-
ing page requires a significant investment, which reduces
stead,phisherscanonlyhopetoincreasethelengthoftime
the potential profit of the phisher. Alternately, the phish-
beforetheirpagesareblacklisted.
erscouldtrytoposttheircontentonareputablehostwhich
alreadyhasahighPageRank. Aphishercouldaccomplish
4 Evaluation
this by exploiting a site with a high PageRank and using
it to display their phishing page. Administrators of sites
withhighPageRankstypicallyremovemaliciouspagesun- In our evaluation, we intend to demonstrate the overall
dertheircontrolpromptly,though,limitingthepotentialau- qualityofourclassificationsystemandthevalueofthefea-
dience and profitability of phishing pages posted to their turesweexamine. Toevaluatethequalityoftheclassifica-
sites. tion system, we first train a fullclassification modelalong
Alternatively, the phishers could attempt to manipulate with cross-validation models as described in Section 3.3.
our classification models. If they could pollute our train- Next, we evaluate the models’ performance on both their
ing set, our classifier would make more user-visible mis- training data and on a validation dataset. We intend that
takeswhichwouldreducethevalueofourblacklist.Specif- these tests closely emulate the environment in which our
ically,phisherscouldtrytoexpandthesetofpagesdeemed classifier normallyoperatesand thereforeprovidea realis-
non-phishingbyintroducingnon-phishingpageswithsome ticevaluationoftheperformanceofoursystem. Toexam-
phishingattributesintoourtrainingset,similartotheattack ine the usefulness of the features, we compare the feature
describedbyBarrenoetal.[4].Theoretically,theycouldal- values in phishing pages and in non-phishing pages. We
terthetrainingsetenoughsothattrainedclassifierswould usepreviouslycollectedclassificationdatatodeterminefea-
mistakephishingpagesfornon-phishingpages. Tocombat turevalues,andweuseourpublishedblacklisttodeterminewhichpagesarephishing.Whileusingourpublishedblack- Apr16–Jul14 Aug1–14
listasgroundtruthintheseevaluationsallowsustoexam- TotalURLsReceived 446,152,060 74,816,740
inealargequantityofdata,errorsinourblacklistintroduce UserSubmittedURLs 75,048 14,490
GmailSpamURLs 446,093,814 74,805,549
somenoiseintotheanalysis. Basedontherelativelysmall
number of misclassifications reported to us by our users, URLs Skipped: In- 226,636,463 44,806,767
valid/Whitelisted
we do not expect this noise to impact our analysis of the
URLs Skipped: Rate 202,727,905 27,228,220
featuressignificantly.
Limited
URLs Skipped: Error 3,606,765 521,093
4.1 EvaluationDataset (e.g.,HostNotFound)
URLs with Complete 13,180,927 2,260,660
Data
Inourevaluation,weusetwosetsofdata. Thefirstset,
DatasetURLs(limited 9,388,395 1,516,076
a copy of a training set used by our system, contains data
#URLs/domain)
collected between April 16, 2009 and July 14, 2009 with
PhishingDatasetURLs 103,684(1.1%) 16,967(1.1%)
labelsfromJuly 15, 2009. We use this set to examineour
Dataset URLs From 46,682 9,830
selected features and train our evaluation models. We use
UserSubmission
thesecondset, collectedduringthefirsttwoweeksofAu-
Dataset URLs From 9,348,783 1,507,682
gust, 2009, as a validation dataset. Besides the different GmailSpam
size,thissecondsetdiffersfromthefirstsetinthatweup-
dateditslabelswithourblacklistdatafromAugust24,ten Table 1. Dataset statistics. Note that URLs
daysaftertheendofdatacollectionperiod. Consequently, may come from both user submissions and
thesecondsetcontainsfewerlabelingerrors,sincewehad Gmail spam. Refer to Section 3.2.2 for
more than a week to respond to reported errors and cor- more information on skipping invalid and
rect any mislabelings. This dataset allows us to show the whitelisted URLs and Section 3.2.3 for more
performanceoftheclassificationmodelwithaslittlenoise onskippingratelimitedURLs.
aspossible. BothdatasetsexcludeURLsdroppedfromthe
systempriortofinalclassification,sinceourdataregarding
theseURLsmaybeincomplete. Forexample,ourdatabase
All of their URLs are in the form http://www.bank-
doesnotincludepageorhostingfeaturesforURLsdropped
ofamerica.com.srv <random>.<random>.<random top-
duetoratelimiting(seeSection3.2.3.) Also,bothdatasets
level domain>/customerservice/securedirectory/cform.do/
limitthenumberofURLsfromanyonedomainto150per
cform.php, and all their page contents are identical. Be-
week, just like we do during our training process, and do
causeofthelargenumberofrandomizeddomains,wesus-
notcontainduplicateURLs. Table1detailsthestatisticsof
pect that a botnet using domain flux, like the Torpig bot-
thesetwodatasets.
netanalyzedbyStone-Grossetal.,hoststhisphishingcam-
Notethatthesedatasetsdonotcontainarandomsubset
paign[31].Whiletheweightingofthisattackinourdataset
ofwebpages.AsdescribedinSection3.2.1,theonlyURLs
is not ideal for our evaluation, it accurately reflects the
analyzed are either submitted as a potential phishing page
widespreadnatureofthisparticularphishingcampaign.We
or collected from a spam email. From these, URL feature
highlightthesituationswherethisattackimpactsthestatis-
extractionfiltersoutapproximatelyhalfofthepagesasei-
ticswepresentinthefollowinganalysis.
therinvalidorwhitelisted(seeSection3.2.2.)Themajority
of these filtered pages are URLs for high profile domains
4.2 EvaluationofFeatures
added to spam emails to enhance their appearance of le-
gitimacy. The remaining pages in the training sets are al-
readyquitesuspect. However,mostofthese pagesarenot Inthissection,weanalyzethevalueoftheassortedfea-
phishing. Since our datasets contain roughly one percent tures in our feature set. For a summary of the feature set
phishingwebpages,ourclassifiermustdemonstrateafalse we described in Section 3.2, see Table 2. Note that since
positiverateof0.1%toachieveprecisionof90%. phishingpagesmakeup1.1%ofourdataset,if1.1%ofthe
Despite skipping many URLs from overrepresented URLswithafeaturearephishing,thenthatfeatureiscom-
domains through rate limiting and capping the num- pletely uncorrelated with phishing. If the feature appears
ber of URLs coming from any single domain in our moreoftenthanthatonphishingpages,thenitiscorrelated
datasets, one phishing campaign is overweighted in withphishing.
our data. Roughly 51,000 of the phishing pages For our URL features, we find that IP address hosting
in the April–July dataset, hosted across hundreds of is several times more common in phishing pages than in
domains, match a particular bank phishing template. non-phishingpagesandthataverysmallpercentageofnon-Feature Type Visualization
URLFeatures(Section3.2.2)
IPAddressforHostname boolean Table3
LongHostname boolean Table3
TokensfromURL booleans Table4 # # Non-
%
PageRank float Figure1 Phishing phishing
Phishing
GmailReputation float Figure2 URLs URLs
HostingFeatures(Section3.2.4) Hostcontains“www” 71,034 4,872,888 1.4%
AutonomousSystemNumbers booleans Table5 Hostcontains“signin” 148 3 98.0%
Geolocations booleans Table6 Hostcontains“blog” 25 33,824 0.1%
PageFeatures(Section3.2.4) Path contains“custom- 54,749 349 99.4%
PasswordField boolean Table7 erservice”
TopTF-IDFTerms booleans Table8 Pathcontains“com” 8,971 46,416 16.2%
ExternalLinkingFrequency float Figure3 Pathcontains“album” 31 83,184 0.04%
Table 2.Summary offeatureset. Featuresof Table4.StatisticsforselectedURLtokensfor
type “boolean” consist of a single boolean data collected Apr 16–Jul 14. Note that the
value. The type “booleans” indicates a URLs from the overweighted phishing tem
sparsesetofbinaryfeatureswhicharealways plate have “www” in the host and “custom
“true” if present. For example, we construct erservice”inthepath.
one such feature for each token in the URL,
and we construct one feature for each au
tonomoussystem numberonwhichtheURL
ishosted.
phishingsiteshaveunusuallylonghostnames(seeTable3.)
Some tokens in the URL, like “signin” in the host, are far
morecommonin phishingpages, whereasothers, like “al-
bum”inthepath,aremorecommoninnon-phishingpages
(seeTable4.) ConfirmingthefindingsofGareraetal., we 0.3
alsofindthatnophishingpageshavehighPageRankscores,
asshowninFigure1[16].WefindthattheGmailreputation
scores,showninFigure2,followasimilarpattern. 0.2
# # Non-
%
Phishing phishing
Phishing
URLs URLs 0.1
IPAddressHost 2,341 33,208 6.6%
#Hostsegmentsbefore 62,383 934 98.5%
domain>3
0.0
Table3.StatisticsforURLcharacteristics for 0.0 0.1 0.2 0.3 0.4 0.5 0.6
datacollectedApr16–Jul14. NotethatURLs
belonging to the overrepresented phishing
template have a long hostname. “% Phish
ing”isthefractionofURLsthatarephishing
outofallURLswiththefeature.
Looking at our hosting features, we find that some au-
tonomous systems, especially those belonging to residen-
tial ISPs, have very high levels of phishing, as shown in
Table 5. Additionally, Table 6 shows that some areas are
highlyassociatedwith phishingactivity. While theUnited
States hosts the largest number of phishing pages, a large
FDCC
PageRank
Phishing Pages
Non-Phishing Pages
Figure1.Complimentarycumulativedistribu
tion function (CCDF) of PageRank for phish
ingandnon phishingpagesfordatacollected
Apr16–Jul14.1.0
0.9
0.8
0.7
0.6
0.5
0.4
0.3
0.2
0.1
0.0
0.0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1.0
FDCC
# # Non-
% ASN Phishing phishing
Phishing
URLs URLs
6739 (Cableuropa - 42,283 883 98.0%
ONO)
8708(RCS&RDS) 35,537 7,777 82.0%
6830(UPCBroadband) 34,921 678 98.1%
7132 (AT&T Internet 29,497 4,829 85.9%
Services)
9116 (Golden Lines 26,645 5,280 83.5%
Main)
19262(VerizonInternet 26,174 1,855 93.4%
Gmail Reputation
Services)
Phishing Pages
Non-Phishing Pages 16338 (Cableuropa - 22,323 6,260 78.1%
ONO)
9141(UPCPoland) 22,219 19 99.9%
Figure2.CCDFofGmailreputationscorefor
5089(NTLGroupLim- 18,213 1,146 94.1%
phishing and non phishing pages for data
ited)
collectedApr16–Jul14.
5617 (Polish Telecom 18,054 3,437 84.0%
(Commercial))
Table 5. ASNs hosting the most phishing
fraction of pages hosted in some Eastern European coun-
pagesfordatacollectedApr16–Jul14. Many
triesarephishing.
phishing pages, including those from the
Turning to features from page HTML, Table 7 shows
widespreadphishingtemplate,arehostedon
that a high proportion of phishing pages have a password
many different ASNs. Each URL may be
field. The number of phishing pages without a password
hosted on multiple ASNs, which is why the
field indicates that nontraditional phishing attacks are be-
sum of the phishing pages hosted by these
coming somewhat more common. When looking at the
ASNs exceeds the total number of phishing
terms with the highest TF-IDF scores for a page, some
pagesinthedataset.
terms are highly indicative of phishing, like “online bank-
ing”and“pin,”whereasothers,like“islands,”arerelatively
safe(seeTable8.) Also,Figure3showsthatrelativelyfew
legitimatepageslinkheavilytootherdomains.
4.3 ClassifierPerformance
# # Non-
%
Country Phishing phishing
Phishing
To evaluate the performance of our classification sys- URLs URLs
tem,weexaminetheclassifiertrainedondatawecollected UnitedStates 76,124 4,675,812 1.6%
between April 16 and July 14, described in Section 4.1. Romania 54,638 76,711 41.6%
As outlined in Section 3.3, we train five cross-validation Spain 53,703 179,682 23.0%
Poland 45,611 93,734 32.7%
models,leavingouta differentportionofthedataseteach
Hungary 35,968 60,598 37.2%
time,andacandidatemodel,leavingoutnothing. Figure4
Russia 34,391 327,142 9.5%
showstheperformanceoftheclassifierinaprecision-recall
Israel 28,003 29,568 48.6%
curvefortheaveragecross-validationperformance,thefinal
UnitedKingdom 25,148 307,708 7.6%
cross-validationfoldby itself, the candidatemodeltrained
Mexico 24,478 10,432 70.1%
and tested on the whole dataset, and the candidate model
Netherlands 22,025 614,726 3.5%
tested on data collected between August 1, 2009 and Au-
gust14, 2009. To generatethese curves, we firstcalculate Table6.Countrieshostingthemostphishing
theclassificationscoresusingthetrainedmodels. Next,as pagesfordatacollectedApr16–Jul14. Each
we vary a threshold from 0.01 to 0.99, we determine the URLmaybehostedinmultiplecountries.
precision and recall obtained by classifying pages with a
scoregreaterthanthatthresholdasphishingpages. Weadd
apointmarkingathresholdscoreof0.5,thepointatwhich# # Non-
%
Phishing phishing
Phishing
URLs URLs
PasswordField 90,072 1,620,184 5.3%
NoPasswordField 13,612 7,664,527 0.2%
%WithPasswordField 86.9% 17.5%
Table7.Passwordfieldstatisticsfordatacol
lectedApr16–Jul14.
# # Non-
%
Term among Top TF- Phishing phishing
Phishing
IDFScores URLs URLs
onlinebanking 55,326 587 99.0%
pin 3,354 1,256 72.8%
paypal 6,683 5,509 54.8%
online 1,353 22,100 5.8%
email 259 52,437 0.5%
islands 223 107,166 0.2%
Table 8. Statistics for pages with selected
termsamongthehighestTF IDFscoredterms
indatacollectedApr16–Jul14. Notethat“on
linebanking”wasoneofthetopscoredterms
forpagesfromtheoverrepresented phishing
template.
1.0
0.9
0.8
0.7
0.6
0.5
0.4
0.3
0.2
0.1
0.0
0.0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1.0
FDCC
our classifier exhibits high precision while not sacrificing
much recall, to each of these curves. Table 9 shows exact
statisticsfortheclassifierincross-validationandontheAu-
gustdatasetforthisthreshold.
Theprecision-recallcurveofthe candidateclassifier on
the August dataset roughly matches the curve generated
duringcross-validation.Thisshowsthatevenamonthlater,
our classification model remains highly predictive. How-
ever, the point corresponding to a threshold of 0.5 shows
higher precision and lower recall relative to the similar
statistics from cross-validation. The improved labeling of
theAugustdatasetexplainsthisdifference.Mostofthecor-
rectionstothephishinglabelsmarkpreviouslyunidentified
phishing pages properly. This raises the precision of the
classifier,sincesomeoftheoriginalclassificationfalsepos-
itivesbecometruepositives. Thisalsolowerstherecall,as
someoftheoriginaltruenegativesbecomefalsenegatives.
1
0.975
0.95
0.925
0.9
0.9 0.925 0.95 0.975 1
External Link Frequency
Phishing Pages
Non-Phishing Pages
Figure 3. CCDF of external link frequency
breakdown for phishing and non phishing
pagesfor datacollected Apr16–Jul 14. Note
that the overrepresented phishing template
has 12.5% of its links pointing to external
targets, accounting for the large jump in the
CCDFforphishingpages.
noisicerP
Recall
Cross-Validation
Final Fold Only
Candidate
Candidate on August Data
Figure4.Precision recallcurvesforclassifier
trainedondatacollectedApr16–Jul14. Note
thatthegraphiszoomedintobettershowthe
differencesbetweenthecurves.
Cross- Candidateon
Validation AugustData
TruePositives 98,467 15,585
FalsePositives 2,479 166
FalseNegatives 5,217 1,382
TrueNegatives 9,282,232 1,498,943
TruePositiveRate/Recall 0.9497 0.9185
Precision 0.9754 0.9895
FalsePositiveRate 0.0003 0.0001
Table9.Statisticsforclassifiertrainedondata
collected Apr 16–Jul 14 using a threshold of
0.5.Figure 5 shows how our classifier scores phishing and
non-phishingpages during cross-validation. The vast ma-
jority of the classification scores are near the extremes.
Over 99.9% of non-phishing pages score below 0.1, and
90% of phishing pages score over 0.9, indicating our fea-
ture space providessufficientseparation between phishing
andnon-phishingpagestoallowforcorrectclassificationin
mostsituations.
1.0
0.9
0.8
0.7
0.6
0.5
0.4
0.3
0.2
0.1
0.0
0.0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1.0
FDCC
dianverificationtime under10hoursforanymonthin the
firsthalfof2009[25].
1.0
0.9
0.8
0.7
0.6
0.5
0.4
0.3
0.2
0.1
0.0
0.1 1.0 10.0 100.0 1000.0
Score
Phishing Pages
Non-Phishing Pages
Figure 5. CCDF of classification score for
phishing and non phishing pages during
cross validationondatacollectedApr16–Jul
14.
TheworkofShengetal. illustratestheultimateimpact
of ourautomaticclassification system [30]. Between their
twoexperiments,webeganusingourclassifiertoautomat-
icallyupdateourpublishedblacklist. Theirresultssuggest
that the coverage of our blacklist improved by 150% dur-
ingthefirsttwohoursofaphishingattackduetoourauto-
maticclassificationsystem. Bytheendofthistimeperiod,
ourblacklistincluded97%ofthephishingpagesexamined.
Thesefindingshighlighthowmuchautomaticclassification
has added to the comprehensivenessand timeliness of our
blacklist.
4.4 Per URLClassificationLatency
Figure6showsthedistributionoflatencybetweenwhen
our classification workflow received URLs and when the
classifier wrote out scores for data we collected between
mid-Apriland mid-July. The workflow processed the ma-
jorityoftasksquicklywithamedianof76seconds. How-
ever, a few tasks took up to a few hours to process, a de-
lay attributedto the throttlingofpage fetchesdescribedin
Section 3.2.3. Nonetheless, this represents a considerable
improvementoverPhishTank,whichhasnotreportedame-
FDCC
Total Time (minutes)
Figure 6. CCDF for end to end classification
timeforclassificationsmadeApr16–Jul14.
5 Conclusion
Inthispaper,wedescribeourlarge-scalesystemforau-
tomatically classifying phishing pages which maintains a
falsepositiveratebelow0.1%.Ourclassificationsystemex-
aminesmillionsofpotentialphishingpagesdailyinafrac-
tionofthe time ofa manualreviewprocess. By automati-
callyupdatingourblacklistwithourclassifier,weminimize
the amount of time that phishing pages can remain active
beforeweprotectourusersfromthem.
Even with a perfect classifier and a robust system, we
recognize that our blacklist approachkeeps us perpetually
astepbehindthephishers. Wecanonlyidentifyaphishing
pageafterithasbeenpublishedandvisibletoInternetusers
forsometime. However,webelievethatifwecanprovide
a blacklist complete enough and quickly enough, we can
forcephisherstooperateatalossandabandonthistypeof
Internetcrime.
6 Acknowledgements
We would like to thank Garrett Casto, Noe Lutz, Eric
Grosse,BradleyTaylor,IanFette,andMoheebAbuRajab.
WegivespecialthankstoNielsProvosforhisguidanceand
insightfulcomments.References M. Treinen. What Makes Web Sites Credible?: A Report
on a Large Quantitative Study. In CHI ’01: Proceedings
oftheSIGCHIconference onHuman factorsincomputing
[1] Advanced NetworkTechnology Center, UniversityofOre-
systems,pages61–68,March-April2001.
gon. University of Oregon Route Views Project. http:
[15] G. Forman. An Extensive Empirical Study of Feature Se-
//www.routeviews.org/,Jan.2005.
lectionMetricsforTextClassification. JournalofMachine
[2] Anti-Phishing Working Group. Phishing Activity
LearningResearch,3:1289–1305,2003.
Trends Report for the Month of January, 2008.
[16] S.Garera,N.Provos,M.Chew,andA.D.Rubin. AFrame-
http://www.antiphishing.org/reports/
workfor Detectionand Measurement of Phishing Attacks.
apwg_report_jan_2008.pdf,2008.
InWORM’07: Proceedingsofthe2007ACMworkshopon
[3] Anti-Phishing Working Group. Phishing Activity Trends
Recurringmalcode,pages1–8,Nov.2007.
Report, H2/2008. http://www.antiphishing.
[17] Gartner, Inc. Gartner Says Number of Phishing
org/reports/apwg_report_H2_2008.pdf, Mar.
Attacks on U.S. Consumers Increased 40 Percent in
2009.
2008. http://www.gartner.com/it/page.jsp?
[4] M. Barreno, B. Nelson, R. Sears, A. D. Joseph, and J. D.
id=936913,Apr.2009.
Tygar. Canmachinelearningbesecure? InASIACCS’06:
[18] Google. Google Safe Browsing API. http://code.
Proceedings of the2006 ACMSymposium on Information,
google.com/apis/safebrowsing/,2009.
computerandcommunicationssecurity,pages16–25,Mar.
[19] C.HerleyandD.Florencio.AProfitlessEndeavor:Phishing
2006.
asTragedyoftheCommons. InNSPW’08: Proceedingsof
[5] J. Bem, G. Harik, J. Levenberg, N. Shazeer, and S. Tong.
the2008workshoponNewsecurityparadigms,Sept.2008.
Large scale machine learning and methods. US Patent
[20] C. Ludl, S. McAllister, E. Kirda, and C. Kruegel. On the
7222127,2007.
Effectiveness of Techniques to Detect Phishing Sites. In
[6] L.Breiman. RandomForests. MachineLearning,45(1):5–
DIMVA’07:Proceedingsofthe4thinternationalconference
32,2001.
onDetectionofIntrusionsandMalware, andVulnerability
[7] G. Casto, O. Fisher, R. Moll, M. Nazif, and D. Born.
Assessment,pages20–39,July2007.
Client specification for the Google Safe Brows-
[21] J.Ma, L.K. Saul, S.Savage, and G.M. Voelker. Beyond
ing v2.1 protocol. http://code.google.
Blacklists: Learning to Detect Malicious Web Sites from
com/p/google-safe-browsing/wiki/
Suspicious URLs. In KDD ’09: Proceedings of the 15th
Protocolv2Spec,2007.
ACMSIGKDDinternationalconferenceonKnowledgedis-
[8] F.Chang, J.Dean, S.Ghemawat, W.C.Hsieh, D.A.Wal-
coveryanddatamining,pages1245–1254,June–July2009.
lach, M.Burrows, T.Chandra, A.Fikes,andR.E.Gruber.
[22] J. Ma, L. K. Saul, S. Savage, and G. M. Voelker. Identi-
Bigtable:ADistributedStorageSystemforStructuredData.
fyingSuspiciousURLs:AnApplicationofLarge-ScaleOn-
InOSDI ’06: Proceedings of the7thsymposium onOper-
lineLearning.InICML’09:Proceedingsofthe26thAnnual
ating systems design and implementation, pages 205–218,
InternationalConferenceonMachineLearning,pages681–
Nov.2006.
688,June2009.
[9] N. Chou, R. Ledesma, Y. Teraguchi, D. Boneh, and
[23] Microsoft. Internet Explorer 8 Security: SmartScreen
J. Mitchell. Client-side Defense against Web-Based Iden-
Filter. http://www.microsoft.com/security/
tity Theft. In NDSS ’04: Proceedings of the 11th Annual
filters/smartscreen.aspx,2009.
NetworkandDistributedSystemSecuritySymposium, Feb.
[24] Netcraft. Netcraft Toolbar. http://toolbar.
2004.
netcraft.com/,2004.
[10] R. Dhamija, J. D. Tygar, and M. Hearst. Why Phishing
[25] OpenDNS. Phishtank. http://www.phishtank.
Works. InCHI’06: ProceedingsoftheSIGCHIconference
com/,2009.
on Human Factors in computing systems, pages 581–590,
[26] L.Page,S.Brin,R.Motwani,andT.Winograd.ThePageR-
Apr.2006.
ankCitationRanking:BringingOrdertotheWeb.Technical
[11] J. S.Downs, M. B. Holbrook, and L. F.Cranor. Decision
report,StanfordDigitalLibraryTechnologiesProject,1998.
Strategies and Susceptibility to Phishing. In SOUPS ’06:
[27] ‘RSnake’. Phishing Social Networking Sites. http://
Proceedings of the second symposium on Usable privacy
ha.ckers.org/blog/20070508/,May2007.
andsecurity,pages79–90,July2006.
[28] G.SaltonandM.J.McGill. IntroductiontoModernInfor-
[12] S. Egelman, L. F. Cranor, and J. Hong. You’ve Been
mationRetrieval. McGraw-Hill,Inc.,NewYork,NY,USA,
Warned: An Empirical Study of the Effectiveness of Web
1983.
BrowserPhishingWarnings. InCHI’08: Proceedingofthe
[29] F. Schneider, N. Provos, R. Moll, M. Chew, and
twenty-sixthannual SIGCHIconference on Human factors
B. Rakowski. Phishing Protection Design Documen-
incomputingsystems,pages1065–1074,Apr.2008.
tation. http://wiki.mozilla.org/Phishing_
[13] I. Fette, N. Sadeh, and A. Tomasic. Learning to Detect
Protection:_Design_Documentation,2006.
PhishingEmails. InWWW’07: Proceedingsofthe16thin-
[30] S. Sheng, B. Wardman, G. Warner, L. F. Cranor, J. Hong,
ternationalconferenceonWorldWideWeb,pages649–656,
andC.Zhang.AnEmpiricalAnalysisofPhishingBlacklists.
May2007.
InCEAS2009: SixthConferenceonEmailandAnti-Spam,
[14] B.J.Fogg,J.Marshall,O.Laraki,A.Osipovich,C.Varma,
July2009.
N. Fang, J. Paul, A. Rangnekar, J. Shon, P. Swani, and[31] B.Stone-Gross,M.Cova,L.Cavallaro,B.Gilbert,M.Szyd- ceedings of the SIGCHI conference on Human Factors in
lowski,R.Kemmerer,C.Kruegel,andG.Vigna. YourBot- computingsystems,pages601–610,Apr.2006.
net isMyBotnet: Analysisof aBotnet Takeover. InCCS [34] Y.Zhang,S.Egelman,L.F.Cranor,andJ.I.Hong.Phinding
’09: Proceedingsofthe16thACMconferenceonComputer Phish: EvaluatingAnti-PhishingTools. InNDSS’07: Pro-
andcommunicationssecurity,Nov.2009. ceedingsofthe14thAnnualNetworkandDistributedSystem
[32] B.Taylor. SenderReputationinaLargeWebmailService. SecuritySymposium,February–March2007.
InCEAS2006: ThirdConferenceonEmailandAnti-Spam, [35] Y. Zhang, J. I. Hong, and L. F. Cranor. CANTINA: A
July2006. Content-BasedApproachtoDetectingPhishingWebSites.
[33] M.Wu,R.C.Miller,andS.L.Garfinkel. DoSecurityTool- InWWW’07: Proceedingsofthe16thinternationalconfer-
barsActuallyPreventPhishingAttacks? InCHI’06: Pro- enceonWorldWideWeb,pages639–648,May2007.