ff
Dynamic Di erential Location Privacy with
Personalized Error Bounds
Lei Yu, Ling Liu, Calton Pu
School of Computer Science, College of Computing, Georgia Institute of Technology
Email: leiyu@gatech.edu, ling.liu@cc.gatech.edu, calton.pu@cc.gatech.edu
Abstractâ€”Location privacy continues to attract significant and applications, such as Uber, Yelp and Foursquare. On one
attentionsinrecentyears,fueledbytherapidgrowthoflocation- hand,theemergenceoflocationawarecomputingandlocation-
based services (LBSs) and smart mobile devices. Location ob- based services creates great opportunities for empowering
fuscation has been the dominating location privacy preserving businesswithnewcompetitiveedgesandenrichingcitizenwith
approach, which transforms the exact location of a mobile user
life-enhancingexperiences.Ontheotherhand,suchcontinuous
to a perturbed location before its public release. The notion
publishing and sharing of mobile usersâ€™ location information
of location privacy has evolved from user-defined location k-
may open doors to potential misuse and abuse of private
anonymitytotwostatisticalquantificationbasedprivacynotions:
location information and serious location privacy risks, such
geo-indistinguishabilityandexpectedinferenceerror.Theformer
promotes differential location privacy but does not protect loca- as exposing places that a user has visited, the travel patterns
tion against inference attacks of Bayesian adversary with using of a user, and using the location information to infer usersâ€™
prior information, whereas the latter promotes the background activitiesanduncovermanyunauthorizedpersonalinformation
inferenceresilientlocationprivacybutdoesnotguaranteediffer- such as their political views, religious affiliation, or state of
entiallocationprivacywithrespecttogeo-indistinguishability.In health.
this paper we argue that geo-indistinguishability and expected
inference error are two complementary notions for location Locationprivacyresearchhasdrawnsignificantinterestsin
privacy. We formally study the relationship between two privacy recent years. Considering the high utility of location informa-
notions. By leveraging this relationship and a personalized error tion and personalized privacy risk variations, instead of cryp-
bound, we can effectively combine the two privacy notions. We tographic solutions, a large body of location privacy research
develop PIVE, a two-phase dynamic differential location privacy
have been centered on the location obfuscation mechanisms
framework. In Phase I, we take into account the user-defined
thatallowmobiletravelerstouseLBSswithperturbedlocation
inference error threshold and the prior knowledge about the
instead of exact location, referred to as pseudo-location, such
userâ€™slocationtodetermineasubsetoflocationsastheprotection
that the release of the pseudo-location can prevent the dis-
location set for protecting the actual location by increasing
adversaryâ€™s expected location inference error. In Phase II, we closure of user-specific and request-specific sensitive location
generate pseudo-locations (i.e., perturbed locations) in the way information [2], [3], [7], [8], [17], [19], while maintaining
thatachievesdifferentialprivacyovertheprotectionlocationset. desired utility of location information.
This two-phase location obfuscation is constructed dynamically
Recently, geo-indistinguishability [2] and expected infer-
by leveraging the relationship between two privacy notions
basedonadversaryâ€™scurrentpriorinformationanduser-specific ence error [18], [19] are proposed in the literature as the two
privacy requirements on different locations and at different statistical notions of location privacy. Geo-indistinguishability
times. Experiments with real-world datasets demonstrate that isderivedfromdifferentialprivacy[5]andensuresthatforany
ourPIVEapproacheffectivelyguaranteesthetwoprivacynotions two location points that are geographically close, the location
simultaneouslyandoutperformstheexistingmechanismsinterms obfuscation mechanism will produce a pseudo-location with
ofadaptiveprivacyprotectioninpresenceofskewedlocationsand similar probabilities. The expected inference error, as a statis-
computation efficiency.
ticalmetricinstead,takesintoaccountthepriorinformationof
an adversary about userâ€™s location, and measures location pri-
I. Introduction vacy by the expected distance between the estimated location
by the adversary and the true location. A number of location
We are entering a mobile Internet era where people and
obfuscationmechanisms[19],[20]havebeendevelopedsolely
vehicles are constantly connected while on the move through
based on the privacy notion of expected inference error.
mobile and wireless devices. Location becomes an important
piece ofinformation for enhancing suchubiquitous connectiv- In this paper, we argue that geo-indistinguishability and
ity through a rich selection of location based services (LBSs) expectedinferenceerroraretwocomplementarynotionsforlo-
cationprivacy.Existinggeo-indistinguishablemechanisms[2],
[3] guarantee location privacy with respect to the information
Permission to freely reproduce all or part of this paper for noncommercial leakage through a differential privacy based location obfus-
purposes is granted provided that copies bear this notice and the full citation
cation mechanism, but they do not consider the inference
on the first page. Reproduction for commercial purposes is strictly prohibited
without the prior written consent of the Internet Society, the first-named author attacks using prior knowledge [17]. We performed the bound
(for reproduction of an entire paper only), and the authorâ€™s employer if the analysis to formally examine the relationship between geo-
paper was prepared within the scope of employment. indistinguishabilityandexpectedinferenceerror.Weshowthat
NDSS â€™17, 26 February - 1 March 2017, San Diego, CA, USA
geo-indistinguishability may not adequately protect the abso-
Copyright 2017 Internet Society, ISBN 1-891562-46-0
http://dx.doi.org/10.14722/ndss.2017.23241 lute privacy of userâ€™s location against inference attacks withusing prior information. On the other hand, the mechanisms The former aims to bound the expected inference error in the
withexpectedinferenceerrorasprivacymetricareconstructed worst case and the latter aims to scope the possible posterior
based on the assumption of certain types of prior information information leakage. The PIVE approach provides dynamic
that the adversary may have, but without consideration of differentiallocationprivacywithpersonalizederrorboundand
constraint on the posterior information gain from the release canworkadaptivelyinpresenceofskewedpriordistributionof
of pseudo-locations. These mechanisms may be vulnerable to locations and efficiently for the scenarios in which users may
inference attacks with arbitrary prior knowledge. Thus, we have personalized and non-uniform privacy needs at different
argue that a strategic combination of the two privacy notions locations and for different LBSs.
can double shield location privacy by simultaneously limiting
Previous work [17] by Shokri is the first to identify the
information leakage of the location perturbation mechanism
need for integrating the two privacy notions and to propose a
andensuringtheinferenceerrortobeconstrainedforinference
joint optimization approach. This approach combines the two
attacks with prior information the adversary may have.
privacy notions together in parallel in a linear program and
In addition to combining the two privacy notions for produce the distribution of perturbed locations statically once
effective defense against inference attacks, we also argue that foralllocationsinanarea,andwerefertoitastheglobalop-
an effective location obfuscation mechanism should maintain timization approach. Compared to the joint optimization [17],
desired location utility and service quality for respective mo- PIVE takes a sequential and local approach to combine two
bile users and their LBSs. In practice, mobile users may have privacy notions. It separately applies the expected inference
verydifferentprivacyrequirementsfordifferenttypesofLBSs. error metric first, which produces a neighborhood protection
Even for the same LBS, users may have different privacy location set for the userâ€™s location by leveraging user defined
demands for different locations or for the same location at error bound and the prior information, and then produces the
different times. For example, a user may want the expected perturbed location by ensuring geo-indistinguishability and at
inferenceerrorofadversarytobelargerthan1kmwhenheisin the same time increasing the resilience of perturbed location
ahospitalorareligiousevent,butmayreducethisrequirement against inference attacks. Another feature of PIVE that is
to 200 meters when he is in a restaurant with a lot of other differentfromthejointoptimizationapproachistoleveragethe
restaurants nearby; or the user may not care about privacy at user defined personalized error bound (threshold) for different
some places (e.g., her home or office) during certain periods locations or for the same location at different times and
of a day, but needs the privacy at other places, such as her for computing the protection location sets dynamically and
travel routes and stops along some trajectories. adaptively.ThisallowsPIVEtobalanceprivacyandutilityfor
In this paper, we propose to design a dynamic differ- different locations while meeting the personalized inference
error bound constraint for perturbed locations.
ential location privacy mechanism with personalized error
bounds.First,weformallystudytherelationshipbetweengeo- PIVE algorithms are highly efficient in terms of com-
indistinguishability and expected inference error and examine putation complexity, compared to existing mechanisms that
their limitations through experimental study. The relationship need to solve a linear program with |X|2 decision variables
between two privacy notions helps to determine the noise and up to O(|X|3) constraints for previous joint optimization
level of location obfuscation required for protecting a location approach[17],whereXisthenumberofallpossiblelocations
against inference attacks. Second, we allow users to define of a user. First, PIVE only requires the search of a protection
personalized error bound for each of their locations and intro- locationsetlocallywithintheneighborhoodofauserâ€™scurrent
duce the concept of protection location set for each location, location by leveraging user-defined error bound, and simple
which identifies the neighborhood locations based on both the probability computation for the exponential mechanism. This
personalized error bound constraint and the prior distribution locality based design enables PIVE to adapt to the dynamic
that the adversary may have based on historical locations of changes of both prior information and privacy preferences per
a user, her mobility model or the population density. Based location more efficiently. Second, PIVE adaptively adjusts the
on the above development, we design a two-phase dynamic noiseleveloflocationobfuscationtopriorinformationthrough
differential location privacy framework, called PIVE, which searching a protection location set under the minimum infer-
integratesgeo-indistinguishabilityandexpectedinferenceerror enceerrorboundconstraint,whichprovidesdynamicdifferen-
toeffectivelyprotectlocationprivacyagainsttwopopulartypes
tially private mechanism to generate perturbed locations. We
of inference attacks: optimal inference attack and Bayesian implementthePIVEdynamiclocationobfuscationmechanism
inference attack. This framework constructs pseudo-locations and evaluate PIVE with real-world datasets. Our experimental
dynamically and adaptively, based on multiple pieces of in- results show that the PIVE approach effectively guarantees
formation that may change frequently in the spatial-temporal the two privacy notions simultaneously and outperforms the
context of a mobile user, such as the userâ€™s current location existing mechanisms that secure geo-indistinguishability or
at the time of her service request, her current location privacy that quantify location privacy by expected inference errors.
requirements,herlocationutilityandLBSqualitypreferences,
and the prior information that the adversary may have at this II. RelatedWork
time. In Phase I, we utilize the user-defined inference error
threshold and the prior knowledge about the userâ€™s location to Location privacy research started about ten years ago
determine the protection location set for protecting the actual with the notion of location k-anonymity with two landmark
location of a user and ensuring the lower bound of adver- results: (i) uniform location k-anonymity [10] and (ii) user-
saryâ€™s expected location inference error over this protection defined, personalized location k-anonymity [9]. The location
location set. In Phase II, we generate pseudo-locations that k-anonymity based solutions hide a userâ€™s exact location point
achieve differential privacy on this protection location set. using a spatial region that meets the two constraints: (a) it
2contains the exact location point of the user; and (b) there are techniques are computationally costly due to solving a linear
atleastkâˆ’1otheruserswhowillusethesamelocationregion program with |X|2 decision variables, and the perturbation
astheirreleasedlocationtomeetthekanonymityrequirement. solution is statically constructed once for all locations, which
Alternatively, some location obfuscation mechanisms achieve can be prohibitively expensive for frequently changing prior
privacy by using landmark objects or random perturbation information and frequently changing privacy/utility preference
instead of k-anonymity. [11] proposes to use the location by users at different locations and times.
of a closest landmark object as the perturbed location such
Our work is primarily related to two recent research
that the LBS severs process the location query based on
efforts in [17] and [4]. Concretely, Shokri [17] is the first
the landmark. [21] proposes to search the region that has
to propose a joint mechanism to integrate the two privacy
sufficientuserfootprintssuchthattheusercanfeelsafeforhis
notionsusingalinearprogrammingframework,demonstrating
location privacy. However, neither user-defined privacy notion
thepotentialforimprovementonprivacyprotection.However,
nor any formal privacy notion is provided and guaranteed by
the joint optimization mechanism uses uniform differential
the proposed region-based location cloaking mechanism.
privacy parameter and global privacy/utility metrics by av-
Recently, two stronger privacy notions are proposed based eraging over all locations. We argue that an overall metric
on statistical quantification of attack resilience: expected in- for all locations and a per-location based metric may result
ference error [18], [19] and geo-indistinguishability [2]. The in different allocations of privacy and utility. Thus PIVE is
former advocates the privacy notion based on its attack re- more suitable to situations where mobile users may have
siliencetothepriorinformationofadversarybymeasuringthe different privacy/utility preferences for different locations, at
expectedinferenceerrorandthelatterpromotesthedifferential different time and working with different LBSs. Next, unlike
privacynotiontoconstraintheposteriorinformationgainofan most existing geo-indistinguishable mechanisms that consider
adversary based on the release of pseudo-locations of mobile uniform differential privacy parameters for all users and all
user. A number of location obfuscation mechanisms [2]â€“[4], locations, Chatzikolakis and his co-authors [4] propose to
[17], [19] have been developed based on them. For example, adaptively decide the noise level of geo-indistinguishability
based on the prior distribution of userâ€™s location, Shokri et according to the privacy characteristics of local area. They
al. [19] proposed an optimal construction mechanism for compute the density of a local area for each location and
location perturbation against inference attacks through linear adds less noise for perturbed location if the density of the
programming. The mechanism aims to maximize the expected actual location area is high and more noise when the actual
inference error (resp. service quality) given the constraint location falls into the low density areas. However, the density
on the service quality loss(resp. expected inference error). of a local area is defined in terms of the public locations
The service quality loss is characterized by the expected suchasrestaurants,churchesandhospitals.Thusthisapproach
distance between real and reported locations. Based on Shokri assumesthatthesedifferenttypesofpubliclocationsareofthe
et al.â€™s optimization framework, Theodorakopoulos et al [20] same privacy sensitivity for all mobile users at all time, and
advocated to follow a user over his trajectory and maximizes thus fails to model the personalized geo-indistinguishability
privacy for each location with considering privacy leakage withrespecttodifferentlocations,differenttimesanddifferent
due to location correlation between past, current and future LBSs. In comparison, PIVE adaptively adjusts the noise level
locations in a trajectory. AndreÂ´s et al. [2] proposed the notion oflocationobfuscationaccordingtoapersonalizederrorbound
of geo-indistinguishability. A Planar Laplace (LP) mechanism and the prior distribution in local area.
isdevelopedtoachievethe(cid:15)geo-indistinguishabilitybyadding
noisetoactuallocationdrawnfromapolarLaplaciandistribu- III. Overview
tion. Several recent location privacy development projects [1], Inthissectionwefirstintroducethenotationofdifferential
[7],[8]haveadoptedorextended(cid:15) geo-indistinguishabilityfor
privacy, describe the model of location obfuscation and the
location privacy protection. Bordenabe et al. [3] proposed an
adversarymodelusedinthispaper.Then,westatetheproblem
optimal geo-indistinguishable mechanism to minimize the ser-
to be addressed in this paper.
vice quality loss. Similar to [19], it uses linear programing to
minimize global expected service quality loss, with a uniform A. Differential Privacy
privacyparameterforgeo-indistinguishability.Chatzikokolakis Differential privacy is a rigorous mathematical framework
et al [4] defines privacy mass over the point of interests thatoffersprovableprivacyguaranteesforprotectingindividual
on the plane and adaptively decide the privacy parameter of
data in statistical databases and has recently become a de-
geo-indistinguishability for a location with considering local
facto standard for privacy. It ensures that arbitrary changes to
characteristics of each area.
asingleindividualâ€™srowresultinonlystatisticallyinsignificant
The mechanisms in [3], [17], [19] follow a global op- changes in the outcome of a data analysis. Formally,
timization framework: given the privacy or service quality Definition 1 (Differential Privacy [5]): A randomized
constraints,alinearprogrammingmodelisformulatedtomax- mechanism A provides (cid:15)-differential privacy if for any two
imizeservicequalityorprivacyrespectively.Suchformulation neighboring database D and D that differ in only a single
uses uniform differential privacy parameter and global pri- 1 2
entry, âˆ€S âŠ†Range(A),
vacy/quality metrics averaged over all locations, which offers
uniform privacy/utility with respect to all locations and all Pr(A(D 1)âˆˆS)
â‰¤e(cid:15) (1)
LBSs.Itcouldbeadifficulttasktopre-determinetheconstraint Pr(A)(D )âˆˆS)
2
for every location where a user will ask for any LBS service
request with his personalized and spatial-temporal dependent The standard approach to achieve differential privacy is
as well as LBS dependent privacy requirement. Besides, these the sensitivity method [5], [6] (e.g., Laplacian mechanism)
3that adds to the query output the noise proportional to the distribution, and human movement pattern, etc. Following
sensitivity of the query function. The sensitivity measures the previous works [18], [19], the prior knowledge is captured
maximum change in the query answers due to the change of by a prior (probability) distribution Ï€ over the set of possible
a single database entry. locations of the user, X. The adversary can build Ï€ for the
target user in multiple ways:
Definition 2 (Sensitivity [6]): The sensitivity of a query
function q:Dâ†’Rd is â€¢ Using the population density or popularity [4], [21]
âˆ†q= max||q(D )âˆ’q(D )|| (2) of every place as Ï€ that can be obtained from public
1 2 1
D1,D2 traces, check-in datasets or demographic information;
where D 1, D 2 âˆˆDareanytwoneighboringdatasetsthatdiffer â€¢ Using the userâ€™s historical access information to a
at most one element, ||Â·|| 1 denotes L 1 norm. location based service that records his locations from
To achieve (cid:15)-differential privacy, the Laplacian mechanism which he sent location based queries [19].
perturbs the output by q(D) + Lap(âˆ†q/(cid:15)), where Lap(âˆ—) = â€¢ Using the mobility pattern modeled by Markov chain
(Z ,...,Z ) in which Z are drawn i.i.d from Laplace distri-
1 d i toinferthepossiblelocationsofauseratcurrenttime
bution.Suchdifferentiallyprivatemechanismensuresthattwo
and their probabilities given his previous disclosed
neighboring datasets are indistinguishable on the distribution
locations [20].
of query answers.
Inthispaperweassumetheadversarywithpriorknowledge
Theexponentialmechanism[14]isanothermechanismthat
preserves (cid:15)-differential privacy. Given the output range R, a of Ï€ regardless of in which way it is derived. We also
utility function u : DÃ—R â†’ R is defined, which maps the assume that the adversary also knows the location obfuscation
dataset/output pairs to utility scores. The sensitivity of utility mechanism, i.e, how it works and the distribution f. Such
adversary is called an informed adversary [6].
function u is
âˆ†u=maxmax|u(D,r)âˆ’u(D(cid:48),r)| (3) Theadversaryâ€™sgoalistoinfertheuserâ€™sactuallocation x.
râˆˆR D,D(cid:48) Once the adversary observes the pseudo-location x(cid:48) reported
by the user, he computes the posterior probability distribution,
over any two neighboring datasets D and D(cid:48).
Pr(x|x(cid:48)) for x âˆˆ X, i.e., the probability that x is the actual
Definition 3 (The exponential mechanism [14]): The ex- location that generated x(cid:48):
ponential mechanism selects and outputs an element r âˆˆ R Ï€(x)f(x(cid:48)|x)
with probability proportional to exp((cid:15)u 2( âˆ†D u,r)). Pr(x|x(cid:48))= (cid:80)
Ï€(x)f(x(cid:48)|x)
(5)
xâˆˆX
B. Location Obfuscation Mechanism
Based on the posterior distribution, a Bayesian adversary
In this paper we are interested in the location based
canperformoptimalinferenceattack[19]whichaimstomin-
services in which the users sporadically reveal their locations
imize his expected inference error, i.e., the expected distortion
for issuing spatial queries, e.g., finding the nearby points-of-
between the estimated location xË† and userâ€™s actual location x,
interests or friends. We do not consider the protection of the
given an observed pseudo-location x(cid:48). That is,
usersâ€™ identities that prevents the adversary to discover which
(cid:88)
user issues the query. In this case, the typical way to preserve xË†=argmin Pr(x|x(cid:48))d (xË†,x) (6)
p
the usersâ€™ location privacy is to randomly obfuscate the userâ€™s xË†âˆˆX xâˆˆX
actual location to a pseudo-location and report this pseudo-
where d can be Hamming distance or Euclidean distance be-
location to the location based service providers. In this paper p
tweenlocations,ortheirsemanticdissimilarity,whichcaptures
we assume discretized locations as in [3], [19] and use X to
the privacy loss from inference attack. We assume d to be
denote the set of the userâ€™s possible locations. An obfuscation p
Euclidean distance d for optimal inference attack.
mechanismdeterminestherandommappingbetweentheuserâ€™s
actual locations A and pseudo-locations O, with following the Ifd isHammingdistance,forwhichd (xË†,x)=0if xË†= x,
p p
probability distribution and d (xË†,x) = 1 otherwise, it is easy to see that the optimal
p
f(x(cid:48)|x)=Pr(O= x(cid:48)|A= x) x,x(cid:48) âˆˆX (4) inferenceattackactuallyguessestheactuallocationastheone
having the maximum posterior probability. We call this attack
That is, it takes the actual location x as input and chooses a as Bayesian inference attack, represented by
pseudo-location x(cid:48) by sampling from the distribution f(x(cid:48)|x).
xË†=argmaxPr(x|x(cid:48)) (7)
An obfuscation mechanism is indeed a specification of prob-
ability distributions f(Â·|Â·) over X. Different obfuscation mech- xâˆˆX
anisms determine such probability distributions in different
D. Problem Statement
ways.
We can categorize the existing research on quantifying
C. Adversary Model
location privacy into two broad categories based on two
Thispaperassumestheadversarythathaspriorknowledge notions of location privacy: geo-indistinguishability and ex-
about userâ€™s location. We argue that the prior information pected inference error. The location privacy solutions that
aboutusersâ€™locationsinherentlyexistsbecauseofthepublicly promote geo-indistinguishability are primarily based on the
available transportation information, geographical information theory of differential privacy [5]. The solutions that quantify
ofpointsofinterest,roadnetworks,residentialarea,population locationprivacybytheamountofexpectedinferenceerrorare
4typically based on Bayesian theory and thus are referred to likenearestneighborandrangequeriesusuallydependsonthe
asBayesianoptimalmechanisms.Theclassofsolutionsbased Euclidean distance between the actual location and reported
ongeo-indistinguishabilityprotectlocationprivacywithoutany location,weusetheEuclideandistanced asd ,asinprevious
q
assumption of adversaryâ€™s prior information but consequently works [3], [17].
do not consider absolute location privacy against inference
An optimal mechanism [19] has been proposed to max-
attacksintermsofexpectedinferenceerrorwhentheadversary
imize the expected inference error (resp. service quality)
has some prior knowledge about the userâ€™s exact location or
given the constraint on the service quality loss (resp. ex-
pastreleasedlocations.Incontrast,theBayesianoptimalmech-
pected inference error). In such approach, privacy and quality
anisms advocate the background inference resilient location
are controlled in terms of these global performance metrics
privacybutarenotasrobustasgeo-indistinguishabilityagainst
that are averaged over all locations, which does not provide
adversary with arbitrary prior information.
users a straightforward way to explicitly specify different
The problem statement can be summarized from three privacy/quality requirements at different locations and times.
dimensions. First, geo-indistinguishability and expected infer- Also, for the prior information that is dynamically built by
ence error are two complementary privacy notions for protect- the adversary with mobility model [20], a linear program has
ing location privacy against inference attacks. It is critical to to be recomputed under every change. More importantly, the
understand the relationship between the two privacy notions, construction relies on the assumption about adversaryâ€™s prior
and the limitations of existing location obfuscation mecha- information, different prior information with higher accuracy
nismsthatsupportonlyoneofthetwoprivacynotions.Second, level may cause privacy degradation of the mechanism, as
it is not only beneficial but also feasible to develop a location shown in [17].
obfuscation mechanism that can effectively integrate the two
We note that the upper limit of expected inference error
privacy notions. Third, incorporating user-defined constraint,
is achieved when the maximum tolerable service quality loss
suchasminimuminferenceerrorbound,notonlyimprovesthe
becomes sufficiently large or not bounded. In this case, the
usabilityperspective,whichiscriticalforthewidedeployment
pseudo-locations are generated independently of userâ€™s loca-
of privacy protection models, but also enables adaptive noise
tions, and the adversaryâ€™s best strategy is to make guess based
adjustmentforgeo-indistinguishabilityandsupportscustomiz-
able privacy/utility requirement of mobile users that allows on prior distribution. Therefore, the upper limit of expected
personalizederrorboundsatdifferentlocations,differenttimes, inference error is
(cid:88)
and for different LBSs. This motivates the design and imple- ExpErr =min Ï€(x)d (xË†,x) (11)
mentation of PIVE, a two-phase dynamic differential location max xË† p
xâˆˆX
privacy framework for ensuring both notions of location pri-
vacy with personalized error bounds.
B. Geo-indistinguishability
IV. LocationPrivacyNotions Amechanismsatisfies(cid:15) -geo-indistinguishability[2]ifffor
g
all x, y,
In this section we provide a detailed analysis and illustra- f(x(cid:48)|x)
tionofthetwolocationprivacynotions:expectedinferenceer- â‰¤e(cid:15)gd(x,y) (12)
f(x(cid:48)|y)
ror and geo-indistinguishability. We first briefly describe each
notion,itsrespectivelocationperturbationmodel,comparethe where d(x,y) is the Euclidean distance between x and y. It
mechanisms based on these two privacy notions and identify ensures that for two locations that are geographically close,
and illustrate their inherent problems through both formal and the probability distributions of pseudo-locations generated at
experimental analysis. them are similar. Note, as shown in [2], (cid:15) is decided by a
g
privacy parameter (cid:15) (â‰¥ 0) and the range of circular region
A. Expected Inference Error
centeredattheuserâ€™slocation x.Essentiallyitmeansthatgeo-
Under the inference attack of Bayesian adversary, the indistinguishability aims to protect this circular region with
location privacy offered by a mechanism is measured by the guaranteeing (cid:15)-differential privacy over it. Because the actual
expected inference error of the adversary averaged over all location is protected by being hidden among all the locations
possible locations in X, referred to as unconditional expected in the region due to their similar probability distributions
inference error [18], [19], computed as for generating pseudo-locations, we call such region as the
(cid:88) (cid:88) protection region and the set of locations within the region as
Pr(x(cid:48))min Pr(x|x(cid:48))d (xË†,x) (8)
p theprotectionlocationset.LetDbethediameterofprotection
xË†âˆˆX
x(cid:48)âˆˆX xâˆˆX region and (cid:15) =(cid:15)/D, the mechanism is (cid:15)-differentially private
(cid:88) (cid:88) g
= min Ï€(x)f(x(cid:48)|x)d (xË†,x) (9) for any two locations x and y in the protection region, i.e.,
p
xË†âˆˆX
x(cid:48)âˆˆX xâˆˆX f(x(cid:48)|x)
eâˆ’(cid:15) â‰¤ â‰¤e(cid:15). (13)
Similarly, the service quality loss is measured by the
f(x(cid:48)|y)
unconditional expected distance between actual location and
reported pseudo-location over the quality metric d (Â·), i.e., Upper bound of posterior probability: Let Î¦ be the
q
protectionregion.Anupperboundoftheposteriordistribution
(cid:88)(cid:88)
Ï€(x)f(x(cid:48)|x)d (x(cid:48),x) (10) of location xâˆˆÎ¦, given any observed pseudo-location x(cid:48), can
q
xâˆˆXx(cid:48)âˆˆX be obtained as follows:
whered q determinesthequalitylossbyreporting x(cid:48) insteadof Pr(x|x(cid:48))= (cid:80)Ï€(x)f(x(cid:48)|x) (14)
actual location x. Since the accuracy of location based queries Ï€(y)f(x(cid:48)|y)
yâˆˆX
5Ï€(x)f(x(cid:48)|x)
= inference attack (6) respectively. Both of them depend on the
(cid:80) yâˆˆÎ¦Ï€(y)f(x(cid:48)|y)+(cid:80)
yâˆˆX\Î¦Ï€(y)f(x(cid:48)|y) prior distribution over protection region Î¦, which suggests
(15) that geo-indistinguishability may not provide enough location
Ï€(x)f(x(cid:48)|x) protection against Bayesian adversary with sufficient prior
â‰¤ (cid:80) yâˆˆÎ¦Ï€(y)f(x(cid:48)|y) (16) information. The protection of geo-indistinguishability only
measures the impact of userâ€™s location on the output, but
Ï€(x)
= (cid:80) (17) not the inference capability of Bayesian adversary with his
yâˆˆÎ¦Ï€(y)f(x(cid:48)|y)/f(x(cid:48)|x)
priorinformation.Wehavearguedthatcertainpriorknowledge
Applying (13),we have to identify the userâ€™s location inherently exists, but geo-
Ï€(x) indistinguishable mechanisms produce pseudo-locations as if
â‰¤ Ï€(x)+eâˆ’(cid:15)(cid:80)
yâˆˆÎ¦,y(cid:44)xÏ€(y)
(18) the adversary does not have any prior knowledge.
Since 0<eâˆ’(cid:15) <1,we have Also, we can see that it has limitations for geo-
Ï€(x) indistinguishable mechanisms in existing works [2], [3], [7],
â‰¤e(cid:15) (cid:80) (19) [8]touseuniformdifferentialprivacyparameterandprotection
yâˆˆÎ¦Ï€(y)
region radius, independently of the userâ€™s locations. Because
the prior distribution over protection regions around different
The upper bound of posterior probability (19) implies locations are mostly different, geo-indistinguishablity may not
that no matter what prior information the adversary has,
achieve the same level privacy against Bayesian adversary,
geo-indistinguishability constrains the multiplicative distance
indicated by bounds (19) and (25) that change with priors.
between posterior distribution Pr(x|x(cid:48)) and prior distribution
For example, in an urban area with many possible locations
(cid:80) yÏ€ âˆˆÎ¦(x Ï€) (y) within e(cid:15), and thus limits the posterior information densely distributed, the user can use a small radius r for his
gain of the adversary. This makes location obfuscation more protection region in which (cid:15)-differential privacy is achieved;
robustagainstBayesianadversarycomparedwiththeBayesian but in a rural area, when the userâ€™s location is only possible
mechanism [19] that could be constructed with incomplete location within it, using a small radius to generate a pseudo-
knowledge about the adversaryâ€™s prior information. locationdoesnotprovidesufficientprotection.Thisisindicated
by that the upper bound (19) achieves maximum e(cid:15) (â‰¥ 1)and
Lower bound of inference error: We further consider
the lower bound (25) becomes zero, which actually means no
location privacy in terms of expected inference error. Let
boundfortheposteriorprobabilityandinferenceerror.Indeed,
z be the estimated location by the adversary, i.e., z =
argmin (cid:80) Pr(x|x(cid:48))d(xË†,x). The conditional expected infer- theadversarycaneasilyassociatethepseudo-locationwiththe
xË† xâˆˆX actuallocationgiventhepriorknowledgethatthereisonlyone
ence error is (cid:88) possible location in this area.
Pr(x|x(cid:48))d (z,x) (20)
p
xâˆˆX
C. Experimental Illustration
Here we consider the lower bound for it, which is indeed
achieved in the worst case that the adversary narrows possible In this section we evaluate the privacy of geo-
guesses to the location set within the protection region that indistinguishability against optimal and Bayesian inference at-
containstheuserâ€™sactuallocation.Therefore,thelowerbound tack and validateour analysis result in previoussection. In or-
is der to see the lack of protection against inference attacks with
(cid:88) Pr(x|x(cid:48))
geo-indistinguishability, we compare a geo-indistinguishable
m xË†âˆˆi Xn
xâˆˆÎ¦
(cid:80) yâˆˆÎ¦Pr(y|x(cid:48))d p(xË†,x) (21)
mechanism with a mechanism constructed with expected in-
ferenceerrorasprivacymetricthatisoptimalagainstinference
Letz(cid:48) =argmin xË†âˆˆX(cid:80) xâˆˆÎ¦ (cid:80) yP âˆˆÎ¦r( Px r|x (y(cid:48)) |x(cid:48))d p(xË†,x),theabovebecomes attacks. Two mechanisms are given below:
=(cid:88)
xâˆˆÎ¦
(cid:80) yP âˆˆÎ¦r( Px r|x (y(cid:48)) |x(cid:48))d p(z(cid:48),x) (22) â€¢ T deh ne oto ep dti bm ya Ml (cid:15) (cid:15)g g,-g the ao t-i mnd inis imtin izg eu sis th ha eb sl ee rvm ice ech qa un ai ls im tyl[ o3 s] s,
(cid:88) Ï€(x)f(x(cid:48)|x) (10) subject to geo-indistinguishability (12);
=
xâˆˆÎ¦
(cid:80) yâˆˆÎ¦Ï€(y)f(x(cid:48)|y)d p(z(cid:48),x) (23)
â€¢ The optimal Bayesian mechanism [19], denoted by
M , that maximizes the expected inference error (8)
Using (13), we have B
undertheconstraintofthemaximumtolerableservice
â‰¥eâˆ’(cid:15)(cid:88)
xâˆˆÎ¦
(cid:80) yÏ€ âˆˆÎ¦(x Ï€) (y)d p(z(cid:48),x) (24) quality loss Qm loa sx s for (10).
â‰¥eâˆ’(cid:15)m xË†âˆˆi Î¦n(cid:88)
xâˆˆÎ¦
(cid:80) yÏ€ âˆˆÎ¦(x Ï€) (y)d p(xË†,x) (25) W eM xe B pec c ch a to n eo das ce inht fih eee rv em e nt cb h ee ec esa rau rm ose rei (t l 8eh )va e ds l eb fioe f ne eln o dcs wah to ii tow hnn Epi urn i cv[ la3 idc] eyt ah i na nt dtM e isr t(cid:15) m ag nsa cn o ed f
,
where we have the derivation from (24) to (25) given that Î¦ which enables us to make a fair comparison of them under
optimal inference attack. To achieve that, given M and the
is convex and thus the minimum is obtained when xË† is the (cid:15)g
weighted geometric median of Î¦ that lies in the region. minimum quality loss q it obtains, M B is derived with letting
Qmax = q. Besides, we are particularly interested in the local
loss
The bounds of posterior probability (19) and inference performance of the mechanisms for protecting each location,
error(25)indicatethecapabilityofgeo-indistinguishabilityfor rather than only considering the global average metrics as
defending against Bayesian inference attack (7) and optimal previous works [3], [19].
65 1
345
78911 01 11111 56789 2222222 1234567 23333 90123
333 567 444 12344 44 67 49
)m k(
ro
rre34 B Ga ey oe -is nia dn istinguishability ytilib
a b
o
rP00 .. 68 B G Ba aey yoe e-is sni ia d an i ns t (i Hng au mis mh ia nb gi )lity
12 6 111 234 202834 334 890 45 e cn
e re
fn
i e
g
a
re12
sse
ccu
S
kca
ttA00 .. 24
48 50 vA0
0
0 10 20 30 40 50 0 10 20 30 40 50
Region id Region id
Fig. 1: The 50 regions in the location Fig. 2: The average inference error of Fig. 3: The success probability of
dataset. optimal inference attack. Bayesian inference attack.
In our experiment we use location data extracted from any userâ€™s location, but M turns out to uniformly sample a
B
Geo-life dataset [22]â€“[24]. The details of data processing is locationfromXasthepseudo-location.Inessence,bothbreak
described in Section VI. Specifically, here we use all-day thedependencybetweenpseudo-locationsandactuallocations.
locationdataofasingleuserwithid0,andconsider50regions
shown in Figure 1 as X. The prior for the user is computed 2)Bayesian inference attack: For Bayesian inference at-
by counting and normalizing the number of his/her location tack, we are interested in the probability that Bayesian infer-
points falling into each of 50 regions. ence attack makes correct guesses about the actual location
for a user. We replace optimal inference attack in the above
1)Optimal inference attack: We use (cid:15) =0.9 for M that
incurs minimum quality loss 0.89km.
Lettig
ng Qmax
=0.8(cid:15)g
9km,
simulation with Bayesian inference attack, repeat the simu-
loss lation 1000 times, and calculate the percentage of successful
we follow the approach in [19] to obtain M with maximum
B guesses at every location. Note that M is constructed with
B
expected inference error 0.89km. We simulate a user using
using Euclidean distance based privacy metric. With using
two mechanisms at every region in X, repeat the simulation
Hamming distance, an optimal Bayesian mechanism against
1000 times, and measure the inference error, i.e., the distance Bayesian inference attack M(cid:48) can be derived in the same way
between the actual location and the location inferred by B
as M . Since we focus on Euclidean distance based privacy
B
optimal inference attack (6), averaged over 1000 times for notions and Hamming distance does not guarantee it, M(cid:48) is
every region. The result is shown in Figure 2. B
only used as a reference for examining the resilience of the
Though both M and M can guarantee the expected two other mechanisms constructed with Euclidean distance
inference error 0.89(cid:15) kg m at moB st locations, we can see that based privacy notion against Bayesian inference attack. With
aM n(cid:15) dg 5h 0as , ba ulm to thst ez oe pro timin af ler se on luce tioe nrro ar gaa it nsre tg ti ho ens inw fei rt eh ni cd e4 a8 tt, a4 c9 k pth re obs aa bm ile itiQ esm loa s ox s f= th0 re.8 e9k mm e, chF ai ng iu sr me s3 . Ash sow ws eth cae nat st ea ec ,k Msu B(cid:48)cc he ass s
M incurs much larger inference error at them. This indicates zero attack success probabilities at all regions except region
thaB tgeo-indistinguishabilitydoesnotprovidesufficientprivacy 25, which demonstrates M B(cid:48)â€™s optimality with using Hamming
protection against optimal inference attack at these locations. distance against Bayesian inference attack compared with M B
The essential reason is that geo-indistinguishability does not and M (cid:15)g. M B has at least 50% success probabilities at 50%
consider any prior distribution the adversary may have. As regions but M (cid:15)g has zero attack success probabilities at more
we can see from Figure 1, region 48, 49 and 50 are isolated than 70% regions. The result demonstrates the improvement
locations on the prior distribution over X, which means zero introduced by geo-indistinguishability compared with M B,
probabilities for any other locations in their neighborhood. as a result of limiting the relative ratio between posterior
Such skewed probability distribution lets the upper bound of distribution and prior distribution.
posterior probability (19) to be e(cid:15) (larger than 1) given any
For M , there are multiple locations, i.e., region 48, 49
pseudo-locationsreportedfromtheseisolatedlocations,which (cid:15)g
and 50, with high success probabilities close to 1. This is
means no bound for the posterior probability and thus it can
because that the posterior probability Pr(x|x(cid:48)) conditioned on
get close to one on the true locations. Similarly, the lower
most pseudo-locations reported from these regions is much
boundofexpectedinferenceerrorin(25)becomeszeroatthese
higher on the actual locations (close to 1) than on others,
regions, meaning no guarantee for location privacy in terms
which also causes lowest inference error at these regions in
of expected inference error. Consequently, with minimization
Figure 2. Intuitively, a region has weak protection against
on the quality loss, M has probability larger than 0.9 to
(cid:15)g inference attacks if the pseudo-locations generated from it
report truthfully at these regions, and the posterior probability
Pr(x|x(cid:48)) conditioned on x(cid:48) = 48,49,50 get close to one on are highly associable with the true location, represented by
x=48,49,50 respectively. high posterior probability on the true location. Our result
demonstrates that no guarantee on the bounds (19) and (25)
InFigure4,wevary(cid:15) from0.7to0.1and Qmax from1to for inference attacks allows such strong association to happen
g loss
2andmeasuretheexpectedinferenceerror(8).Wecanseethat to the skewed locations with M , leading to weak protection
both M and M havetheexpectedinferenceerrortoincrease for these regions. Note that, b(cid:15) eg cause for M(cid:48) region 25 is
to
1.178(cid:15)g
and
remB
ain the same after that. This value is exactly the maximum point of posterior distributions
PB
r(x|x(cid:48)) for any
the value calculated by (11), which validates the upper limit x(cid:48), the adversary always guess 25 no matter where the user
(11).Wenote M and M achievethislimitindifferentways: is, and thus region 25 has success probability 1. It is not
(cid:15)g B
M alwayschoosesthesameregion25aspseudo-locationfor because of the weak protection as for regions 48-50 with
(cid:15)g
7ðœ–ðœ–ð‘”ð‘” )mk(
rorrE
ecnerefnI
detcepxE
0.8 0.6 0.4 0.2 0 0.6 privacy preference for his current location. Considering these ytilib
a
b0.5 i cs as nue es ff, ew ce tiva eim lyt co od me bsi ig nn ea gelo oc -a inti do in sto inb gf uu is sc ha ati bo in litm ye ac nh dan ei xs pm ect th ea dt
o rp
sse
ccu00 .. 34
i cn uf se tr oe mnc ize abe lr ero pr r, ivw ach yile pro efp ee rr ea nti cn eg
s
fa od ra tp ht eive ul sy ersw .ith supporting
GBa ey oe -is nia dn
istinguishability
s kca ttA00 .. 12
V. OurSolutionApproach
0 0.5 1 0 g 1.5 2 2.5
ð‘šð‘šð‘šð‘šð‘šð‘š In this section we describe PIVE, a two-phase dynamic
Fig. 4: Max Eð‘„ð‘„xð‘™ð‘™ð‘™ð‘™pð‘™ð‘™ð‘™ð‘™ected Error. Fig. 5: (cid:15) v.s. P .
g s approach to protect location privacy in terms of both geo-
indistinguishability and expected inference error. We first
M . The posterior probability achieves maximum on region present the PIVE two phase location obfuscation framework
(cid:15)g
25 but only up to 0.37, which is much smaller than that on and then describe each phase in detail. In the first phase, we
regions48-50with M .Highposteriorprobabilityincursboth determine a set of locations (i.e., protection location set) to
(cid:15)g
low inference error and high success probability, and skewed protect userâ€™s actual location, with guaranteeing the expected
locations actually show the worst case vulnerabilities of that, location inference errors with the user-defined threshold and
thusinourexperimentwehaveparticulardiscussionsforsuch the adversaryâ€™s prior knowledge with respect to the userâ€™s
regions. location. we develop a Hilbert curve based method and its
optimization for efficiently and accurately determining the
Becausetheuserhasdifferentprobabilitiestovisiteveryre-
protection location set. In the second phase, we devise a
gion,weevaluatetheexpectedsuccessprobabilityofBayesian differentially private mechanism to generate pseudo-locations
inference attack as follows:
withstrongutilityguaranteewithrespecttotheservicequality.
(cid:88)(cid:88)
P = Ï€(x)f(x(cid:48)|x)c(x,x(cid:48)) (26)
s A. PIVE Two-Phase Framework
xâˆˆXx(cid:48)âˆˆX
where c(x,x(cid:48)) = 1 if the actual location x is correctly Our goal is to design a mechanism that achieves geo-
inferred given pseudo-location x(cid:48), i.e., x=argmax Pr(y|x(cid:48)); indistinguishability while providing lower bound on expected
otherwise c(x,x(cid:48)) = 0. We compute P for two myâˆˆ eX chanisms inference error against optimal inference attacks. A chal-
showninFigure3,andobtain P =0.19s for M and P =0.27 lenging problem is how to integrate both privacy notions to
s B s a mechanism designed to obfuscate locations instantly and
for M . M that is constructed with prior information against
(cid:15)g B adaptively. Basically, our solution is to dynamically choose
Bayesian inference attack achieves better privacy than M .
(cid:15)g a protection location set to guarantee expected inference error
We also measure the expected attack success probability for
M with different privacy parameter (cid:15) , shown in Figure 5. and produce pseudo-locations in a differentially private way
(cid:15)g g for every location in the set.
Smaller (cid:15) indicates higher privacy. When (cid:15) gets close to
g g
zero, the multiplicative distance between posterior and prior To introduce our approach, we first define (cid:15)-differential
distributionapproachestoone,whichmeansthattheadversary location privacy over an arbitrary region containing the actual
cannot do better than just guessing the actual location by location, as opposed to geo-indistinguishability that is defined
prior knowledge. Thatâ€™s why the curve becomes flat when over the circular neighborhood centered at the actual location.
(cid:15) approaches to zero in Figure 5. In contrast, when (cid:15) (as
g g Differential privacy requires that a query function has un-
also(cid:15))increases,theupperboundofposteriorprobability(19)
substantialdifferencefortheoutputsoveranytwoneighboring
increases,lettingthemechanismtruthfullyreportthelocations
datasets that differ only in a single element. The location
with higher probabilities under quality loss minimization.
obfuscation mechanism for a user only involves a single
data record, i.e., his current location. Differentially private
D. Our Design Objective
location obfuscation requires the definition of â€œneighboringâ€
Fromourformalandexperimentalanalysis,wecanseethat location points to the userâ€™s location, such that they have
geo-indistinguishabilitylimitstheprivacyleakagebybounding the similar probabilities to produce a pseudo-location. The
the relative information gain of the adversary given observed neighborhood consisting of all â€œneighboringâ€ locations indeed
pseudo-locations, regardless of what kind of prior information functionsasâ€œaminimumcrowdâ€fortheactuallocationtoâ€œbe
the adversary may have. But it does not ensure absolute hidden in a crowdâ€. As mentioned in Section IV-B, previous
location privacy guarantee in terms of expected inference geo-indistinguishabile mechanisms [2], [3] actually regard the
error against inference attacks (6) and (7). Bayesian optimal circular region centered at the userâ€™s location with a uniform
mechanisms protect location privacy by maximizing expected radius as such neighborhood for protection. In this paper, we
inference error against inference attacks but require assuming define â€œneighboringâ€ relationship over a set of locations in an
apriorlocationdistributionthattheadversaryhas,whichisnot arbitraryregionthatcontainstheuserâ€™sactuallocation,referred
robustagainstadversarieswitharbitraryknowledge.Thus,itis to as protection location set, and accordingly differentially
desirabletohavebothprivacynotionsinalocationobfuscation private location obfuscation is defined as follows:
mechanism. On the other hand, existing geo-indistinguishable
Definition 4: A randomized location obfuscation mecha-
mechanisms suppose uniform differential privacy parameters
nism f(Â·|Â·)satisfies(cid:15)-differentialprivacyonprotectionlocation
over every location, which may either cause unnecessarily
set Î¦, if for any locations x,yâˆˆÎ¦, and any output x(cid:48),
large noise level at some locations or insufficient noise level
at others leading to privacy disclosure, and their formulations f(x(cid:48)|x)
â‰¤e(cid:15) (27)
donotprovidetheuserastraightforwardwaytocustomizehis f(x(cid:48)|y)
8Prior distribution Differential privacy parameter
protectionlocationsetthatisdeterminedwithpriordistribution
ðœ‹ ðœ–
Ï€ and e(cid:15)E , PIVE achieves differential privacy while guaran-
m
True location
teeing a lower bound for the adversaryâ€™s expected inference
ð‘¥ Pseudo-location
â„± Î¦ ð’¦ ð‘¥â€² error. This framework offers adaptive location protection for
ð¸ Protection users according to their current locations and requirements on
ð‘š
location set two privacy notions (expressed by E and (cid:15)), and the latest
Minimum Inference error m
prior distribution the adversary could have known (e.g., by
Fig. 6: The framework of PIVE. F is the algorithm to
inference with the mobility model of users). Previous geo-
determinetheprotectionlocationsetÎ¦andK isthedifferential
indistinguishable mechanisms [2], [3] can be regarded as the
mechanism to produce a pseudo-location.
special cases of our framework with F using the circular
neighborhood with a fixed radius as the protection location
Based on the upper bound of posterior probability (19), here set without considering any prior distribution and inference
(cid:15) is chosen to achieve a desired bound of the multiplicative error bound.
distance between posterior distribution and prior distribution,
PIVEprovidestwoprivacycontrolknobs:1)theminimum
to limit the adversaryâ€™s posterior information gain.
inference error E and 2) the differential privacy parameter
m
Then,weconsiderhowtoguaranteetheexpectedinference (cid:15). Through these parameters, we allow users to define their
error via protection location set. Let desiredprivacypreferencesatdifferentlocations.Theminerror
(cid:88) parameter E aims to bound the expected inference error in
ExpEr(x(cid:48))=min Pr(x|x(cid:48))d(xË†,x) (28) the worst cam se. The differential privacy parameter (cid:15) allows
xË†âˆˆX
xâˆˆX users to constrain the posterior information leakage via the
E(Î¦)=min(cid:88) (cid:80)Ï€(x)
d(xË†,x) (29)
provisioning of differential privacy. Given that (cid:15)-differential
xË†âˆˆÎ¦
xâˆˆÎ¦
yâˆˆÎ¦Ï€(y) privacyisthepropertyoftherandommechanismK producing
pseudo-locations, one possible way for a user to set these two
where we choose Euclidean distance as privacy metric as parametersistouseafixed(cid:15)forK andsetE accordingtothis
m
previous works [3], ExpEr(x(cid:48)) is the conditional expected userâ€™s tolerance estimation on the lowest bound of expected
inference error given any observed pseudo-location x(cid:48). For inference error of the adversary against the protection region,
optimal inference attack with using x(cid:48), according to the lower for example, E =0.1km.
m
bound result for expected inference error in (25), we have
B. Determining Protection Location Set
ExpEr(x(cid:48))â‰¥eâˆ’(cid:15)E(Î¦) (30)
Given the userâ€™s location x, the problem is how to effi-
Toensurealowerboundforconditionalexpectedinference ciently determine its protection location set Î¦ (x âˆˆ Î¦) that
error ExpEr(x(cid:48)), we introduce privacy parameter E m that satisfies E(Î¦) â‰¥ e(cid:15)E m with a diameter as small as possible.
is specified by the user according to his current locationâ€™s Meanwhile, we note the diameter of the protection location
sensitivity, such that âˆ€x(cid:48), ExpEr(x(cid:48)) â‰¥ E m. To ensure that, set cannot be less than e(cid:15)E m, given by the following theorem.
it is sufficient to satisfy that Theorem 2: Let D(Î¦) be the diameter of protection loca-
E(Î¦)â‰¥e(cid:15)E (31)
tionsetÎ¦thatisthelargestdistancebetweenanytwolocations
m in Î¦. If E(Î¦)â‰¥e(cid:15)E , we have D(Î¦)â‰¥e(cid:15)E .
m m
Then, we have the following theorem (with the above as a
Proof: D(Î¦)â‰¥d(xË†,x) for âˆ€xË†, x in Î¦, so
proof):
(cid:88) Ï€(x)
achiT eh ve eo sr (cid:15)e -m di1 ff: erF eno tr iaa
l
pl ro ivc aa cti yon ono pb rf ou ts ec ca tt ii oo nn lom ce ac tih oa nni ss em
t
Î¦th ,a ift e(cid:15)E mâ‰¤E(Î¦)â‰¤m xË†âˆˆi Î¦n
xâˆˆÎ¦
(cid:80) yâˆˆÎ¦Ï€(y)D(Î¦)=D(Î¦)
E(Î¦)â‰¥e(cid:15)E , the optimal inference attack using any observed
m
pseudo-location x(cid:48), ExpEr(x(cid:48))â‰¥ E .
m A simple way to determine the protection location set is
Based on (31), we regard Î¦ as a variable and propose to to gradually increase the radius of circular region centered
dynamically search a region of Î¦ where the user is located at the userâ€™s location from e(cid:15)E /2 (given by Theorem 2)
m
to satisfy E(Î¦) â‰¥ e(cid:15)E . Then, with the protection location until it satisfies E(Î¦) â‰¥ e(cid:15)E . However, this approach may
m m
set Î¦, we propose an exponential mechanism that generates a produce unnecessarily large diameter, leading to significant
pseudo-location in the way that achieves (cid:15)-differential privacy service quality loss. Figure 7 shows an example in which the
on Î¦, defined in Definition 4. Because the maximum change desiredprotectionlocationsetisobtainedbyincreasingradius
of the userâ€™s location is within the range of Î¦, the sensitivity to r to include four location points, resulting in 2r diameter.
method to achieve differential privacy introduces the noise However, in this way we cannot find another qualified set that
perturbation proportional to Î¦â€™s diameter D(Î¦), as shown in istherectangleareainthefigurewithamuchsmallerdiameter.
Section V-C. To maximize the utility, the noise magnitude
should be minimized, and thus it is desired to find Î¦ that Hilbert Curve based Search: To efficiently search over the
plane for the protection location set, we propose a Hilbert
satisfies (31) with a minimum diameter.
curve based search algorithm. Hilbert curve [13] is a popular
Figure 6 illustrates the workflow of PIVE. It shows two member in the family of space-filling curves. It provides a
components with their inputs: the algorithm F for generat- mapping from a data point in a 2-D space to a point in one
ing the protection location set and the differentially private dimensional space that preserves the proximity of data. That
mechanismK forproducingapseudo-location.Inessence,via is, points which are close to one another in the 2-D space
9Algorithm 1: Protection Location Set Search Algorithm
Input: x: userâ€™s location E : error bound, (cid:15): privacy parameter
ð¸ 2" 1 if Ï€(x)=0 then m
2 S â†{l | H(l)âˆˆ[H(x)âˆ’range,H(x)+range] on H };
3 else
4 S â†{l | H(l)âˆˆ[R(x)âˆ’range,R(x)+range] on sorted X};
ð‘Ÿ 5 Let S be x âˆ’l,x âˆ’l+1,..., x 0=x, x 1,x 2,...,x r;
6 Lâ†âˆ…;
Fig. 7: The non-optimal case for the simple approach 7 for i from âˆ’l to 0 do
8 for j from 0 to r do
9 Î¦={x k | iâ‰¤kâ‰¤ j} ;
6 7 10 11 10 Calculate E(Î¦) by(29) ;
11 if E(Î¦)â‰¥e(cid:15)E m then
5 8 9 12 12 Add Î¦ to L;
13 break ;
14 return a set having the smallest diameter in L;
4 3 14 13
1 2 15 16
Fig. 8: Hilbert Curve for 4Ã—4 and 16Ã—16 grid
sortedsequenceofX.Thealgorithmappliesthesearchstrategy
mentionedabovetothesearchingrangetoobtaintheprotection
location set. The pseudo-code is given in Algorithm 1.
will also remain close to each other in the transformed 1-D
space. It has been shown that Hilbert curves have the superior
distancepreservingproperties[15].Figure8showstheHilbert The range must be large enough to have better chance to
curves for 4Ã—4 and 16Ã—16 grids in 2-D space. The Hilbert find a qualified protection location set. Given T = e(cid:15)E and
m
curvemapsalocationpoint xtoa1-Dvaluedenotedby H(x). Theorem2,rangecanbedecidedheuristically.Wecantraverse
We call H(x) as the Hilbert value of x. The locations in X is along the Hilbert curve in both directions from userâ€™s location
sorted by their Hilbert values, and the rank of a location x in x. Once reaching the locations a and b in each direction with
the sorted X is denoted by R(x). their distances to x being some multiple of T, we set range=
max(|H(a)âˆ’H(x)|,|H(b)âˆ’H(x)|). In our implementation we
Given userâ€™s location x, our algorithm searches the neigh- simply choose sufficiently large range that incurs low failure
borhood of x along the Hilbert curve to find a protection
rate for finding protection location set. We can also specify an
locationsetÎ¦thatsatisfies xâˆˆÎ¦and E(Î¦)â‰¥e(cid:15)E .Thebasic
m upper bound for range to limit the searching cost and avoid
search strategy in the algorithm can be generally described
large region that causes unacceptable quality loss. Note the
as follows. Let x âˆ’l,x âˆ’l+1,..., x 0(= x), x 1,x 2,...,x
r
be the
algorithm may not find any qualified protection location set,
sequenceoflocationsinthesearchingneighborhoodofxalong
forexample,inthecasethattheuserâ€™scurrentlocationisonly
the Hilbert curve, sorted by their Hilbert values. For each x (
i possiblelocationforhimandallotherlocationshaszeroprior
âˆ’lâ‰¤iâ‰¤0), the algorithm checks every interval from x to x
i j probabilities on the plane. Thus, if an empty set is returned,
for0â‰¤ jâ‰¤r inthesequence,denotedby[x,x ],andevaluate
i j which indicates the location privacy cannot be protected, the
E([x,x ])by(29).Onceanintervalthathas E([x,x ])â‰¥e(cid:15)E
i j i j m user can choose to suppress location report.
is found for x, the algorithm stops interval check for x, adds
i i
location set in [x,x ] to a candidate list, and repeats with the
i j
next x i. Finally, the set having the smallest diameter in the list Improvement with Multiple Rotated Hilbert Curves: Al-
is returned, with breaking ties by a random choice. though using Hilbert curve enables efficient search over 2-
D plane, a drawback is that the search is conducted along a
In the case that all locations in Î¦ have zero prior proba-
bilities, i.e., (cid:80) yâˆˆÎ¦Ï€(y) = 0 in (29), we define (cid:80) yÏ€ âˆˆÎ¦(x Ï€) (y) = |Î¦1 |, s ci on ng sl ie std oir fec nt eio ign ha bn od rinth ge ls oe ca ar tc ioh ned s ore ngi to hn es cc ua rn veo .n Aly cb ee llo an ce ts uath lla yt
because a uniform distribution is assumed in an area when can have four neighbors on the plane while two neighboring
the adversary does not have any prior information about it. cells may be far apart on the curve (e.g., location 2 and 15
Accordingly, the algorithm searches Î¦ for locations with zero in Figure 8). Since there are regions where locations are not
andnon-zeropriorprobabilityinXindifferentways.Because adjacent on the curve, we propose to use multiple different
over the plane any locations outside X (e.g., the un-numbered Hilbert curves to connect locations in different ways such that
regions in Figure 1) indeed have zero prior probabilities, more possible regions can be involved, which can improve
the protection location set Î¦ for the userâ€™s location x with the chance to find the protection location set with a smaller
Ï€(x) = 0 can involve them with E(Î¦) being computed in diameter.PreviousworkshaveutilizedmultipleHilbertcurves
the defined way. Thus, the searching range is determined as to improve the quality of k-Nearest Neighbor queries [12] and
all the locations on the plane with Hilbert values in a range reduce cloaking area [16]. In PIVE, given a Hilbert curve H
[H(x)âˆ’range,H(x)+range]. For the protection location set over 2nÃ—2n grid, other three Hilbert curves are generated by
of x with Ï€(x)>0, the locations with zero prior probabilities rotating it 90, 180, 270 degrees clockwise about the center
contribute zero to E(Î¦) in (29) and thus the locations outside point. We use Algorithm 1 to find the protection set of the
X are not considered. The searching range is defined as the userâ€™s location x for each Hilbert curve, and choose the one
locations with ranks in [R(x)âˆ’range,R(x)+range] over the with smallest diameter among four results.
10C. Differentially Private Mechanism it is sampled with is at most w exp( âˆ’(cid:15)c ). Thus, the total
x 2D(Î¦)
Given the protection location set Î¦, PIVE achieves differ- probabilityofd(x,x(cid:48))â‰¥cforall x(cid:48) isatmostw x|X|exp( 2Dâˆ’(cid:15) (Î¦c )).
On the other hand,
ential privacy on it through the exponential mechanism [14].
Considering the set X as the output range of location obfus-
w
=1(cid:46)(cid:16)(cid:88) exp(cid:0)âˆ’(cid:15)d(x,x(cid:48))(cid:1)+ (cid:88) exp(cid:0)âˆ’(cid:15)d(x,x(cid:48))(cid:1)(cid:17)
cation, the utility of output x(cid:48) is measured by the distance x 2D(Î¦) 2D(Î¦)
between x(cid:48) and userâ€™s location x in Î¦. Smaller distance has x(cid:48)âˆˆÎ¦ x(cid:48)âˆˆX\Î¦
higher utility. As the protection location set decides â€œneigh-
â‰¤1(cid:46)(cid:16)(cid:88) exp(cid:0)âˆ’(cid:15)d(x,x(cid:48))(cid:1)(cid:17) â‰¤1(cid:46)(cid:16)(cid:88) eâˆ’(cid:15)/2(cid:17)
2D(Î¦)
boringâ€ locations to the userâ€™s location, the sensitivity of the x(cid:48)âˆˆÎ¦ x(cid:48)âˆˆÎ¦
utility function u is e(cid:15)/2
=
|Î¦|
âˆ†u=maxmax|d(x,x(cid:48))âˆ’d(y,x(cid:48))| (32)
x(cid:48)âˆˆX x,yâˆˆÎ¦ Thus, we have Pr(d(x,x(cid:48)) â‰¥ c) â‰¤ |X|e(cid:15)/2 exp( âˆ’(cid:15)c ). Let Î´ be
|Î¦| 2D(Î¦)
Itiseasytosee,accordingtotriangleinequality,forany x,yâˆˆ the right-hand side and we can derive (35).
Î¦, |d(x,x(cid:48))âˆ’d(y,x(cid:48))| â‰¤ d(x,y) â‰¤ D(Î¦), so âˆ†u = D(Î¦) where
D(Î¦) is the diameter of Î¦. Because the searching range is limited in Algorithm 1,
ln|Î¦| is bounded by ln(2range) that is a small constant (e.g,
Exponential mechanism K: Given the userâ€™s location x and at most 4 in our experiment), while D(Î¦) can vary a lot given
locationprotectionsetÎ¦,theexponentialmechanismK selects possible sparse location distribution. Therefore, the value of
and outputs a location x(cid:48) âˆˆX with probability proportional to right hand side of (35) mainly depends on D(Î¦). Given fixed
exp(âˆ’(cid:15)d(x,x(cid:48))).
E , increasing (cid:15) can incur a protection
loca(cid:15)
tion set with a
2D(Î¦) m
larger diameter since D(Î¦) â‰¥ e(cid:15)E given by Theorem 2.
The mechanism K samples each location x(cid:48) from X with Because D(Î¦) increases exponentiallm y with (cid:15), with increasing
the probability w xexp(âˆ’ 2(cid:15)d D( (x Î¦,x )(cid:48))) where w
x
is the normalization
(cid:15) from the value close to zero,
D(Î¦)
will decrease first and
factor for the probability distribution over X, (cid:15)
thenincrease.Therefore,weexpectthattheservicequalityand
w
=1(cid:46)(cid:16)(cid:88) exp(cid:0)âˆ’(cid:15)d(x,x(cid:48))(cid:1)(cid:17)
(33)
also location privacy will exhibit the similar changing pattern,
x 2D(Î¦) which is demonstrated in our evaluation.
x(cid:48)âˆˆX
VI. Evaluation
Following the proof of Theorem of McSherry and Tal-
war [14], we can easily obtain the theorem below,
In this section we first evaluate the performance of our
Theorem 3: The exponential mechanism K preserves (cid:15)- PIVE mechanism, and compare PIVE approach with other
differential privacy on the protection location set Î¦. mechanisms on location privacy and service quality. Our
evaluation shows that PIVE effectively combines two privacy
Proof: notions,andefficientlyaddressestheissuesofexistinglocation
(cid:16) (cid:17) obfuscation mechanisms.
f(x(cid:48)|x) w xexp âˆ’(cid:15)d(x,x(cid:48))/(2D(Î¦))
=
f(x(cid:48)|y) w exp(cid:16) âˆ’(cid:15)d(y,x(cid:48))/(2D(Î¦))(cid:17) We use the dataset provided by authors of [3]. The dataset
y wasextractedfromtheGeoLifeGPSTrajectoriesdataset[22]â€“
w w
â‰¤ xe(cid:15)|d(x,x(cid:48))âˆ’d(y,x(cid:48))|/(2D(Î¦))â‰¤ xe(cid:15)d(x,y)/2D(Î¦) [24], which contains 17621 traces collected from 182 users
w w
y y in Beijing, China, during a period of over five years. The
â‰¤ w
w
yxe(cid:15)/2â‰¤ (cid:16)(cid:16) (cid:80)(cid:80) xx (cid:48)(cid:48) âˆˆâˆˆ XX ee xx pp (cid:0)(cid:0) âˆ’âˆ’ 2 2(cid:15)(cid:15) dd D D(( ( (y xÎ¦ Î¦, ,x x) )(cid:48) (cid:48)) )(cid:1) (cid:1)(cid:17) (cid:17)e(cid:15)/2
(34)
t
l
or
o
fa gc dge aes
td
are
e
pc
v
ro
e
or
r
cd
y
esu
1
ss
-
in5er gs
se
co
c
au
o
nt nd bdo esor
o
form
ue
no
v
dv ee
r
im
y
ne
5
[n 3-t
1
]s
0
aw nmi dth
e
htel ero rsc e.a wTtio
h
en es
pd
rb oee vtai in
i
dlg
es
â‰¤ (cid:16)(cid:80) (cid:16)x(cid:48) (cid:80)âˆˆXexp e(cid:0) xâˆ’ p(cid:15) (cid:0)(d âˆ’(x 2 (cid:15), dDx ((cid:48) ( x) Î¦ ,âˆ’ x)D (cid:48))( (cid:1)Î¦ (cid:17)))(cid:1)(cid:17) e(cid:15)/2 a ofbr ri ee gf iod ne ssc 0ri .p 6t 5io 8n k. mTh we idm ea ap no df 0B .7e 1ij 2in kg mis hd igiv hi ,de thd ein 5t 0o a â€œmg ori sd
t
x(cid:48)âˆˆX 2D(Î¦) popularâ€ regions of the grid is used as the set of all locations
(cid:16)(cid:80) exp(cid:0)âˆ’(cid:15)d(x,x(cid:48))(cid:1)(cid:17)
X,asshowninFigure1,andtheuserswhohavefewrecorded
â‰¤ (cid:16)(cid:80)x(cid:48)âˆˆX exp(cid:0)âˆ’2 (cid:15)dD (( xÎ¦ ,x) (cid:48))(cid:1)(cid:17)e(cid:15)/2e(cid:15)/2â‰¤e(cid:15) points for each time period at these regions are filtered out.
x(cid:48)âˆˆX 2D(Î¦) The final dataset contains 84 users. The prior for each user is
computed by counting and normalizing the number of points
falling in each of 50 regions with in different time periods
The exponential mechanism provides strong utility guar-
(all day, morning, afternoon and night). In this paper we use
antees since it discounts the pseudo-locations exponentially
all-daypriortoconstructmechanisms.Inordertodemonstrate
quickly as their distances to the actual location increase. To
the performance in a single user setting, at default we always
see that, we have the following theorem
choose the user with id 0, as in Section IV-C.
Theorem 4: Given the actual location x, let x(cid:48) be the
pseudo-location randomly sampled from X by the exponential A. Performance of Protection Location Set Search
mechanism K, with probability at least 1âˆ’Î´ we will have Given (cid:15) and E , a threshold T = e(cid:15)E is determined and
m m
2D(Î¦)(cid:16) (cid:15) (cid:17) Algorithm 1 searches a location protection set Î¦ for userâ€™s
d(x,x(cid:48))â‰¤ (cid:15) ln|X|+ 2 âˆ’ln|Î¦|âˆ’lnÎ´ (35) location that has E(Î¦) in (29) no less than T while with the
smallest diameter. In this section we study the performance of
Proof: For any x(cid:48) that has d(x,x(cid:48)) â‰¥ c, the probability our search algorithm in terms of the diameter D(Î¦) and value
11E(Î¦). In the algorithm, we choose sufficient large range=50 15
a
fi
imt
nd
pd ae
a
cfa
tq
,u
u
wl at. elifiT teeh sde
tl
rs
o
ae
c
na ar gtc
i
eoh
n
win ipg
tr
hora
t
ven
ac
lg
t
ue
i eo
snra 2sn 0eg ,te
4fo
0d
r
,e
a
5c 0i ld
o
ae
c
ns
a
dtt ih
o
6e
n
0.c fTh ooa rn
s
Tec ee =it
t
2o
s
)m
k(retem aiD10
5
that is corresponding to the largest average diameter in Figure
0
9. The number of regions for which the algorithm fails to find 0.10.20.30.40.50.60.70.80.91.01.11.21.31.41.51.61.71.81.92.0
T
qualified protection location set is 19, 8, 6, 6 for each range
Fig. 9: Boxplot of Diameter with different T
value respectively. We can see that from range=50 that is the
sizeofX,thenumberofsuchregionsremainstobe6.Smaller
range 40 has approximate number of failures as 50. Since the 3
s thiz ae
t
io nf cu5 r0 sr se mg aio lln es stis nus mm ba ell r, oin
f
fo au ilr ure ex sp .e Wrim ithe in nt aw le arc gh eoo sis ze e5 o0
f
)eulav
)2
X, range can be a relatively smaller value.
(E1
0
0.10.20.30.40.50.60.70.80.91.01.11.21.31.41.51.61.71.81.92.0
We vary T from 0.1 and 2.0 and measure the diameters of
T
protection (location) sets obtained by our algorithm for userâ€™s Fig. 10: Boxplot of E(Î¦) with different T
locationateachof50regions.TheresultsareshowninFigure
9 where the whiskers represents minimum and maximum 14
diameters in each group. It is clear that the average diameter 12
ofallregionsincreaseswiththethresholdT.Thediametersfor 10
isolated region 48, 49, and 50 remain between 4km and 5km 8
under different T. They are maximum ones in the results from 6 T=0.1 to 0.8. For some regions like 24, 25, 32, 33 and 34, 4
the diameters become higher than 12km from T=1.2. From 2
T=1.4 to 2.0, the algorithm cannot find qualified protection 0
0 10 20 30 40 50
sets for regions like 24, 25, 26, 32 and 33. Figure 10 shows Region id
the corresponding E(Î¦) values of obtained protection sets for
every region under different T. As we can see, the average
E(Î¦) value increases linearly with T and is approximate to T.
This indicatesthat our algorithmeffectively findsthe qualified
protection location set with E(Î¦) â‰¥ T as desired. We also
observe that the maximum E(Î¦) for each T is about 2km
from T=0.1 to 1.5, which is because that the protection set
for region 49 always has maximum E(Î¦) 2km. By further
looking into the results, we find that for both region 49 and
50,theprotectionlocationsetremainsthesamefromT=0.1to
1.5, resulting the same diameter and E(Î¦). Region 49 always
has protection set {47,49}, and 50 has {48,50}. From Figure
1, we can see the reason is that they are isolated regions and
theirnearestneighborsare47and48respectivelythatprovide
qualifiedprotectionsets.ForT >1.5,region50hastoinvolve
another region 45 to satisfy E(Î¦)â‰¥T.
To see how the diameter of protection location set varies
amongdifferentregions,weshowtheresultsofT=0.5,1.0and
1.5 in Figure 11a. It is clear that the diameter of protection
location set for each region increases with T. The curve is
discontinuous at some points for T=1.5 because the algorithm
cannot find qualified set at those locations. The diameters for
regions49and50remainsthesamewiththreedifferentT due
to the reasons mentioned above.
Improvement with Multiple Hilbert curves: Our algorithm
utilizes multiple Hilbert curves that are generated by the
rotationoftheoriginalHilbertcurvetofindprotectionlocation
set with the smallest diameter. To see the effectiveness of
such improvement, we compare the diameter of every region
with the search algorithm using one single Hilbert curve
and multiple ones respectively, under a given T. Figure 11b
shows the result with T=1.0. We can see that using multiple
Hilbert curves effectively reduces the diameter of protection
location set. At some regions the improvement is significant.
For example, the diameter is reduced by more than half at
)mk(
retemaiD
12
T=0.5 Single Hilbert T=1.0 10 Multiple Hilbert
T=1.5 )m
k(
re
8
te m 6 a iD
4
2
0 10 20 30 40 50
Region id
(a)DiameterofÎ¦forregions (b)SingleV.S.multipleHilbert
Fig. 11: Diameter of protection location set for every region.
14
12
)m10
k ( re 8
te m 6
a
iD 4
2
User id
Fig. 12: The diameters under T =1 for every user.
region 31 and 50. Such improvement holds for different T
values.
We further investigate the diameters for all 84 users in
the dataset and show the result with T=1 in Figure 12. All
users have approximate average diameters between 2km and
4km, but the maximum diameter for some users can be as
large as 14km. Large diameter will incur significant noise
and extremely low utility. To avoid that, a maximum tolerable
diameter D can be specified in the mechanism, such that
m the mechanism can use the location set with maximum E(Î¦)
among those with diameters no larger than D if the diameter
m
of the produced protection location set exceeds D .
m
B. Location Privacy and Service Quality
In this section, we evaluate the impact of differential
privacy parameter (cid:15) and inference error threshold E on
m
locationprivacyandservicequalityunderasingleusersetting.
AlthoughPIVEallowsdifferentprivacyparametersatdifferent
locations, we use uniform parameters over all locations and
unconditionalexpectedinferenceerror(8)andqualityloss(10)
as privacy and quality metric, in order to examine the effects
of different (cid:15) and E on the performance.
m
121.2
1.1
1
0.9
0 0.05 0.1 0.15 0.2
E m
)mk(
)rorrE
detcepxE(
ycavirP
3
2.5
2
0=0.5
0=0.9 1.5
0=1.5 0=1.9
1
0 0.05 0.1 0.15 0.2
E m
(a)PrivacyV.S.Em
)mk(
ssoL
ytilauQ
location privacy and quality loss, and thus increasing (cid:15) incurs
lower location privacy and quality loss. As the diameter
increases exponentially with (cid:15), the diameter takes effects, thus
increasing(cid:15) causeshigherprivacyandqualityloss.Comparing
0=0.5 Figure13cand13d,wecanseethattheturningpointsofboth
0=0.9
0=1.5 metrics under the same E occurs at the same (cid:15) values. 0=1.9 m
C. Comparison with other mechanisms
(b)QualityLossV.S.Em
In this section we compare PIVE with typical geo-
1.2 3.5 indistinguishable mechanisms to verify the advantage of in-
)m1.15
3
troducing inference error bound. Because PIVE focuses on
k( )rorrE
detcepxE( ycavirP01 ..
01
90
..
55
91
1 E E E E Em m m m m= = = = =0 0 0 0 0. . . . .0 0 0 1 11 5 9 3 9
)m
k( ssoL
ytilauQ
12 .. 55
2 E E E E Em m m m m= = = = =0 0 0 0 0. . . . .0 0 0 1 11 5 9 3 9
l
t
w n
po
h
i
roc
a
s
ivmra
n
k
al
s
csp
t
yhe m[er
3
pf
o]
ro
g
, s
or
tl
tm
l[o ey1b
ca
7a
tn
i]
il
n
oc ,e
na
[
av
1o
pe
9
sf
er
i]
rp
a
n,
fgr
g
owi
e
lv
re
mea pc
u
acey
s
nor ef
cp
m
ro
er ro
p
sm
at
a
ee
tr
tac
e t
en
it ni aco
P
cgen
I
h,Vef
i
io
E
nx
nr
a dom
we ivrv
i
i d
ie
n
t
dehr
e
ury
d
ao
tr
lt
oe
i
h
rng
e
eci
r
go
hp
in
em
or ce
nr
v
e
ka .cit
o
Whh thue
a e
esr
-
0.85 1
0 0.5 1 1.5 2 0 0.5 1 1.5 2 examine the performance of PIVE for every user, and only
0 0
show results with regard to user with id 0 due to the similar
(c)PrivacyV.S.(cid:15) (d)QualityLossV.S.(cid:15)
behaviors of these mechanisms for other users. It is worth to
Fig. 13: Impact of privacy parameters (cid:15) and E m note that PIVE provides the users a way to specify different
privacy requirements for different locations through two pri-
Figure 13a and 13b show that under different (cid:15), both vacyparameters E m and(cid:15).Giventhattheexistingmechanisms
location privacy and quality loss monotonically increase with like optimal geo-indistinguishable mechanism do not support
E . This is because that higher E leads to larger diameter different privacy specifications for different locations, we set
m m
of the protection location set, and the pseudo-location is more the same privacy parameters everywhere for PIVE in order to
likely to be further from the actually location and thus incurs make meaningful comparisons.
lower utility, which is indicated by Theorem 4. The mono-
We first consider an exponential mechanism EM, that is
tonic relationship between E and the corresponding location
m like the one proposed in PIVE except using uniform constant
privacy (i.e., expected inference error) indicates that E is
m diameter for every locationâ€™s protection location set. It rep-
an effective control knob to guarantee the expected inference
resents geo-indistinguishable mechanisms like discrete Planar
error. The difference in order of magnitude between E and
m Laplace Mechanism that ensure (cid:15)-differential privacy in the
corresponding expected inference error is because E is the
m circularneighborhoodcenteredattheuserâ€™slocation.Tomake
lowerboundoftheexpectedinferenceerrorgivenanypseudo-
a fair comparison, for each user, we run PIVE with different (cid:15)
locations in the worst case that the adversary have identified
andE ,andobtainitslocationprivacy(i.e.,expectedinference
the protection set. Therefore, E should be determined with m
m error (8)). Then, given the same (cid:15), we derive EM by choosing
consideration of such worst case to protect location privacy in
thediametertoachievethesamelocationprivacy.Todealwith
terms of unconditional expected inference error.
floating point comparisons, two values with less than 0.005
For smallest (cid:15)=0.5 indicating the strongest privacy guar- differenceareregardedtobeequalforlocationprivacy.Figure
antee, e(cid:15)E increases linearly with E with a small factor 14 shows boxplots of the quality losses of all users for PIVE
m m
e(cid:15), that is to say, the impact of diameter changes on the and EM respectively under different pairs of (cid:15) and E . In
m
privacyandqualityismuchsmallercomparedwiththatof(cid:15).In each subfigure, we can see that overall PIVE achieves smaller
contrast,underlarger(cid:15) like1.9thatincurweakrequirementfor quality loss than EM, though they have the same location
differentialprivacy,E(Î¦)increaseswithE withamuchlarger privacy. This is because that PIVE adaptively determines
m
factore(cid:15),whichincurslargerdiametervariance.Therefore,E protection location sets to implement geo-indistinguishability
m
hasmoresignificantimpactonlocationprivacyandqualityloss but EM uses protection regions of uniform radius everywhere.
for (cid:15)=1.9, indicating by its highest curve steepness in Figure Atsomelocationswithsufficientnumberofpossiblelocations
13aand13b.Also,inFigure13a,locationprivacyfordifferent in their neighborhood, PIVE can use smaller diameters than
(cid:15) increases to the same upper limit 1.178 as in Section IV-C1. at locations in sparse areas for providing the same level of
(cid:15)=0.5 achieves this limit regardless of E . Other cases have location privacy. Comparing these subfigures, we can see
m
location privacy approximate to the upper limit starting from that lower (cid:15) or higher E , both indicating higher privacy
m
E =0.1. Therefore, we can choose E no larger than 0.1 for requirements, incur larger quality loss.
m m
improving utility. Accordingly, in our comparison experiment
we focus on E =0.05 and 0.09. We further look into the level of privacy protection for a
m single user at every region, with using the same simulation
We further examine the impact of (cid:15) on location privacy approach described in Section IV-C1. Suppose E =0.05 and
m
and quality loss with given E . The results are shown in (cid:15) = 1.5 for PIVE. We derive EM with (cid:15) = 1.5 and also
m
Figure13cand13d.Wecanseethattherelationshipbetween(cid:15) the optimal geo-indistinguishable mechanism Opt-geo (M
and location privacy as well as quality loss is not monotonic. in Section IV-C) with (cid:15) = 0.7 such that they achieve th(cid:15) eg
g
Location privacy and quality loss first decrease with (cid:15) and same expected inference error as PIVE. Figure 15a and 15b
then increase. This result confirms our discussion following showtheaverageerrorofoptimalinferenceattackandsuccess
Theorem 4. The reason is that, at first (cid:15) takes control of probabilityofBayesianinferenceattackagainsteachregionfor
130 =1.5 0 =1.5 0 =0.9 0 =0.9 12
)m
k(
ssol
ytilauQ234 ... 555
34
Em=0.05
34 .. 55
345
Em=0.1
234 ... 555
2345
Em=0.05
234 ... 555
2345
Em=0.1 )m
k(
rorre
ecnerefni
egarevA10
02468
0
(aP
E
O
)1I
M
p
0V
t
OE
-G peo
tima2 l0
R ine fg eio rn
e
i
nd3 c0 eattack40 50
2 2.5 1.5 1.5 1
1 1 PIVE
1.5
2
0.5 0.5
ytilib0.8 E OM
pt-Geo
a
b
1
P1IVE
2EM1.5
P1IVE E2M
0
P1IVE E2M
0
P1IVE E2M
o rp sse00 .. 46
Fig. 14: Boxplot of quality loss of 84 users
ccu
s kca0.2
three mechanisms. We can see that for both E and Opt-geo,
ttA
0
M 0 10 20 30 40 50
the skewed regions 48, 49 and 50 suffer strong association Region id
between pseudo-locations and true locations, manifested by (b)Bayesianinferenceattack
approximate zero inference error for the optimal inference
Fig.15:Comparisonoflocalprivacyprotectionateveryregion
attack and high success probability for Bayesian inference
attack simultaneously. PIVE is resilient to such vulnerable 12
cases due to the skewed probability distribution on these 10
isolated regions by finding a sufficient protection location set 8
and ensuring the lower bound of inference error in the worst 6
cases. By using a protection region to include other possible 4
locations,PIVEavoidsthestrongassociationbetweenpseudo- 2
location and true location for skewed cases that happen to 0
0 10 20 30 40 50
E M and Opt-geo. That is the reason of why PIVE has much Region id
larger inference error and approximate zero attack success
probabilities at these isolated locations. Furthermore, with
PIVE, the Bayesian inference attack success probability is
capped to be no more than 60% as shown in Figure 15b.
To see the PIVEâ€™s difference compared with others against
Bayesian inference attack, in Table I we show the percentage
of regions that have the Bayesian inference attack success
probability higher than X% with X range 50%âˆ¼90% for all
mechanisms. As we can see, given different threshold X,
PIVEobtainstheleastpercentageofregionsthathavesuccess
probabilitylargerthan X.Comparingtheservicequalitylosses
ofthreemechanisms,wehaveEM=1.49>PIVE=1.32>Opt-
geo=1.02. PIVE has smaller quality loss than EM, which has
been explained above, and Opt-geo achieves smallest quality
losses due to its global optimization on service quality. Here
we also note that region 25 is not skewed location and does
nothaveasstrongassociationissue(highposteriorprobability)
as the skewed locations, thus with just satisfying minimum
lower bound 0.05, PIVE does not have much effect on the
inferenceerrorandsuccessprobabilityonregion25,compared
with others mechanisms.
Next, we compare PIVE with the joint optimization mech-
anism [17] in terms of effectivess for privacy protection by
combining geo-indistinguishability and expected inference er-
ror.WechoosethesameparametersforPIVEasintheprevious
expeirments, and then use its expected inference error as the
minimum desired distortion privacy level d for constructing
m
the optimal joint mechanism. (cid:15) in the joint mechanism is
g
chosen to achieve the same location privacy as PIVE in terms
ofunconditionalexpectedinferenceerror.Figure16showsthe
average inference error and success probability for two infer-
ence attacks respectively at each region, with d =0.9986km
m
)mk(
rorre
ecnerefni
egarevA
1
PIVE P JoIV inE t ytilibaborp
sseccus
kcattA0000 .... 2468
0
Joint
0 10 20 30 40 50
Region id
(a)Optimalinferenceattack (b)Bayesianinferenceattack
Fig. 16: Comparison of PIVE and joint mechanism
X. PIVE EM Opt-geo Joint
>50% 6% 8% 14% 12%
>70% 0% 6% 8% 10%
>90% 0% 6% 6% 4%
TABLEI:Thepercentageoflocationsexceedinggivensuccess
probability
and (cid:15) =0.8. It can be seen that (1) the joint mechanism
g
and PIVE exhibit similar performance at most locations with
small variation; and (2) the joint mechanism incurs the weak
regions,e.g.,regionid48,49and50,againstinferenceattacks,
despite having bound on global expected distortion metric.
These weak regions represent some skewedness as they are
far away from the rest of the regions. Concretely, PIVE has
the average inference error bounded to be no lower than 0.22
and at the same time the Bayesian inference attack success
probability capped to be no higher than 60% (Table I shows
PIVE has smaller percentage of regions compared to the
joint mechanism with different X). In comparison, the joint
optimization achieves good privacy at most of the locations
but fail to avoid the worst case scenarios when the location
dataset contains some skewed locations.
Note for the joint mechanism, when (cid:15) increases, its
g
performance gets close to the optimal Bayesian mechanism,
since its linear model is equal to the optimal Bayesian mech-
anism with geo-indistinguishability constraint and larger (cid:15)
g
will relax the constraint of geo-indistinguishability. But it will
causelessrobustnessagainsttheadversarywitharbitraryprior
information. PIVE shows the benefits of both privacy notions
14against optimal inference attack simultaneously: similar (or [5] C.Dwork. Differentialprivacy. InAutomata,LanguagesandProgram-
sometimesslightlylower)expectedinferenceerrorasthejoint ming,volume4052ofLectureNotesinComputerScience,pages1â€“12.
mechanismunderstronggeo-indistinguishability(with(cid:15) =0.8) SpringerBerlinHeidelberg,2006.
g
except regions 48-50 where PIVE provides similar privacy [6] C. Dwork, F. McSherry, K. Nissim, and A. Smith. Calibrating noise
to sensitivity in private data analysis. In Proceedings of the Third
protectionastheoptimalBayesianmechanismgiveninFigure
Conference on Theory of Cryptography, TCCâ€™06, pages 265â€“284,
2.Wewouldliketomaketworemarks:(1)Thelevelofprivacy
Berlin,Heidelberg,2006.Springer-Verlag.
protection offered by both PIVE and joint optimization are
[7] K. Fawaz, H. Feng, and K. G. Shin. Anatomization and protection
exceedingtheuser-definedlowererrorboundatmostlocations, of mobile appsâ€™ location privacy threats. In Proceedings of the 24th
thus are acceptable for users as good privacy protection, even USENIXConferenceonSecuritySymposium,SECâ€™15,pages753â€“768,
though the inference error of PIVE can be slightly lower at Berkeley,CA,USA,2015.USENIXAssociation.
some locations. (2) For the weak locations, PIVE shows high [8] K.FawazandK.G.Shin. Locationprivacyprotectionforsmartphone
users. In Proceedings of ACM CCS, pages 239â€“250, New York, NY,
resilience and adaptivity to the skewed distribution against
USA,2014.ACM.
inference attacks, compared to all three existing approaches
[9] B. Gedik and L. Liu. Location privacy in mobile systems: A per-
(see Figure 15 and Figure 16).
sonalized anonymization model. In Distributed Computing Systems,
2005.ICDCS2005.Proceedings.25thIEEEInternationalConference
VII. Conclusions on,pages620â€“629,June2005.
WehavepresentedPIVE,atwo-phasedynamicdifferential [10] M. Gruteser and D. Grunwald. Anonymous usage of location-based
services through spatial and temporal cloaking. In Proceedings of
location privacy framework for providing stronger notion of
MobiSys,pages31â€“42,NewYork,USA,2003.ACM.
location privacy in terms of background knowledge based
[11] J. I. Hong and J. A. Landay. An architecture for privacy-sensitive
inference attacks. This paper makes three novel contribu- ubiquitous computing. In Proceedings of MobiSys, pages 177â€“189,
tions. First, we formally study the relationship between geo- NewYork,NY,USA,2004.ACM.
indistinguishability and expected inference error, and demon- [12] A.KhoshgozaranandC.Shahabi. Blindevaluationofnearestneighbor
strateinherentproblemsofusinggeo-indistinguishabilityalone queries using space transformation to preserve location privacy. In
Proceedings of the 10th International Conference on Advances in
astheultimategoaloflocationprivacyprotectionthroughfor-
Spatial and Temporal Databases, SSTDâ€™07, pages 239â€“257, Berlin,
malanalysisandexperimentalillustration.Second,wepropose
Heidelberg,2007.Springer-Verlag.
a dynamic differential location privacy protection framework,
[13] J. K. Lawder and P. J. H. King. Using space-filling curves for multi-
where we first determine a set of protection locations by dimensional indexing. In Proceedings of the 17th British National
guaranteeing the expected inference error bound defined by Conferenc on Databases: Advances in Databases, BNCOD 17, pages
a mobile user with respect to her service request by taking 20â€“35,London,UK,UK,2000.Springer-Verlag.
into account the adversaryâ€™s prior distribution of the userâ€™s [14] F.McSherryandK.Talwar. Mechanismdesignviadifferentialprivacy.
locations.Then,wegeneratethepseudo-locationsinadifferen- InProceedingsofthe48thAnnualIEEESymposiumonFoundationsof
ComputerScience,FOCSâ€™07,pages94â€“103,2007.
tially private way. Third, this two-phase framework constructs
[15] B.Moon,H.v.Jagadish,C.Faloutsos,andJ.H.Saltz. Analysisofthe
locationobfuscationdynamicallybycapturingtherelationship
clusteringpropertiesofthehilbertspace-fillingcurve. IEEETrans.on
betweentwoprivacynotionsbasedonadversaryâ€™scurrentprior Knowl.andDataEng.,13(1):124â€“141,Jan.2001.
informationanduser-specificprivacyrequirementsfordifferent [16] H.NgoandJ.Kim.Locationprivacyviadifferentialprivateperturbation
spatial-temporal contexts. Our experimental evaluation shows of cloaking area. In 2015 IEEE 28th Computer Security Foundations
that the proposed PIVE approach effectively guarantees the Symposium,pages63â€“74,July2015.
two privacy notions simultaneously and outperforms the ex- [17] R. Shokri. Privacy games: Optimal user-centric data obfuscation.
isting mechanisms that either offer geo-indistinguishability or PoPETs,2015(2):299â€“315,2015.
quantifylocationprivacybyexpectedinferenceerrors,interms [18] R. Shokri, G. Theodorakopoulos, J.-Y. Le Boudec, and J.-P. Hubaux.
of adaptive privacy protection and computation efficiency. Quantifyinglocationprivacy. InSecurityandPrivacy(SP),2011IEEE
Symposiumon,pages247â€“262,May2011.
Acknowledgment [19] R. Shokri, G. Theodorakopoulos, C. Troncoso, J.-P. Hubaux, and J.-
Y. Le Boudec. Protecting location privacy: Optimal strategy against
The authors would like to thank Dr. Shokri, our shepherd, localizationattacks.InProceedingsofACMCCS,pages617â€“627,New
York,USA,2012.ACM.
and all the reviewers for their helpful comments and sugges-
[20] G.Theodorakopoulos,R.Shokri,C.Troncoso,J.-P.Hubaux,andJ.-Y.
tions, which help improving both the technical quality and the
LeBoudec.Prolongingthehide-and-seekgame:Optimaltrajectorypri-
presentationofourpaper.Theauthorsacknowledgethepartial
vacyforlocation-basedservices. InProceedingsofthe13thWorkshop
supportfromNSF1547102,NSFSaTC1564097,andanIBM on Privacy in the Electronic Society, WPES â€™14, pages 73â€“82, New
faculty award. York,NY,USA,2014.ACM.
[21] T.XuandY.Cai.Feeling-basedlocationprivacyprotectionforlocation-
References basedservices.InProceedingsofACMCCS,pages348â€“357,NewYork,
NY,USA,2009.ACM.
[1] Location guard. https://addons.mozilla.org/en- [22] Y. Zheng, Q. Li, Y. Chen, X. Xie, and W.-Y. Ma. Understanding
US/firefox/addon/location-guard/. mobility based on gps data. In Proceedings of the 10th International
[2] M.E.AndreÂ´s,N.E.Bordenabe,K.Chatzikokolakis,andC.Palamidessi. Conference on Ubiquitous Computing, UbiComp â€™08, pages 312â€“321,
Geo-indistinguishability: Differential privacy for location-based sys- NewYork,NY,USA,2008.ACM.
tems. InProceedingsofACMCCS,pages901â€“914,2013.ACM. [23] Y.Zheng,X.Xie,andW.-Y.Ma. Geolife:Acollaborativesocialnet-
[3] N. E. Bordenabe, K. Chatzikokolakis, and C. Palamidessi. Optimal workingserviceamonguser,locationandtrajectory. IEEEData(base)
geo-indistinguishablemechanismsforlocationprivacy. InProceedings EngineeringBulletin,June2010.
ofACMCCS,pages251â€“262,NewYork,USA,2014.ACM. [24] Y.Zheng,L.Zhang,X.Xie,andW.-Y.Ma.Mininginterestinglocations
[4] K.Chatzikokolakis,C.Palamidessi,andM.Stronati.Constructingelas- andtravelsequencesfromgpstrajectories. InProceedingsofthe18th
ticdistinguishabilitymetricsforlocationprivacy.PoPETs,2015(2):156â€“ InternationalConferenceonWorldWideWeb,WWWâ€™09,pages791â€“
170,2015. 800,NewYork,NY,USA,2009.ACM.
15