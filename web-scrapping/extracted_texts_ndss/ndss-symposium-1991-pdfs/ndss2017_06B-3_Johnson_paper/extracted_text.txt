Avoiding The Man on the Wire: Improving Tor’s
Security with Trust-Aware Path Selection
Aaron Johnson∗, Rob Jansen∗, Aaron D. Jaggard∗, Joan Feigenbaum† and Paul Syverson∗
∗U.S. Naval Research Laboratory, {aaron.m.johnson, rob.g.jansen, aaron.jaggard, paul.syverson}@nrl.navy.mil
†Yale University, joan.feigenbaum@yale.edu
Abstract—Tor users are vulnerable to deanonymization by cuits) by using similarities in the volume and timing of the
an adversary that can observe some Tor relays or some parts traffic at both ends to match them with each other, thereby
of the network. We demonstrate that previous network-aware deanonymizing the user. These techniques are efficient and
path-selection algorithms that propose to solve this problem are effective [27]. In order to carry out traffic-correlation attacks,
vulnerabletoattacksacrossmultipleTorconnections.Wesuggest
an adversary must be in a position to (i) observe Tor traffic
that users use trust to choose the paths through Tor that are
on an Internet path between a client and its chosen entry
less likely to be observed, where trust is flexibly modeled as a
guard or control that entry guard, and (ii) observe an Internet
probability distribution on the location of the user’s adversaries,
path between the selected exit relay and the destination or
andwepresenttheTrust-AwarePathSelectionalgorithmforTor
that helps users avoid traffic-analysis attacks while still choosing control the exit or destination. Due to Tor’s volunteer-relay
paths that could have been selected by many other users. We model and its bandwidth-weighted path-selection algorithm,
evaluate this algorithm in two settings using a high-level map of an adversary may get in a position to observe a large amount
Internet routing: (i) users try to avoid a single global adversary of traffic simply by running a fast relay, and it can otherwise
that has an independent chance to control each Autonomous observe traffic by controlling or coercing entities on the paths
System organization, Internet Exchange Point organization, and toandfromrelaysincludingInternetServiceProviders(ISPs),
Tor relay family, and (ii) users try to avoid deanonymization by
Autonomous Systems (ASes), and Internet Exchange Points
any single country. We also examine the performance of Trust-
(IXPs).
Aware Path selection using the Shadow network simulator.
Previous approaches to improving resilience against traffic
observationandcorrelationattackshavebeenlimitedinnature
I. INTRODUCTION andonlyconsiderspecificthreats.Onemainapproachfocuses
Tor is a popular tool for low-latency anonymous commu- ondefeatinganadversarythatobservesanASorIXP[6],[8],
nication, with over an estimated 1.5 million daily users. In [12], [14], [23], [28], [29] and suggests creating Tor circuits
order to use Tor to communicate with others, clients choose a such that the set of ASes and IXPs that appear on the Internet
three-hop path from the set of over 7000 relays volunteering paths between the client and guard is disjoint from the set
bandwidth to the network. In order to balance load among of ASes and IXPs between the exit and destination. However,
the relays, and in particular to optimize the allocation of thissolutionignoresthecriticaleffectsofmultipleconnections
Tor’s limited bandwidth, the default path selection algorithm overTor,whichunderthisapproachleakincreasingamountsof
is bandwidth-weighted so that a client will select a relay with informationthatcanallowtheadversarytodetermineaclient’s
a probability equivalent to the ratio of that relay’s available location. We present attacks of this nature on Astoria [29], a
bandwidth to the total network bandwidth capacity. Clients recentproposalofthissort,withourresultsshowingthateven
communicate with arbitrary Internet hosts via a cryptographic a moderately-resourced adversary can identify the client’s AS
circuitwithalayerofencryptionforeachofthethreerelayson within seconds. These attacks have similar implications for all
its path, which are termed the entry guard, middle, and exit, path-selection proposals using this approach.
according to their position on the path. Because this circuit The other main approach focuses on an adversary that
is built using a telescoping process, it provides unlinkability can observe some Tor relays [20], [21] and suggests that,
against a passive, non-global adversary that cannot observe for the most sensitive circuit positions, users choose a small
both ends of the circuit. number of relays from among those the user trusts the most.
Unfortunately for many Tor users, a global adversary that However, this approach leaks information to an adversary that
can observe both ends has become a very real and significant caneventuallyidentifythetrustedrelays(e.g.,viaacongestion
threat. An adversary in such a position can perform a “first- attack[13],[15])andusesarestrictivetrustmodel.Noexisting
last” traffic-correlation attack for any of the circuit’s streams solution to traffic correlation attacks provides protection from
(i.e., TCP connections to destinations multiplexed over cir- thevarietyofattackerresourcesandtacticsthatrecentresearch
and experience suggests is realistic [22].
In contrast, this paper develops defenses against traffic
correlation that are based on a general probabilistic model
This paper is authored by an employee(s) of the United States Government and
is in the public domain. Non-exclusive copying or redistribution is allowed, of network adversaries. Using this model we can consider
provided that the article citation is given and the authors and agency are clearly adversaries with diverse resources, such as those that observe
identified as its source. network traffic at any combination of network providers, ex-
NDSS ’17, 26 February - 1 March 2017, San Diego, CA, USA
changepoints,physicalcables(underseaorelsewhere),andTor
Internet Society, ISBN 1-891562-46-0
relays. The model allows us to incorporate uncertainty about
http://dx.doi.org/10.14722/ndss.2017.23307and randomness in an adversary’s actions. It also enables us much of the network and doing so in a bandwidth-weighted
to express common factors underlying the adversaries’ ability manner.Weexplorethesetrade-offsusingtheShadowsimula-
to compromise different network locations, such as shared tor [2], [18] and find that there exist parameters that result in
legal jurisdiction or corporate ownership. A user expresses a only a slight decrease in performance, and only for less than
trust belief about her adversaries by specifying a probability 5 percent of users.
distribution over their presence at a set of network locations, The full version of this paper [19] contains additional
and she turns this belief into a trust policy by including results and details.
a weight for each adversary indicating her relative level of
II. ATTACKSONNETWORK-AWAREPATHSELECTION
concern about that adversary.
There have been several proposals to improve Tor security
Using these trust policies, we design Trust-Aware Path
by considering the network entities (e.g., AS or IXP) that
Selection (TAPS), a novel path-selection algorithm that uses
can observe a circuit [6], [8], [12], [14], [23], [29]. However,
trustinnetworkelementstoinformauser’sdecisionabouthow
none of these works considers anonymity across multiple
to select relays for its Tor path. Using TAPS, clients select
Tor connections. Any realistic use of Tor involves multiple
paths so as to minimize the probability that an adversary is
connectionsfromthesameuser,though,andtheseconnections
in a position to observe both ends of their Tor circuit while
are linkable by the adversary in many important cases, which
at the same time ensuring that their path selection behavior
means that it doesn’t suffice to consider the security of an
does not harm their security by making them stand out from
individual connection. Indeed, we present two specific attacks
other clients. In addition to defending against a much broader
that can deanonymize users by identifying and analyzing
class of adversaries, TAPS addresses the other deficiencies
multiple connections from the same user.
of prior proposals. In particular, it provides security against
While there have been several proposals for network-
an adversary that can monitor and link user activity across
aware path selection, we focus on just one for concreteness:
multiple connections, influence how users make connections,
Astoria [29]. It is among the most recent and complete
and identify the relays used repeatedly by a client.
proposals, and it provides a valuable example as many of
In order to facilitate the adoption of TAPS, we describe
the others suffer the same weaknesses. Astoria is designed to
both a long-term and a short-term deployment strategy. In
prevent deanonymization by an AS (or group of sibling ASes
the long-term strategy, all Tor users participate and use the
controlled by the same organization). To choose a circuit for
TrustAll version of TAPS to replace Tor’s existing bandwidth-
a given destination, a client determines the ASes between the
weighted algorithm. In the short-term strategy, TAPS provides
clientanditsguardsandbetweentheexitsandthedestination.
the option for security-conscious users to use trust to defend
It then makes a bandwidth-weighted random choice from
against traffic-correlation attacks while most users continue to
among the guard-exit pairs such that no AS appears on both
use“vanilla”Tor(i.e.,bandwidth-weightedpathselection).We
the client side and the destination side. If no such pair exists,
designtheTrustOneTAPSversionforthiscase,inwhichusers
alinearprogramisusedtodeterminetheselectiondistribution
mustbothavoidtrafficcorrelationandchoosepathsthatblend
over guard-exit pairs that minimizes the maximum probability
in with the vanilla Tor users.
that some AS appears on both sides. Circuits are reused for
We evaluate the security of TAPS via simulation with
destinations within the same AS.
modifiedversionsoftheTorPathSimulator(TorPS)[22].This
evaluationisdonewithrespecttotwoplausibleandillustrative A. Multiple-Connection Attacks
trustpolicies:(i)TheManpolicy,inwhichasingleadversary Chosen-DestinationAttack:Consideranadversarythatruns
has an independent probability of compromising each AS a number of web servers in different locations and runs some
organization (i.e., group of ASes run by the same entity), IXP Torrelays.IfaToruservisitsoneofthemaliciouswebservers,
organization, and self-declared relay family (i.e., set of relays theadversarycanforcethebrowsertovisittheothermalicious
run by the same entity) in Tor; and (ii) the Countries policy, servers and request resources that are linkable to the original
in which each country is considered a potential adversary and request (e.g., images with unique names). The adversary will
observes all ASes, IXPs, and relays located inside of it. Our then observe the pattern of exits chosen by the client to visit
analysis of TheMan policy for a popular Tor client location the servers in different locations, and it will also observe
shows a reduction in the probability of a successful first-last some of the client’s guards if the malicious relays are ever
attackfromabout0.7toabout0.4inTrustAllwithtypicalweb- selected in the middle position. This attack strategy applies
browsing activity over the first week in December 2013, and more generally to any situation in which the adversary can
from about 0.68 to as little as 0.1 in TrustOne with repeated choose the destinations that the client visits and is able to link
connectionsoverthesameweektoasingleIRCserverpopular those connections as originating at the same client.
withTordevelopers.OuranalysisoftheCountriespolicyover Underthisattack,path-selectionalgorithmsthatchoosere-
thatweekshowsareductioninthemediannumberofcountries laysbasedontheclient’slocationcanleakincreasingamounts
that “unnecessarily” compromise a stream (i.e., compromise a of information about that location with each additional desti-
streamwhentheydon’tcontainboththeclientanddestination) nationvisited.ThisisthecaseforAstoria,andwedemonstrate
from 5 to 2 in TrustAll with typical user behavior. that this attack is effective on that system.
Our algorithms are designed not only to improve security, To demonstrate the attack, we construct an AS-level In-
but also to allow security to be traded off for performance. ternet map using traceroute-based topology data and inferred
They achieve this by allowing clients to configure the fraction AS relationships from CAIDA [10], and BGP routing tables
ofbandwidthweightthattheirtrustedsetsofcandidateguards supplied by Route Views [33]. We use the data from these
and exits should exceed before making a bandwidth-weighted sources for October 2015. Routes between AS locations on
choicefromthem.Thismechanismresultsinaclientselecting ourmapareinferredusingthealgorithmproposedbyQiuand
from among the most secure relays while still making use of Gao [32], which takes AS paths observed in BGP tables and
2extends them to other locations using shortest “valley-free” be completed within the time needed to construct circuits and
paths. Conversion of IPs to ASes is performed using routing open streams on them in parallel, which is on the order of
prefix tables from Route Views. seconds.
We also use data from Tor Metrics [4] to evaluate the
attack’s effectiveness as if it were run on the Tor network
9
in the recent past. We use the archived network consensuses 8
and server descriptors to determine such facts as which relays 7
existed,whatfamiliestheyweregroupedin,whattheirrelative
6
bandwidthcapacitieswere,andwhattheir“exitpolicies”were. 5
We use the first network consensus from October 2015 and 4
its listed descriptors. We also use data from Juen [23] that 3
identifies 414 Tor client ASes as ever being observed making 2
a Tor connection and shows their relative popularity. 389 of 1
these appear in our AS map and are used in our analysis. 0
0 200 400 600 800 1000
The five most popular client ASes identified by Juen, in order Number of attack destinations
from most popular, are 6128 (Cable Vision Systems, US),
25019(SaudiNet,SA),8972(PlusServerAG,DE),6893(Saitis
Network, CH), and 15467 (Enternet Libercom, HU).
WesimulateAstoria’spathselectionsfor1000destinations
in ASes selected uniformly at random from those 44626 ASes
in a maximal fully-connected component in our map that also
advertise prefixes. For each destination AS, an IP is chosen
arbitrarily from an advertised prefix, and a connection to port
443 is simulated. We repeat the simulation 100 times. We
suppose that the adversary runs the 4 relays with the largest
probabilities of being selected as a middle, which have a
total advertised bandwidth of 1.01 Gbps and a cumulative
probability of 3.3% of being selected as a middle.
TableIshowshowoftentheadversaryobservessomeorall
of the client’s guards when the client uses 3 guards. It shows
that with 100 destinations the adversary observes all guards
with 30% probability, and with 300 destinations it observes
all guards with 94% probability. Itsometimes observes guards
even with no destinations due to being selected as a guard.
TABLE I: Probability of observing the client’s guards
Pr.0guards Pr.1guard Pr.2guards Pr.3guards
observed observed observed observed
0destinations 0.96 0.04 0 0
100destinations 0.04 0.14 0.52 0.30
200destinations 0 0.01 0.25 0.74
300destinations 0 0 0.06 0.94
We then consider how well the adversary can guess the
client’s AS after the attack in the case that he observes all of
theclient’sguards.WeagainsimulateAstoria’spathselections
for 1000 random destination ASes and repeat the simulation
100 times. We follow Nithyanand et al. [29] in using 3
guards (1 and 2 guards yield similar results). We suppose
that the adversary uses a uniform prior distribution on the
389 client ASes. We then compute the adversary’s conditional
distribution on the client ASes given the observed guard set
andthesequenceofexits.Theaverageentropyoftheresulting
distributions as we increase the number of attack destinations
is shown for the top 5 client ASes in Figure 1. It shows an
expected steady decrease in entropy for all client locations
as the attacker uses more destinations. By 300 destinations,
all locations result in less than 4 bits of entropy on average,
and by 1000 destinations, the average entropy is less than 2.5
bits for all locations. Identifying the client AS could be very
dangerous for a Tor user, as it can identify the country of that
user as well as the ISP whose network logs could be used
to completely identify the user. Note that this attack could
)stib(
yportne
roiretsop
.gvA
AS 15467
AS 25019
AS 6128
AS 6893
AS 8972
Fig. 1: Avg.entropyofposteriorclient-ASdistributionafterchosen-
destination attack on Astoria
Cross-Circuit Attack: Consider a popular website that
causestheuser’sbrowsertofetchresourcesofaknown(rough)
size from a set of servers in other ASes. An AS-avoiding
path-selection algorithm like Astoria may choose paths that
place a malicious AS between the exit and website on the
initial connection and then between the client and guard on
a subsequent connection to fetch a linked resource. If the
adversary can link its observations on those two connections,
which it might by using the timing and amount of traffic
on the circuit, then it can deanonymize the user, effectively
performing a correlation attack across circuits. See the full
version of this paper [19] for details and results on the
effectiveness of this attack. Choosing two different guards for
twodifferentdestinationsisusefulwhenforbothguardssome
AS between the client and guard appears between the exits
and destination for one destination but not the other, which
is precisely the situation when some AS is in a position to
perform this cross-circuit attack. This suggests that clients
should always choose guards obliviously to the destination.
III. TRUSTMODEL
A. Trust Policies
We use the definition of network trust given by Jaggard et
al. [16]. A trust belief is a probability distribution that indi-
cates how likely adversaries are to observe traffic at different
network locations. A location is considered to be more trusted
the less likely it is that adversaries are observing it. Although
the belief may be expressed as the adversaries’ success in
compromising any number of relevant factors, such as relay
software or physical location, ultimately it must describe the
probability that the adversaries observe traffic on the virtual
links into and out of the Tor network. A virtual link is an
unordered pair of network hosts, and the entry virtual links
consist of client-guardpairs while the exit virtual links consist
ofdestination-exitpairs.Anadversaryisconsideredtoobserve
a virtual link if it can observe traffic in at least one direction
between the two hosts. Although the representation of an
arbitrary distribution over all virtual links can be very large,
Jaggard et al. [16] describe how distributions of likely Tor
adversaries can be represented efficiently by aggregating host
locations(e.g.,attheASlevel)andbyidentifyingasmallsetof
relevant compromise factors and indicating their dependencies
in a Bayesian network.
3To indicate how to trade off vulnerability to different to contribute persistently-high levels of service to the Tor
adversaries, each user adopts a trust policy that pairs her trust network. However, it can require adversaries to either make
belief with a weight for each adversary. Each weight is a their own persistent commitments to the network or to have
number in [0,1] that indicates the relative level of concern compromised others who have done so (and are thus most
thattheuserhasfortheassociatedadversary.Inthiswork,we committed,experienced,anddifficulttoattack).ForTheMan,
assume that distinct adversaries do not collude. If a user were we therefore assume each family is compromised by the
worried about two adversaries colluding, she could combine adversary independently with probability between 0.02 and
her beliefs about them into those for a single adversary. 0.1, where the probability increases as the family’s longevity
Trustpoliciesarequitegeneralandcaneasilybeusedwith inTordecreases.Wecalculatelongevityasfollows:First,relay
many kinds of beliefs and sources of trust information. For uptimes are calculated as the exponentially-weighted moving
example, previous work that considered each relay to have an average of the relay’s presence in a consensus with Running,
independent and individual probability of compromise [20], Fast, and Valid flags with a half-life of 30 days. A relay
[21] can be represented as a trust policy by including a family’s uptime is simply the sum of its relays’ uptimes. The
single adversary and allowing him to compromise each relay probability that a family is compromised is then taken as
independently with its given probability. As another example, (0.1−0.02)/(family uptime+1)+0.02.
previousworkthatconsideredasapotentialthreateachASand
C. Countries
IXP[12],[14],[23],[28]canberepresentedasatrustpolicyby
As an alternative to TheMan, the Countries trust policy
including each AS and IXP as an adversary with equal weight
includes as an adversary each individual country in the world.
andallowingeachASandIXPtocompromisewithprobability
Aparticularcountryadversarycompromiseswithprobability1
1 all virtual links passing through it. Moreover, as described
every AS or IXP that is located in that country and no others.
by Jaggard et al. [16], trust policies can incorporate beliefs
All country adversaries are given a weight of 1. This policy
about a variety of other sources of network compromise,
illustratesageographicperspectiveforTorsecurity,anditalso
such as software vulnerabilities, physical cable tapping, and
demonstrates how we handle multiple adversaries.
geographic location.
Wedonotexpectthatmostindividualuserswillcrafttheir IV. SECURITYMODELANDMETRICS
owntrustpolicies.Indeed,doingsoislikelybestlefttoexperts A. Adversary Model
unlesstheuserhasstrongandidiosyncraticbeliefsorconcerns. As we have described in our trust model, we are con-
Rather, we envision that knowledgeable specialists, such as sidering an adversary who may control or observe some Tor
security researchers and professionals, will provide opinions relays and parts of the Internet infrastructure. Note that an
about vulnerability to specific kinds of adversaries, and that important special case of this is that the adversary might
institutions, such as governments and consumer advocacy observe the destination itself. From these positions, we then
groups, will incorporate these opinions into trust policies that analyzetheadversary’ssuccessindeanonymizingusersviathe
are appropriate for their communities. An important special followingmethods:(i)performingafirst-lastcorrelationattack,
case of this is that we expect that the Tor Project would select (ii)identifyingtherelaysusedonanobservedconnection,and
a default policy that is in the broad interest of all Tor users, (iii) observing Tor connections over time and linking them as
and then would configure the standard Tor client to use it belonging to the same user.
as well as provide any necessary supporting data through the As described earlier, first-last correlation attacks are possi-
Tornetwork,muchasTorconsensuses(i.e.,hourlydocuments ble whenever the adversary is in a position to observe traffic
describing available relays) are distributed today by a set of between the client and entry guard as well as between the
directory authorities. destination and exit. In such a situation, we assume that the
We will consider two specific trust policies in our analysis adversary can immediately determine that the observed traffic
ofTAPS:(i)TheMan,whichmodelsasinglepowerfulglobal is part of the same Tor circuit and thereby link the client with
adversarywhoseexactlocationisn’tknownwithcertainty,and its destination.
(ii) Countries, which models each country as an adversary Even when the adversary is not in a position to perform a
whose locations are known exactly. Either of these policies first-last correlation attack, he still may observe different parts
constitutes a plausible default policy as well as that of a of the circuit and use traffic correlation to link together those
particular user community. We now describe these models. parts. In such a case, if the observed relays on the circuit are
unusually likely for a particular client to haven chosen (e.g.,
B. TheMan because of atypical trust beliefs), then the adversary may be
TheManrepresentsapowerfuladversarywhomaycreate, abletoidentifytheclientevenwithoutdirectobservation.This
compromise, or coerce the diverse entities that make up the is even more of a concern if the adversary applies congestion
Tor network. Specifically, we give The Man an independent orthroughputattacks[13],[25]toindirectlyidentifytherelays
probability to observe each Tor relay family, AS organization, onatargetcircuit.Therefore,wewillconsidertheabilityofthe
and IXP organization. A relay self-identifies its family in a adversarytoidentifythesourceanddestinationofanobserved
descriptor [36] that it uploads to the directory authorities, circuit based on knowledge of its relays.
and an AS or IXP organization is identified using public Finally, it is important to consider multiple connections
informationasbeingcontrolledbythesamecorporateorlegal over time instead of just one in isolation. Every circuit that
entity[9],[22].Withoutanybasisfordifferentiation,TheMan a client creates may give the adversary another opportunity
compromises each AS and IXP organization independently obtainasensitivepositionormayleakmoreinformationabout
with probability 0.1. For relays, we consider that trust may the client. This problem is made worse by the fact that the
increase the longer a given relay has been active. This will adversary may be able to determine when some circuits are
not guarantee protection against an adversary that is willing created by the same client. This could happen, for example,
4if the adversary repeatedly observes traffic to the destination with two different types of other users: those who do use trust
and the client interacts with the same online service using a in path selection and those who do not. The main approach
pseudonym or requests a sequence of hyperlinked documents. of both algorithms is to choose guards and exits to avoid
Observe that in both of these examples the linking is done first-last correlation attacks while also blending in with other
using similarities in the content of traffic and not via any users. Parts of this approach are shared with some previously-
weakness in the Tor protocol. Thus we will consider an proposed path-selection security improvements [6], [12], [21].
adversary who can link observed connections by client. However, TAPS includes several novel features that improve
Note that we are not considering an adversary that can the security and performance issues of these proposals. We
identify traffic content based only on the timing and volume highlight those features before proceeding to describe the
of data, that is, an adversary that can perform website finger- algorithms in detail.
printing [37]. Also, in reality we can expect adaptive adver- First, TAPS uses an API that encapsulates flexible trust
saries who continually learn and shift the allocations of their policies. These trust policies support adversaries from a very
resources, but we only analyze static adversaries in this paper. generalclassofprobabilisticmodels.Aspreviouslydescribed,
However, adaptiveness can be captured to a certain extent this class can represent features such as uncertainty, multiple
already by defining trust policies with respect to adversary adversaries, and adversarial control of diverse network ele-
behavior over time. That is, the compromise probability for a ments.
relayorvirtuallinkcanrepresenttheprobabilitythatitwillat Second, TAPS clusters client locations and (separately)
somepointduringagivenperiodbeobservedbytheadversary. destination locations. Each location cluster has a represen-
tative, and all locations in the cluster are treated as if they
B. Anonymity Metrics
were the representative. The main purpose of this clustering
We evaluate anonymity using two kinds of metrics. The
is to prevent leakage of location information over multiple
first kind will give empirical estimates of the speed and
connectionsthatwouldoccurifpathswereselecteddifferently
frequency of first-last correlation attacks. The second kind
for each pair of client and destination location. Treating all
will provide worst-case estimates for the adversary’s ability
members of the cluster as if they were the representative
to identify the source or destination of streams that are only
maintainsanonymitywithinthecluster.Asecondarybenefitis
partially observed.
reducing the amount of information needed to represent trust
First-lastcorrelationattacksarerelativelysimpleandresult
policies by reducing the number of paths to and from guards
in complete deanonymization, and therefore we are interested
and exits that need be considered.
in accurate estimates for how likely they are to occur. More-
Third, TAPS treats its set of entry guards collectively, that
over, their success depends on the behavior of the user and of
is, in a way that provides security when multiple circuits, po-
thecircuit-creationalgorithm,andthereforewecanmeasureit
tentially using different guards, are considered. TAPS chooses
empirically via simulation. Following Johnson et al. [22], we
each additional guard in a way that minimizes the additional
use the following as metrics: (i) The probability distribution
exposure of its entry paths. Moreover, once a set of entry
of time until a client is deanonymized via a correlation attack;
guards is chosen, TAPS doesn’t prefer one guard in the set
and (ii) The probability distribution of the fraction of streams
overanotherwhencreatingaconnectiontoagivendestination.
that are deanonymized via a correlation attack.
This prevents the cross-circuit attack discussed in Sec. II-A.
Measuring the anonymity of multiple connections that
It also makes TAPS compatible with the Tor’s current default
are only partially observed is more difficult because it isn’t
configurationofoneguard,asitdoesnotdependonbeingable
clear how successful the adversary can be at both linking
tochoosethebestguardamongseveralforagivendestination.
separate streams and indirectly identifying relays on a circuit.
Fourth, TAPS provides a configurable tradeoff between
Therefore, we take a worst-case approach and consider the
security and performance by parameterizing how much relay-
adversary’s ability to guess the source (resp. destination) of a
selection deviates from ideal load-balancing. The Tor network
sequence of streams that have been linked as coming from the
is under heavy load relative to its capacity [4], and latency
sameclient(resp.goingtothesamedestination)andforwhich
is dominated by queuing delay at the relays [17]. Thus good
the circuit relays have been identified. We measure this ability
load balancing is essential to maintaining Tor’s performance,
as the posterior distribution over network locations. Note that
which is itself a crucial factor in Tor’s success.
we do not take into account the fact that the adversary knows
that streams for which the client or destination is unknown
B. Trust API
can only travel over virtual links that the adversary does not
TheTAPSalgorithmsworkwiththetrustpoliciesdescribed
observe. Ruling out certain virtual links is more challenging
in Sec. III via an Application Programming Interface (API).
thanjustpositivelyidentifyingtrafficonavirtuallinkbecause
Jaggardetal.[16]describehowtorepresentsuchpolicieswith
it requires the false negative rate for traffic correlation to be
a Bayesian network. However, such a representation may not
extremely low (in addition to the existing requirement that the
be the most efficient for the computations needed during path
falsepositivebeextremelylow).Thus,weleavethisextension
selection. Therefore, we abstract those computations into an
to our analysis to future work.
API,andwedescribehowtheycanbeefficientlyimplemented
V. TRUST-AWAREPATHSELECTION for TheMan and Countries policies in Sec. V-E. We assume
A. Overview that the API is implemented by the creator of the trust policy.
WedescribetwovariantsoftheTrust-AwarePathSelection Several API functions take as an argument a network
algorithms(TAPS):(i)TrustAll,whichisintendedforsystem- location. There are several possible levels of granularity at
wide deployment, and (ii) TrustOne, which works with Tor’s whichanetworklocationmaybedefinedinTAPS,suchasthe
existing path-selection algorithm and is intended for use by a Autonomous-SystemlevelortheBGP-prefixlevel.Usingmore
minority of users. Two TAPS variants are needed to blend in fine-grained locations will result in more accurate predictions
5aboutthe adversaries’locations andthusimprove security,but We now detail these processes.
itwillalsoresultinincreasedruntimefortheTAPSalgorithms 1)Cluster: Network locations are clustered twice. One
(and likely for the API functions as well). clustering will be applied to the destination’s location during
We assume that API users can provide a locations data path selection, and the other will be applied to the client’s
structure that (i) allows the locations to be enumerated, (ii) location. The output of a clustering is a partition of network
includes each location’s popularity rank for Tor clients, (iii) locations with a single member of each cluster in the partition
allows IP addresses to be mapped to locations, and (iv) designated as that cluster’s representative. Client and destina-
includessizeofeachlocation(e.g.,thenumberofIPaddresses tion clusterings are performed slightly differently because a
originated by an Autonomous System). single client is likely to visit many destinations. Therefore,
We also assume that API users can provide a relays data if we were to bias destination clusters, we could potentially
structure that (i) allows relays to be enumerated by unique reduce security for all clients on at least one connection, but
identity keys (e.g., as represented by fingerprints [36]), (ii) we can bias client clusters towards the most likely locations
includes the data in each relay’s consensus entry (e.g., the and improve security for most clients.
statusflags,weight,andIPaddress),and(iii)includesthedata a)Clustering destination locations: Destinations are
in each relay’s descriptor (e.g., the exit policy). clusteredwithak-medoidsalgorithm[31],modifiedtoproduce
The trust API functions are as follows: balanced-size clusters. Balance is needed for good anonymity,
1) LOCATIONDISTANCE(loc 1, loc 2, relays, weights): This as each cluster is an anonymity set. The medoids of the
functionreturnsanabstractdistancebetweentwolocations resulting clusters are used as representatives. The destination-
that measures the dissimilarity of the adversaries that clustering algorithm takes two parameters: (i) num clusters,
appear on the network paths between the locations and the number of clusters to produce, and (ii) max rounds, the
the relays. This distance is the expected sum over relays maximum number of assignment rounds. The clustering is
weightedby weights ofthe totalweightof adversariesthat accomplished as follows:
appear on one of the virtual links between the relays and
1) Choose as an initial cluster representative a location uni-
loc and loc but not the other. This function turns the set
1 2 formly at random from locations.
of locations into a metric space.
2) Choose the remaining num clusters−1 cluster representa-
2) GUARDSECURITY(client loc, guards): This function re-
tives by iteratively choosing the location with the largest
turns a security score for the use of the given guards as
distance to the representatives already chosen (i.e., the
entry guards by a client in location client loc. The score
maximin distance), with distances determined by LOCA-
must bein [0,1], andit should represent theexpected total
TIONDISTANCE().
weight of adversaries not present on the paths between
3) Assign locations to cluster representatives by greedily
client locandguards,normalizedbythesumofalladver-
assigning to the smallest cluster (in terms of the total size
saryweights.Thusahigherscoreindicateshighersecurity.
of its locations) at a given time the location closest to its
3) EXITSECURITY(client loc, dst loc, guard, exit): This
representative, as measured by LOCATIONDISTANCE().
function returns a security score for the use of guard
4) Recalculate the cluster representatives by determining the
and exit by a client in location client loc to connect to a
location in each cluster with the smallest average distance
destination in dst loc. The score must be a value in [0,1],
to each other member in the same cluster.
and it should represent the expected total weight of the
5) Repeat from step (3) if any cluster representative changed
adversaries that either are not present on the path between
and there have been fewer than max rounds assignment
client locandguardorarenotpresentonthepathbetween
rounds.
dst locandexit(i.e.,thosenotabletoperformacorrelation
6) Return both the clusters and their representatives.
attack), normalized by the sum of all adversary weights.
Thus, again, a higher score indicates higher security. b)Clustering client locations: Client clustering uses
known popular client locations as cluster representatives and
C. TrustAll then clusters the remaining locations in one round. The client-
TrustAll consists of two separate processes: clusteringalgorithmtakesasinputnum clusters,thenumberof
1) CLUSTER: This process is run by the trust-policy provider clusters to produce. It creates the set of cluster representatives
(e.g.,bytheTordirectoryauthoritiesforthedefaultpolicy). by selecting the num clusters most-popular client locations.
It clusters client and destination locations and makes the The remaining locations are assigned to clusters by greedily
results available to clients. To maintain the anonymity assigning to the smallest cluster at any time as in the destina-
sets provided by the clusters, this process should execute tion clustering.
infrequently (e.g., every 6 months) and only to reflect 2)CONNECT: The CONNECT process is invoked when
significant changes in the trust on entry and exit virtual a Tor client is requested to connect to a destination. We
links. It takes the locations and relays data structures as assume for now that any needed DNS resolution has been
inputsandproducesclustersasoutput,whichisamapping performed, and CONNECT has been given a destination IP
fromeachlocationchosenasaclusterrepresentativetothe address. Section V-F discusses how DNS resolution might
set of locations in its cluster. occur.
2) CONNECT:ThisprocessisrunbyaTorclient.Itrunsevery The essential mechanism that TrustAll uses to improve se-
time a new connection is requested. It uses the output of curityistocomputesecurityscoresforrelaysintheguardand
the CLUSTER process, the state of the client (e.g., current exitpositionsandthentoonlyselectthehighest-scoringrelays
networkconsensus,currentcircuits,andclientIPaddress), for those positions. Guard security scores are determined with
locations, and relays. It may create a new circuit or reuse GUARDSECURITY(), which takes into account any existing
an existing one. guards when choosing a new one and thus provides security
6with respect to the entire guard set. Exit security scores are other options are considered.
determined with EXITSECURITY(), which takes into account αw represents the desired minimum bandwidth fraction of
p
the guard to be used for the circuit and thus can mitigate first- relays in position p for the secure relays. It will be reached if
last correlation attacks. the safe and acceptable relays together constitute at least that
Given scores for relays in position p∈{g,e} (g for guard fraction. The weights argument to SECURERELAYS() maps
andeforexit),theSECURERELAYS()function(Alg.1)isused relays to their positional bandwidth to determine if and when
to determine the secure relays, that is, those relays with high- αw is reached.
p
enough scores to be selected for a given position. Note that Letclient repbetherepresentativelocationfortheclient’s
in Alg. 1 REVERSESORT(X,Y) sorts the entries x ∈ X by cluster and dst rep be the representative location for destina-
descending values Y[x], and LENGTH(X) returns the number tion’s cluster. The CONNECT process proceeds as follows:
ofentriesinX. SECURERELAYS()identifiesthehighestscore If the number (cid:96) of selected and responsive guards is less
than the number k desired (e.g., k is the value of NumEntry-
Algorithm 1 TrustAll secure relays to use for position p Guards [36]), then k−(cid:96) new guards are selected. Each guard
is added by (i) creating scores where each potential guard g
function SECURERELAYS(α p,scores,relays,weights)
has score GUARDSECURITY(client rep,G∪{g}), with G is
R← REVERSESORT(relays,scores)
the current set of guards; (ii) identifying as the set of secure
s∗ ←scores[R[0]] (cid:46) Maximum score
n← LENGTH(relays) (cid:46) Number of relays
guardsS = SECURERELAYS(α g,scores,P,g weights),where
α contains the guard security parameters, P contains all
S ←∅, w ←0, i←0 g
potentialguardsnotcurrentlyselected,andg weightscontains
while (scores[R[i]]≥s∗αsu)∧
p the relays’ weights for the guard position; and (iii) randomly
(1−scores[R[i]]≤(1−s∗)αsc)∧
p selecting from S with probability proportional to g weights
(i<n) do (cid:46) Add all safe relays
(i.e. making a bandwidth-weighted choice).
S ←S∪{R[i]}
Consider the existing circuits in reverse order of the time
w ←w+weights[R[i]]
a stream was most-recently attached. If current circuit c is
i←i+1
too dirty, that is, a stream was first attached too long ago
while (scores[R[i]]≥s∗αau)∧
p (Tor’s default dirtiness threshold is 10 minutes), then proceed
(1−scores[R[i]]≤(1−s∗)αac)∧(w <αw)∧
p p to the next circuit. Otherwise, let g c be the circuit’s guard, let
(i<n) do (cid:46) Add acceptable relays α contain the security parameters for exit selection, let exits
e
S ←S∪{R[i]} containallpotentialexitsforthedesiredconnectionaccording
w ←w+weights[R[i]] to the criteria Tor currently uses that don’t depend on the
i←i+1
guard(e.g.,acompatibleexitpolicy),andlete weightscontain
return S the relays’ weights for the exit position. Let scores contain
the exit scores, with scores[e] = EXITSECURITY(client rep,
s∗. It adds to the set of secure relays all safe relays, that dst rep, g , e) for all e∈exits. Compute the set of secure exit
c
is, relays with scores very close to s∗. Then it considers the relays S = SECURERELAYS(α e, scores, exits, e weights). If
acceptablerelays,thatis,relayswithscoresclosetos∗ butnot the circuit’s exit e is in S, then reuse the circuit. Otherwise,
c
close enough to make them safe. Acceptable relays are added proceed to the next circuit.
in descending order of score until the desired fraction of the If no suitable circuit has been found and reused, let
total bandwidth in position p is reached. Distinguishing safe c be the circuit among those that are not too dirty
from acceptable relays enables improved load balancing when that most recently had a stream attached, and let g
c
there are many highly-trusted choices available. be its guard. Choose a new exit e by (i) creating
The parameters defining these sets are given as the list scores where each e ∈ exits has score EXITSECU-
α
p
= (α psu,α psc,α pau,α pac,α pw). α psu and α psc are used just RITY(client rep,dst rep,g c,e);(ii)identifyingasthesetofse-
for safe relays, and α pau and α pac are used just for acceptable cure exits S = SECURERELAYS(α e,scores,exits,e weights);
relays. Safe and acceptable relays are defined using the same and (iii) randomly selecting from S with probability propor-
method, but acceptable relays use less restrictive parameters, tional to e weights. Reuse c through its first two hops but
with αau ≤αsu and αac ≥αsc. “splice” e onto the end after the middle relay. This effectively
p p p p
The“uncompromised”parameterαu ∈{αsu,αau}isused operates as a new circuit, but the handshakes through the first
p p
toincludearelayonlyifithasasecurityscoressuchthats≥ two hops are not repeated to reduce the latency of creating it.
s∗αu. It must be that αu ≤1, or no relays would qualify. αu If no circuit exists that is not too dirty, create a new
isthustherequiredfractionofthemaximumpossibleexpected circuit as follows: (i) choose a guard g uniformly at random
weightofadversarieswithrespecttowhomthecircuitposition from the k selected and responsive guards, (ii) choose an
is considered uncompromised. One effect of this constraint is exit e as described for the case that a new exit is being
that relays with completely untrusted paths will not be chosen spliced onto an existing circuit with g as the guard, and (iii)
if there is at least one other option. choose a middle node as Tor currently does given g and
The “compromised” parameter αc ∈{αsc,αac} is used to e (e.g., bandwidth-weighted random selection). Note that, in
p p
include a relay only if it has a score s such that 1 − s ≤ contrast to vanilla Tor path selection, the guard and exit are
(1−s∗)αc.Itmustbethatαc ≥1,ornorelayswouldqualify. not explicitly prevented from being contained in the same /16
αc is thus a limit on the multiple of the minimum possible subnet or relay family. Instead, the threat of entry and exit
expected weight of adversaries to whom the circuit position is paths being observed by the same relay family or network
considered compromised. An effect of this constraint is that is incorporated into the trust policy, and vulnerable paths are
if relays with completely trusted paths are available, then no avoided by TAPS.
7D. TrustOne the Bayesian-network representation of Jaggard et al. [16].
TrustOne path selection is designed to be used when most However,policiesshoulduseimplementationsthatareefficient
users are not using TAPS and instead are using vanilla Tor for their specific features.
path selection. Thus slightly different behavior is required in For The Man policy, the trust API functions need access
order to fully blend in with the larger group. Also, if most to data describing the relay families, AS organizations, IXP
users do not use trust, then more secure parameters can be organizations, and the virtual entry and exit links on which
used without impacting performance much. each AS and IXP organization has a presence. The API
AswithTrustAll,TrustOneconsistsofaCLUSTERprocess functions can easily be implemented efficiently for TheMan
and a CONNECT process. CLUSTER is performed in the same becausethereisasingleadversarywhosepresenceonavirtual
way as in TrustAll. The CONNECT process differs from that link depends on the compromised status of network entities
of TrustAll in the following ways: (i.e., relay families, AS organizations, and IXP organizations)
• SECURERELAYS() doesn’t use the notions of safe and that are each independently compromised. We implement the
acceptable relays. It simply orders relays by their score API functions as follows:
and chooses the most secure up to the desired bandwidth • LOCATIONDISTANCE(loc 1,loc 2,relays,weights):Tocom-
fraction. The TrustOne version of this function appears pute this, consider each r ∈ relays. Let E be the set of
1
in Alg. 2. Note that the performance parameter is a network entities that exist between r and both loc and
1
single value (i.e., α = αw). TrustOne doesn’t use the loc , let E be the set of network entities that exist only
p p 2 2
concept of acceptable relays because it must allow exit between r and loc , and let E be the set of network
1 3
relays to be chosen the same they are in vanilla Tor path entities that exist only between r and loc . Let p be the
2 r
selection, which in TrustOne will happen when αw = 1. probabilitythattheadversaryispresentononeofthepaths
e
Also, TrustOne can omit the distinction between safe and from r to loc and loc but not the other. p is simply the
1 2 r
acceptable relays because load balancing is less important probability that (i) no e ∈ E is compromised and (ii)
1
when few users are using trust. either some e ∈ E is compromised and no e ∈ E is
2 3
• Given a guard, potential exits (i.e., the set over which compromised or vice versa. The distance is computed as
scores are computed with EXITSECURITY()) are chosen the weights-weighted sum of p
r
over r ∈relays.
exactly as they are in vanilla Tor path selection, including • GUARDSECURITY(client loc,guards):LetE bethesetof
in particular the constraints preventing exits and guards network entities between client loc and the guards. The
from sharing a family or /16 subnet. This prevents a security score computed as the product of the probabilities
TrustOne user from being identified as using non-standard that each e∈E is individually uncompromised.
path selection (e.g., by a middle relay). • EXITSECURITY(client loc,dst loc,guard,exit):LetE
1
be
the set of network entities that exist both between
client loc and guard and between dst loc and exit, let
Algorithm 2 TrustOne secure relays to use for position p
E be the set of network entities that exist only between
2
function SECURERELAYS(α pw,scores,relays,weights) client loc and guard, and let E
3
be the set of network
R← REVERSESORT(relays,scores) entities that exist only between dst loc and exit. The
S ←∅, w ←0, i←0 security score is the product of the probability that no
while w <α pw do (cid:46) Add desired fraction of relays e ∈ E
1
is compromised and that either no e ∈ E
2
is
S ←S∪{R[i]} compromised or no e∈E is compromised.
3
w ←w+weights[R[i]]
For the Countries policy, the trust API functions need
i←i+1
the list of all countries as well as a data structure map-
return S
ping each relay to its country and each virtual link to
the countries it passes through. LOCATIONDISTANCE(loc 1,
Note that a client can choose not to protect the fact the he loc ,relays,weights)isjustaweightedsumoverr ∈relaysof
2
is using TrustOne instead of vanilla Tor by setting a desired the number of countries on which the virtual links {loc ,r}
1
exit bandwidth fraction of α ew < 1. He may do this when he and {loc 2,r} disagree. GUARDSECURITY(client loc,guards)
doesn’t believe that revealing his use of TrustOne will reveal returns the fraction of countries not containing guards or
his identity, and using a smaller α ew will improve his security on the virtual links between client loc and guards. EXIT-
against a first-last correlation attack by restricting his circuits SECURITY(client loc,dst loc,guard,exit) returns the fraction
to more-secure exits. of countries either not containing guard and not on the
{client loc,guard} virtual link or not containing exit and not
E. Trust API implementations
on the {dst loc,exit} virtual link.
The efficiency of the trust API depends on the type of
trustpoliciesused.Forexample,auserwithtrustinindividual F. Discussion
relays may only need to store a single trust value for each So far, we have been discussing trust-aware routing to
relay and perform simple arithmetic computations for the API destination IP addresses. Many or most connections will
functions, while a user with trust in Autonomous Systems require DNS resolution before the destination IP is known.
may need to store an entire Internet topology and perform Exit relays resolve DNS requests in current Tor routing to
routinginference.Ingeneral,becausetheAPIfunctionsreturn prevent linking of client IP address directly to a destination
the expectation of values that can easily be computed if DNS request. This must also be done in a trust-aware manner,
the compromised relays and virtual links are unknown, they or there is little point in using trust-aware routing from exit
can be implemented by repeatedly sampling the adversary to destination once the IP address is known. If we rely on
distributions. Thus the API functions are compatible with a chosen exit to control the DNS resolution, then, even if
8it shares the default trust values, it may not be a good exit we observe to resolve to 82.195.75.116 in AS 8365 (TU
for resolving the intended destination. When doing iterative Darmstadt, DE). This model repeatedly plays the trace 8 a.m.
DNS resolution from the client, possibly switching to new to 5 p.m. every weekday. This results in 135 TCP connections
circuits depending on the next identified DNS resolver, the per week.
performance overhead could be significant. In this paper, we ToevaluatesecuritywithrespecttoTheMan,weuseitto
assumethatprimaryandbackupnameserverASesareincluded drawasampleofthecompromisedrelaysandvirtuallinksfor
withexit-relaydescriptors.Assumingthatthesearetypicallyin each TorPS sample and consider the security of that sampled
the same AS as or immediately adjacent to the exit, this will path-selection behavior against that sampled adversary. That
at least make sure that initial DNS requests are trust-aware. is, we independently assign a compromised status to each
How best to address DNS issues beyond that is outside the AS organization, IXP organization, and relay family using
scope of this paper. the probabilities given in Section IV. We then consider the
We expect the CLUSTER process to be performed by anonymity of the circuits in the TorPS sample against the
organizations (e.g., Tor or EFF) and the results distributed sampled adversary. We run simulations over the first week of
to users who trust their analysis and calculations. End-users December 2013. We use 3 guards for all simulations.
wouldthenonlyneedtoperformtheCONNECTprocess.Inthe
caseofTrustAll,securitydependsontheassumptionthatmany B. Location Clusters
other users are using the same policy. Therefore, the TrustAll TheTrustAllalgorithmpreventsthechosenTorpathsfrom
CONNECT process could be integrated with the standard Tor revealingclientanddestinationlocationsbeyondtheirlocation
release and enabled with a default policy (e.g., The Man or clusters. An adversary that can identify the relays in each
Countries). However, TrustOne was designed to be used by a positionofacircuit(e.g.,byrunningarelayandbeingselected
minority of users, and while the algorithm could be included as a middle) may use them as evidence for the clusters of
with Tor, it would not be enabled by default. We analyze the the client and destination. For example, if the adversary is
security and performance of both approaches in the following also observing the exit-destination link, it may be the case
sections. that a given guard and exit would only be used to visit that
destination by members of a given client cluster. As was
VI. SECURITYANALYSIS showninSectionII,thisisanespeciallypowerfulattackifthe
A. Experimental Setup adversary can additionally link together multiple connections
We experimentally evaluate the security of the TrustAll as belonging to the same (pseudonymous) user.
and TrustOne algorithms against The Man using an Internet Thuswemustconsidertheanonymitythatisaffordedwhen
map,dataabouttheTornetwork,andpath-selectionsimulators a client or destination is known to belong to a given cluster.
for TAPS and for vanilla Tor. The AS-level routing map and In our experiments, we partition all Internet ASes into 200
past state of the Tor network are constructed as described clusters.Thisnumberofclustersallowsforsignificantdiversity
in Sec. II-A, but for these experiments we use data from inclusterbehaviorwhilereducingtheanonymitysetofroughly
December 2013. 3.7 billion addresses in IPv4 by a factor of 200. We perform
We augment the routing map using sibling information clustering using as the guard and exit locations the sets of
based on RIPE WHOIS records. We identify IXPs and place ASes in which Tor guards and exits were observed to reside
them on these on the AS-level paths using data from the IXP during the six-month period from June 2013 to November
mapping project [7]. We group ASes into commercial organi- 2013,whichprecedesthesimulationperiodinDecember2013.
zations using the results of Cai et al. [9]. We conservatively Following the cluster-formation algorithm given in Sec-
group IXPs into organizations based on similarities in their tion V, the 200 client clusters are created by choosing as
listingsinthePacketClearingHouseandPeeringDB(see[22] clusterrepresentativesthetop200TorclientASesreportedby
for details). Juen [23]. In the resulting clustering, the median cluster size
We simulate path selection on past Tor networks using the in terms of contained addresses is 11,363,072, the minimum
Tor Path Simulator (TorPS) [22]. TorPS provides Monte Carlo size is 10,840,321, and the maximum size is 118,966,528.
simulation of user circuit creation over weeks and months on Also as described in Section V, the destinations clusters
the changing Tor network. Each TorPS sample consists of were formed slightly differently, using k-medoids clustering
a sequence of circuits and assignments to those circuits of to identify representatives that were best able to minimize
requested user connections over the period of simulation. We distances between cluster members and their representatives.
use TorPS unmodified to evaluate the security of vanilla Tor, The clusters that were the output of this process had a median
and we also modify TorPS to use the TAPS path selection of 11,992,641 IPv4 addresses, with a minimum of 11,358,466
algorithms. and a maximum of 119,068,928. Our clustering algorithm
We perform our TorPS simulations for two models of user sought to maximize the number of addresses contained in
behavior: the Typical model, and the IRC model. Johnson et each cluster, but it could easily incorporate other anonymity
al. describe these models in detail [22]. The Typical model concerns, such as AS or country diversity.
consists of four 20-minute user traces obtained from actual
(volunteer)useractivityoverTor:(i)Gmail/GoogleChat,(ii) C. TrustAll Security
Google Calendar / Docs, (iii) Facebook, and (iv) web search First we consider security against The Man when all
activity. It includes 205 unique destination IPs and uses TCP users use TAPS as the default path-selection algorithm (i.e.,
ports 80 and 443. These traces are played every day in five TrustAll). In particular we consider the threat of complete
sessions between 9 a.m. and 6 p.m. This results in 2632 TCP deanonymization via first-last correlation. We used the se-
connections per week. The IRC model uses the trace of a curity parameters (αsu,αsc,αau,αac) = (0.95,2.0,0.5,5.0),
g g g g
single IRC session to irc.oftc.net on port 6697, which (αsu,αsc,αau,αac) = (0.95,2.0,0.1,10.0), and (αw,αw) =
e e e e g e
91.0
0.9
0.8
0.7
0.6
0.5
0.4
0.3
0.2
0.1
0.0 0 1 2 3 4 5 6 7
Days from first stream
ytilibaborp
evitalumuC
Vanilla Tor, Typical
TrustAll, Typical
Vanilla Tor, IRC
TrustOne, IRC, exit wt 1.0
TrustOne, IRC, exit wt 0.005
Fig. 2: Time to first compromise in TheMan model
1.0
0.9
0.8
0.7
0.6
0.5
0.4
0.3
0.2
0.1
0.0 0.0 0.2 0.4 0.6 0.8 1.0
Fraction of streams
ytilibaborp
evitalumuC
1.0
0.9
0.8
0.7
0.6
0.5
0.4
0.3
0.2
0.1
0.0
0.00 0.05 0.10 0.15 0.20 0.25
Fraction of streams unnecessarily compromised
Vanilla Tor, Typical
TrustAll, Typical Vanilla Tor, IRC
TrustOne, IRC, exit wt 1.0
TrustOne, IRC, exit wt 0.005
Fig. 3: Fraction of compromised streams in TheMan model
(0.2,0.2). Figures 2 and 3 show cumulative distributions for
when and how often deanonymization occurs for a Typical
user in the most popular Tor client AS (6128) over 7 days of
simulation.
We can see that TrustAll significantly reduces the chance
of first-last correlation by The Man as compared to vanilla
Tor. Users coming from AS 6128 see the probability of at
least one successful first-last correlation attack drop from 0.7
to about 0.4. Observe that this overall reduction occurs both
because the chance of choosing a compromised guard among
the initial set of 3 is reduced (as seen in the values at 1 day)
and because the chance of choosing additional compromised
guards, precipitated by network churn, is reduced (as seen in
the smaller slopes of the CDF). The results also show that the
median fraction of compromised streams drops from around
0.1 to 0.
NextweconsiderthesecurityofTrustAllintheCountries
model. In this model, users face multiple country adversaries
(249), each of which deterministically compromises all ASes
andIXPswithinitsborders.Inthissetting,usersaresometimes
necessarily compromised against those countries that contain
both the source and destination AS. Thus we only consider
the fraction of those streams that are to a destination AS in
different country than the client AS and are “unnecessarily”
compromisedbysomecountry.Figure4showsthedistribution
of this value for a Typical user in AS 6128 (which is in the
US) active over seven days. It shows that TrustAll reduces the
fractionofunnecessarily-compromisedstreamsfromamedian
of about 0.24 to a median of about 0.17.
Finally, we consider security of IRC users using the Tru-
stOne algorithm when default users are using vanilla Tor. In
this case, the TAPS users choose guards and exits in a way
dseigned to be sufficiently similar to how they are selected in
vanillaTor.Specifically,guardsareselectedusingαw =0.005
g
ytilibaborp
evitalumuC
TrustAll
Vanilla Tor
Fig. 4: Security in the Countries model
andexitsareselectedusingeitherαw =0.005orαw =1.The
e e
former weight for exits results in a TrustOne user being 200
times more likely to have chosen a given exit than a vanilla
Tor user. This could be an appropriate setting for a user who
is not concerned with revealing his use of TrustOne and his
trustbeliefs.Itcouldalsobeappropriateforauserwhoisjust
tryingtoprotectanonymityforasingleconnectionconsidered
in isolation. The weight αw = 1 results in exit selection by
e
a TrustOne user that is identical to that of Tor users. This is
an appropriate setting when the user wants to hide his use of
TrustOneandtheuser’sadversariesmaybeabletolinkcircuits
together over time as belonging to the same user.
Figures2and3showsthechanceofdeanonymizationofan
IRCuserinAS6128viafirst-lastcorrelationforTrustOneand
vanilla Tor. We can see that TrustOne results in a significantly
lower chance of compromise, from a 0.68 chance for vanilla
Tor users to about 0.2 or 0.1, depending on the exit-selection
parameter αw. The median compromise rate also drops from
e
about 0.7 to 0.
VII. PERFORMANCEANALYSIS
The TAPS algorithm was designed to provide tunable
performance while improving users’ security by limiting the
probability that an adversary can observe both sides of a
Tor circuit. We now analyze the effect TAPS has on client
performance and relay load balancing.
A. Tor Network Model
We evaluate the performance effects of TAPS using
Shadow [2], [18], a scalable and deterministic discrete-event
network simulator with a plug-in architecture that enables
it to run real software. Shadow runs the Tor software, and
so we can directly implement our algorithms in Tor’s code
base while increasing our confidence that the application-level
performance effects are realistic.
We configure a private Tor deployment using Shadow and
the large-scale topology produced by Jansen et al. [17]. Our
base configuration consists of 400 Tor relays (including 4
directory authorities and 93 exits), 1380 Tor clients that also
run a simple file-fetching application, and 500 simple file
servers.Oftheclients,1080areWebclientsthatareconfigured
to: choose a random server and download a 320 KiB file from
it; pause for [1, 60] seconds chosen uniformly at random;
and repeat. 120 of the remaining clients are bulk clients that
are configured to repeatedly download a 5 MiB file without
pausing between downloads. Each experiment is configured
to run for 1 virtual hour, which takes about 5 hours on our
machine (using 12 Shadow worker threads) while consuming
40 GiB of RAM.
10We also run 180 ShadowPerf clients and model their these clients, because of their location, consistently choose
behavior after the TorPerf [5] clients that measure and publish low capacity guards and exits that cause their downloads to
performanceovertimeinthepublicTornetwork.Wecompared receive bad performance. (Clients in the long neck of number
ShadowPerf to TorPerf performance over several experiments ofdownloadsarealsointhelongtailofdownloadtimes.)This
and found that Shadow is able to model Tor performance isalsoaresultofourbehaviormodels,inwhichclientsdonot
characteristics with reasonable accuracy over a range of file start a new download until the previous one finishes. A richer
download sizes. behaviormodelinwhichsomeclientsstartmultipledownloads
at a time (e.g., representing users opening multiple tabs or
B. TAPS Implementation Details
starting multiple background file transfers) could alleviate this
WebranchedShadow[1]atcommit023055eb5,shadow-
artifact.
plugin-tor [3] at commit 9eed6a7c5, and Tor at version
As shown in Figure 5e, the reduction in the number of
0.2.5.2-alpha and modified them to support experimen-
downloads also reduces total aggregate network throughput
tation with TAPS. The implementation of both the TrustOne
(bytes written summed across all relays every second). This
and TrustAll versions of TAPS was done in 1126 lines of C
again indicates a reduction in the ability of Tor to properly
code in Tor itself.
balanceloadwhenallclientsinthenetworkuseTAPS.Again,
C. TrustAll Against TheMan αw = 1.0 performs the closest to vanilla Tor and does not
Recall that in the TrustAll variation of TAPS, all users result in a significant loss in performance, despite removing
in the network are configured to select paths based on a the least secure relays during path selection.
common trust policy. We explore the performance of TAPS Finally, Figure 5f shows the cumulative fraction of band-
under different configurations of the parameters described in widthweightfromrelaysthatfalloutsideofthesafethresholds
Section V. We use the same values of the parameters defining but that were still considered during path selection. These
safeandacceptablerelaysinpositionp∈{g,e}(i.e.,αsu,αsc, relays represent those that were within the acceptable thresh-
p p
αau, and αac) that were used for the security experiments in olds but not within the safe thresholds. Recall that TrustAll
p p
Section VI-C.Wethenadjusttherequiredbandwidthfraction selects relays in this acceptable zone one at a time, from most
αw = αw = αw in order to adjust the amount of load to least secure, until the desired consensus weight fraction
g e
balancing that happens due to client path selection. Higher αw is reached. As expected, the more performance that is
values of αw relax security by requiring clients to consider demanded (i.e., as αw increases), the more relays outside
more nodes in an attempt to exceed the bandwidth fraction of the safe thresholds must be used to reach the desired
and allow the algorithm to better distribute load among relays performance. Our results indicate that there are settings of
that have the capacity to support it (relays that are not safe or αw that result in performance nearly as good as Tor’s default
acceptable are never chosen in any case). Lower values of αw performance-optimized algorithm, while also taking security
reducethenumberofrelaysthataclientmustconsider,which into consideration.
means they effectively prefer more secure relays and perform
D. TrustAll Against Countries
less load balancing. We experiment with different values of
The experimental results discussed above were obtained
αw to explore these effects.
using The Man policy. For completeness, we also experi-
The results of our experiments are shown in Figure 5.
mented with the same parameters using the Countries policy.
Figure 5a shows the distribution of the time to receive the
We confirmed that the same trends are present against the
firstbyteofeachdownloadaggregatedacrossallclientsinour
Countries policy as were discussed above, and the results
network. As can be seen, there is a significant and consistent
increased our confidence in the conclusions drawn about the
improvement in latency to the first byte as αw increases. As
performanceofTAPS.(Thefullsetofgraphsareexcludedfor
αw increases, client load is better distributed because more
space reasons.)
clients will end up choosing high capacity nodes even if they
are not the most secure choice. Similar results are shown for E. Trading Security for Performance
time to complete the downloads, for Web clients in Figure 5b Figure 6 demonstrates how TAPS directly trades perfor-
andbulkclientsinFigure5c.Also,performancedifferencesare mance for security according to the parameter αw. Figure 6a
consistentacrosstheαw settingsforbothWebandbulkclients, shows the security-performance tradeoffs of TrustAll against
which we would expect because our path-selection algorithm TheManpolicyforvariousvaluesofαw.Showninthefigure
is the same in both cases. are two performance metrics: “Client Download Time” rep-
Ourexperimentsresultedindecreasingperformanceasαw resents the median across all clients of the median download
decreases. We expect this to be the case since any deviation timeforeachclient;“RelayThroughput”representsthemedian
from Tor’s default bandwidth-weighted algorithm will result application throughput in terms of bytes written per second,
in suboptimal load balancing. However, our results indicate accrossallrelaysoverallsecondsduringtheexperiments.Both
thataclearperformance-securitytrade-offispossibleinTAPS of these metrics are normalized with respect to vanilla Tor,
and that the algorithm can be tuned to a desired level of meaningthatvaluescloserto1.0indicatesthatTAPSachieves
performance while still removing the least secure relays from performancemoresimilartothatachievedbyvanillaTor.Also
consideration. shown in Figure 6a are the “Probability of Compromise” and
A side effect of the decrease in performance is fewer the “Stream Compromise Rate” as metrics of security. The
completed downloads by each client over the course of the metrics are again normalized with respect to vanilla Tor, so
experimentduetoourbehaviormodels,asevidentinfigure5d. that values closer to 0 are less similar to vanilla Tor and
Related to download times, there is a significant reduction in indicatehighersecurity.Asisclearinthefigure,asthetradeoff
thenumberofdownloadsforclients(andalongneckforabout parameter αw increases, both of the performance metrics
20 percent of Web clients). This is likely due to the fact that improve while both of the security metrics get worse. This
111.0
0.8
0.6
0.4
0.2
0.0
0 2 4 6 8 10 12
DownloadTime(s)
noitcarFevitalumuC
1.0
0.8
0.6
vanilla
αw=1.0 0.4
αw=0.7
αw=0.4 0.2
αw=0.1
0.0
0 5 10 15 20 25 30
DownloadTime(s)
(a)Timetofirstbyteofdownloadperclient
noitcarFevitalumuC
1.0
0.8
0.6
vanilla
αw=1.0 0.4
αw=0.7
αw=0.4 0.2
αw=0.1
0.0
0 50 100 150 200 250 300
DownloadTime(s)
(b)Timetolastbyteof320KiBdownloadperclient
noitcarFevitalumuC
vanilla
αw=1.0
αw=0.7
αw=0.4
αw=0.1
(c)Timetolastbyteof5MiBdownloadperclient
1.0
0.8
0.6
0.4
0.2
0.0
0 20 40 60 80 100
NumberofDownloads
noitcarFevitalumuC
1.0
0.8
0.6
vanilla
αw=1.0 0.4
αw=0.7
αw=0.4 0.2
αw=0.1
0.0
40 60 80 100 120
Throughput(MiB/s)
(d)Numberofdownloadsperclient
noitcarFevitalumuC
1.0
0.8
0.6
vanilla
αw=1.0 0.4
αw=0.7
αw=0.4 0.2
αw=0.1
0.0
0.0 0.2 0.4 0.6 0.8 1.0
UnsafeConsensusWeightFraction
(e)Aggregaterelaythroughputpersecond
noitcarFevitalumuC
αw=1.0
αw=0.7
αw=0.4
αw=0.1
(f)Unsafeconsensusweightsconsidered
Fig. 5: Performance of the TrustAll variation of TAPS against TheMan policy, varying required bandwidth fraction αw
is expected: as more relays are used to reach the performance metric αw=0.005 αw=1.0 vanilla
requirements of αw, it is more likely that insecure relays or TimetoFirstByte 0.870,1.548 0.783,1.694 0.690,1.419
TimetoLastByte320KiB 3.806,3.785 2.685,3.255 2.172,2.597
relays that exist on insecure paths will be selected and used in TimetoLastByte5MiB 39.825,29.342 35.203,14.395 35.777,20.658
a circuit. TorThroughput(MiB/s) 98.635,4.893 99.699,5.387 100.660,4.250
A similar analysis applies to the Countries policy, the
resultsforwhichareshowninFigure6b.Thesecuritymetrics TABLE II: Statistical summary (median, standard deviation) of
include the median fraction of “Unnecessarily Compromised performance for TrustOne
Streams”, where the source and destination of a stream do
not exist in the same country and yet the stream was still
compromised,andthemediannumberofcountrieswithwhich All other clients use the vanilla-Tor path-selection algorithm.
the client unnecessarily had a compromised circuit. The per- Thus the TrustOne clients choose secure guards, and they
formance metrics are as above. The same basic trends hold either choose exits identically to vanilla-Tor users in order
for the Countries policy: as αw increases and the number of to blend in (αw = 1.0) or don’t attempt to hide their use of
e
potentially unsafe relays considered for a path increases, so TrustOneandinsteadchooseexitsverysecurely(αw =0.005).
e
does the number of avoidable stream compromises and the Table II provides a statistical summary of the performance
number of countries to which a given client is unnecessarily of the vanilla and trust clients. Note that the results for
compromised. In all cases, however, security improves with αw ∈ {0.005,1.0} come from two separate TrustOne experi-
respect to vanilla Tor while performance decreases depending ments, the vanilla-Tor results come from another experiment
on the tunable setting of the tradeoff parameter αw. with no TrustOne clients, and the reported download times
for αw ∈ {0.005,1.0} are only for TrustOne clients. Across
F. TrustOne Against TheMan all three client performance metrics (time to first byte, and
In order for TrustAll to be effective, most clients must use time to last byte of Web and bulk downloads), we see only
it. If only a minority of clients use trust, then they should use a small drop in client performance for both settings tested.
TrustOneinordertoblendinwithvanilla-Torusers.Theycan Althoughoursamplesizeissmall,bothsettingsofαw resulted
e
also take advantage of their minority status by using higher- in similar performance for the trusted user set. This indicates
security parameters without affecting Tor’s load balancing that performance for those clients was due to the capacity
much. and congestion of their guard nodes (which they chose using
We demonstrate the performance of TrustOne by configur- a secure value of αw). Also shown in Table II are results
g
ing 68 of our Web clients and 5 of our bulk clients to run the showing that relay throughput in the TrustOne experiments
TrustOne algorithm with αw =0.005 and αw ∈{0.005,1.0}; was not significantly lower than in the vanilla Tor experiment
g e
theotherparametersettingsareasintheTrustAllexperiments. (relay throughput is over all relays and thus in the TrustOne
121.0
0.8
0.6
0.4
0.2
0.0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1.0
TradeoffParameterαw
cirteMdezilamroN
ProbabilityofCompromise ClientDownloadTime
StreamCompromiseRate RelayThroughput
1.0
0.8
0.6
0.4
0.2
0.0
(a)TheManPolicy
1.0
0.8
0.6
0.4
0.2
0.0
0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1.0
TradeoffParameterαw
cirteMdezilamroN
adversary.
These client properties are combined with various adver-
saries, which may or may not match the client’s beliefs and
policies:
Type0:TheadversaryisTheManadversarydescribedabove.
Type1:Theprobabilityofcompromiseisincreased,relativeto
TheMan, by a factor of 1.25 for AS/IXP organizations, lone
ASes, and relay families. This reflects the possibility that the
client uniformly underestimates the adversary’s capabilities.
Type 2a: This is the same as The Man except ASes that are
not part of any organization are not compromised.
Type 2b: This is the same as The Man except ASes that are
notpartofanyorganizationarecompromisedwithprobability
0.05.
Type 3: For each run, half of the AS organizations and half of
Unnecess.Comp.Streams ClientDownloadTime
CountrieswithUnnecess.Comp. RelayThroughput the IXP organizations are compromised with probability 0.15,
1.0 and the others are compromised with probability 0.05. For
efficiency,anASthatisnotpartofanASorganizationisonly
0.8 assigned a compromised status when it is first encountered
on a virtual link during analysis. Upon its initial observation,
0.6
such an AS is assigned one of 0.15 and 0.05 as a compromise
probability using a fair coin, and then it is compromised with
0.4
that probability.
Type 4: The adversary is the same as TheMan except longer
0.2
uptimeincreasesthecompromiseprobabilityforarelayfamily
(e.g., because of the increased chance of unpatched software).
0.0
In particular, the compromise probability for a relay family
with uptime t is 0.1−(0.1−0.02)/(t +1).
(b)CountriesPolicy f f
Type5:Theadversarycompromiseseachrelaywithprobability
Fig. 6: Trading performance and security in TrustAll with αw
0.1 and each virtual link with probability 0.3439 =1−0.94.
(The latter value is chosen to approximate the probability of
experiments includes traffic from both trust-aware and vanilla compromising ASes/IXPs independently. On the virtual links
clients). This is attributable to a relatively small change in that we consider, the median number of ASes/IXPs is four,
the load balancing across the network since only the trust althoughthesearenotnecessarilyfromdistinctorganizations.)
users deviate from the optimized load balancing algorithm. Type6:TheadversaryisthesameasTheManforASes/IXPs.
Our results indicate that little performance is lost from using For relays and relay families, the adversary compromises
the TrustOne algorithm when a relatively small set of users nontrivial families with probability 0.1 and individual relays
are doing so. that are not part of a nontrivial family is 0.05.
Type7:TheadversaryisthesameasTheManforASes/IXPs.
VIII. TRUSTERRORS For relays and relay families, the adversary compromises
Because the client’s paths depend on her beliefs and may families with probability p
max
−(p
max
−p min)2−(fsize−1),
not be accurate, it is important to investigate the effects of where p and p are the minimum (0.02) and maximum
min max
errors in the client’s beliefs on her security. Here, we do (0.1) probabilities of family compromise for The Man and
that experimentally by considering a variety of mismatches f is the number of relays in the family.
size
betweenclienttrustbeliefsandtheactualadversary.Welookat Table III shows the median time to first compromise
three client behaviors against nine different actual adversaries (TTFC) in days and the probability that some circuit is com-
for a single location (AS 6128) over one week. We also look promised for the three different client types and nine different
atourTypicalclientin401differentlocations(theclientASes adversary distributions noted above. In each case, we take the
observed by Juen [23] and in our AS-level map for December client to be in AS 6128. The data are obtained from 10,000
2013)withtrustbeliefscorrespondingtoTheMan,butwhere simulationsofclientbehavior from12/1/13to12/7/13.Values
the actual adversary distribution is one of a selected set of of “>7” for the TTFC indicate that the value is at least seven
other behaviors. days, the length of these experiments.
The client might also have beliefs about the structure of TableIVshowsvariouscompromisestatisticsforaTypical
the network. Errors in those may have significant impacts on client who chooses paths based on beliefs that match The
the client’s security if, for example, the client believes that an Man against three different adversary distributions. For each
untrustworthy AS organization does not contain an AS that it of the 401 client locations, we ran 10,000 simulations and
actuallydoes.Wefocusourexperimentshereonerrorsintrust took the median TTFC, compromise probability, and fraction
beliefs, however. of compromised paths for that location. The table shows the
We consider three different client behaviors: The Typical minimum,median,andmaximumoftheseper-locationmedian
and IRC clients with TheMan policy are as described above. values. Values of “> 1” for the TTFC indicate that the value
We also consider a client with Typical network behavior who is at least one day, the length of these experiments.
chooses paths based on trust beliefs that match the Countries
13Client:Typical,againstTheMan “based on trust in the node administrator”. However, they do
Adv.→ 0 1 2a 2b 3 4 5 6 7
TTFC >7 >7 >7 >7 >7 >7 .01 >7 >7 not develop this idea. A mathematical notion of trust in Tor
Prob. .4 .49 .4 .4 .41 .47 .68 .47 .47 wasintroducedbyJohnsonandSyverson[20].Theyformalize
Client:IRC,againstTheMan trust as the probability of compromise of a relay, and they
Adv.→ 0 1 2a 2b 3 4 5 6 7 provide an analysis of end-to-end correlation attacks when
TTFC >7 4.17 >7 >7 >7 >7 .07 >7 >7
Prob. .41 .5 .41 .41 .41 .48 .71 .49 .48 there are just two different levels of trust. This model was
Client:Typical,againstCountries later used by Johnson et al. [21] to produce a “downhill” Tor
Adv.→ 0 1 2a 2b 3 4 5 6 7 path-selectionalgorithmthatcanhandlearbitrarytrustlevelsat
TTFC .38 .01 .38 .38 .38 .26 .0 .25 .38 therelaysandisdesignedtopreventtraffic-correlationattacks.
Prob. .58 .66 .56 .57 .57 .6 .82 .61 .58
Jaggard et al. [16] greatly expand this probabilistic notion of
TABLE III: Median time to first compromise (in days) and prob- trust by describing how to identify compromise factors that
ability of compromise for three different client behaviors and nine can apply to the links as well as the nodes, such as AS
different actual adversary distributions. Data are from 10,000 simu- organizations, legal jurisdictions, and router software. They
lations of a client in AS 6128 running for 7 days.
focusonexpressingsuchrichtrustmodels,whileinthispaper
we focus on using these models in a path-selection algorithm
Adv. Med.TTFC Med.Prob. Med.Frac.
min./med./max. min./med./max. min./med./max. that improves security.
2a .01 >1 >1 .21 .45 .66 .0 .0 .09 Another approach to trust for anonymous communication
4 .01 >1 >1 .27 .49 .69 .0 .0 .11
is to explicitly leverage social network relations. Danezis et
5 .0 .01 .01 .59 .66 .79 .1 .13 .16
al.[11]describethisforinteractivebutlow-volumeanonymous
TABLE IV: Statistics (minimum, median, and maximum) on the communication. Concentrating on low-volume applications
median times to first compromise (in days), compromise probability, allowed them to make use of padding, which is generally too
andfractionofpathscompromisedover10,000trialsforeachof401
expensive and too ineffective for some of the more popular
client locations running for one day each against a selected set of
applications that use Tor. Mittal et al. [26] describe a social-
adversaries. The clients choose paths against The Man; the actual
networkonion-routingarchitecturedesignedforWebbrowsing
adversary is shown in the first column.
and other interactive communications that adds resistance to
an active adversary. This design uses potentially much longer
Comparing Table III with Fig. 2, we see that when the paths than Tor’s three hops to achieve intended security, and
client in AS 6128 chooses paths against TheMan, the use of performance may suffer significantly as a result of this and
TAPSincreaseshersecurity,comparedwithvanillaTor,against other features of the design.
adversaries that are related to The Man even though the The threat of AS adversaries to Tor was first recognized
client is wrong about the exact nature of the adversary. More by Feamster and Dingledine [14]. Their analysis shows that
precisely, this is true for all of the adversary types considered entry and exit paths through the network are likely to be
in this section other than Type 5, which is the adversary that simultaneously observed by a single AS 10% to 30% of the
independently compromises each relay and virtual link and is time, depending on the locations of the client and destination.
the only type that does not compromise the network based on They suggest that clients choose entry and exit nodes to avoid
organizations and families. When the adversary is actually of traversing the same AS upon entry and exit. Edman and
Type 5, Tables III and IV show that it is able to do quite well Syverson [12] update this work and show that, despite the
against the client over many locations and client behaviors. growthofthenetworkfromabout30toabout1300relays,the
risk of denanonymization by a single AS is not reduced. They
IX. OBTAININGANDPROPAGATINGTRUST
also show how to efficiently implement the AS-aware path
We consider as an example how much data must be stored
selection suggested by Feamster and Dingledine by providing
and communicated to implement The Man policy. First, the
clients with routing data that enables them to infer AS-level
client must be able to determine the cluster of itself and
routing paths. Murdoch and Zielin´ski [28] introduce IXPs as
its destinations. With 46368 ASes in the network map used
a potential adversary. They show that an IXP can correlate
for TAPS analysis, 200 client clusters, and 200 destination
traffic even at low rates of sampling. Link adversaries at
clusters, 182 KiB suffice for each client to determine the
both ASes and IXPs were extended by Johnson et al. [22]
needed clusters. Second, to choose guards and exits, the client
to consider adversaries controlling multiple ASes or IXPs,
needs the ability to determine the AS and IXP organizations
such as companies that own many IXPs. Akhoondi et al. [6]
on any virtual link either between their cluster representative
present an alternate method for clients to efficiently infer the
and a guard or between a destination-cluster representative
ASes between hosts for purposes of choosing Tor paths that
and an exit. There are only 359 IXPs, and so an AS or IXP
avoid allowing the same AS to observe entry and exit traffic.
organizations can be specified in two bytes. For data gathered
Juen [23] presents another method for this purpose, this time
December 2013, all guards are within 603 ASes, all exits are
with the addition of inferring IXPs on those paths. All of the
within 962 ASes, and the average number of AS and IXP
preceding suggestions for AS-aware tor path selection neglect
organizations on a virtual link is 4.05. Thus a list of the
keydetails,suchashowcircuitsarereusedandhowtohandle
entities on all the relevant virtual links for a given client is
destinations with no path that avoids putting an AS on both
would be 1.68 MiB. Routing changes could be propagated
sides. In addition, Juen et al. [24] show that methods of
daily or weekly with much smaller updates once the full data
AS inference for detecting Tor paths vulnerable to AS-level
is obtained.
compromise suffer from significant false-positives and false-
X. RELATEDWORK negatives when compared to direct traceroute measurements.
An early proposals to use trust for Tor routing came from Nithyanand et al. [29] present Astoria, which is the first
Øverlier and Syverson [30], who suggest choosing guards reasonably-complete network-aware Tor path-selection algo-
14rithm. As described in Section II, like other previous work on [12] M. Edman and P. Syverson, “AS-awareness in Tor path selection,” in
network-awarepathselection,Astoriaisonlysecurewheneach ACMConferenceonComputerandCommunicationsSecurity,2009.
[13] N. S. Evans, R. Dingledine, and C. Grothoff, “A practical congestion
connectionisanalyzedindependently.DeNASA[8],byBarton
attackonTorusinglongpaths,”inUSENIXSecuritySymposium,2009.
and Wright, is another recent and fully-specified network- [14] N. Feamster and R. Dingledine, “Location diversity in anonymity
aware Tor path-selection algorithm. DeNASA only considers networks,”inWorkshoponPrivacyintheElectronicSociety,2004.
as adversaries individual ASes, and chooses to just protect [15] J.Geddes,R.Jansen,andN.Hopper,“Howlowcanyougo:Balancing
performancewithanonymityinTor,”inPrivacyEnhancingTechnolo-
againsttheeightASesthataremostlikelytobeinapositionto
giesSymposium,2013.
deanonymizeaconnection.DeNASAalsodoesn’tconsiderthe
[16] A.D.Jaggard,A.Johnson,S.Cortes,P.Syverson,andJ.Feigenbaum,
specific destination when constructing a circuit, which allows “20,000 in league under the sea: Anonymous communication, trust,
it to use pre-built circuits for speed but makes it unable to MLATs, and undersea cables,” Proceedings on Privacy Enhancing
protect connections to destinations with paths dissimilar from Technologies,2015.
[17] R.Jansen,J.Geddes,C.Wacek,M.Sherr,andP.Syverson,“Neverbeen
thepre-selectedsetusedforexitselection.However,DeNASA
KIST: Tor’s congestion management blossoms with kernel-informed
isstillvulnerabletoleakageaboutaclient’sASacrossrepeated sockettransport,”inUSENIXSecuritySymposium,2014.
connections (assuming its guard and exit-selection algorithms [18] R. Jansen and N. Hopper, “Shadow: Running Tor in a box for accu-
are jointly used). rate and efficient experimentation,” in Network & Distributed System
Sun et al. [34] show that traffic correlation attacks on Tor
SecuritySymposium,2012.
[19] A. Johnson, R. Jansen, A. D. Jaggard, J. Feigenbaum, and
areeffectiveevenwhentheattackerobservespathsindifferent
P. Syverson, “Avoiding the man on the wire: Improving tor’s
directions on the entry and exit sides. They also demonstrate security with trust-aware path selection.” [Online]. Available: http:
the application of BGP hijacking and interception attacks to //arxiv.org/abs/1511.05453
redirect Tor traffic to malicious ASes in order to deanonymize [20] A.JohnsonandP.Syverson,“Moreanonymousonionroutingthrough
trust,”inIEEEComputerSecurityFoundationsSymposium,2009.
users. Tan et al. [35] extend this analysis and show that 90%
[21] A. Johnson, P. Syverson, R. Dingledine, and N. Mathewson, “Trust-
of Tor’s bandwidth is vulnerable to BGP hijacking, and they based anonymous communication: Adversary models and routing al-
proposeasadefenseasetofmonitorstodetectroutingattacks gorithms,” in ACM Conference on Computer and Communications
and notify Tor clients to avoid the affected relays. Security,2011.
[22] A. Johnson, C. Wacek, R. Jansen, M. Sherr, and P. Syverson, “Users
XI. CONCLUSION getrouted:TrafficcorrelationonTorbyrealisticadversaries,”inACM
In this paper, we show how previous network-aware Tor ConferenceonComputerandCommunicationsSecurity,2013.
path-selection algorithms are vulnerable to attacks across [23] J. Juen, “Protecting anonymity in the presence of autonomous system
andinternetexchangeleveladversaries,”Master’sthesis,Universityof
multiple Tor connections. We present TAPS, a path-selection
IllinoisatUrbana-Champaign,2012.
algorithmforTorthatisnotvulnerabletosuchattacksandthat [24] J. Juen, A. Johnson, A. Das, N. Borisov, and M. Caesar, “Defending
enablesclientstoavoidtraffic-correlationattacksbyusingtrust torfromnetworkadversaries:Acasestudyofnetworkpathprediction,”
that they have in network elements. We present two global- ProceedingsonPrivacyEnhancingTechnologies,2015.
[25] P. Mittal, A. Khurshid, J. Juen, M. Caesar, and N. Borisov,
adversary models, analyze the security and performance of
“Stealthy traffic analysis of low-latency anonymous communication
TAPS against these adversaries, and consider both trust errors usingthroughputfingerprinting,”inACMConferenceonComputerand
and trust propagation. CommunicationsSecurity,2011.
Acknowledgments. We thank Ryan Wails for contributing to [26] P.Mittal,M.Wright,andN.Borisov,“Pisces:Anonymouscommunica-
the results in Section II. The work at NRL was supported by
tionusingsocialnetworks,”inNetwork&DistributedSystemSecurity
Symposium,2013.
ONR. Joan Feigenbaum’s research was supported in part by
[27] S. J. Murdoch and G. Danezis, “Low-cost traffic analysis of Tor,” in
NSF grants CNS-1407454 and CNS-1409599, DHS contract IEEESymposiumonSecurity&Privacy,2005.
FA8750-16-2-0034,andWilliamandFloraHewlettFoundation [28] S. J. Murdoch and P. Zielin´ski, “Sampled traffic analysis by Internet-
grant 2016-3834. exchange-level adversaries,” in Privacy Enhancing Technologies Sym-
posium,2007.
REFERENCES [29] R. Nithyanand, O. Starov, P. Gill, A. Zair, and M. Schapira, “Mea-
[1] “ShadowGitRepository,”https://github.com/shadow/shadow. suringandmitigatingAS-leveladversariesagainstTor,”inNetwork&
[2] “ShadowHomepage,”http://shadow.github.io/. DistributedSystemSecuritySymposium,2016.
[3] “Shadow Tor plug-in Git Repository,” https://github.com/shadow/ [30] L. Øverlier and P. Syverson, “Locating hidden servers,” in IEEE
shadow-plugin-tor. SymposiumonSecurity&Privacy,2006.
[4] “TorMetricsPortal,”http://metrics.torproject.org/. [31] H.-S.ParkandC.-H.Jun,“AsimpleandfastalgorithmforK-medoids
[5] “TorPerf,”https://gitweb.torproject.org/torperf.git/. clustering,”ExpertSystemswithApplications,vol.36,no.2,2009.
[6] M.Akhoondi,C.Yu,andH.V.Madhyastha,“LASTor:Alow-latency [32] J.QiuandL.Gao,“ASpathinferencebyexploitingknownASpaths,”
AS-awareTorclient,”inIEEESymposiumonSecurity&Privacy,2012. inIEEEGLOBECOM,2005.
[7] B.Augustin,B.Krishnamurthy,andW.Willinger,“IXPs:Mapped?”in [33] “UniversityofOregonrouteviewsproject,”http://www.routeviews.org/.
InternetMeasurementConference,2009. [34] Y.Sun,A.Edmundson,L.Vanbever,O.Li,J.Rexford,M.Chiang,and
[8] A. Barton and M. Wright, “DeNASA: Destination-naive as-awareness
P. Mittal, “RAPTOR: Routing attacks on privacy in Tor,” in USENIX
in anonymous communications,” Proceedings on Privacy Enhancing
SecuritySymposium,2015.
Technologies,2016.
[35] H.Tan,M.Sherr,andW.Zhou,“Data-planeDefensesagainstRouting
[9] X. Cai, J. Heidemann, B. Krishnamurthy, and W. Willinger, “An
Attacks on Tor,” Proceedings on Privacy Enhancing Technologies,
organization-levelviewoftheInternetanditsimplications(extended),”
2016.
USC/ISI,Tech.Rep.ISI-TR-2009-679,2012.
[36] “Tor directory protocol,” https://gitweb.torproject.org/torspec.git/blob/
[10] “The CAIDA UCSD Internet Topology Data Kit - December 2013,”
HEAD:/dir-spec.txt.
http://www.caida.org/data/internet-topology-data-kit.
[37] T.WangandI.Goldberg,“ImprovedwebsitefingerprintingonTor,”in
[11] G.Danezis,C.Diaz,C.Troncoso,andB.Laurie,“Drac:Anarchitecture
WorkshoponPrivacyintheElectronicSociety,2013.
for anonymous low-volume communications,” in Privacy Enhancing
TechnologiesSymposium,2010.
15