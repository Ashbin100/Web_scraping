Automated Synthesis of Semantic Malware
Signatures using Maximum Satisfiability
Yu Feng Osbert Bastani Ruben Martins
University of Texas at Austin Stanford University University of Texas at Austin
yufeng@cs.utexas.edu obastani@cs.stanford.edu rmartins@cs.utexas.edu
Isil Dillig Saswat Anand
University of Texas at Austin Google, Inc.
isil@cs.utexas.edu saswatanand@google.com
Abstract—This paper proposes a technique for automatically number of Android malware, with 4,900 malware samples
learning semantic malware signatures for Android from very being introduced every day [1]. Correspondingly, this upsurge
few samples of a malware family. The key idea underlying our in Android malware has also led to a flurry of research for
techniqueistolookforamaximallysuspiciouscommonsubgraph automaticallydetectingmaliciousapplications[2,3,4,5,6,7].
(MSCS)thatissharedbetweenallknowninstancesofamalware
family. An MSCS describes the shared functionality between Generallyspeaking,approachesforautomatedmalwarede-
multiple Android applications in terms of inter-component call tection can be classified as either signature-based or learning-
relationsandtheirsemanticmetadata(e.g.,data-flowproperties). based.Signature-basedtechniqueslookforspecificpatternsin
Our approach identifies such maximally suspicious common theapplicationtodeterminewhethertheappismalicious,and,
subgraphs by reducing the problem to maximum satisfiability.
if so, which malware family the app belongs to [8, 2, 9, 10].
Once a semantic signature is learned, our approach uses a
These patterns can either be syntactic (e.g., sequence of in-
combination of static analysis and a new approximate signature
structions) or semantic (e.g., control- or data-flow properties).
matchingalgorithmtodeterminewhetheranAndroidapplication
Signature-based approaches allow security analysts to quickly
matches the semantic signature characterizing a given malware
family. identify the malicious component of an application; hence,
they are widely-used by several commercial anti-virus (AV)
WehaveimplementedourapproachinatoolcalledASTROID
companies.However,onekeyshortcomingofthesetechniques
and show that it has a number of advantages over state-of-the-
isthattheyrequireatrainedsecurityanalysttomanuallywrite
artmalwaredetectiontechniques.First,wecomparethesemantic
suitable signatures that can be used to detect each malware
malware signatures automatically synthesized by ASTROID with
family. Unfortunately, this manual effort is typically time-
manually-writtensignaturesusedinpreviousworkandshowthat
thesignatureslearnedbyASTROIDperformbetterintermsofac- consuming and error-prone.
curacyaswellasprecision.Second,wecompareASTROIDagainst
Learning-based techniques [3, 6, 11, 12, 4, 13, 14, 5]
two state-of-the-art malware detection tools and demonstrate its
aim to address this limitation by automatically learning a
advantages in terms of interpretability and accuracy. Finally,
malware classifier from data. These techniques extract various
wedemonstratethat ASTROID’sapproximatesignaturematching
algorithm is resistant to behavioral obfuscation and that it can features from the application and use standard machine learn-
be used to detect zero-day malware. In particular, we were able ing algorithms to learn a classifier that labels apps as either
tofind22instancesofzero-daymalwareinGooglePlaythatare benign or malicious. Compared to signature-based techniques,
not reported as malware by existing tools. current learning-based approaches suffer from a number of
shortcomings:
I. INTRODUCTION
• They produce results that are difficult to interpret (for
Due to the enormous popularity of Android as a mobile example, they typically cannot be used to determine the
platform, the number of applications (“apps”) available for malware family), which makes it difficult for a security
Androidhasskyrocketed,with1.6millionappsbeingcurrently analyst to discharge false positives.
available for download. Unfortunately, the soaring number • They typically require a large number of samples from
of Android users has also led to a rapid increase in the each malware family, which is problematic for families
that have recently emerged or that are rare (58% of
malware families in [3] have fewer than 5 samples).
Permission to freely reproduce all or part of this paper for noncommercial
purposes is granted provided that copies bear this notice and the full citation
This paper aims to overcome these disadvantages of ex-
on the first page. Reproduction for commercial purposes is strictly prohibited
without the prior written consent of the Internet Society, the first-named author isting malware detectors by proposing a new technique to
(for reproduction of an entire paper only), and the author’s employer if the automatically infer malware signatures. By identifying mal-
paper was prepared within the scope of employment. ware based on inferred signatures, our approach retains all
NDSS ’17, 26 February - 1 March 2017, San Diego, CA, USA
the advantages of signature-based approaches: it can pinpoint
Copyright 2017 Internet Society, ISBN 1-891562-46-0
http://dx.doi.org/10.14722/ndss.2017.23379 the location of the malicious components as well as thecorresponding malware family, and requires very few samples behavioral obfuscations and is also useful for detecting zero-
(<5 in our evaluation). Furthermore, our approach can learn day malware. Specifically, in a corpus of apps collected from
semantic signatures that are resilient to low-level obfuscation Google Play, ASTROID identified 103 apps from more than
mechanisms and produces very few false alarms. Finally, 10 malware families for which we did not previously have
because our signature matching algorithm uses approximate signatures. Furthermore, among these 103 apps, 22 of them
(rather than exact) matching, our algorithm is also resilient to were previously unknown and are not reported as malware by
high-level obfuscation mechanisms that modify the program’s existing tools.
control flow and data-flow properties.
This paper makes the following key contributions:
The first key insight underlying our approach is to au-
tomatically identify a semantic pattern that (a) occurs in all • We propose a novel technique for inferring malware
instances of a given malware family, and (b) is maximally signatures from few samples of a malware family.
suspicious(i.e.,maximizesthenumberof“suspicious”features • We formulate signature inference as the problem of find-
thataretypicallynot foundinbenignapps).Here,criterion(a) ingamaximallysuspiciouscommonsubgraph(MSCS)of
servestominimizethenumberoffalsenegatives:Ifthepattern a set of Android applications and show how to reduce
does not occur in all instances of the malware family, then MSCS detection to maximum satisfiability.
our signatures would not match all malicious apps, thereby • We propose a novel approximate signature matching
resulting in false negatives. In contrast, criterion (b) serves algorithm that leverages automated signature synthesis.
to minimize false positives: By requiring that the identified • WeimplementourapproachinatoolcalledASTROIDand
semantic pattern is maximally suspicious, we ensure that our evaluate it against manually written malware signatures,
signatures are unlikely to flag benign apps as malicious. other state-of-the-art malware detectors, and behavioral
obfuscation strategies.
The second key insight underlying our technique is to
automatically learn these semantic patterns by finding a maxi-
mallysuspiciouscommonsubgraph(MSCS)ofthemalwarein-
stances. An MSCS describes the shared functionality between II. BACKGROUND
multiple Android applications in terms of inter-component
call relations and their semantic metadata (e.g., data-flow In this section, we provide some background that is nec-
properties,intentfilters,APIcallsetc.).Ourapproachautomat- essary for understanding the rest of this paper.
ically finds an MSCS by reducing the problem to maximum
satisfiability(MaxSAT).Intuitively,theMaxSATproblemaims
tomaximizetheamountofsuspiciousmetadatawhileensuring A. Android Basics
that this functionality is shared between all instances of the
An Android application consists of four kinds of com-
malware family. The solution to the MaxSAT problem can
ponents, namely Activity, Service, BroadcastReceiver, and
then be directly translated into a semantic signature that
ContentProvider. Every screen of an app corresponds to an
characterizes a specific malware family.
Activity. Services run in the background without a user in-
Our third and final insight is to utilize the proposed sig- terface, ContentProviders store data, and BroadcastReceivers
nature inference algorithm for approximate matching. Specif- react asynchronously to messages from other applications.
ically, given a database of malware signatures and a new
applicationA,wemustdecidewhetherAmatchesanyofthese In Android, different components communicate with each
signatures. Rather than performing exact signature matching other through Intents, which are effectively messages that
as done in previous work [2], we employ a novel approximate describe operations to be performed. Components can receive
signature matching algorithm. The key idea is to generate a intents from other components or from the Android system;
new signature S assuming that A is an instance of family thus intents form the basis of inter-component communication
F. We then decide if A is actually an instance of F based on (ICC) in Android. Intent objects can have several attributes,
thesimilarityscorebetweenS andF’sexistingsignature.The three of which we discuss below:
mainadvantageofthisapproachisthatitmakesourtechnique
• The optional target attribute explicitly specifies the spe-
evenmoreresilienttoobfuscations,includingthosethatchange
cific component invoked by this Intent.
program behavior.
• The action attribute specifies the type of action that the
We have implemented the proposed technique in a tool receiver of the Intent should perform.
called ASTROID1 and evaluate it in a number of ways. • The data type attribute specifies the type of data that the
Our first experiment shows that the signatures automatically receiver of the intent is supposed to operate on.
inferred by ASTROID are competitive with (in fact, better
than)manually-writtensignaturesusedforevaluatingprevious AnIntentwhosetargetattributeisspecifiediscalledanexplicit
work [2]. We also compare ASTROID with two state-of- Intent. In contrast, an implicit Intent does not have its target
the-art Android malware detectors, namely DREBIN [3] and attribute specified, so the Android system decides the targets
MASSVET [15], and show that ASTROID compares favorably ofanimplicitintentI atruntimebycomparingI’sactionand
with these tools in terms of accuracy, false positives, and data attributes against the intent filters of other components.
interpretability.Third,wedemonstratethatASTROID’sapprox- The intent filter of a component C specifies the action that C
imate signature matching algorithm is both resilient to various is able to perform and the data it can operate on. Such intent
filtersaredeclaredintheapp’smanifest,whichisanXMLfile
1ASTROIDstandsforAutomaticSignaTurefindeRforandrOID containing information about the app.
2ISniper GameAct HandPics AdActivity
MyReceiver
zjReceiver
moreGame Highscore Profile animal fengjing feizhuliu dongman
BoolService
zjService
viewpics
UserAct
GoldDream Sample 1 (G1) GoldDream Sample 2 (G2)
activity0
receiver0
activity1 activity2 activity0
service0
activity3
Signature candidate (S1) Signature candidate (S2) Signature candidate (S3)
Fig. 1: Motivating example to illustrate our approach
B. Inter-component Call Graphs (v,v,(cid:5)Act)∈Y indicates that component Y can perform
action Act.
Ourtechniqueusestheinter-componentcallgraph(ICCG)
• Intent filters, denoted as (cid:63)o, represent the data type
representation introduced in previous work [2]. The ICCG for
that a given component can operate on. In particular,
an Android app summarizes inter-component communication
(v,v,(cid:63)o) ∈ Y indicates that component v can operate
within the app as well as any relevant metadata (e.g., dataflow
on data of type o (passed using intents).
or API calls). More formally, an ICCG for an application A
is a graph (V,X,Y) where: For a given set of apps, the universe of labels from which
metadata can be drawn is fixed. In the rest of the paper, we
• V is a set of vertices, where each v ∈V is a component
use D to indicate the domain of edge labels d in Y.
of A. The type of a vertex v, written T(v), is the type of
the component that v represents. Hence, we have: Example 1: Consider the ICCG labeled as Gold Dream
Sample 1 in Figure 1. Here, solid edges represent X, and
T(v)∈T ={activity,service,receiver,provider}
dashed edges with metadata represent Y. Nodes drawn as
• X is a set of edges representing inter-component call re- rectangles are Activities, while ellipses indicate Broadcas-
lations.Specifically,(v,v(cid:48))∈X indicatesthatcomponent tReceivers and hexagons denote Services. Since there is a
v may invoke component v(cid:48) either through an explicit or solid edge from zjReceiver to zjService, broadcast
implicit intent. receiver zjReceiver may call zjService. Furthermore,
• Y is a set of labeled edges representing metadata. In sincethereisadashededgefromzjServicetoitselflabeled
particular, (v,v(cid:48),d)∈Y indicates that components v and as deviceId (cid:59) Internet, source deviceId flows to the Internet
v(cid:48) are related by metadata d. within component zjService.
Metadata edges Y in the ICCG indicate potentially suspi- III. OVERVIEW
ciousbehaviorsoftheapp.Weexplainthreekindsofmetadata
that will be used in this paper: Suppose that Alice, a security auditor at an anti-virus
company, recently learned about a new malware family called
• Data flow information, denoted as src (cid:59) sink. In GoldDream [16]. Alice would like to update their anti-virus
particular, (v,v(cid:48),s (cid:59) s(cid:48)) ∈ Y indicates that the source tool to detect GoldDream instances. Alice wants to use a
s originating from component v flows to the sink s(cid:48) in learning-based tool to save work, but then she must man-
component v(cid:48). Sources represent confidential information ually examine each app flagged by the tool due to high
(e.g.,IMEInumber),andsinksrepresentexternallyvisible false positive rates (which is time-consuming because the
channels (e.g., Internet, SMS). explanations produced by these tools typically do not pinpoint
• Suspicious API calls, written (cid:46)API. Specifically, an edge malicious functionalities). Furthermore, the malware family is
(v,v,(cid:46)f) ∈ Y indicates component v calls Android API new, so Alice only has two samples, and current learning-
method f (e.g., exec). based approaches require many training samples to achieve
• Suspicious actions, denoted as (cid:5)Act, represent actions high accuracy. Defeated, Alice manually writes signatures to
that can be performed by a component. In particular, detect GoldDream instances by reverse engineering common
3maliciousbehaviorsfromthebytecodeofthetwoGoldDream • Type preserving. For every v ∈V , F must map v to a
0 S
samples,andworkingtoensurethatnobenignappsareflagged vertex of the same type, i.e., T(v)=T(F (v))
S
by her signatures. • Edge preserving. For every v,v(cid:48) ∈V , F must map an
0 S
edge (v,v(cid:48))∈X to an edge in X :
ASTROID can greatly benefit Alice by automatically infer- 0 S
ring a signature characterizing the GoldDream family from as (v,v(cid:48))∈X ⇒(F (v),F (v(cid:48)))∈X .
0 S S S
few as two samples. In the top half of Figure 1, we show the
• Metadatapreserving.Foreveryv,v(cid:48) ∈V ,F mustmap
ICCGsofAlice’stwoGoldDreamsamples.Observethatthese 0 S
metadata (v,v(cid:48),d)∈Y to metadata in Y :
two samples have different component names and perform 0 S
very different functionalities—the ICCG on the left belongs (v,v(cid:48),d)∈Y ⇒(F (v),F (v(cid:48)),d)∈Y .
0 S S S
to a game, while the one on the right belongs to an app for
browsing pictures. Example 2: Consider the candidate signature S1 with
ICCG(V ,X ,Y )andtheGoldDreamsampleG1withICCG
0 0 0
To detect the malice shared by these two samples, AS-
(V ,X ,Y )fromFigure1.Now,letusconsiderthefollowing
1 1 1
TROIDsearchesforconnectedsubgraphsofthetwoICCGsthat candidate embeddings F(a) and F(b) from V to V :
are isomorphic to each other. In this case, there are multiple 1 1 0 1
suchsubgraphs;threeareshowninthebottomhalfofFigure1. (cid:40) F(a)(receiver0)=zjReceiver
Forinstance,theredgraphlabeledSignaturecandidate(S1)is 1
F(a)(service0)=zjService
isomorphic to the red subgraphs of G1 and G2. Similarly, the 1
yellow graph labeled Signature candidate (S2) is isomorphic (cid:40) F(b)(receiver0)=zjReceiver
to the yellow subgraphs of G1 and G2. The key insight in 1
F(b)(service0)=GameAct.
deciding between these candidates is to find the maximally 1
suspiciouscommonsubgraph(MSCS).Intuitively,anMSCSis
Here, candidate F(b) is not a valid embedding because the
thesignaturecandidatethatmaximizesthenumberofmetadata 1
types of service0 and GameAct are not compatible, since
edges, where each edge is weighted by its suspiciousness.
service0 is a service whereas GameAct is an activity.
Continuing our example, S2 does not exhibit any “suspi- Thus, F(b) does not preserve types. Furthermore, F(b) is also
1 1
cious” behaviors such as suspicious information flows from invalid for another reason: There is an edge receiver0 →
confidential sources to public sinks. On the other hand, S1 service0 ∈ X in S1, but there is no corresponding edge
0
contains multiple suspicious behaviors, such as calling the zjReceiver→GameActinG1.Therefore,F(b) alsodoes
sendSMS API and leaking confidential data. Based on these 1
not preserve edges. On the other hand, F(a) satisfies all the
suspicious features, ASTROID decides that among the three 1
properties above and is a valid embedding.
candidates S1-S3, the candidate S1 most likely encodes the
malicious behavior characterizing malware in the GoldDream Given signature G =(V ,X ,Y ) and app S with ICCG
0 0 0 0
family. G = (V ,X ,Y ), we say that G exactly matches (or
S S S S 0
simply matches) S if G occurs as a subgraph of G . In
Internally,ASTROIDusesaMaxSATsolvertofindMSCSs. 0 S
other words, given a signature (V ,X ,Y ) and a sample S
Sinceeachsuspiciousbehaviorisencodedasasoftconstraint, 0 0 0
with ICCG (V ,X ,Y ), we can check whether (V ,X ,Y )
an optimal satisfying assignment to the MaxSAT problem S S S 0 0 0
matches S. If so, we have determined that S ∈F; otherwise,
corresponds to a maximally suspicious common subgraph of
S (cid:54)∈F.
the malware samples. Once ASTROID infers an MSCS of the
malware samples, it automatically converts this MSCS into a In general, our signature may not exactly capture the se-
signature.Hence,ASTROIDallowsasecurityauditorlikeAlice manticpropertiesofthemalwarefamilyF.Asaconsequence,
to automatically detect future instances of the GoldDream there may be samples S ∈F such that (V ,X ,Y ) does not
0 0 0
family without having to manually write malware signatures. match S (called false negatives), or samples S (cid:54)∈F such that
(V ,X ,Y ) matches S (called false positives). In practice, a
0 0 0
IV. SEMANTICANDROIDMALWARESIGNATURES signature should minimize both the false positive rate and the
false negative rate, even though there is a tradeoff between
We now formally define our malware signatures and state
optimizing these two values in practice. When detecting mal-
what it means for an app to match a signature. Intuitively, a
ware,weuseapproximatematching,whichenablesourtoolto
signatureforafamilyF isanICCG(V ,X ,Y )thatcaptures
0 0 0 detectpartialmatches;tuningthecutoffforwhatconstitutesan
semantic properties common to all malware in F. Ideally,
approximatematchallowsustobalancethetradeoffasdesired.
G =(V ,X ,Y ) would satisfy the following:
0 0 0 0 See Section VII for details.
• G occurs as a subgraph (defined below) of the ICCG
0
G =(V ,X ,Y ) of every malware sample S ∈F. V. SIGNATUREINFERENCEPROBLEM
S S S S
• G does not occur as subgraph of the ICCG G =
0 S Our goal is to infer a signature from few samples of a
(V ,X ,Y ) of any sample S (cid:54)∈F.
S S S malware family. Suppose we are given n malware samples
from a single family F. Na¨ıvely, we can search for any
By“occursasasubgraph”,wemeanthereexistsanembedding
F :V →V such that the following properties hold: signature that matches each of the n malware samples; then,
S 0 S
the resulting signature would intuitively have a low false
• One-to-one. For every v,v(cid:48) ∈ V where v (cid:54)= v(cid:48), F negative rate. However, even the empty signature fits this
0 S
cannot map both v and v(cid:48) to the same vertex, i.e., criterion (since it can be embedded in any sample), but the
F (v)(cid:54)=F (v(cid:48)). empty signature has a high false positive rate.
S S
4Instead, we want to maximize the amount of semantic sample (since it must be embedded in each sample). Hence,
informationcontainedinthesignature.Moreprecisely,weseek wecangiveanupperboundonthenumberofverticesoftype
to find a signature (V ,X ,Y ) that is: r in V :
0 0 0 0
• A common subgraph: (V 0,X 0,Y 0) should match |{v ∈V 0 |T(v)=r}|≤m r.
each given sample i ∈ {1,...,n}. Intuitively, the
Here, m denotes the minimum number of vertices of type r
r
common subgraph requirement seeks to minimize false
inanysample.Thisobservationimmediatelygivesusanupper
negatives. If the inferred signature S was not a common
bound on the total number of vertices:
subgraph of all the samples, then S would not match
(cid:88)
somesamplesofF,meaningthatwehavefalsenegatives. |V 0|≤m= m r.
r∈T
• Maximally suspicious: (V ,X ,Y ) has maximal suspi-
0 0 0
ciousness |X |+(cid:80) w , where weight w indicates Our approach is to fix a large set of vertices V, and then
indicates the0 relativy e∈Y im0 poy rtance of metadaty a edge y. thinkofV 0 asanunknownsubsetofV inourencoding.Since
Intuitively, maximal suspiciousness seeks to minimize thereareatmostmverticesinthesignature,itsufficestotake
false positives: The less frequently a metadata edge y V = {v 1,...,v m}. Furthermore, for each type r, we assign
appears in benign apps (i.e., the more “suspicious” y type r to exactly m r of the vertices in V. Now, we can think
is), the higher the weight associated with it. Hence, of each embedding F i as a partial function F i : V → V i,
m ita lx ei sm si lz ii kn eg lyth the atsu asp bi ec nio igu nsne as ps ps wco ilr le m(cid:80) aty c∈ hY0 thw ey inm fea rk ree ds w sah me pre lew i.e Tr heq enu ,ir Ve 0th isat et xh ae ctd lyom tha ein coo mf mF oi nis doth me as ia nm oe
f
tf ho er Fea ic ’sh
,
signature. We describe how the weights w y are chosen in and we have X 0 ⊆V 0×V 0 as well as Y 0 ⊆V 0×V 0×D.
Section VI-C. Example 3: Consider the two GoldDream samples shown
in Figure 1. The first sample has only 6 activities, 1 service,
In summary, given a set of samples S of malware
F and 1 receiver, so m =6, m =m =1, and
family F, we refer to the problem of computing a signature activity service receiver
(V ,X ,Y ) that is both maximally suspicious and a common m=m +m +m =8.
0 0 0 activity service receiver
subgraph of all G∈S as signature synthesis.
F Therefore,wetakeV ={v ,...,v },with6activitiesv ,...,v ,
1 8 1 6
1 service v , and 1 receiver v . Note that the vertices V used
VI. SIGNATURESYNTHESISASMAXSAT 7 8 0
inthecandidatesignaturemustbeasubsetofV,andX must
0
As mentioned earlier, our approach reduces the signature be a subset of V ×V .
0 0
synthesis problem to MaxSAT [17]. Given a boolean formula
In our description of the variables in our encoding, we use
in conjunctive normal form (CNF), the MaxSAT problem is
indices i,j ∈ {1,...,n} to enumerate over the samples and
to find satisfying assignments to the variables in the formula
k,h ∈ {0,1,...,n} to enumerate over both the samples and
thatmaximizesthenumberofclausesthatevaluatetotrue.For
the signature. Also, we use the indicator function:
example, given the unsatisfiable formula
(cid:26)
1 if C holds
(x ∨x )∧(¬x ∨x )∧(x ∨¬x )∧(¬x ∨¬x ), I[C]= .
0 1 0 1 0 1 0 1
0 otherwise
the assignment {x (cid:55)→ 0,x (cid:55)→ 0} achieves the maximum of
0 1
three satisfied clauses. For readability, we use the notation x(a,b,...) to denote
a boolean variable x indexed over a ∈ A, b ∈ B, and
In addition, we can specify that certain clauses must be a,b,...
so forth. Our constraint system is defined using the following
satisfied; these clauses are referred to as hard constraints and
constants and free variables:
the remaining clauses are referred to as soft constraints. We
encode the common subgraph requirement of the signature • Domain indicators. For every v ∈V, a boolean variable
synthesisproblemusinghardconstraints.Incontrast,sincethe d(v) indicates whether v is in the domain of the embed-
maximally suspicious requirement corresponds to optimizing dings F . These are all free variables.
i
an objective function, we encode this requirement using soft • Embedding indicators. For each v ∈V,
constraints that should be maximally satisfied.
f (v,u)=I[F (v)=u].
i i
A. Variables in Encoding In other words, f (v,u) indicates whether the embedding
i
F maps v to u. These are all free variables.
Before we describe how to reduce the signature synthesis i
• Type indicators. For each v ∈ V (or V if k = 0) and
problem to MaxSAT, we introduce some terminology and k
r ∈T, t (v,r) indicates whether the type of v is r:
describe the propositional variables used by our encoding. k
t (v,r)=I[T(v)=r].
First,wedenotetheICCGofagivensamplei∈{1,...,n} k
of malware family F as (V i,X i,Y i). Recall that the common Since the types of all components are known, each
subgraph criterion requires that the signature (V 0,X 0,Y 0) t k(v,r) is a boolean constant.
matches each i (i.e., we can find isomorphic embeddings • Control-flow indicators. For each v,u ∈ V (or V if
k
F i : V 0 → V i). The first difficulty in encoding the common k =0),x k(v,u)indicateswhetherthereisanedge(v,u)
subgraph requirement is that the number of vertices |V 0| in in X k:
the signature is unknown. However, for each type r ∈ T, we
x (v,u)=I[(v,u)∈X ].
know that V cannot contain more vertices of type r than any k k
0
5For k = 0, these are free variables; the remainder are into G2. Then, the domain is represented as V =
0
constants (since the control-flow edges X are known). {service0,receiver0},sotheassignmentstothedomain
i
• Metadata indicators: For every v,v(cid:48) ∈V (or V if k = indicators are
k
0) and d ∈ D, y (v,v(cid:48),d) indicates whether there is a
k
metadata (v,v(cid:48),d)∈Y : d(v (cid:96))(cid:55)→0 (for 1≤(cid:96)≤6)
k
d(v )(cid:55)→1, d(v )(cid:55)→1.
y (v,v(cid:48),d)=I[(v,v(cid:48),d)∈Y ]. 7 8
k k
For k = 0, these are free variables; the remainder are The assignments to the embedding indicators for F 1(a) are
constants (since the metadata edges Y are known).
i f (v ,zjReceiver)(cid:55)→1, f (v ,zjService)(cid:55)→1
1 7 1 8
Each assignment to the free variables corresponds to a f (v ,w)(cid:55)→0 (for w (cid:54)=zjReceiver)
1 7
candidate signature together with embeddings F into the
i f (v ,w)(cid:55)→0 (for w (cid:54)=zjService)
1 8
ICCG of each given sample i.
f (v ,w)(cid:55)→0 (for 1≤(cid:96)≤6 and w ∈V )
1 (cid:96) 1
Example 4: Consider the ICCGs of samples from the
GoldDream malware family shown in Figure 1. Recall that,
given these samples, our algorithm uses V ={v ,...,v }. We The assignments to the control-flow indicators are
1 8
first describe the constants constructed by our algorithm, and
then the free variables.
x 0(v 7,v 8)(cid:55)→1, x 0(v (cid:96),v (cid:96)(cid:48))(cid:55)→0 (for ((cid:96),(cid:96)(cid:48))(cid:54)=(7,8)).
The constants include type indicators both for the samples
IfinsteadthecandidateembeddingofthesignatureS1into
and for the signature, as well as control-flow and metadata
the sample G1 were F(b) (also described in Example 2), then
indicatorsforthesamples.Forthesignature,thenon-zerotype 1
the assignments to the embedding indicators would become
indicators are
t 0(v (cid:96),activity)=t 0(v 7,service) f 1(v 7,zjReceiver)(cid:55)→1, f 1(v 8,GameAct)(cid:55)→1
= t 0(v 8,receiver)=1, f 1(v 7,w)(cid:55)→0 (for w (cid:54)=zjReceiver)
f (v ,w)(cid:55)→0 (for w (cid:54)=GameAct)
for 1≤(cid:96)≤6, and the remaining type indicators are zero. For 1 8
thevertexzjReceiverinfirstsampleG1,thetypeindicators f 1(v (cid:96),w)(cid:55)→0 (for 1≤(cid:96)≤6 and w ∈V 1),
are:
and assignments to the remaining free variables would be
t (zjReceiver,receiver)=1
1 unchanged.
t (zjReceiver,service)
1
B. Encoding of Common Subgraph
= t (zjReceiver,activity)
1
= 0 We now describe how to encode the requirement that
(V ,X ,Y )shouldbeacommonsubgraphofallthesamples.
0 0 0
For the outgoing edges from zjReceiver, the control- Recall from earlier that the common subgraph requirement
flow indicators are corresponds to our hard constraints.
x (zjReceiver,zjService) • Constant domain. For every v ∈V, the domain of F is
1 i
= 1 the same for each i:
(cid:40) (cid:41)
and (cid:94) (cid:95)
d(v)= f (v,w)
i
x 1(zjReceiver,zjReceiver)
i w∈Vi
= x (zjReceiver,ISniper)
1 Here, the conjunction over i states that d(v) should be
= x 1(zjReceiver,moreGame) assigned to true if v is in the domain of the embedding
= x 1(zjReceiver,HighScore) F i.Therefore,thisconstraintensuresthateachv iseither
in the domain of F for every i, or not in the domain of
= x (zjReceiver,Profile) i
1 F for any i.
= x 1(zjReceiver,UserAct) • Fui nction property. For every v ∈ V and w,w(cid:48) ∈ V
i
= x 1(zjReceiver,GameAct) where w (cid:54)=w(cid:48), F
i
cannot map v to both w and w(cid:48).
= 0
(¬f (v,w))∨(¬f (v,w(cid:48))).
i i
Assignments to the free variables correspond to candidate • One-to-one. For every v,v(cid:48) ∈ V where v (cid:54)= v(cid:48) and w ∈
signatures along embeddings F 1 and F 2 into the samples V i:
G1 and G2 respectively. For example, consider the candidate
signature S1, along with the candidate embedding F(a) into (¬f i(v,w))∨(¬f i(v(cid:48),w)).
1
G1 described in Example 2, and the candidate embedding
• Type preserving. For every v ∈ V, w ∈ V , and r ∈ T,
i
(cid:40)
F(a)(receiver0)=MyReceiver we have:
2
F(a)(service0)=BoolService
f (v,w)⇒(t (v,r)=t (w,r)).
2 i 0 i
6• Control-flow preserving. For every v,v(cid:48) ∈ V and To choose the weights w , we use the frequency of the
y
w,w(cid:48) ∈V : metadatainbenignsamplestoassignweightstodifferentkinds
i
of metadata. In particular, we define w to be:
f (v,w)∧f (v(cid:48),w(cid:48))∧x (v,v(cid:48))⇒x (w,w(cid:48)). y
i i 0 i
• Metadata preserving. For every v,v(cid:48) ∈ V and d ∈ D, w = #{benign apps}+1
we have: y #{benign apps containing y}+1
f (v,w)∧f (v,w(cid:48))∧y (v,v(cid:48),d)⇒y (w,w(cid:48),d). In other words, w is the inverse frequency with which
i i 0 i y
metadata edge y occurs in benign samples, computed on a
• Nospuriouscontrol-flow.Foreveryv,v(cid:48) ∈V,theedges
large corpus of benign apps (we add one to avoid division
X are a subset of V ×V :
0 0 0 by zero). The intuition is that metadata edges in the malware
x (v,v(cid:48))⇒d(v), x (v,v(cid:48))⇒d(v(cid:48)) samples that rarely occur in benign apps are more likely to
0 0
correspond to malicious behaviors.
• No spurious metadata. For every v,v(cid:48) ∈V and d∈D,
the metadata Y are a subset of V ×V ×D: However, some kinds of behaviors in Y are strictly more
0 0 0 0
dangerous than others. In particular, according to previous
y (v,v(cid:48),d)⇒d(v), y (v,v(cid:48),d)⇒d(v(cid:48))
0 0 literature [3, 7], suspicious intent filters are far more likely
Example 5: Consider the ICCGs for the samples G1 and to indicate malicious behavior than API calls, which are in
G2fromtheGoldDreamfamilyshowninFigure1,alongwith turn much more suspect than data-flows:
the candidate signature S1. In Example 4 we described the
intent filters > API calls > data-flows.
constants in our MaxSAT encoding of the signature synthesis
problem, as well as the assignments to free variables corre-
Rather than simply optimizing the weighted sum, we first
spondingtothecandidatesignatureS1togetherwithcandidate
prefersignaturesthathavethehighestweightedsumrestricted
embeddings F(a) and either F(a) or F(b).
2 1 1 to intent filters, regardless of other metadata. Ties are broken
Recall that F(a) satisfies the properties described in Sec- by the weighted sum restricted to suspicious API calls, and
1 further ties are broken by the weighted sum restricted to data-
tionIV(asdoesF(a)),whereasF(b) isneithertypepreserving
2 1 flows.ThenumberofedgesinX isconsideredlast,sinceitis
nor edge preserving. In particular, the candidate embedding 0
already indirectly optimized by the other objectives. To incor-
F 1(b) has corresponding free variable assignments porate this strict ordering on different kinds of metadata, we
x (v ,v )(cid:55)→1, f (v ,zjReceiver)(cid:55)→1, groupthesumsintheobjectiveaccordingtothedifferentkinds
0 7 8 1 7
ofmetadataandthenencodetheobjectiveasalexicographical
f (v ,GameAct)(cid:55)→1.
1 8 optimization problem in the MaxSAT solver [18].
These assignments violate the type preservation constraint
f (v ,GameAct) VII. APPROXIMATESIGNATUREMATCHING
1 8
⇒(t 0(v 8,activity)=t 1(GameAct,activity)) In addition to making semantic malware detection fully
because one of these subterms t (v ,activity) = 0 but automatic,anotherbenefitofoursignatureinferencealgorithm
0 8
t (GameAct,activity) = 1, so F(b) does not satisfy the isthatitenablesapproximatesignaturematching.Supposewe
1 1 are given an app A, and we want to determine if A is an
type preservation constraints. In addition, these assignments
instance of malware family F. Even if A does not exactly
violate the control-flow preservation constraint
matchF’ssignature,wemightwanttodetermineifAexhibits
f (v ,zjReceiver)∧f (v ,GameAct)∧x (v ,v ) a high degree of similarity with other instances of F. This
1 7 1 8 0 7 8
⇒x (zjReceiver,GameAct) problem,whichwerefertoasapproximatematching,isuseful
1
both for detecting zero-day malware and also for mitigating
sincetheconstantx (zjReceiver,GameAct)=0,soF(b) behavioralobfuscation.Thissectionexplainshowweleverage
1 1
is not control-flow preserving. signature inference for approximate signature matching.
On the other hand, it is not difficult to verify that the To perform approximate matching between an app A and
candidatesignatureS1togetherwiththecandidateembeddings amalwarefamilyF withsignatureS ,wefirstassumethatA
F
F 1(a) and F 2(a) correspond to an assignment that satisfies the and S F belong to the same malware family. We then compute
constraints described above. a new signature S that captures the common behavior of A
and all instances of F. If S and S are “similar” (see below),
F
C. Encoding of Maximally Suspicious there is a high probability that A is an obfuscated instance of
malware family F.
Now, we describe how to encode the maximally suspi-
cious requirement, which is that the synthesized signature To understand how we measure similarity, note that S is
(cid:80)
(V ,X ,Y ) has a maximal suspiciousness |X |+ w , always a subgraph of S ; hence, we can measure similarity
0 0 0 0 y∈Y0 y F
where the weight w indicates the relative importance of in terms of number of nodes and edges that are removed from
y
metadata edge y (as described in Section V). In particular, S to form S. Specifically, given signature S, let f(S) be a
F
we maximize the objective function that measures the size of S as a weighted sum of
(cid:88) (cid:88) (cid:88) the number of nodes and edges in S. Then, given app A and
O = x (v,v(cid:48))+ w y (v,v(cid:48),d).
0 (v,v(cid:48),d) 0 family F with signature S F, we define the similarity metric
v,v(cid:48)∈V v,v(cid:48)∈V d∈D as follows:
71
δ(A,F)=
f(INFERSIGNATURE(A,S F))
f(S ) 0.9
F
Hence,ifδ(A,F)issufficientlyhigh,thenAismorelikelyto 0.8
beaninstanceoffamilyF.AsweshowinSectionIX,approx-
imatematchingusingthissimilaritymetricbetweensignatures 0.7
makes ASTROID more resilient to behavioral obfuscation.
0.6
Zero-day malware detection. We can also use approximate
signature matching to detect zero-day malware. Suppose we 0.5
0.01 0.02 0.03 0.04 0.05
have a database of signatures for existing malware families
Falsepositiverate
F ,...,F , and suppose that an app A does not match any
1 n
of them. Now, to determine whether A belongs to a new
(unknown) malware family, we compute δ(A,F ) for each
i
1 ≤ i ≤ n and report A as malware if δ(A,F ) exceeds a
i
certain cutoff value for some malware family F . We explain
i
how we pick this cutoff value in Section VIII.
VIII. IMPLEMENTATION
We have implemented the proposed technique in a tool
called ASTROID for inferring semantic malware signatures for
Android. Our implementation consists of about 7,000 lines of
Java code and uses the OPEN-WBO MaxSAT solver [19].
Our implementation builds on top of APPOSCOPY [2] for
staticallyconstructingICCGsandtaintflowsofAndroidapps.
Specifically, APPOSCOPY implements a field- and context-
sensitive pointer analysis and constructs a precise callgraph
by simultaneously refining the targets of virtual method calls
and points-to sets. For context-sensitivity, APPOSCOPY uses
thehybridapproachproposedin[20].Specifically,itusescall-
sitesensitivityforstaticmethodcallsandobject-sensitivityfor
virtual method calls. To scale in large apps, APPOSCOPY also
leverages the EXPLORER [21] tool to construct ICCGs in a
demand-driven manner. APPOSCOPY’s average static analysis
time for constructing an ICCG is 87 seconds for an app from
the Android Genome benchmarks and 126 seconds for an app
from Google Play, including analysis time for all third-party
libraries. Unlike DroidSafe [22] which analyzes the source
code of Android framework directly, APPOSCOPY uses about
1,210 manually-written models for classes that are relevant to
its underlying taint analysis.
Once a signature for a given malware family is generated,
ASTROID can perform both exact matching (described in
Section IV) as well as approximate matching (described in
SectionVII).Ourimplementationoftheapproximatematching
algorithm differs slightly from the description in Section VII;
in particular, we use the transitive closure of the control-flow
edges in the ICCG (computed in a preprocessing step) rather
than the original ICCG control-flow edges; this modification
increases the resilience of ASTROID against obfuscations that
introduce dummy components.
We use approximate matching both to detect obfuscated
apps and to detect zero-day malware. Recall from Section VII
that our approximate matching algorithm uses a cutoff value
for how high the similarity metric must to count as a match.
We choose a cutoff of 0.5 for zero-day malware, and a stricter
cutoff of 0.8 for obfuscated malware. In other words, an app
with a similarity score = 1.0 is flagged as an unobfuscated
instance of a known malware family, an app with similarity
score > 0.8 is flagged as an obfuscated instance of a known
etarevitisopeurT
Fig. 2: Effect of varying cutoff values on false positives and
false negatives for zero-day malware detection
malware family, and an app with similarity score > 0.5 is
flagged as a possible zero-day malware.
We describe our methodology for choosing the similarity
metric cutoff for zero-day malware detection; the cutoff for
obfuscated malware is chosen similarly. We use the Android
Malware Genome Project as a training set. For each family F
intheAndroidMalwareGenomeProject,weomitthesignature
for F from ASTROID’s database of signatures (so samples
in F appear as zero-day malware to ASTROID). Then, we
use the remaining signatures in the database to try and detect
samples in F using our zero-day malware detection algorithm
inSectionVII,usingeachcutoffvalue0.6382,0.5834,0.5832,
0.4927, and 0.4505 (selected by manually binning the data).
For each cutoff value and each F, we compute the true
positive rate (i.e., the fraction of samples in F that ASTROID
detects); then, for each cutoff value, we take the weighted
average over families F to obtain an overall true positive rate
for that cutoff value. Finally, we select the largest possible
cutoff that still achieves a 90% true positive rate. The selected
cutoff is 0.4927, which we round to 0.5. Figure 2 shows the
ROC curve obtained using the various cutoff values, with the
y-axis showing the computed true positive rate. The x-axis
showsthecorrespondingfalsepositiverate,whichiscomputed
on an independent test set of benign apps.
IX. EVALUATION
The goal of our evaluation is to answer the following
questions:
Q1. Howdothesignaturessynthesizedby ASTROID compare
with manually-written signatures used for evaluating AP-
POSCOPY in terms of precision and accuracy?
Q2. How do the quality of learned signatures improve as we
increase the number of samples?
Q3. How does ASTROID compare against other state-of-the-
art malware detectors?
Q4. How effective is ASTROID at detecting zero-day mal-
ware?
Q5. How resistant is ASTROID to behavioral obfuscation?
In what follows, we describe a series of five experiments
designed to answer these questions. All experiments are con-
ductedonanIntelXeon(R)computerwithanE5-1620v3CPU
and 32G of memory running on Ubuntu 14.04.
8100
90
80
70
60
50
40
30
20
10
0
A B C D E F G H I J K L M
ycaruccA
ManualSignature ASTROID Avg.AccuracyManualSignature Avg.AccuracyASTROID
Id Malware Family #Samples
A DroidKungFu 444
B AnserverBot 184
C BaseBridge 121
D Geinimi 68
E DroidDreamLight 46
F GoldDream 46
G Pjapps 43
H ADRD 22
I jSMSHider 16
J DroidDream 14
K Bgserv 9
L BeanBot 8
M GingerMaster 4
Fig. 3: Accuracy of APPOSCOPY with a manual and an automated signature synthesized by ASTROID
A. Astroid vs. Manual Signatures ples. In contrast, APPOSCOPY reports two such false positives
(specifically, it misclassifies two instances of other malware
In our first experiment, we compare the signatures syn-
families as belonging to Geinimi). Hence, the signatures syn-
thesized by ASTROID with manually written signatures used
thesized by ASTROID outperform manually written ones, both
for evaluating APPOSCOPY [2]. Since ASTROID generates
in terms of accuracy as well as precision.
semantic malware signatures in the specification language
used in APPOSCOPY, we use APPOSCOPY’s (exact) signature
False positives on benign apps. To determine whether AS-
matching algorithm to decide if an app matches a signature.
TROID produces false positives on benign apps, we analyze a
Accordingaco-authorof[2],ittookseveralweekstomanually
corpus of 10,495 apps downloaded from Google Play during
construct signatures for all malware families in their dataset,
2013-14. According to [7], over 99.9% of these apps are
even with full knowledge of the malware family of each app
known to be benign. ASTROID reports a total of 8 mali-
and the nature of the malice.
cious apps (specifically, 2 instances each of DroidDream and
DroidDreamLight, 1 instance of Pjapps, and 3 instances of
Accuracy on known malware. Since the authors of [2] have
DroidKungFu). We uploaded these 8 apps to VirusTotal [24],
manually written semantic signatures for all malware families
which is a service that provides aggregated reports from
from the Android Malware Genome Project [23], we use
multiple anti-virus tools. VirusTotal agreed with ASTROID on
ASTROID to synthesize signatures for malware families from each of these 8 apps.2 In other words, ASTROID reported zero
this dataset. The table in Figure 3 shows the malware family
false positives of either kind.
names and the number of samples for each family. For each
family F, we randomly select 5 samples from F and use
ASTROID toinferasignatureforF fromthesesamples.Since B. Varying the Number of Samples
different sets of samples may produce different signatures,
We evaluate the performance and accuracy of ASTROID
we run ASTROID with 11 different sets of randomly chosen
with respect to the number of samples. In Figure 4, the blue
samples, and report our results for the signature that achieves
line plots signature inference time (in seconds) against the
the median accuracy out of these 11 runs.
numberofsamples.ASTROIDisquitefast,takinglessthantwo
The plot in Figure 3 compares the accuracy ASTROID seconds on average to infer a signature for a malware family.
againstAPPOSCOPY.Here,accuracyisthenumberofcorrectly Since manually writing malware signatures typically requires
classified samples divided by the total number of samples. severalhoursofhumaneffort,webelievethesestatisticsshow
For most malware families, ASTROID yields similar or bet- that ASTROID is quite practical.
ter accuracy than APPOSCOPY, and the overall accuracy of
The bars in Figure 4 show how the accuracy varies with
ASTROID (93.8%) is higher than that of APPOSCOPY (90%).
respect to the number of samples. ASTROID achieves 90.8%
Furthermore, for two malware families (specifically, Pjapps
accuracy using only two samples. When we increase the
and BaseBridge), ASTROID generates significantly better sig-
number of samples to 5, ASTROID achieves 93.8% accuracy.
natures than manually written ones. In summary, these results
Moresamplesdonotseemtobenefit,likelyduetoimprecision
show that ASTROID can achieve significantly fewer false
in the static analysis for ICCG constructions. These results
negatives compared to APPOSCOPY.
2Toaccountfortheinclusionofsomelower-qualityAVtoolsinVirusTotal
False positives on known malware. ASTROID reports zero
results,weonlyconsiderVirusTotaltoreportanappasmalwareifthemajority
false positives on the Android Malware Genome Project sam- (i.e.,morethanhalf)ofAVtoolsclassifytheapptobemalicious.
9100
90
80
70
60
50
40
30
20
10
0
2 3 4 5 6 7 8 9 10
Numberofsamples
ycaruccA
Accuracy Time
5
4
3
2
1
0
sdnoceS
100
90
80
70
60
50
Fig. 4: Accuracy and time to synthesize the signature with
different number of samples
show that ASTROID can infer very good signatures from a
very small number of malware samples.
C. Comparison Against Existing Tools
We compare ASTROID to two state-of-the-art malware
detection tools, namely DREBIN [3] (a learning-based mal-
ware detector) and MASSVET [15] (which detects repackaged
malware).WedonotexplicitlycompareASTROIDagainstanti-
virustools(e.g.,VirusTotal)because ASTROID isanextension
of APPOSCOPY, which has already been shown to outperform
leadinganti-virustoolsinthepresenceofobfuscatedmalware.
Comparison to Drebin. We first compare ASTROID against
DREBIN [3], a state-of-the-art malware detector based on
machinelearning.Sinceourgoalistoinfermalwaresignatures
using few samples, we focus on the setting where only five
samples are available for the target family. We believe this
setting is very important because many malware families have
very few known samples. For example, in the Drebin dataset,
only 42% of families have more than 5 samples.
DREBIN takes as input a set of apps and extracts fea-
tures using static analysis. It then trains an SVM on these
feature vectors to classify apps as malicious or benign. Unlike
ASTROID, which classifies each app into a specific malware
family, DREBIN only determines whether an app is malicious
orbenign.SincetheimplementationofDREBINisunavailable,
weusedtheirpubliclyavailablefeaturevectorsandtrainSVMs
based on the methodology described in [3] using the libsvm
library [25]. For each malware family F, we start with the
full DREBIN trainingset,butremoveF exceptfor5randomly
chosen samples from F (to achieve our small-sample setting).
In summary, we train DREBIN on a large number of benign
apps, all samples from other malware families, and 5 samples
from the target family. As with ASTROID, we train the SVM
with 11 different sets of randomly chosen samples and report
the median accuracy.
Inordertoperformanapples-to-applescomparison,weuse
the 1,005 samples in the Android Malware Genome Project
ycaruccA
DREBIN-FP0.01% MASSVET DREBIN-FP1% ASTROID
Fig. 5: Comparison between DREBIN with FP0.01% and
FP1%, MASSVET and ASTROID
for which DREBIN feature vectors are available.3 We use
two cutoffs to evaluate the accuracy on these apps. The first
achieves a false positive rate of 1%, which is used in the orig-
inal evaluation [3]. However, 1% false positives still amounts
to more than 10,000 false positives on Google Play, which
contains more than a million apps. For a closer comparison to
ASTROID (which reports zero false positives on Google Play
apps),wechooseasecondcutoffthatachievesafalsepositive
rate of 0.01%.
As shown in Figure 5, ASTROID outperforms DREBIN
in our small-sample setting: While ASTROID achieves 93.8%
accuracy, DREBIN yields 70.7% and 88.9% accuracy using
the0.01%and1%cutoffvaluesrespectively.Webelievethese
resultsindicatethatASTROIDcomparesfavorablewithexisting
learning-based detectors in the small-sample setting.
Comparison to MassVet. We also compare ASTROID against
MASSVET[15],astate-of-the-arttoolfordetectingrepackaged
malware—i.e.,malwareproducedbyaddingmaliciouscompo-
nents to an existing benign app. MASSVET maintains a very
large database of existing apps and checks whether a given
appisarepackagedversionofanexistingoneinthedatabase.
The authors of MASSVET provide a public web service [26],
which we use to evaluate MASSVET.
As shown in Figure 5, the overall accuracy of MASSVET
on the Android Malware Genome Project is 84.0%, which
is significantly lower than the 93.8% accuracy of ASTROID.
These false negatives occur because many malware samples
are not repackaged versions of existing benign apps, and even
repackaged malware may go undetected if the original app is
missing from their database.
We also evaluate the false positive rate of MASSVET on
a corpus of 503 benign apps from Google Play. 4 MASSVET
reports that 176 of these apps are malware, but all except one
3Inthisexperiment,weusetheAndroidMalwareGenomeProjectdataset
as opposed to the DREBIN dataset because some of the malware families
in the DREBIN dataset are mislabeled, which is problematic for multi-label
classification (as done by our technique). For example, some of the family
labelsintheDrebindatasetdonotmatchthelabelsintheMalwareGenome
project.
4WewereunabletoapplyMASSVETtoall10,495appsfromGooglePlay
duetolimitationsofthewebservice.
10of these apps are classified as benign by VirusTotal. Since
several benign applications repackage existing apps by adding 100
ad libraries, MASSVET seems to mistakenly classify them
as malware. In summary, this experiment demonstrates that 90
ASTROID achieves both higher accuracy as well as a lower
80
false-positive rate compared to MASSVET.
70
Interpretability. In addition to comparing favorably with
MASSVET and DREBIN in terms of accuracy and false pos-
60
itives, we believe that ASTROID produces better explanations
of malice compared to existing tools. In the Appendix, we 50
compare the semantic signatures produced by ASTROID with
the evidence of malice produced by DREBIN and MASSVET. 40
Since ASTROID can pinpoint the malicious components and
30
theirsuspiciousmetadata(e.g.,sensitiveinformationleakedby
Obfuscated Non-obfuscated
the component), we believe that the signatures generated by
ASTROID are more interpretable (and therefore more helpful)
to security analysts.
D. Detection of Zero-day Malware
To evaluate whether ASTROID can effectively detect zero-
daymalware,weconductexperimentsontwodifferentdatasets
and evaluate ASTROID’s accuracy and false positive rate.
MalwarefromSymantecandMcAfee.Inourfirstexperiment,
we use 160 malware samples obtained from Symantec and
McAfee, two leading anti-virus companies. Eventhough these
applications are known to be malicious, none of them belong
to the malware families from the Android Malware Genome
Project dataset. Since ASTROID’s database only contains sig-
natures for the families shown in Figure 3, all of these 160
applications are zero-day malware with respect to ASTROID’s
signature database. Using ASTROID’s approximate signature
matching algorithm (with the cutoff of 0.5, as described in
Section VIII), ASTROID correctly identifies 147 of these apps
asmalware;hence, ASTROID’saccuracyforzero-daymalware
detection on this dataset is 92%. In contrast, MASSVET’s
accuracy on this dataset is 81%. We were not able to compare
against DREBIN on this dataset because we do not have their
feature vectors available.
Apps from Google Play. For our second experiment, we ana-
lyze 10,495 Google Play apps using ASTROID’s approximate
signaturematchingalgorithm.Asbefore,ASTROID’ssignature
database only contains the malware families from Figure 3.
Among these apps, ASTROID reports 395 of them (i.e., 3.8%)
as being malicious. Of these 395 apps, 8 exactly match one
of the signatures in ASTROID’s database; as discussed in
Section IX-A, these 8 apps are all malicious.
To investigate which of the remaining 387 apps are known
malware, we use VirusTotal to analyze each of these apps.
Among these 387 samples, 21 of them are reported as ma-
licious by the majority (i.e., more than half) of the anti-
virus tools, and 81 of them are reported as malicious by at
least one anti-virus tool. Of the remaining 306 apps reported
by ASTROID, we randomly selected 40 apps and manually
inspected them. Our manual inspection shows that 22 of
these 40 apps are actually malicious since they contain highly
suspicious behaviors:
• 4 apps appear to be SMS Trojans because they automat-
ically block all incoming SMS events when they receive
ycaruccA
Exact Approximate
Fig. 6: Evaluation of different matching techniques
an SMS at a specific time or the contents of the SMS
match a certain pattern.
• 1 app silently records audio in a background process and
aborts all incoming SMS events.
• 1appautomaticallylocksthescreenandpreventstheuser
from unlocking it.
• 11 apps dynamically install apk files from untrusted
sources and leak the user’s device id, IMSI number, and
other confidential phone information to untrusted remote
servers.
• 1 app silently takes pictures (i.e., without the user trig-
gering it) and saves the picture to an encrypted file.
• 2 apps contain Android.Cauly library, which has recently
been classified as PUA (“Potentially Unwanted App”) by
Symantec.
• 2appsperformhighlysuspiciousactionswithouttheuser
triggering them. For instance, they send email or SMS
messages to a fixed address or phone number.
Hence, our manual inspection shows that ASTROID can
detect malicious apps that are not identified by existing anti-
malware tools. Furthermore, based on our manual inspection,
we estimate that of the 306 apps not identified as malicious
by existing tools, 55% are in fact malicious. By this estimate,
ASTROID’s false positive rate is approximately 1.3% for zero-
day malware detection (i.e., using approximate matching with
a cutoff of 0.5).
Finally,weremarkthatthepartialmatch(i.e.,thesubgraph
INFERSIGNATURE(A,S F) of the ICCG of A) computed by
our approximate matching algorithm was indispensable for
finding the malicious behaviors in the 40 randomly selected
apps. In every case, some part of malicious code was con-
tained in the partial match, allowing us to quickly identify
the malicious behavior. In particular, examining all 40 apps
took a single analyst only a few hours. As discussed earlier,
the interpretability of the inferred signatures is an important
feature of ASTROID.
E. Detection of Obfuscated Apps
To evaluate whether ASTROID is resilient to obfuscations,
we perform a combination of low-level (syntactic) and high-
level (semantic) obfuscations. First, we obfuscate existing
11malware using the ProGuard tool [27] to rename method/class Third, ASTROID requires an analyst to provide at least
names,encryptstrings,andmodifytheprogram’scontrolflow. two representative samples of a given malware family, so
Second, we also perform obfuscations at the ICCG level, such there is still a minimal amount of human effort involved in
as inserting dummy components and removing taint flows. using ASTROID. However, we believe this effort is miniscule
compared to the laborious task of writing malware signatures
Figure 6 shows the accuracy of signature matching using
manually.
exact vs. approximate matching for 1,025 malware samples
from the Android Malware Genome Project and their corre- Finally, ASTROID’s accuracy in detecting malware is de-
sponding obfuscated versions. When using the exact matching pendent on the initial database of malware signatures. The
algorithm of APPOSCOPY, ASTROID can detect 93.8% of larger the database, the higher the accuracy in detecting ex-
the non-obfuscated malware samples but only 61% of the isting and zero-day malware. However, our experiments show
obfuscated malware samples. In contrast, when we use the that ASTROID can effectively detect new malware families
approximate matching algorithm (with the cutoff of 0.8, as even though we added only thirteen malware signatures to its
described in Section VIII), ASTROID is able to detect 94.3% database. Furthermore, we believe that it is easier to maintain
of malware samples for both obfuscated and non-obfuscated a database of malware signatures compared to the task of
versions.Hence,thisexperimentdemonstratesthatASTROID’s maintaining a much larger database of individual malware
approximate signature matching algorithm significantly in- samples.
creases the resilience of ASTROID to behavioral obfuscations.
In contrast, other anti-virus tools (e.g., Symantec, McAfee, XI. RELATEDWORK
Kaspersky etc.) have been shown to be much less resilient
Android malware detection and classification have been
to even a subset of the obfuscations that we employ in this
extensively studied in recent years. In this section we briefly
experiment [2].
discuss prior closely-related work.
False positives. Both exact and approximate matching report
zerofalsepositivesonmalwaresamples.Asbefore,withexact Machine learning approaches.Mostpriormalwareclassifica-
matching, ASTROID reportsthat8appsaremaliciousfromthe tiontechniquesarebasedonmachinelearning[3,6,11,12,4,
corpus of 10,495 Google Play apps, but all of these apps are 13, 14, 5]. The key idea underlying all ML-based approaches
classified as malware by VirusTotal. When using approximate is to extract a feature vector summarizing the application’s
matching, ASTROID reports a total of 13 apps as malicious, 9 behavior and then train a classifier to predict whether an app
of which are classified as malware by VirusTotal. Hence, the is malicious or benign.
false positive rate of ASTROID remains very low (<0.04%)
Many ML-based approaches generate their feature vectors
even with approximate matching.
from a graph representation of the program. For instance,
SMIT [11] and Gascon et al. [12] model programs using call-
X. LIMITATIONS graphs and use clustering algorithms (e.g., KNN) to group
similar applications.
Like any other malware detection tool, ASTROID has a
number of limitations:
SimilartoSMIT,bothMASSVET[15]andDROIDSIFT[4]
useagraphabstractiontorepresentAndroidapps.Specifically,
First, the quality of the signatures inferred by ASTROID MASSVET[15]computesgraphsimilaritybetweenagivenapp
dependsontheprecisionoftheunderlyingstaticanalysisused A and the database of existing apps to determine if A is the
to constructthe ICCGof the samples.In particular, sourcesof repackaged version of an existing app. As we show in our
imprecision (or unsoundness) in the analysis can degrade the evaluation, ASTROID can achieve better precision and fewer
quality of the signatures inferred by ASTROID. However, our false positives compared to MASSVET. Similarly, DROID-
experimentsindicatethatASTROIDcansynthesizehigh-quality SIFT abstracts programs using an API dependency graph
signatures despite possible imprecision in the static analysis. and employs graph similarity metrics to cluster applications
into different malware families. Similar to ASTROID, DROID-
Second,ASTROID’ssignaturematchingalgorithm(boththe
SIFT performsmulti-labelratherthanbinaryclassificationand
exactandapproximatevariants)arealsoaffectedbythequality
employs a semantics-based approach to resist obfuscation.
of the underlying static analysis. Since signature matching
However, unlike DROIDSIFT, ASTROID can infer signatures
requirescomputingtheICCGoftheapplicationunderanalysis,
from very few samples and does not need a large training set.
any source of unsoundness in the analysis may translate
We tried to compare ASTROID against DROIDSIFT but we
into false negatives in the context of malware detection. For
were not able to reproduce their results using DROIDSIFT’s
example, if an app dynamically loads a malicious payload,
web service [28]. While we have contacted the authors, the
then ASTROID may fail to flag it as malware. However, such
issues with DROIDSIFT’s web service have not been resolved
attempts to escape detection can be identified as suspicious,
by the time of this submission.
thereby requiring further scrutiny. On the other hand, sources
of imprecision due to the underlying static analysis may also Another related tool is HOLMES [6], which detects Win-
translate into false positives. For instance, given a benign app, dows malware by constructing the program’s behavior graph.
iftheanalysisgeneratesalotofspurioustaintflowsandinter- Such behavior graphs are constructed dynamically by analyz-
component call edges, ASTROID may mistakenly mark it as ing data dependencies in program traces. Given a behavior
malware. However, our evaluation show that the underlying graph, HOLMES then uses discriminative subgraph mining
static analysis achieves a high precision without sacrificing to extract features that can be used to distinguish malicious
scalability. applications from benign ones. DROIDMINER [14] and Bose
12et.al [5] also use a variant of behavior graphs to abstract Information flow analysis for Android. Several tools, in-
malware as a set of malicious components and use machine cluding ASTROID, use information flow as a component of
learningforclassification.Incontrasttothesethesetechniques malware signatures or feature vectors. While information flow
which require a large number of samples (e.g., HOLMES uses does not directly predict malware, ASTROID can benefit from
492 samples in their evaluation), ASTROID requires as few recent advances in information flow analysis to improve the
as two samples to automatically generate malware signatures. quality of its signatures. Some examples of Android infor-
Second, our constraint-based approach is guaranteed to gener- mation flow analysis tools include FLOWDROID [33], AP-
ate the optimal signature (in terms of maximizing suspicious PINTENT [34], APPAUDIT [35], TAINTDROID [36], DROID-
behaviors). Finally, we believe that the semantic signatures SCOPE [37], CHEX [38], EPICC [39], HI-CFG [40] and
synthesized by ASTROID are easier for security analysts to APPCONTEXT [41].
interpret.
Another state-of-the-art malware detector for Android is XII. CONCLUSION
DREBIN [3], which combines syntactic and semantic features
We have presented a new technique for automatically
into a joint vector space. The syntactic features are obtained
inferring interpretable semantic malware signatures from a
fromtheapplication’smanifestfile,whilethesemanticfeatures
smallnumberofmalwaresamples.Ourtechniquesignificantly
areobtainedthroughstaticanalysis.Someofthefeaturesused
improves the usability of signature-based malware detectors
byDREBINaresimilartoASTROID;forinstance,DREBINalso
by eliminating the human effort required for writing malware
extracts data flow information as well as suspicious API calls.
signatures. Furthermore, we show that ASTROID s signature
As we demonstrate experimentally, ASTROID can achieve the
inference algorithm enables approximate signature matching,
sameorbetterprecisionasDREBINusingmuchfewersamples.
which is useful both for zero-day malware detection and for
makingourtechniquemoreresilienttobehavioralobfuscation.
Signature-based approaches. As mentioned earlier, signature-
basedapproacheslookforexplicitpatternstoidentifyinstances We implemented our technique in a tool called ASTROID,
of a malware family [8, 2, 9, 10, 29, 30, 31]. These signatures which we evaluated both on malicious apps in the Android
can be either syntactic or semantic, or a combination of Genome Malware Project as well as on benign apps from
both. Our approach extends the applicability of signature- Google Play. Our experiments show that (i) the signatures au-
based detectors by automatically synthesizing signatures from tomaticallysynthesizedby ASTROID arebetterthanmanually-
a handful of malware samples. writtensignaturesintermsofaccuracyandfalsepositives,and
(ii) the proposed approximate signature matching algorithm
Among signature-based detectors, APPOSCOPY [2] uses
allows detecting zero-day and behaviorally- obfuscated mal-
semantic signatures to identify Android malware. Specifically,
ware with a very low false positive rate. Our tool is publicly
it performs a combination of static taint analysis and inter-
available [42] and can be easily used by security analysts to
component control flow analysis to determine whether a sig-
synthesize malware signatures from very few samples.
nature matches an Android application. As mentioned earlier,
ASTROID is integrated as a plug-in to APPOSCOPY and can
generate signatures in APPOSCOPY’s malware specification ACKNOWLEDGMENTS
language.
We would like to thank Thomas Dillig, Martin Rinard,
KIRIN[8],whichisanothersignature-basedtool,leverages Tao Xie, Eric Bodden, Wei Yang and Ashay Rane for their
Android permissions to detect malware. Specifically, KIRIN insightful comments. We also thank the anonymous reviewers
uses permission patterns to perform binary classification of for their helpful feedback.
apps as benign vs. malicious. While FACT [29] obtains a
ThisworkwassupportedinpartbyNSFAward#1453386,
signaturebycomputingtheunweightedmaximalcommonsub-
AFRL Awards #8750-14-2-0270 and #8750-15-2-0096, and a
graph extracted from dynamic analysis, ASTROID computes a
Google Ph.D. Fellowship. The views, opinions, and findings
weighted maximally suspicious common subgraph using static
containedinthispaperarethoseoftheauthorsandshouldnot
analysis.
be interpreted as representing the official views or policies of
the Department of Defense or the U.S. Government.
Zero-day malware detection.Zero-daymalwaredetectors[32,
7, 15] can detect malicious applications that belong to new
REFERENCES
malware families. For instance, RISKRANKER [32] ranks
Androidapplicationsashigh-,medium-,orlow-riskdepending [1] Mobilemalwarereport.https://public.gdatasoftware.com/Presse/
onthepresenceofsuspiciousfeatures,suchascertainkindsof Publikationen/Malware Reports/G DATA MobileMWR Q1
functioncalls.Asanotherexample,DROIDRANGER[7]uncov- 2015 US.pdf, 2015.
ers zero-day malware by performing heuristic-based filtering [2] Yu Feng, Saswat Anand, Isil Dillig, and Alex Aiken. Ap-
to identify suspicious behaviors. Some ML-based approaches poscopy:Semantics-baseddetectionofandroidmalwarethrough
static analysis. In FSE, pages 576–587. ACM, 2014.
(e.g.,[3],[5])can,inprinciple,alsouncoverzero-daymalware,
[3] Daniel Arp, Michael Spreitzenbarth, Malte Hubner, Hugo Gas-
even though their detection rate is much higher for instances
con, and Konrad Rieck. DREBIN: Effective and Explainable
of known malware families. Even though the primary goal of
Detection of Android Malware in Your Pocket. In NDSS. The
ASTROID is not zero-day malware detection, our experiments
Internet Society, 2014.
in Section IX-D show that ASTROID can nonetheless be [4] MuZhang,YueDuan,HengYin,andZhiruoZhao. Semantics-
successfully used to detect instances of unknown malware awareandroidmalwareclassificationusingweightedcontextual
families. API dependency graphs. In CSS, pages 1105–1116. ACM.
13[5] Abhijit Bose, Xin Hu, Kang G. Shin, and Taejoon Park. Be- [26] MassVet. https://bdsec.soic.indiana.edu:8080/, 2016.
havioraldetectionofmalwareonmobilehandsets. InMobiSys, [27] Proguard. https://www.guardsquare.com/en/proguard, 2016.
pages 225–238. ACM, 2008. [28] DroidSift. https://haven.syr.edu:3000/, 2016.
[6] Matt Fredrikson, Somesh Jha, Mihai Christodorescu, Reiner [29] Young Hee Park, Douglas S. Reeves, Vikram Mulukutla, and
Sailer, and Xifeng Yan. Synthesizing Near-Optimal Malware Balaji Sundaravel. Fast malware classification by automated
Specifications from Suspicious Behaviors. In Malware, pages behavioral graph matching. In CSIIRW, pages 45–48. ACM,
41–50. IEEE Computer Society, 2010. 2010.
[7] YajinZhou,ZhiWang,WuZhou,andXuxianJiang. Hey,you, [30] Mihai Christodorescu, Somesh Jha, and Christopher Kruegel.
get off of my market: Detecting malicious apps in official and Mining specifications of malicious behavior. In FSE, pages 5–
alternative android markets. In NDSS. The Internet Society, 14. ACM, 2007.
2012. [31] Brian Chin, Daniel von Dincklage, Vuk Ercegovac, Peter
[8] WilliamEnck,MachigarOngtang,andPatrickDrewMcDaniel. Hawkins,MarkS.Miller,FranzJosefOch,ChristopherOlston,
On lightweight mobile phone application certification. In CSS, andFernandoPereira. Yedalog:ExploringKnowledgeatScale.
pages 235–245. ACM, 2009. In SNAPL, pages 63–78. LIPICS, 2015.
[9] Kent Griffin, Scott Schneider, Xin Hu, and Tzi-cker Chiueh. [32] Michael C. Grace, Yajin Zhou, Qiang Zhang, Shihong Zou,
Automaticgenerationofstringsignaturesformalwaredetection. and Xuxian Jiang. Riskranker: scalable and accurate zero-day
In RAID, pages 101–120. Springer, 2009. android malware detection. In MobiSys, pages 281–294. ACM,
[10] MihaiChristodorescu,SomeshJha,SanjitA.Seshia,DawnXi- 2012.
aodongSong,andRandalE.Bryant. Semantics-awaremalware [33] Steven Arzt, Siegfried Rasthofer, Christian Fritz, Eric Bod-
detection. InS&P,pages32–46.IEEEComputerSociety,2005. den, Alexandre Bartel, Jacques Klein, Yves Le Traon, Damien
[11] Xin Hu, Tzi-cker Chiueh, and Kang G. Shin. Large-scale Octeau, and Patrick McDaniel. Precise context, flow, field,
malware indexing using function-call graphs. In CSS, pages object-sensitive and lifecycle-aware taint analysis for android
611–620. ACM, 2009. apps. In PLDI, pages 259–269. ACM, 2014.
[12] Hugo Gascon, Fabian Yamaguchi, Daniel Arp, and Konrad [34] Zhemin Yang, Min Yang, Yuan Zhang, Guofei Gu, Peng Ning,
Rieck. Structuraldetectionofandroidmalwareusingembedded and Xiaoyang Sean Wang. AppIntent: analyzing sensitive data
call graphs. In AISEC, pages 45–54. ACM, 2013. transmission in android for privacy leakage detection. In CSS,
[13] HaoPeng,ChristopherS.Gates,BhaskarPratimSarma,Ninghui pages 1043–1054. ACM, 2013.
Li, Yuan Qi, Rahul Potharaju, Cristina Nita-Rotaru, and Ian [35] MingyuanXia,LuGong,YuanhaoLyu,ZhengweiQi,andXue
Molloy. Usingprobabilisticgenerativemodelsforrankingrisks Liu. Effective real-time android application auditing. In S&P,
of android apps. In CSS, pages 241–252. ACM, 2012. pages 899–914. IEEE Computer Society, 2015.
[14] Chao Yang, Zhaoyan Xu, Guofei Gu, Vinod Yegneswaran, [36] WilliamEnck,PeterGilbert,Byung-GonChun,LandonP.Cox,
and Phillip A. Porras. Droidminer: Automated mining and JaeyeonJung,PatrickMcDaniel,andAnmolSheth. Taintdroid:
characterization of fine-grained malicious behaviors in android Aninformation-flowtrackingsystemforrealtimeprivacymon-
applications. In ESORICS, pages 163–182. Springer, 2014. itoring on smartphones. In OSDI, pages 393–407. USENIX
[15] Kai Chen, Peng Wang, Yeonjoon Lee, XiaoFeng Wang, Nan Association, 2010.
Zhang, Heqing Huang, Wei Zou, and Peng Liu. Finding [37] Lok-Kwong Yan and Heng Yin. Seamlessly reconstructing the
UnknownMalicein10Seconds:MassVettingforNewThreats OS and dalvik semantic views for dynamic android malware
attheGoogle-PlayScale. InUSENIXSecurity,pages659–674. analysis. In USENIX Security, pages 569–584. USENIX Asso-
USENIX Association, 2015. ciation, 2012.
[16] Xuxian Jiang. Security alert: New Android malware – [38] Long Lu, Zhichun Li, Zhenyu Wu, Wenke Lee, and Guofei
GoldDream– found in alternative app markets. http://www.csc. Jiang. CHEX: statically vetting android apps for component
ncsu.edu/faculty/jiang/GoldDream/, 2011. hijacking vulnerabilities. In CSS, pages 229–240. ACM, 2012.
[17] Chu Min Li and Felip Manya`. MaxSAT, Hard and Soft [39] Damien Octeau, Patrick McDaniel, Somesh Jha, Alexandre
Constraints. In Handbook of Satisfiability, volume 185, pages Bartel,EricBodden,JacquesKlein,andYvesLeTraon. Effec-
613–631. IOS Press, 2009. tive inter-component communication mapping in android: An
[18] JoaoMarques-Silva,JosepArgelich,AnaGrac¸a,andIneˆsLynce. essential step towards holistic security analysis. In USENIX
Booleanlexicographicoptimization:algorithms&applications. Security, pages 543–558. USENIX Association, 2013.
AnnalsofMathematicsandArtificialIntelligence,62(3-4):317– [40] DanCaselden,AlexBazhanyuk,MathiasPayer,StephenMcCa-
343, 2011. mant,andDawnSong.HI-CFG:constructionbybinaryanalysis
[19] RubenMartins,VascoManquinho,andIneˆsLynce.Open-WBO: and application to attack polymorphism. In ESORICS, pages
A Modular MaxSAT Solver. In SAT, pages 438–445. Springer, 164–181. Springer, 2013.
2014. [41] WeiYang,XushengXiao,BenjaminAndow,SihanLi,TaoXie,
[20] George Kastrinis and Yannis Smaragdakis. Hybrid context- and William Enck. AppContext: Differentiating Malicious and
sensitivity for points-to analysis. In PLDI, pages 423–434. Benign Mobile App Behaviors Using Context. In ICSE, pages
ACM, 2013. 303–313. IEEE Computer Society, 2015.
[21] YuFeng,XinyuWang,IsilDillig,andCalvinLin.EXPLORER: [42] Astroid. https://utopia-group.github.io/astroid/, 2016.
query-anddemand-drivenexplorationofinterproceduralcontrol [43] Smart phone malware: The six worst offenders. http://tinyurl.
flow properties. In OOPSLA, pages 520–534. ACM, 2015. com/huaor8y, 2011.
[22] Michael I Gordon, Deokhwan Kim, Jeff H Perkins, Limei [44] Fake android apps. http://us.norton.com/fake-android-apps/
Gilham, Nguyen Nguyen, and Martin C Rinard. Information article, 2016.
flow analysis of android applications in droidsafe. In NDSS.
The Internet Society, 2015.
APPENDIX
[23] Android malware genome project. http://www.
malgenomeproject.org/, 2012. APPENDIXA:INTERPRETABILITYOFEXPLANATIONS
[24] VirusTotal. https://www.virustotal.com/en/, 2016.
[25] Chih-Chung Chang and Chih-Jen Lin. LIBSVM: A library In this section, we describe the explanations for the Gold-
for support vector machines. ACM Transactions on Intelligent Dream malware family generated by ASTROID, DREBIN and
Systems and Technology, 2, 2011. MASSVET, which are shown in Figure 7. In particular, we
14V ={r:receiver,s:service}
X={(SYSTEM,r),(r,s)}
(SYSTEM,r,IntentFilter(BOOT_COMPLETED)), 
(
(
(S
S
SY
Y
YS
S
ST
T
TE
E
EM
M
M,
,
,r
r
r,
,
,I
I
In
n
nt
t
te
e
en
n
nt
t
tF
F
Fi
i
il
l
lt
t
te
e
er
r
r(
(
(S
P
NM
H
ES
O
W_
N
_R
E
OE
_
UC
S
TE
T
GI
A
OV
T
IE
E
N)D
G)
_) ,) C,
ALL)),
S
N
Pu
ee
rs
t
mwpi ioc sri so
k
iu oAs ndA
(d
DP
r
EeI(
s
Lss E(e
l
Tn
e
Ed
b
_S
a
PM
r
AS
.
C)
g
K(
i
A1
c
G.
p
E0
.
S7 n)
)e (t 0) .5( 80 ).93) o on nR Re ec ce ei iv ve
e
→ →c gr ee ta Ot re iF gr io nm aP td iu
ngAddress
Y = (s,s,SuspiciousAPI(sendTextMessage)), IntentFilter(SMS_RECEIVED)(0.56) onReceive →getDisplayMessageBody
(
(
(
(s
s
s
s,
,
,
,s
s
s
s,
,
,
,T
T
T
Ta
a
a
ai
i
i
in
n
n
nt
t
t
tF
F
F
Fl
l
l
lo
o
o
ow
w
w
w(
(
(
(D
S
F
Su
i
ie
l
mb
ev
,s
Sic
c
I
ee
r
n
riI
t
ibD
e
ae
r
l,
r
,nII
e
IDn nt)t t,e e)Ir r,nn nte eet tr) )n) )e,
t)),
 SuspiciousAPI(getSubscriberID)(0.53)
ASTROID DREBIN MASSVET
Fig. 7: Explanations produced by each tool for the GoldDream family.
discuss how a security analyst might use these explanations 6.6% of benign apps in the Drebin dataset call sendSMS,
to pinpoint and understand the malicious behaviors of Gold- but 92.8% of GoldDream malware make this call. Therefore,
Dream malware. calling sendSMS is a good statistical signal that an app is
malicious, but it does not give conclusive evidence of malice.
The left-hand side of Figure 7 shows the signature synthe-
Unlike ASTROID, DREBIN fails to pinpoint any malicious
sized by ASTROID for the GoldDream malware family. This
components, intent filters, and information leaks, let alone the
signature conveys a wealth of information about the malware
complex relationships between these entities.
family to the auditor:
The presence of the network address lebar.gicp.net
Components. Simply by looking at the vertices V in the
might be a more conclusive signal of malice, but if this
signature, the auditor sees that the malware consists of two
feature were used to filter apps on Google play, then malware
components: a receiver r and a service s. Furthermore, the
developers would quickly learn to obfuscate it. In contrast,
inter-component call relations X convey that r is called by
ASTROID solely relies on semantic features of apps that are
the Android framework (denoted by the vertex SYSTEM), and
significantly harder to obfuscate.
s is subsequently called by r.
Triggers. The metadata Y encodes intent filters registered Comparison to MassVet. The explanation produced by
by each receiver. For the GoldDream family, the receiver MASSVET consists of a set of method calls added as part of
r can be triggered by a variety of common system events the repackaging process. These method calls typically do not
including BOOT_COMPLETED (triggered when the app starts) pinpoint the malicious functionality in the app. For example,
and SMS_RECEIVED (triggered when an SMS message is the explanation produced by MASSVET for an instance of the
received). GoldDream family is shown in Figure 7 (right). It consists
of a list of calls to APIs that MASSVET considers suspicious.
Malice. The metadata Y also encodes malicious behaviors WhiletheseAPIcallsplayaroleinthemaliciousfunctionality
associated with the relevant components. For the GoldDream of this app, they are also commonly used by benign apps to
family, this includes suspicious API calls (e.g., the service s process SMS messages, and do not capture the overall malice
calls sendTextMessage) and information leaks (e.g., the present in this app.
service s leaks the device ID to the Internet).
In addition, we believe the results produced by ASTROID
In summary, the signature inferred by ASTROID encodes confer a number of other benefits:
that members of the GoldDream family contain a receiver
triggered by common system events, and this receiver calls Malware family. Unlike DREBIN and MASSVET, which can
a service that leaks sensitive information to the Internet.
onlyidentifywhetheranappismaliciousorbenign, ASTROID
Unlike ASTROID, DREBIN and MASSVET do not charac- determines which malware family the app belongs to. Since
terizethemalicecorrespondingtoaparticularmalwarefamily. some malware families are more malicious than others, the
Instead, they produce explanations for why a specific app ability to categorize different apps into malware families pro-
might be malicious. videsfiner-grainedinformationaboutthethreatlevelcompared
binary classification as malicious vs. benign. For instance,
ComparisontoDrebin.Theexplanationproducedby DREBIN some malware families merely affect user experience [43]
consists of a list of the features most indicative of malicious whereas others introduce financial risks by stealing user’s
behavior together with weights indicating their relative signif- personal account or credit card information [44].
icance. Figure 7 (middle) shows this list of top features and
correspondingweightsfortheGoldDreamfamily(obtainedby Disinfection. Since ASTROID pinpoints the malicious compo-
averagingoverallmembersofthefamily).Themostsignificant nents in the malicious app, it can be used to “disinfect” the
feature is the call to the suspicious API sendSMS. Only app by removing these malicious components.
15