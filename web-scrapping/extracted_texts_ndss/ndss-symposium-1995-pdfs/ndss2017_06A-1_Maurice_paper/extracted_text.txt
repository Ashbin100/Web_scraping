Hello from the Other Side: SSH over
Robust Cache Covert Channels in the Cloud
Cle´mentine Maurice∗, Manuel Weber∗, Michael Schwarz∗, Lukas Giner∗,
Daniel Gruss∗†, Carlo Alberto Boano∗, Kay Ro¨mer∗, Stefan Mangard∗
∗Graz University of Technology, † Microsoft Research
Abstract—Covert channels evade isolation mechanisms be- However, caches are currently quite small due to the price
tween multiple parties in the cloud. Especially cache covert of SRAM and its physical footprint on dies. They are a few
channels allow the transmission of several hundred kilobits megabytes at most, compared to gigabytes of main memory.
per second between unprivileged user programs in separate Cachesarealsosharedbetweenprocessesandbetweentenants
virtual machines. However, caches are small and shared and
in virtualized environments. Cache-based communication is
thus cache-based communication is susceptible to noise from
therefore susceptible to noise from any system activity and
any system activity and interrupts. The feasibility of a reliable
interrupts. Indeed, data gets unintentionally evicted by other
cache covert channel under a severe noise scenario has not
programs,e.g.,memoryintensiveprograms,theoperatingsys-
been demonstrated yet. Instead, previous work relies on either
of the two contradicting assumptions: the assumption of direct tem, and the hypervisor. In addition to this, operating system
applicability of error-correcting codes, or the assumption that and hypervisor scheduling is also a source of noise, as sender
noise effectively prevents covert channels. and receiver are not necessarily scheduled at the same time.
Noise causes substitution errors as well as synchronization er-
In this paper, we show that both assumptions are wrong.
rorssuchasinsertedanddeletedbitsincachecovertchannels.
First, error-correcting codes cannot be applied directly, due
Noiseisawell-knownproblemincacheattacks,butithasnot
to the noise characteristics. Second, even with extraordinarily
high system activity, we demonstrate an error-free and high- beenstudiedinmoredepththantheobservationofanincreased
throughput covert channel. We provide the first comprehensive error rate. Yet, some applications of covert channels require
characterization of noise on cache covert channels due to cache error-free communication, e.g., an SSH connection between
activity and interrupts. We build the first robust covert channel the two communicating parties.
basedonestablishedtechniquesfromwirelesstransmissionproto-
cols,adaptedforouruseinmicroarchitecturalattacks.Ourerror- Noisy communication channels are not a unique issue
correcting and error-handling high-throughput covert channel of CPU caches: there are many protocols and techniques to
cansustaintransmissionratesofmorethan45KBpsonAmazon
cope with noise in wireless protocols, such as error detection
EC2,whichis3ordersofmagnitudehigherthanpreviouscovert
and error correction schemes. Previous work on cache covert
channels demonstrated on Amazon EC2. Our robust and error-
channels relied on one of the two contradicting assumptions:
free channel even allows us to build an SSH connection between
the assumption that an error-correcting code can be directly
two virtual machines, where all existing covert channels fail.
applied, and the assumption that noise effectively eliminates
covert channels [5], [32].
I. INTRODUCTION
With the advent of cloud computing and virtualization, In this paper, we show that both assumptions are wrong.
CPU caches have been largely studied in terms of covert We show that caches offer some unique challenges in terms
channels. Covert channels are unauthorized communication of errors and how to deal with them at the protocol level.
channels between two parties, a sender and a receiver. The In particular, the fact that sender and receiver may not be
basis for cache covert channels is the difference in latency scheduled at the same time introduces synchronization errors.
for memory accesses, depending on whether data is cached or Thereceivercancompletelymissbitswhenitisnotscheduled,
not. Caches are well-suited for covert channels in virtualized and wrongfully read additional bits when the sender is not
environments, as they are not virtualized, and are thus shared scheduled. Sender and receiver have no trivial way to detect
acrossvirtualmachinesofasamephysicalmachine.Moreover, when the other process is not scheduled. In addition to this,
caches are a fast type of memory, shared across the cores of virtualized environments do not offer a synchronized clock
a CPU, and coherent between CPUs of the same machine. between sender and receiver.
Therefore,state-of-the-artattackshavemovedfromsame-core
to cross-core and even cross-CPU covert channels. We comprehensively characterize errors on cache covert
channels, and use this knowledge to build a robust error-
handling protocol. We thus show that even in the presence of
Permission to freely reproduce all or part of this paper for noncommercial heavynoiseduetohighsystemactivityincloudenvironments
purposes is granted provided that copies bear this notice and the full citation
our protocol still achieves a throughput of up to 45.09KBps
on the first page. Reproduction for commercial purposes is strictly prohibited
without the prior written consent of the Internet Society, the first-named author between two instances of Amazon EC2. Using our robust
(for reproduction of an entire paper only), and the author’s employer if the covert channel, we demonstrate a reliable SSH connection
paper was prepared within the scope of employment. between two virtual machines. This is not possible with any
NDSS ’17, 26 February - 1 March 2017, San Diego, CA, USA
previous covert channel between virtual machines, as even a
Copyright 2017 Internet Society, ISBN 1-891562-46-0
http://dx.doi.org/10.14722/ndss.2017.23294 minuscule error rate will prevent a sustained connection.To summarize, we make the following contributions: cache attacks, access-driven attacks are the most powerful
ones, where an attacker monitors its own activity to infer the
1) We comprehensively characterize noise on cache covert activity of its victim, and in particular which cache lines or
channels, due to cache activity and interrupts. cache sets the victim has accessed.
2) We propose a protocol that handles the physical layer
as well as the data-link layer of a robust cache covert Access-driven attacks can further be categorized into two
channel. types,dependingonwhetherornottheattackersharesmemory
3) We evaluate our covert channel between two virtual ma- with its victim, e.g., using a shared library or memory dedu-
chines on Amazon EC2 and obtain a throughput as high plication. Flush+Reload [43], Evict+Reload [13] and Flush+
as 45.25KBps, with 0% error rate. The communication Flush [12] all use shared memory, that is then shared in the
stays error-free in the presence of extraordinarily high cache, to infer whether the victim accessed a particular cache
systemactivity,whereweobtainbetween34.27KBpsand line. The attacker evicts data from the victim either by using
45.09KBps.Thisis3ordersofmagnitudefasterthanany theclflushinstruction(Flush+ReloadandFlush+Flush),or
previouslydemonstratedcovertchannelonAmazonEC2. accessing congruent addresses, i.e., cache lines that belong
4) Using our robust and error-free channel, we demonstrate to the same cache set (Evict+Reload). These attacks have a
an SSH connection between two virtual machines on very fine granularity (i.e., a 64-byte cache line), but they are
Amazon EC2, where existing covert channels fail. not applicable in any environment where shared memory is
not available. This is the case for some cloud providers, who
Section II presents the background and state of the art. disable memory deduplication for security concerns.
Section III describes the covert channel and the measurement
The second type of access-driven attacks, called Prime+
method, and introduces our problem statement. Section IV
Probe[26],[21],[19],doesnotrelyonsharedmemoryandis,
characterizesnoiseonthecache,bothduetocacheactivityand
therefore, applicable in more restrictive environments. As the
interrupts. Section V proposes our new protocol. Section VI
attackerhasnosharedcachelinewiththevictim,itcannotuse
evaluates the speed and robustness of our covert channel.
the clflush instruction but rather has to access congruent
Section VII gives a practical application: building an SSH
addresses to evict data from the victim. The granularity of
connection over our covert channel.
the attack is coarser, i.e., an attacker only obtains information
about which cache set the victim accessed, and is also more
II. BACKGROUNDANDSTATEOFTHEART
pronetonoise.Indeed,inadditiontothenoisecausedbyother
A. CPU Caches processes, the replacement policy makes it hard to guarantee
that data has actually been evicted from a cache set [11].
CPU caches are a type of memory that is small and fast,
In the remainder of this article, we focus on Prime+
that the CPU uses to store copies of data of main memory in
Probe, as it has the lowest requirements concerning execution
order to hide the latency of memory accesses. Modern CPUs
privileges and is more prone to noise than the other cache
have different levels of cache, typically three, varying in size
attacks.
andlatency:theL1cacheisthesmallestandfastest,whilethe
L3 cache, also called last-level cache, is bigger and slower.
C. Cache Covert Channels
ModernCPUsareset-associative,i.e.,acachelineisstored
in a fixed set, as determined by either its virtual or physical Table I summarizes state-of-the-art cache covert channels.
address. Each line can then be stored in any of the ways Thefirstcachecovertchannelhasbeentheoreticallyshownby
of this cache set, as determined by the replacement policy. Hu[16]in1992.Percival[26]wasthefirsttopracticallybuild
The L1 cache typically has 8 ways, and the last-level cache a covert channel on the L1 cache, and estimated the capacity
has 12 to 20 ways, depending on the size of the cache. The to 400KBps, “using an appropriate error-correcting code”.
replacementpolicyisacrucialelementfortheperformanceof Ristenpart et al. [30] were the first to build a cache covert
thecache.Forexample,forIntelCPUsuntilSandyBridge,the channel in a cloud environment, with 0.2bps between two
replacementpolicyhasbeenpseudoleast-recentlyused(LRU). virtual machines on Amazon EC2. Xu et al. [41] studied the
Since Ivy Bridge, this has changed and is now undocumented. disparitybetweentheoreticalandpracticalresults,inparticular
invirtualizedandnoisyenvironments.Fromaquiettoanoisy
Thelast-levelcacheisphysicallyindexedandsharedacross
environment, they showed a decrease of the bit rate from
cores of the same CPU. It is also inclusive of L1 and L2,
215.11bpsto81.19bps,andanincreaseoftheerrorratefrom
which means that all data stored in L1 and L2 is also stored
5.12% to 28%.
in the last-level cache. To maintain this property, every line
evicted from the last-level cache is also evicted from L1 and Covert channels on the last-level cache allow the sender
L2 caches. The last-level cache, though shared across cores, and the receiver to run on different cores of the same CPU.
is also divided into slices. The undocumented hash function Wu et al. [40] described the first cross-core covert channel
that maps physical addresses to slices in Intel CPUs has been using Prime+Probe on a Nehalem CPU and were followed by
reverse-engineered [23], [44], [17]. Maurice et al. [24] and Liu et al. [21] on more recent CPUs.
Gruss et al. [12] later demonstrated cache covert channels
using Flush+Reload and Flush+Flush. The authors built a
B. Cache Attacks
framework with a protocol to be able to compare different
Cache attacks are based on the difference of timing be- cache covert channels. The protocol includes retransmission
tween cached and non-cached memory. They can be applied in case the receiver did not receive a packet in order to
tobuildside-channelattacksandcovertchannelsalike.Among createalow-errorcovertchannel.However,itdoesnotinclude
2TABLE I: State-of-the-art cache covert channels. Bit rates have been converted to bytes per second for comparison.
Article Type Setup Bitrate Errorrate Remarks
Hu[16] – – – – Theoretical
Percival[26] Prime+Probe Native 400KBps – CovertchannelonL1,bitrateisanestimationwitherror-correctingcodes
Ristenpartetal.[30] Prime+Probe Cloud 0.025Bps – AmazonEC2
Xuetal.[41] Prime+Probe Virtualized 26.9Bps 5.12% Quietsetup
Xuetal.[41] Prime+Probe Virtualized 10.1Bps 28% Noisyenvironment:thirdVMadded
Wuetal.[40] Prime+Probe Native 23.8KBps – Errorratenotmeasured,NehalemCPU
Mauriceetal.[24] Prime+Probe Native 129.1Bps 1.6% Quietsetup,noprotocol,receiverdecodesbitsoffline
Mauriceetal.[24] Prime+Probe Virtualized 93.9Bps 5.7% Quietsetup,noprotocol,receiverdecodesbitsoffline
Liuetal.[21] Prime+Probe Virtualized 75KBps 1% RZself-clockingencoding,busywaitbetweenbits
Grussetal.[12] Prime+Probe Native 67KBps 0.36% Quietsetup,5Bpackets,1Bsequencenumber,CRC-16checksum
Grussetal.[12] Flush+Reload Native 298KBps 0.00% Quietsetup,28Bpackets,1Bsequencenumber,CRC-16checksum
Grussetal.[12] Flush+Flush Native 496KBps 0.84% Quietsetup,28Bpackets,1Bsequencenumber,CRC-16checksum
error-correcting codes and has not been evaluated in a noisy eitherviaanacknowledgment(ACK)oritscounterpartnegative
environment. Yet, with noise, the retransmission rate will ACK (NACK). To detect bit errors, parity bits are added to
increase, and the bit rate will decrease. each packet by the sender. The receiver then checks if all the
parity equations are fulfilled. If so the incoming transmission
The fastest Prime+Probe cross-core covert channel in the
is valid. Another approach is to detect the presence of noise,
literaturereportsabitrateof75KBpsfora1%errorrate[21].
e.g., an ongoing concurrent transmission, before starting to
However, note that the error rate is calculated using an
send. This avoids colliding with either ongoing transmission
edit distance, i.e., counting the minimum number of single-
or channel activity strong enough to corrupt and destroy the
character edits, including insertion and deletion, to transform
messagebeingsent.Ifso,thesenderpostponesitstransmission
onestringintoanother.Yet,insertionanddeletionerrorscause
for a certain time, which increases with every successive
numeroussubstitutionerrors,whichcannotbecorrectedbyan
postpone, up to a maximum when the packet is dropped.
upper layer in a protocol. Thus, the practical utility of such a
This approach, typical to wireless communication, is known
covert channel is severely limited.
as carrier sense multiple access. A third approach is to avoid
noiseonthechannelaltogetherbyusingachannelwhichisnot
D. Countermeasures Against Cache Covert Channels inuseyetorchangingthecommunicationchannelperiodically.
This approach is known as channel hopping. Even though this
Thetechniquesusedtobuildcacheattacksarethesamefor
method evades much temporal interference and is far more
covert channels and side-channel attacks. Thus, both share the
resilient than just retransmitting, it is not always possible.
samecountermeasures.Thecountermeasurescantargettiming
sourcesbyeitherremovingthemormakingthemmorecoarse-
If sender and receiver are not synchronized well, a differ-
grained.Theycanalsotargetthetimingdifferencesthemselves
ent category of errors occurs: synchronization errors. If the
by either removing them or introducing noise such that they
receiver’s sampling rate is too high, the receiver reads more
are not exploitable anymore.
symbols than the sender has sent. If the sampling rate is
too low, i.e., the sender transmits faster than the receiver is
Countermeasures introducing noise include Du¨ppel [46], a
able to sample, some symbols are not seen by the receiver.
kernel component that cleanses private caches by priming all
It is necessary to deal with these errors first, as they often
thesetsuntiltheentirecachehasbeenevicted.Thiscomponent
make other measures taken against noise unusable, causing
has been created to cleanse shared-time caches, on CPUs
too many substitution errors. Methods against synchronization
not equipped with simultaneous multithreading (SMT). As
errors include sampling more often to increase certainty about
it targets private caches, it defends against same-core cache
the measured signal or using a coding scheme which includes
attacks, and would need to be modified to defend against the
timing information (e.g., Manchester coding). One adopted
newer cross-core cache attacks on the last-level cache, where
countermeasure is to slow down communication sufficiently
thespyandthevictimcanrunconcurrently.FuchsandLee[9]
to achieve reasonable synchronization. It is also possible to
propose to add a randomized prefetching policy that performs
add redundancy to messages to recover from single bit syn-
additional memory accesses and makes the behavior of the
chronization errors, but this is ineffective against burst errors
cache less predictable. Brumley [5] and Schmidt et al. [32]
and deletion or insertion of whole bytes [25]. Therefore, a
also cite noise as a countermeasure against covert channels.
basic form of synchronization must exist before these codes
Adding noise to caches has also been investigated on the are applicable. Wireless sensor networks also suffer from
attacker side to improve attacks. Indeed, Gruss et al. [13] and synchronizationproblems:Duetotheirgoaltosaveenergy,the
Allan et al. [1] have shown that by constantly flushing data, sensor nodes switch on their radios only for short periods of
anattackercanslowdownanencryptionprocessandtherefore time to check for incoming transmissions. This is called radio
amplify side-channel leaks to get more information. duty-cycling. To make resynchronization easier, the sender
starts transmissions with a specific pattern, called preamble,
E. Efficient Protocols For Noisy Channels before sending the actual data [6].
There are different possibilities to handle transmission er- Shannon’stheorem[33]statesthatitispossibletocompute
rorsinacommunicationchannel.Afirstapproachistoretrans- the maximum capacity of a channel and to achieve error-free
mitadatapacketuntilitssuccessfularrival,whichisindicated transmission through a noisy channel if the data is sufficiently
3encodedandthenoiseisnottoostrong.Sincetheintroduction
·107
of this theorem, the community has been developing codes
to either detect and correct errors in data transmission. With
error detection codes, the message is augmented with extra
1
redundancy bits in order to detect errors, also called parity
bits. There are also special codes that can detect all bit flip
errors, such as the Berger codes [2], which have been used
0.5
in ECC RAM. Error-correcting codes comprise block codes
and convolutional codes. With block codes, fixed-sized blocks
are encoded using methods such as the Reed-Solomon codes
0
[29]. Although quite old, Reed-Solomon codes were the most
60 160 260 360 460 560 660 760 860
widely used error-correcting codes [39] and are still used
Accesstime[CPUcycles]
today, e.g., for correcting errors in Android verified boot [35].
Classical block codes are deterministic and perform well,
even without dedicated hardware. Convolutional codes use
additional information about received symbols in the form of
probabilities, which are then used to find the word which was
most likely transmitted. While being introduced rather early
[10],[38],thesecodesrequiresignificantcomputationalpower
and have started to be used only recently. These codes benefit
greatly from dedicated hardware and are used in today’s latest
communicationtechnologies.Examplesarelow-densityparity-
check codes and turbo codes [3].
Often, more than one code is used to enable better error
correction capabilities. This technique is called concatenation.
One error-correcting code is applied to the words which are
transmitted, while another code is applied to the packet. In
addition, the encoded data can be interleaved such that burst
errors do not destroy blocks that are too big to correct.
F. Operating System and Hypervisor Scheduling
On modern computer systems, the number of processes
exceeds the number of cores and processors by far. Thus, it is
still necessary to run time-sharing algorithms that frequently
interrupt the process running on a CPU core to hand over
control to another waiting process. Besides hardware inter-
rupts originating from I/O devices and software interrupts
such as page faults, the most frequent interrupt source are
timer interrupts mostly used for scheduling. These scheduling
interrupts can be periodic or deadline driven (e.g., earliest-
deadline first) [18]. If the hardware is configured to issue
periodic timer interrupts, the timer interrupts will occur at
a constant frequency that is fixed to real time and does not
depend on the actual speed of the CPU. With deadline driven
timer interrupts, the operating system sets a number of CPU
cyclesafterwhichtheinterruptwilloccur.Onmodernsystems,
theinterruptfrequencyistypicallyintherangeof1Hzto1000
Hz [7], [31]. Similarly to the operating system, hypervisors in
cloudsystemsusetimerinterruptstocontroltheschedulingof
the different virtual machines.
Scheduling has also been exploited for microarchitectural
attacksandinstrumentedforcountermeasuresagainstmicroar-
chitectural attacks. Gullasch et al. [14] exploited a flaw in
the deadline-driven “completely fair scheduler” of Linux to
reducethetimethevictimgetsscheduledtoaminimum.Thus,
they were able to measure the cache footprint of the victim
applicationatamuchhigherfrequency.Varadarajanetal.[36]
instrumentedthe schedulerof ahypervisorto preventfrequent
context switches between an attacker virtual machine and a
victim virtual machine.
sesacforebmuN
‘0’received ‘1’received
Fig. 1: Histogram for time taken to receive ‘0’s and ‘1’s.
III. PROBLEMSTATEMENT
In this Section, we describe our Prime+Probe covert chan-
nel, the challenges we face in making it robust, and in
particular the type of errors we encounter.
A. Description of the Covert Channel and Measurements
At a high level, the sender transmits bits by evicting cache
lines from the receiver. The receiver constantly probes a set in
his L1 cache. These cache lines are also present in the last-
levelcacheduetotheinclusiveproperty.Totransmita‘0’,the
sender does nothing. The lines thus stay in the L1 cache of
the receiver, which thus observes a short timing to probe its
lines.Totransmita‘1’,thesenderaccessescachelinesthatare
mappedtothesamesetinthelast-levelcacheasthereceiver’s.
The lines of the receiver are thus evicted from the last-level
cache,andconsequentlyfromtheL1cacheduetotheinclusive
property.Thereceiver thusobservesalongtiming toprobeits
lines, as they have to be retrieved from the DRAM.
Prime+Probe cache covert channels are based on timing
information, i.e., whether a received bit is a ‘0’ or a ‘1’
depends on the timing difference measured over a defined
set of memory accesses. The measurement itself thus takes
a different amount on time depending on the bit that is
transmitted.Moreover,cachehitsandcachemissesthemselves
have varying timings, influenced by a multitude of factors
such as unrelated system activity. Thus, the timing difference
measured also varies independently of the actual bit that is
transmitted, due to the memory accesses that are performed.
Figure 1 shows a histogram of the measured time for the set
of memory accesses when the sending party transmits a ‘0’
or a ‘1’ on an Intel Core i7-4790. While the two cases are
clearlydistinguishable,theexacttimemeasuredvarieswidely.
If a ‘0’ is transmitted, the access time is between 120 and
240 cycles in 93.59% of the cases. In 5.78% of the cases, the
access time was above 300 cycles due to noise. If a ‘1’ is
transmitted, the access time is between 380 and 800 cycles in
86.51% of the cases. In 8.25% of the cases, the access time
was below 300 cycles due to the cache eviction performed by
the sender process being unsuccessful or sender and receiver
evicting simultaneously.
The sender and receiver processes run independently and
have no way of communicating apart from the covert channel.
4Sender 1 0 0 1 1 0 1 1 0 Sender 1 0 0 1 1 0
Receiver 1 0 0 1 1 0 1 1 0 Receiver 1 1 0 1 1 0
(a)Transmissionwithouterrors.Sendersends100110,receiver (b) Substitution error due to noise on the cache. Sender sends
receives 100110. 100110, receiver receives 110110.
Sender 1 0 0 1 1 0 Sender 1 0 0 1 1 0
Receiver 1 0 0 0 0 0 1 1 0 Receiver 1 0 0
(c) Insertion errors due to the sender descheduled during trans- (d) Deletion errors due to the receiver descheduled during
mission.Sendersends100110,receiverreceives100000110. transmission. Sender sends 100110, receiver receives 100.
Fig. 2: Illustration of a normal transmission and the three different types of errors. Dashed lines represent the time when either
the sender or the receiver is not scheduled.
Thus,thesendercannotdeterminehowmanycyclesittookthe Insertion errors and deletion errors are synchronization
receiverprocesstomeasurethetransmittedbit.Hence,theop- errors that are due to the changing sampling rate of both
erations of the two processes are inherently not synchronized. the sender and the receiver. These errors are caused by
scheduling and are therefore burst errors. Synchronization
errors further complicate the problem, causing a dramatic
B. Measurement Errors increaseinsubstitutionerrorsuntilthenextsynchronization—
if any—, as the receiver has the wrong symbol boundaries. It
There are mainly two sources of errors in cache covert
is, therefore, necessary to first correct synchronization errors
channels. First, the cache is a resource shared with other
before substitution errors.
programs. It is a rather small memory, thus data gets evicted
by other concurrent programs. As eviction is also used by the
C. On the Absence of a Common Clock
sender to transmit a bit, a heavy use of the cache creates
interferences with the covert channel in the form of false Inanativeenvironment,covertchannelsbetweenprocesses
positivesforthereceiver.Itcanalsointroducefalsenegativesif can be synchronized based on a common clock, such as
the eviction is not successful. These kinds of errors are called the time stamp counter. The time stamp counter provides
substitutionerrors.Second,senderandreceiverarenotalways a high-resolution timestamp which is accessible through the
running simultaneously, depending on the scheduler. As they unprivileged rdtsc instruction. This cycle count can be used
have no way of signaling that they are either not transmitting for highly accurate measurements even on a sub-nanosecond
or not receiving any bits, this results in insertion or deletion scale. While it is sometimes assumed that such a common
errors on the receiver’s end. clock exists in cloud environments as well, this is in fact not
the case for security and compatibility reasons. For instance a
Theseissuesresultinthreedistincttypeoferrors.Figure2
virtualizedrdtsccanmakesandboxdetectionmoredifficult.
illustrates a normal transmission and the effect of errors.
At the same time virtualizing rdtsc incurs wide deviations
Substitution errors: Another program causes eviction of the whencomparedinsidetwoindependentvirtualmachines.This
receiver’s lines, resulting in ‘0’ → ‘1’ bit flips. Substitution is due to the fact that the rdtsc base offset is frequently
from ‘1’ → ‘0’ happens when the sender unsuccessfully adapted by the hypervisor to account for interrupts [22].
evicted the set. Hypervisor interrupts are sometimes completely hidden from
thevirtualmachine,i.e.,thetimestampcounterisnotupdated.
Insertion errors: The sender is interrupted or not scheduled, In fact, there is typically no common clock apart from very
while the receiver still continues its measurements. The re- coarse-grained clocks in the range of milliseconds. Even here
ceiver will read consecutive ‘0’s while the sender is being clock deviation can occur, depending on the hypervisor.
descheduled.Ifnothandledcorrectly,thereceiverwillcontinue
In order to reliably transmit and receive data, the com-
to put the incoming transmission after the block of ‘0’s,
municating parties do not require a synchronized clock. The
resulting in corrupted data after the first appearance of this
clock does not deviate as long as the current party is running,
kind of error. Insertions of ‘1’s are possible in the case where
but the clock can deviate as soon as the communicating party
there is a lot of noise, but this happens less than insertions of
is descheduled. Wireless sensor networks have to deal with
‘0’s.
similar problems, as the sending party often does not know if
Deletion errors: The receiver is interrupted during measure- its communication peer is awake. The communicating parties
ment, which leads to a sequence of bits never being read and using the cache covert channel have the problem that they are
lostwithoutbeingnoticed.Ifnothandledcorrectly,thesender switched off seemingly randomly, in contrast to sensor nodes,
willcontinueasifnothinghappened;theresultwouldbefaulty which decide themselves when they switch off their radios.
data beginning from the first occurrence of this error. Therefore, due to the emulated rdtsc and scheduling, we
5Algorithm 1: Creating a heatmap
TABLE II: Experimental setup.
input : nb sets: int, nb ways: int, threshold: int,
Environment CPUmodel Cores LLCassociativity nb measure: int,
Lab Corei5-5200U 2 12 pointers: uint64 t[nb sets][nb ways]
Lab Corei7-4790 4 16 output: expected: double[nb sets]
Lab XeonE3-1220v3 2 16
AmazonEC2 XeonE5-2670 8 20 cases ← new int[nb sets][nb ways +1];
expected ← new double[nb sets];
for 1..nb measure do
need to resynchronize during communication, while sensor for s←0 to nb sets do
nodes only need to synchronize once and note the wake-up misses ←0;
time of its peer. for l←0 to nb ways do
Intuitively, a common clock might solve these problems. time ← probe line(s,l);
Generally the transmitted signal can be used to derive a if time >threshold then misses++ ;
common clock or also transmit a clock signal. However, the cases[s][misses]++;
transmission of a common clock would suffer from the same
issuesasthetransmissionofthedataitself.Theonlypossibility for s←0 to nb sets do
would be to transmit a self-clocked signal, which also needs for l←0 to nb ways +1 do
to be resilient against noise. Thus, the transmission of a clock expected[s]+=l×cases[s][l]/nb measure;
signal is possible but causes a huge overhead. As described
in Section III-B, sender and receiver can run simultaneously,
but due to interrupts and scheduling, there are phases where
one process is active but not the other. If the sender transmits
IV. CHARACTERIZINGNOISEONTHECACHE
a clock signal and the receiver misses multiple clocks, the
receiver cannot detect this error. Similarly, the sender has no In this Section, we characterize the noise on the channel
way to detect that the receiver was sleeping. Thus, additional due to cache activity of other programs as well as interrupts.
bits would need to be transmitted to reduce the probability of
errors in the clock signal.
A. Characterizing Eviction by Other Programs
D. Problem Statement
We first characterize unwanted cache line evictions due
While many of the errors that are encountered on our to cache activity of other programs. Heatmaps have already
channel have already been solved in communication engineer- been used to find cache usage patterns on the L1 cache [46],
ing and information theory, there is no readily usable design [36], [9]. We propose a new heatmap to help to determine the
to solve the particular issues of our channel. Moreover, we parameters of the covert channel, by computing the expected
are aiming at a high capacity channel, while minimizing the value of the number of evicted cache lines for every set of the
complexity of the protocol. It is, therefore, impossible to just last-level cache.
apply error-correcting codes as was hinted in previous work.
To do so, we run a Prime+Probe attack on all sets, as
As we cannot influence noise or synchronization issues described in Algorithm 1. We start with an array of addresses
on our channel, we apply existing methodology for wireless mapping to every set, with nb ways addresses per set. We
communication. We start by characterizing noise on the chan- probe all addresses mapping to one set, and measure the
nel, both due to other applications and the scheduler. We then probing time of each line to determine if it is a hit or a
designaprotocolthatiscapableofcorrectingtheseerrorsand miss. We thus count the number of evicted lines for each
evaluate our covert channel in high-noise environments. set. The probing function probe_line first accesses a line,
then waits for some time, so that other programs have the
E. Experimental Setups
time to evict it, and finally times the access of this line. The
In the remainder of the article, we use the experimental waiting time is performed using the sched_yield() Linux
setups described in Table II. function. We repeat this procedure for every set, and repeat
the measurements over all sets to compute probabilities of the
For our experiments in a cloud environment, we used
number of cache lines evicted, and subsequently the expected
AmazonEC2g2.2xlargeinstances.Recentworkshavealready
value for each set.
shown how to acquire co-located instances with a victim [37],
[42], [17]. As the co-location step is not in the scope of TheheatmapofthreescenarioscanbeseeninFigure3,for
our paper, we obtain co-located instances by performing our an i5-5200U, with 10240 measurements. The expected value
experiments on a dedicated host. The g2.2xlarge instances is on average 0.38 on a quiet system, 3.89 while watching a
are backed by 8 vCPUs from an Intel Xeon E5-2670, which 1080p video, and 10.41 while running stress -m 2. We
correspondsto8hardwarehyperthreadsaccordingtoAmazon. observe that noise is equally distributed over all sets (i.e., the
The larger instance of this family, g2.8xlarge, has 32 vCPUs. varianceisverylow),andthatasexpected,themorememory-
As a Xeon E5-2670 has 8 cores, and it is possible to fit 32 intensive the application, the higher the expected number of
hardware hyperthreads on a single machine, we speculate that evicted cache lines. This metric can be used both to measure
one machine is composed of 2 CPUs, and we run 3 instances the noise caused by other applications on the cache and to
on the same host. choose parameters for the covert channel.
6(a) Quiet system: (b) Watching a 1080p video: (c) Running stress -m 2:
mean = 0.38, mean = 3.89, mean = 10.41,
variance = 0.016. variance = 0.0043. variance = 0.0010.
Fig. 3: Heat maps of the expected value for the number of lines evicted by other programs in 3 scenarios, on an i5-5200U
(12-way cache). Small square represent last-level cache sets. The height of a square represents the number of evicted lines.
The heatmap gives us a good visual indication of the kind spacecommunication[20].Themodelappliestocacheattacks
of noise. However, to choose optimal error-correcting codes, as well, as there are no physical effects generating noise.
we are interested in a mathematical model of the noise. The
One important property of Gaussian noise is that the
overall noise in a cache set is a summation of different noise
noise is independent of the data. As the sender and receiver
sources.EachprogramrunningontheCPUaccessesthecache
access the cache as well, it seems that we cannot guarantee
in an unpredictable manner, i.e., the access pattern appears
this property. Inevitably, there will be sets containing data-
to be random for an observer. According to the central limit
dependent values. However, as they form only a subset of all
theorem, the summation of a large number of random effects
available cache sets, we will always be able to use sets that
will be approximately normal [8]. Assuming that the noise is
are independent of the data.
Gaussian is, therefore, a valid assumption in this scenario.
The exact location of data inside a cache is determined Modeling the background noise as AWGN is a common
by its address and consequently also the cache slice function. principle in wireless sensor networks. Most of the research in
As programs have no control over these parameters, the theareaofwirelesscommunicationviewAWGNasastandard
data is uniformly distributed over the cache. The heatmap model to characterize wireless transmission. AWGN is the
visualization shows that this is indeed the case for the em- worst-case additive noise in general wireless networks if the
pirical experiments. Therefore, we assume that the cache sets noise is independent of the transmitted data [34]. Having a
are independent and identically distributed random variables. robust communication over this channel guarantees that the
Underthisassumption,itissufficienttoanalyzeonlyonecache communication will work in all other noise scenarios at least
set to characterize the noise. aswell,aslongastherearenobursterrors.However,tohandle
burst errors, encoded packets can be interleaved.
Similar to the heatmap, we analyze one set over time.
At discrete time intervals, we determine the number of lines
B. Characterizing Interrupts
that have been evicted from the cache set. If this number
is higher than our threshold for sending a bit, the set is Asalreadydiscussed,schedulingintroduceseitherinsertion
“destroyed” by noise, represented as −1 in the time series. or deletion errors. These errors are in all cases burst errors.
In contrast, if fewer lines are evicted, the set is usable for
transmission, represented as 1 in the time series. Applying the Hardware interrupts are always handled in kernel space.
autocorrelation function ρ(τ) on this data reveals underlying Thus, control is handed to a kernel thread for some time,
noisepatterns.Werepeatedthisanalysisformultiplecachesets just as regular scheduling interruptions. Therefore, we do not
overvaryingtimespans.Asaresult,ρ(τ)wasalwayszerofor distinguish between hardware and scheduling interrupts.
non-zero τ. Given these empirical results, we can assume that
The frequency of the Linux process scheduler influences
the observed signal is white noise.
the running time after which a process is interrupted. This
The Gaussian white noise generated by processes running frequency depends on several kernel parameters, such as
on the same CPU is always present in our channel. We CONFIG_NO_HZ or CONFIG_HIGH_RES_TIMERS. We de-
can model the background noise as additive white Gaussian rivethemaximumtimerinterruptfrequencybyrequestingsuch
noise (AWGN). An AWGN channel does not account for interrupts and measuring their time difference. This gives the
differentnoisesourcespresentinwirelesscommunicationsuch highest frequency we have to expect for scheduling interrupts.
as fading, dispersion or interference. However, if these effects DependingontheCPUmodel,weobservefrequenciesofupto
play no role, the model is sufficient to describe the noise [15]. 1MHz. In order to calculate the average length of a desched-
The absence of such physical effects makes the AWGN an uled phase, we require the average scheduling frequency. We
accuratemodel.Real-worldapplicationscanbefoundindeep- readthenumberofschedulessfrom/proc/self/status
780
60
40
20
0
0 20 40 60 80 100
CPUusage(%)
)dnocesrep(sehctiwstxetnoc
1
0.1
0.01
)sm(emithctiwstxetnoc.gva Algorithm 2: Sender transmitting a ‘1’
input: nb ways: int, addrs: int[nb ways]
for i←0 to nb ways −1 do
*addrs[i];
*addrs[i+1];
*addrs[i];
*addrs[i+1];
Fig. 4: Number of schedules and average scheduling times at
different CPU loads. Algorithm 3: Receiver accessing a set.
input: nb probes: int,
addrs: int[nb probes]
after a fixed time t. We observe an average scheduling fre- for i←0 to nb probes −2 do
quency of 85Hz. During the time t we measure the CPU time *addrs[i];
t of the process, i.e., the time the process actually runs *addrs[i+1];
CPU
on the CPU. The average length of the descheduled phase is *addrs[i+2];
then t
schedule
= t−tC sPU. * *a ad dd dr rs s[ [i i] +;
1];
The length of the descheduled phase is heavily affected *addrs[i+2];
by the current CPU usage. The time a process is not running
on the CPU is directly proportional to the number of active
processes. Figure 4 shows the results of measurements con-
ducted on an Intel Core i7-4790. For low CPU utilization, the can reliably detect incoming transmissions. Additionally, it
length of an average descheduled phase is 10µs. The time our has to take decisions about the encoding on the medium
programisnotscheduledisbelow1mseachsecond.Forhigh itself as well as dealing with synchronization errors. Words
CPU utilization, the length of a descheduled phase increases consists of multiple symbols (single bits) that are transmitted
to several milliseconds. At a scheduling rate of 85 schedules simultaneously.
per second, the process is not running for several hundred
1)Transmitting a symbol: Transmitting and receiving bits
milliseconds per second.
relies on priming and probing lines of set associative caches.
In a quiet environment, one solution to prevent errors Ingeneralinwirelesscommunication,notonlyonebutseveral
caused by not being scheduled is to increase the transmission bits per symbol are transmitted using different modulation
time of one bit. If the transmission time exceeds the time it techniques, such as amplitude modulation, phase-shift keying
takes to get re-scheduled, no bit is lost. The average length of orfrequencymodulation.Thesemethodsarenotavailabledue
a descheduled phase requires a minimum transmission time of to the nature of the signal and the unreliable clock.
10µs for one bit, resulting in a maximum transmission speed
To transmit any information, the sender primes lines in
of 100,000 bits per second. For higher CPU utilization, i.e.,
one last-level cache set. It has to prime enough lines in order
undernoise,thiswouldagainintroducesynchronizationerrors
to actually evict the receiver’s lines inside the same last-level
and therefore require even slower transmission speeds. Hence,
cache set, leading to an eviction from the receiver’s L1 cache
we will instead ensure that a word is sufficiently small to be
set. Depending on the number of lines evicted from the L1,
transmitted during one scheduling.
the receiver could then infer which symbol was transmitted.
The minimum of information to transmit is either achieving
V. ROBUSTCACHECOVERTCHANNELS
eviction (‘1’) or not (‘0’). The sender does not need to evict
ThisSectioncontainsthedescriptionofthecommunication all lines of this last-level cache set, as the L1 has fewer ways
protocol we developed for the covert channel, first on the than the last-level cache. However, there is no way for it to
physical and then on the data-link layer. The data-link layer know which lines of the last-level cache are present in the L1
receives a buffer with data which is to be transmitted. Before cachesetofthereceiver.Inpractice,wefoundthattheoptimal
transmissionstarts,thedataisdividedintochunksofthesame numberoflinesprimedbythesenderisthenumberofwaysin
size, which are afterwards enhanced with error correction, the last-level cache. Since Ivy Bridge, the replacement policy
resulting in a packet. Then transmission is started, where each is not pseudo-LRU anymore. To increase the probability of
packet is divided into words small enough to be transmittable evicting the set, we access cache lines with the same patterns
easily in between scheduling. These words are then again as described by Gruss et al. [11]. Algorithm 2 describes set
encoded to guard them against synchronization errors. The eviction.
whole encoding process can be seen in Figure 5 including the
To receive any information, the receiver probes nb probes
requests sent on the physical layer. We will explain in detail
lines in one L1 cache set. At the minimum, the receiver has
how every layer works in the remainder of the section.
to probe one line. Using more lines opens up the possibility
to transmit more data through one set. Intuitively, probing all
A. Physical Layer
L1linesandcountingthenumberofevictionsseemstobethe
Thephysicallayerisconcernedwithtransmittingwordsas best way to achieve the maximum of bits per symbol, but it
asequenceof‘0’sand‘1’s.Ithastomakesurethatthereceiver incurstheriskofhavinginterferenceswithlinesbeingevicted
8to L2 and last-level cache. This can happen either because physical addresses1. We call a slice physical index the slice
of the sender itself probing more than 8 lines—as the L1 index computed with the addressing function on all bits of the
is 8-way associative—or because of other programs even in physicaladdress.Knowingonlyavirtualaddress,wecompute
the case the receiver probes less than 8 lines. However, even theslicevirtualindexbytruncatingthe21leastsignificantbits
at a lower number of lines probed, counting the number of of the address and applying the reverse-engineered addressing
evicted lines proved to be too unreliable to infer more than 1 function.Insidea2MBpage,alladdresses thathavethesame
bit of information as self-eviction and interference by other slicevirtualindexbelongtothesameslice.Toeachpair(page,
programs introduced too much uncertainty. Therefore, only slice virtual index) corresponds a slice physical index. The
one bit per cache set or symbol is transmitted. In practice, goal is to find the virtual index for each page, such that it
we fixed nb probes = 5. The decision whether a value of 0 corresponds to the same physical index for all pages, without
or a value of 1 was transmitted is based on the number of knowing this physical index.
CPU cycles (cf. Section III-C) the memory accesses take. The
The following notations hold for a CPU with c cores and
memoryaccessesaredoneinthesamefashionasthereceiver,
a w-way last-level cache:
by accessing memory lines in a certain pattern, as shown in
Algorithm 3.
– p is a 2MB page.
– i is a set index, irrespective of the slice.
2)Transmittingwords: Inordertoincreasethecapacityof – j is a slice virtual index.
thecovertchannel,wecanusespatialmultiplexingtotransmit – S is the set of addresses in a page p, that belong to the
p,i,j
multiple symbols (bits) of a word concurrently. We do so by same cache set, i.e., that have the same cache set index i
exploitingthe different cachesets,whichdo notinterferewith and slice virtual index j. |S |=n .
p,i,j a
each other. In this setup, each channel is used to transmit – Sr is the probe set in the reference page p, composed of
i,j r
one bit, either a ‘0’ or a ‘1’. The total number of symbols addresseswiththesamesetindexiandslicevirtualindexj.
per word depends on the error detection codes that we apply. Itissufficientthatthissetiscomposedoftwoaddresses.The
The order of the bit fields is the order in which the sets are addresses of the probe set must be evicted by the eviction
probed. Spatial multiplexing is a difference with the covert set, ensuring that we obtain addresses with the same set
channel of Liu et al. [21], where only two sets are used, one index in the same physical slice.
to transmit ‘1’s exclusively, and the other ‘0’s exclusively. In – Se is the eviction set for i and j, i.e., the set of addresses
i,j
order to introduce further reliability, the receiver reads every evicting Sr . Given a set Sr , we thus seek to build the
i,j i,j
word several, odd number of times and does a majority vote set Se .
i,j
on each symbol.
P is the set of allocated 2MB pages, i.e., p ∈ P with
To avoid triggering the prefetcher and unintentionally |P|=n . We exclude the reference page p from P. I is the
p r
prefetching a line in another set, both the sender and the set of set indices, irrespective of the slice, i.e., i ∈ I with
receiver must access lines that are in different 4KB pages, as |I| = 32. Indeed, to ensure that each address belongs to a
the hardware stride prefetcher does not prefetch lines across different 4KB page, we only target sets that have addresses
page boundaries. The sender thus avoids to unintentionally aligned to 4KB. There are 2048 set indices per slice, i.e., 32
prime a set that should not be primed, which could cause the different sets aligned with 4KB pages—independently of the
receiver to receive a ‘1’ instead of a ‘0’. The receiver also number of cores. There are 16 addresses having the same set
avoidsprefetchingalinethatitcouldprobeafterwards,risking index i per 2MB page, i.e., n =16/c addresses belonging to
a
receiving a ‘0’ instead of a ‘1’. thesetindexiinthesameslice.Wethereforeneedtoallocate
n =(cid:100)w/n (cid:101) pages to obtain an eviction set of w addresses.
p a
3)Setagreement: Senderandreceivermustagreeonwhich
J isthesetofslicevirtualindices,i.e.,j ∈J with|J|=c.
sets to use to transmit words. The main challenge to this part
As we do not have the knowledge of all bits of the physical
is that an unprivileged process — or a process in a virtual
address, the slice virtual indices are different for every 2MB
machine — cannot translate virtual addresses to physical
page. For example, if an address a in the reference page p,
addresses, and therefore cannot target a specific set index in r r
an address a in a page p and an address a in a page p
a specific slice. As noted by previous work, it is still possible 1 1 2 2
all belong to the same slice physical index 1, it is possible
for an unprivileged process to target a set index, irrespective
that the virtual index for a is 0, the one for a is 2 and the
oftheslice,using2MBpages[19],[21].Indeed,a2MBpage r 1
one for a is 3. As the indices in themselves are irrelevant,
givesthe21leastsignificantbitsofaphysicaladdress,asthey 2
we take as a reference the virtual indices of addresses in the
are then the same for virtual and physical addresses. The set
referencepagep.Wethusseektofindthecorrectiveoffseto
agreement is done in two steps: (1) both the sender and the r p
to apply for each page p, so that the slice virtual index j on
receiverperformthesameproceduretobuildevictionsets,(2)
page p and the slice virtual index j on the reference page p
they perform an agreement to ensure that they both target the r r
correspond to the same slice physical index. In our previous
same set in the same slice.
example, o =2 and o =3.
p1 p2
Inthefirststepofthesetagreement,boththesenderandthe We build an eviction set Se for a fixed set index i and
receiverselectcandidateaddressesthatformevictionsets,i.e., the slice virtual index j =0.
Wi e,jr
start by constructing the set
r
addressesthatbelongtothesamesetinthesameslice,without of candidate addresses Sc , which is our test eviction set. We
i
knowing which exact slice. We describe a new method that
uses the information given by the reverse-engineered function 1If the last-level cache addressing function is unknown, it is possible to
from Maurice et al. [23] without privileges, i.e., without using reverttothemethodofLiuetal.[21]whichassumesnopriorknowledge.
9have Sc ={S |p∈P,j ∈J}, with |Sc | = n ×c. By
i p,i,j i p TABLEIII:Speedofsetagreementinnativeenvironment(i7-
construction, this set contains the addresses of the eviction set
4790) and between 2 instances of Amazon EC2, on 100 runs.
thatwearesearchingfor,aswellasmoreaddressesthatbelong
to the same set index, but a different slice. We seek to remove
Average Standard
these additional addresses to build an optimal set. Thus, for Environment speed(s) deviation Noise
one page p and set index i, we remove one set S of n
p,i,j a Native 0.30 0.03 –
addresses from Sc i. We then test the eviction of the probe set Native 0.40 0.02 stress -m 1
withthissmallertestevictionset.Ifevictionsucceeds,thenthe AmazonEC2 2.62 0.15 –
AmazonEC2 2.74 0.22 stress -m 1onthesenderVM
set S is not part of the final eviction set, and we remove
p,i,j AmazonEC2 3.47 0.38 stress -m 1onthereceiverVM
it from the test eviction set. For one page, we remove sets AmazonEC2 2.95 0.27 stress -m 4onthethirdVM
S testingallpossiblevaluesforj untiltheprobesetisnot AmazonEC2 – – stress -m 8onthirdVM
p,i,j
evicted anymore. We have then found one set S ∈ Se ,
p,i,j i,jr
i.e., the set of addresses for the page p belonging to the final
eviction set for the set index i. We repeat this procedure for cannot distinguish intensive noise on a cache set from cache
all pages p∈P, until we have the final eviction set Se . We misses induced by the other party.
i,jr
can compute the corrective offset o for page p, o =j⊕j,
p p r 4)Handling Synchronization Errors: The covert channel
with S ∈Se . As we have fixed j =0, we have o =j,
p,i,j i,jr r p suffersfromthethreedistincterrorsdescribedinSectionIII-B
and we can now compute the eviction sets for other values of
of which two are due to synchronization issues described in
j and i.
r Section IV-B.
In the second step of the set agreement, the sender and
Deletion errors: Deletion can only appear if the receiver is
the receiver ensure that they both target the same sets using
descheduled while the sender continues to transmit. Therefore
jamming agreement, inspired by the method of Boano et al.
we apply a simple request-to-send scheme that also serves
[4] in wireless communication. The sender and receiver both
as acknowledgment. Every word contains a 3-bit sequence
have a set of eviction sets. As every slice virtual indices
number, which is used to avoid desynchronization at the
are computed given their own reference page, they do not
low level. The receiver repeatedly transmits a request with a
matchbetweenthesenderandthereceiver.Thesenderandthe
sequence number. Upon reception, the sender begins to send
receiverperformjammingandlisteningoperationsthatarethe
the requested word and transmits this word until the receiver
same as sending and receiving bits during the transmission.
transmits the next request – which serves as acknowledgment
The sender starts by jamming its first set, i.e., accessing its
of the current request. The sequence number is encoded
ownsetinaloopthatwefixedto5,000iterations.Thesender
with Hadamard codes to make the scheme robust against
then listens if the receiver jams back to agree on this set,
substitution errors, resulting in a 7-bit request. We can always
i.e., it measures the time it takes to access this set in a loop
recover 2-bit or detect errors as long as less than half the
that we fixed to 10,000 iterations. The sender repeatedly jams
bits are flipped. We can also use the nature of the substitution
and listens to one set until it receives a signal back from the
errors to calculate the most probable candidates and increase
receiver.Duringthistime,thereceiverlistenstooneofitsown
the error correcting capability. We chose to use the Hadamard
eviction sets in a loop that we fixed to 10,000 iterations. If
codes only for their error detecting capabilities as using them
the number of misses is greater than a threshold, the receiver
otherwise introduced too many wrongly decoded requests.
jams back for 15,000 iterations. If not, the receiver repeats its
procedure for the next set. When the sender gets a signal for ‘0’-Insertion errors: Inserted ‘0’s happen if the sender is
one set, it repeats this procedure until they agree on enough descheduled while the receiver continues its measurements.
cache sets to proceed to the communication. To reliably detect these errors we use Berger codes, which
consist in appending the number of ‘0’s contained in the word
TableIIIshowstheevaluationofthespeedofthesetagree-
toitself.TheBergercodeneeds(cid:100)log (len(sqn+data)+1)(cid:101)
ment, comprising of the set creation and jamming agreement, 2
bits, in our case 4 bits. While Berger codes are typically
in native environment and between two instances on Amazon
used to correct unidirectional substitution errors, we use their
EC2, on 100 measurements, with varying degree of noise. In
properties to detect insertion errors. In addition to detecting
a native environment on a 4-core i7-4790, without noise, the
errors,Bergercodesguaranteethepropertythatawordcannot
agreementtakesonaverage0.30s,withastandarddeviationof
consist solely of ‘0’s, since even if a data-word only consists
0.03. When running stress -m 1, the agreement takes on
of ‘0’s, the transmitted word will contain ‘1’s. The Hadamard
average 0.40s, with a standard deviation of 0.02. On Amazon
codes used for the request do not guarantee non-zero words.
EC2, the jamming agreement between two instances takes on
Therefore,wedonotallowthesequencenumber‘0’.Theseven
average 2.62s with a standard deviation of 0.15 without any
differentsequencenumbersintroduceaslidingwindowofsize
noise. When running high synthetic noise such as stress
6, i.e., the receiver can detect a sequence number mismatch
whether on the sender, receiver or a third virtual machine, the
in the range ±3. If there is a mismatch between sender and
jamming agreement still works and takes between 2.74 and
receiver,e.g.,thesenderskipsawordduetosubstitutionerrors,
3.47s. The jamming agreement is unlikely to succeed in case
which is accepted by the receiver. The position of the skipped
of an extremely high noise such as stress -m 8 on the
word is then noted and used in the error correction in the
third virtual machine. The reason is the high amount of noise
data-link layer (see Section V-B).
onmanycachesetsthatiscausedbythehighsystemload.As
described in Section V-A1, the lack of a reliable amplitude on By not allowing any ‘0’ words to be transmitted, ‘0’
our measurement makes it impossible to distinguish different readings are dismissed as errors and are not saved for the
noise levels on a particular cache set. Thus, the two parties majority vote. In addition, one reading before the first ‘0’
10409 Sender Receiver
3686RS-words RS-words
1−p
Data-linklayer
Data Parity 1 1
packet
pp
Physicallayer Data SQN EDC 1−p
word 0 0
12bits 3bits 4bits
Fig. 7: The covert channel without synchronization errors: A
(a)Relationbetweenwordsonthephysicallayerandpacketsonthe
binary symmetric channel
data-link layer.
0 1 2 3 4 5 6
Encoded SQN
Usingthatwecancalculatetheprobabilityofreceivingaword
(b) A request on the physical layer. without errors: p =(1−p)n where n is the number of
cor,word
bitstransmittedperword.Thereforep =1−p .
err,word cor,word
Fig. 5: The structure of a word and an acknowledgment. MostoftheerroneouswordswillbefoundbytheBergercode
and will be corrected by retransmissions, while the rest will
have to be corrected by the data-link layer.
Sender Receiver
B. Data-Link Layer
SEQ=1
Initiate
transmission Thephysicallayertransmitssymbolswithafairlylowerror
[DATA]SEQ=1 rate, but it is still not error free, a property which we need for
furtherapplications.WeshowedinSectionIVthatthenoiseon
SEQ=2 thechannelisAWGNandwillthereforeuniformlydestroybits
and words with the error probability shown in Section V-A5.
[DATA]SEQ=2 Receiver
Thus we chose a commonly used error-correcting code with
descheduled
high decoding speed for small packets: Reed-Solomon codes
[DATA]SEQ=2
(RS codes). In order to achieve fast encoding and decoding
speedweuseanRSwordsizeof12bitsforencoding,therefore
Sender SEQ=3
our packet size is 212 − 1 = 4095 RS words with 4095 −
descheduled
len(data) parity. We use the word size of the physical layer
SEQ=3
as RSword size,as anerroneous symboldoes not affectmore
than one RS word. For small packets of data (i.e., less than
[DATA]SEQ=3
. 100 bytes), it is not advisable to use a RS word size of 12,
.
.
as it would introduce a huge overhead in transmitted parity.
Therefore we choose to use 8 bits for RS word size in these
Fig.6:Retransmissiononthephysicallayerduetoscheduling
cases, resulting in 255 bytes per RS encoded packet.
interrupts.
We adjust the number of parity RS words to be able to
correct more than packetsize · p symbols. RS codes
err,word
can correct up to
(cid:4)parity(cid:5)
RS words. Therefore, we have
reading and after the last one are dismissed as well, due to 2
twice the number of expected errors as parity RS words. If
the chance of being affected by insertion errors as well.
the positions of the erroneous RS words are known, one can
Figure 5 shows the structure of the 19-bit word and the 7- correct up to a maximum of parity errors, which is exploited
bit acknowledgment that are transmitted on the physical layer. if a symbol has been skipped by the physical layer. Using
A 4-bit Berger code is used as Error Detection Code (EDC) these numbers, we decided to use 10% error-correcting code
for the 12-bit data and the 3-bit sequence number (SQN) of 409 parity and 3686 data RS words for packet size 4096 and
theword.TheacknowledgmentconsistsonlyoftheHadamard 25 parity and 230 data RS words for packet size 255. With
encoded sequence number. Figure 6 shows the transmission in these settings, we achieve error-free communication while
the absence of noise. Interrupts caused by scheduling trigger either a YouTube video is being watched or stress -m 1
implicit retransmission of packets. In noisy environments, the is running.
numberofretransmissionswillincreaseduetocorruptpackets.
VI. EVALUATION
5)Channel Model: Channels in communication engineer-
In this section, we evaluate our covert channel on different
ing are commonly modeled after a binary symmetric channel
environments,includingbetweentwoinstancesoftheAmazon
(BSC). In this model, a signal arrives at the receiver with
EC2 cloud, and in the presence of high system activity. For
probability 1−p correctly or with probability p flipped. This
our tests we transfer 9MB of image data between the sender
is the case for our covert channel, see Figure 7. The higher
and the receiver. To compute the error rate, we compare the
the system load the higher the probability of a bit flip.
transmitted data bit-by-bit with the original. Our experimental
Our channel consists of several parallel BSCs which all setups are described in Table II. The results are summarized
havethesameerrorprobabilitydistribution,seeSectionV-A4. in Table IV.
11TABLE IV: Experimental results, with 10% error-correcting codes.
Environment Bitrate Errorrate Correctederrors Noise
Native 75.10KBps 0.00% 6333 –
Native 36.03KBps 0.00% 13166 stress -m 1
AmazonEC2 45.25KBps 0.00% 12996 –
AmazonEC2 45.09KBps 0.00% 11574 webserverservingfilesonsenderVM
AmazonEC2 44.64KBps 0.00% 11258 stress -m 1onsenderVM
AmazonEC2 44.25KBps 0.00% 11819 webserverservingfilesonthirdVM(10concurrentusers)
AmazonEC2 42.96KBps 0.00% 8462 stress -m 2onsenderVM
AmazonEC2 42.26KBps 0.00% 6974 stress -m 1onreceiverVM
AmazonEC2 37.42KBps 0.00% 6093 webserverservingfilesonallthreeVMs,stress -m 4onthirdVM,stress -m 1onboth
senderandreceiverVMs
AmazonEC2 34.27KBps 0.00% 7147 stress -m 8onthirdVM,startedafterthejammingagreement
B. Cloud Environment
TABLEV:Channelcapacityandobservederrorswithdifferent
sizes for the error-correcting code (in relation to the total Forourexperimentsinacloudenvironment,weusedthree
packet size). instances on Amazon EC2 as described in Section III-E. As
our covert channel operates across cores but not across CPUs,
ECC Bitrate Biterrors Byteerrors Correctederrors we use the jamming agreement to find the two instances that
10% 43.70KBps 0 0 6922 reside on the same CPU. In the remainder, the sender runs
4% 47.34KBps 0 0 6728 on one instance, and the receiver on the other instance, and
2% 48.76KBps 105 59 6570
1% 46.69KBps 9448 6120 2093 communicationisperformedacrossvirtualmachines.TableIV
0% 48.29KBps 14841 9509 0 contains the results for the communication in terms of speed,
error rate and number of errors corrected.
Without any additional noise, our covert channel achieves
A. Lab-controlled Environment a bit rate of 45.25KBps with an error rate of 0%. We then
varied the noise on the sender and receiver virtual machines,
We start by evaluating our covert channel in a native aswellasonthethirdinstance.Unlessstatedotherwise,noise
environment, on a Core i7-4790 CPU. The sender and the is started before the jamming agreement. The communication
receiver are two unprivileged processes that do not share stays error-free with 45.09KBps when running a web server
memory. For our measurement, we transmitted 9MB of data on the sender virtual machine. It still stays error-free with
over 2 minutes. Without any additional noise, our covert extreme synthetic noise generated by the stress tool in a
channel achieves a bit rate of 75.10sKBps and an error rate single virtual machine, with a bit rate going from 42.26KBps
of 0.00%. We then increased the noise on the machine by to 44.64KBps. Likewise, with a mix of synthetic noise and
running stress -m 1. Our covert channel stays error-free web server running on all three virtual machines, we obtain a
and achieves a bit rate of 36.03KBps. bit rate of 37.42KBps with 0% error rate. Our most extreme
case, running stress -m 8 on the third virtual machine,
Figure 8 illustrates the need for error correction as well breaks the jamming agreement, but not the transmission itself
as its different stages. Figure 8a illustrates the result of the that is 34.27KBps with 0% error rate when the noise starts
transmission, prior to solving scheduling issues: bit insertions after the jamming agreement.
and deletions render the image unreadable. Even a few bit
Table IV also shows the relation between the errors cor-
insertionsordeletionsthatwouldyieldaloweditdistancecan
rected by the RS codes and the bit rate. We see that the
create an entirely illegible image. Figure 8b is obtained after
number of corrected errors decreases with the bit rate, and
dealing with synchronization issues, but prior to applying RS
when noise increases. With more noise, the Berger codes at
codes:withabiterrorrateof0.72%,theimageisreadablebut
thephysicallayer areabletodetectmore errors,whichcauses
noisy. Finally, Figure 8c shows the result after applying error
more retransmissions, leading to fewer errors which need to
correction: we obtain a crystal clear, error-free image.
be corrected by RS codes.
Wealsoanalyzedhowthesizeoftheerror-correctingcode
influences the raw channel capacity and the number of errors. C. Comparison with State of the Art
We performed the experiments on a Xeon E3-1220v3, in a
The fastest cache covert channels in the literature are
virtualized environment with the KVM hypervisor. Table V
the ones relying on shared memory such as Flush+Reload
shows that increasing the percentage of error-correcting code
with 298KBps and 0.00% error rate and Flush+Flush with
slows down the connection if too much error correction is
496KBps and 0.84% error rate [12]. These implementations,
applied and increases the number of corrected errors due
while yielding a low error rate thanks to a retransmission
to the slightly increased length. We can see that at 2%
protocol, have not been tested in a noisy environment, and
error correcting a few errors are introduced. During all the
require shared memory that is not available in most cloud
experiments the average amount of errors per packet stayed
environments, such as Amazon EC2.
thesame:22RS-wordsperRS-messagewereerroneous,which
is correctable by 2% error-correcting code. However, due to Prime+Probe covert channels achieve between 67KBps
errorsofuptoabove40inonemessagethe2%arenotenough. with 0.36% error rate [12] and 75KBps with 1% error
12(a) Image distortion caused by insertion (b) Noisy image after handling insertion (c) The image after applying error correc-
and deletion errors due to scheduling. and deletion errors. tion. It is equivalent to the original image.
Fig. 8: The stages of error correction.
rate [21]. Similarly, Pessl et al. [27] demonstrated a covert correct, we can implement higher level protocols using our
channel based on DRAM addressing that is up to 307KBps covertchannelasdata-linklayer.Wedecidedontheubiquitous
with 1.8% error rate in native environment and 51KBps with TransmissionControlProtocol(TCP)asthetransportprotocol.
4.1%errorrateinvirtualizedenvironment.Comparedtocache- Being a core protocol of the Internet protocol suite, many
based covert channels, this one has the advantage of working applications rely on it. Supporting this protocol over a covert
across CPUs, but its lack of synchronization mechanism at channel opens the field for practical applications, such as
the protocol level causes a dramatic loss in performance in remote connections with SSH or Telnet.
virtualizedenvironments.However,thesecovertchannelshave
neither been tested in a noisy environment nor in a real-world So far, the communication over our covert channel is
scenario such as Amazon EC2. By first optimizing our covert unidirectional. TCP requires a bidirectional data transmission
channel for speed, and then applying a protocol to deal with on the data-link layer. A straightforward solution would be
synchronizationissuesandcacheactivity,wedemonstratethat to run one covert channel per direction. However, this is not
we can obtain the same order of magnitude in speed as state- a viable option as an additional instance increases the noise
of-the-art covert channels. Moreover, in contrast to previous drastically. Instead, we implement a half-duplex system. In
work, our covert channel is able to stay error-free and fast in this setting, one channel is used to transmit data alternately
thepresenceofextraordinaryhighsystemactivityandhasbeen in both directions, i.e., data cannot be sent in both directions
evaluated between two virtual machines on Amazon EC2. simultaneously. These transmission details are transparent to
TCP and have to be handled in the lower layers to be
Previous work by Wu et al. [40] demonstrated a covert
compatible with existing applications. To ensure practical use,
channel exploiting the memory bus on Amazon EC2 between
arbitrary applications must be able to communicate via TCP
two instances of 100bps, i.e., 0.01KBps, with 0.75% error
over the covert channel without adaption.
rate. In addition to being error-free, our covert channel thus
outperforms previous covert channels demonstrated on Ama- Our solution is to provide local TCP sockets as covert
zon EC2 by 3 orders of magnitude. channel endpoints. The client application initiates the commu-
nication by connecting to the client endpoint socket, just as it
VII. SSHOVERCACHECOVERTCHANNEL would connect to the target application. The client endpoint
communicates with the server endpoint through the covert
We demonstrated that our covert channel is robust against
channel. The server endpoint connects itself to the server
noisewhilestillyieldinggoodperformance.Thissectiongives
application.TheendpointsbufferTCPpacketsfortransmission
a practical application of the covert channel that exploits both
while receiving data from the covert channel. The received
the speed and the error-free transmission: SSH and Telnet
data is directly sent to the connected application through the
connections between two instances in the cloud.
local TCP sockets. When the covert channel has sent all
buffereddata,itswitchesthetransmissiondirection.Additional
A. Implementing TCP over Covert Channel switches can be introduced at the cost of transmission rates to
allow a more responsive connection.
Current state-of-the-art covert channels cannot be used as
anunderlyinglayerforhigh-levelprotocols.Indeed,high-level
Figure 9 illustrates the communication between the client
protocolsexpectthephysicallayertotransmitthedatawithout
and the server application. Due to the transparent TCP socket
errors.Dependingonthehigh-levelprotocol,corruptedbitscan
endpoints, the applications do not see a difference to being
be repaired using error correction or retransmission. However,
connected directly through a socket. One limitation of this
inserted or deleted bits corrupt the data stream and cannot be
methodisthatwecannothavemultiplesocketssimultaneously
repaired by high-level protocols.
asthesimplecommunicationendpointdesigndoesnotsupport
IntheOSImodel,whichistypicallyusedtomodelnetwork packetswitching.However,formostapplicationsitissufficient
layers, the data-link layer provides a mostly error-free data to have one socket for communication. Especially remote
transmission for the higher communication layers. As our shells,whicharethemostlikelyusecase,donotrequiremore
covert channel is error-free, i.e., sent packets are always than one socket connection.
13VM1 VM2
TABLE VI: Stability of SSH connection over the covert
TCPClient TCPServer
(e.g.ssh) (e.g.sshd) channel in the presence of noise, between two instances on
Socket Socket Amazon EC2.
TCP↔File TCP↔File
FileSystem FileSystem Noise Connection
CovertChannel CovertChannel Nonoise (cid:51)
stress -m 8onthirdVM (cid:51)
Hypervisor WebserveronthirdVM (cid:51)
WebserveronSSHserverVM (cid:51)
Prime+Probe Prime+Probe WebserveronallVMs (cid:51)
LastLevelCache(LLC) stress -m 1onserverside unstable
Fig. 9: TCP tunneling over the covert channel.
TABLE VII: Stability of Telnet connection over the covert
channel in the presence of noise, between two instances on
B. Evaluation of SSH Connections Amazon EC2.
As a practical proof-of-concept, we used an SSH client Noise Connection
andserverasapplication.WechoseSSHasitisawell-known Nonoise (cid:51)
protocol for secure network services and remote login [45]. stress -m 8onthirdVM (cid:51)
The protocol is also a good evaluation criterion for the covert WebserveronthirdVM (cid:51)
WebserveronSSHserverVM (cid:51)
channel’srobustnessandfreedomfromerrors.Duetothecryp- stress -m 1onserverside (cid:51)
tographic nature of the protocol, the connection is terminated
as soon as there is a corrupted package, therefore our covert
channel succeeds where previous work would fail. running stress -m 1 with occasional corrupted bytes. Ta-
ble VII summarizes the experiments. Note that system mod-
WeestablishedanSSHconnectionoverthecovertchannel
ifications should not be executed over this connection as a
in a native environment first. To evaluate the connection’s
random corruption of bytes might have devastating effects.
stability, we executed common tasks, such as viewing files
using cat or running more sophisticated programs such as
top. For a more realistic scenario, we increased the level of VIII. CONCLUSION
noise on the computer. As a source of noise, we used Chrome
Caches are an ideal shared resource to establish covert
to watch a music video on YouTube. Even in the presence of
channels between multiple virtual machines to exfiltrate sen-
noise the SSH connection was stable and remained usable.
sitive data, as they are fast and shared by all tenants in public
To evaluate a more realistic use case, we established clouds. However, cache covert channels are prone to noise
the SSH connection between two co-located Amazon EC2 due to cache activity and scheduling, impairing their direct
instances. To evaluate the practicability of the connection, applicability in a real-world public cloud scenario.
we tried four common tasks: listing the files in the current
In this paper we characterized the sources of noise and
directory (ls), viewing a text file (cat /etc/passwd),
errors in cache covert channels comprehensively. We conse-
displaying the CPU utilization (top) and creating a file using
quently designed a protocol that handles the physical layer
nano. Without the presence of noise, the SSH connection
andthedata-linklayerofacachecovertchannel.Weevaluated
remainedstableoverthewholetime.Westeadilyincreasedthe
the performance of our covert channel in different scenarios
noiselevelbyrunninganApache2webserveronathirdvirtual
in native and virtualized environments. Even in the presence
machine,ontheSSHserversideandfinallyonallthreevirtual
of extraordinarily high system activity, we can maintain a
machines. Even the simulation of heavy noise on the third
transmissionratebetween34.27KBpsand45.09KBpswithan
virtual machine using stress -m 8 did not interrupt the
error rate of 0% on Amazon EC2 virtual machines, which is
SSH connection. Table VI summarizes the experiments. The
threeordersofmagnitudehigherthanpreviouscovertchannels
delay between user input on the client side and the processing
on Amazon EC2. Based on this error-free covert channel, we
of the input on the server side is influenced on how frequent
built the first implementation of TCP through a cache covert
senderandreceiverswitchrolesandcanbeconfiguredtobein
channel. We verified the practical applicability of our error-
the range of milliseconds. The influence of noise on the input
free TCP connection by tunneling SSH and telnet connections
latency is barely perceivable.
reliablybetweentwocolocatedAmazonEC2virtualmachines.
C. Evaluation of Telnet Connections The possibility to establish reliable SSH connections and
telnetsessionsthroughthecache,movescachecovertchannels
Only after we started to generate artificial noise on the beyond typical academic use cases, emphasizing the crucial
SSH server’s virtual machine by running stress -m 1, importance of finding effective countermeasures.
we observed occasional disconnects due to corrupt packets
or timeouts. In this scenario, we could still achieve a stable
ACKNOWLEDGMENTS
connection using Telnet instead of SSH. As Telnet is an
unencryptedtext-orientedprotocolwithoutauthentication[28], This project has received funding from the European Re-
there are fewer packets transmitted and the packets are not search Council (ERC) under the European Union’s Horizon
error-checked. Telnet allows stable communication even while 2020 research and innovation programme (grant agreement
14No 681402). This work was partially supported by the TU [24] C.Maurice,C.Neumann,O.Heen,andA.Francillon,“C5:Cross-Cores
GrazLEADproject“DependableInternetofThingsinAdverse CacheCovertChannel,”inDIMVA’15,2015.
Environments”. [25] H. Mercier, V. K. Bhargava, and V. Tarokh, “A survey of error-
correcting codes for channels with symbol synchronization errors,”
IEEECommunicationsSurveys&Tutorials,vol.1,no.12,pp.87–96,
REFERENCES 2010.
[26] C. Percival, “Cache missing for fun and profit,” in Proceedings of
[1] T.Allan,B.B.Brumley,K.Falkner,J.V.D.Pol,andY.Yarom,“Am-
BSDCan,2005.
plifyingSideChannelsThroughPerformanceDegradation,”Cryptology
ePrintArchive:Report2015/1141,2015. [27] P.Pessl,D.Gruss,C.Maurice,M.Schwarz,andS.Mangard,“DRAMA:
Exploiting DRAM Addressing for Cross-CPU Attacks,” in USENIX
[2] J.M.Berger,“Anoteonerrordetectioncodesforasymmetricchannels,”
SecuritySymposium,2016.
InformationandControl,vol.4,no.1,pp.68–73,1961.
[28] J. Postel and J. Reynolds, “Telnet protocol specification,” Internet
[3] C. Berrou and A. Glavieux, “Near optimum error correcting coding
Requests for Comments, RFC Editor, RFC 854, May 1983. [Online].
and decoding: Turbo-codes,” IEEE Transactions on communications,
Available:https://tools.ietf.org/html/rfc854
vol.44,no.10,pp.1261–1271,1996.
[29] I.S.ReedandG.Solomon,“Polynomialcodesovercertainfinitefields,”
[4] C. A. Boano, M. A. Zuniga, K. Ro¨mer, and T. Voigt, “Jag: Reliable
Journal of the society for industrial and applied mathematics, vol. 8,
and predictable wireless agreement under external radio interference,”
no.2,pp.300–304,1960.
inIEEE33rdReal-TimeSystemsSymposium(RTSS),2012.
[30] T. Ristenpart, E. Tromer, H. Shacham, and S. Savage, “Hey, You,
[5] B. B. Brumley, “Covert timing channels, caching, and cryptography,”
Get Off of My Cloud: Exploring Information Leakage in Third-Party
Ph.D.dissertation,2011.
ComputeClouds,”inCCS’09,2009.
[6] M. Buettner, G. V. Yee, E. Anderson, and R. Han, “X-mac: a short
[31] M.E.Russinovich,D.A.Solomon,andA.Ionescu,Windowsinternals.
preamble mac protocol for duty-cycled wireless sensor networks,” in
PearsonEducation,2012.
Proceedings of the 4th international conference on Embedded net-
workedsensorsystems. ACM,2006,pp.307–320. [32] W. Schmidt, M. Hanspach, and J. Keller, “A case study on covert
channelestablishmentviasoftwarecachesinhigh-assurancecomputing
[7] J. Corbet, “(Nearly) full tickless operation in 3.10,” https://lwn.net/
systems,”arXiv:1508.05228,2015.
Articles/549580/,May2013.
[33] C. E. Shannon, “A mathematical theory of communication,” ACM
[8] T.M.CoverandJ.A.Thomas,Elementsofinformationtheory. John
SIGMOBILE Mobile Computing and Communications Review, vol. 5,
Wiley&Sons,2012.
no.1,pp.3–55,2001.
[9] A. Fuchs and R. B. Lee, “Disruptive Prefetching: Impact on Side-
[34] I.ShomoronyandA.S.Avestimehr,“Isgaussiannoisetheworst-case
ChannelAttacksandCacheDesigns,”inProceedingsofthe8thACM
additive noise in wireless networks?” in International Symposium on
InternationalSystemsandStorageConference(SYSTOR’15),2015.
InformationTheory(ISIT’12),July2012,pp.214–218.
[10] R. Gallager, “Low-density parity-check codes,” IRE Transactions on
[35] S. Tolvanen, “Strictly Enforced Verified Boot with Error
informationtheory,vol.8,no.1,pp.21–28,1962.
Correction,” Jul. 2016, retrieved on August 9, 2016.
[11] D. Gruss, C. Maurice, and S. Mangard, “Rowhammer.js: A Remote [Online]. Available: http://android-developers.blogspot.co.at/2016/07/
Software-InducedFaultAttackinJavaScript,”inDIMVA’16,2016. strictly-enforced-verified-boot-with.html
[12] D. Gruss, C. Maurice, K. Wagner, and S. Mangard, “Flush+Flush: A [36] V.Varadarajan,T.Ristenpart,andM.Swift,“Scheduler-basedDefenses
FastandStealthyCacheAttack,”inDIMVA’16,2016. against Cross-VM Side-channels,” in USENIX Security Symposium,
[13] D.Gruss,R.Spreitzer,andS.Mangard,“CacheTemplateAttacks:Au- 2014.
tomatingAttacksonInclusiveLast-LevelCaches,”inUSENIXSecurity [37] V. Varadarajan, Y. Zhang, T. Ristenpart, and M. Swift, “A Placement
Symposium,2015. VulnerabilityStudyinMulti-TenantPublicClouds,”inUSENIXSecu-
[14] D. Gullasch, E. Bangerter, and S. Krenn, “Cache Games – Bringing ritySymposium,2015.
Access-BasedCacheAttacksonAEStoPractice,”inS&P’11,2011. [38] A. Viterbi, “Error bounds for convolutional codes and an asymptoti-
[15] H. Hemmati, Deep Space Optical Communications, ser. JPL Deep- callyoptimumdecodingalgorithm,”IEEEtransactionsonInformation
SpaceCommunicationsandNavigationSeries. Wiley,2006.[Online]. Theory,vol.13,no.2,pp.260–269,1967.
Available:https://books.google.at/books?id=Cj52X7jK5OgC [39] S. B. Wicker and V. K. Bhargava, Reed-Solomon codes and their
[16] W.-M.Hu,“LatticeSchedulingandCovertChannels,”inS&P’92,1992. applications. JohnWiley&Sons,1999.
[17] M. S. Inci, B. Gulmezoglu, G. Irazoqui, T. Eisenbarth, and B. Sunar, [40] Z. Wu, Z. Xu, and H. Wang, “Whispers in the Hyper-space: High-
“CacheAttacksEnableBulkKeyRecoveryontheCloud,”inCHES’16, bandwidth and Reliable Covert Channel Attacks inside the Cloud,”
2016. IEEE/ACMTransactionsonNetworking,2014.
[18] Intel,“Intel(cid:13)R 64andIA-32ArchitecturesSoftwareDeveloper’sMan- [41] Y.Xu,M.Bailey,F.Jahanian,K.Joshi,M.Hiltunen,andR.Schlichting,
ual, Volume 3 (3A, 3B & 3C): System Programming Guide,” vol. “An exploration of L2 cache covert channels in virtualized environ-
253665,2014. ments,” in Proceedings of the 3rd ACM Cloud Computing Security
[19] G. Irazoqui, T. Eisenbarth, and B. Sunar, “S$A: A Shared Cache Workshop(CCSW’11),2011.
Attack that Works Across Cores and Defies VM Sandboxing – and [42] Z.Xu,H.Wang,andZ.Wu,“AMeasurementStudyonCo-residence
itsApplicationtoAES,”inS&P’15,2015. ThreatinsidetheCloud,”inUSENIXSecuritySymposium,2015.
[20] M. Jeganathan and S. Mecherle, “A technical manual for focas [43] Y. Yarom and K. Falkner, “Flush+Reload: a High Resolution, Low
2.0—freespaceopticalcommunicationsanalysissoftware,”1998. Noise, L3 Cache Side-Channel Attack,” in USENIX Security Sympo-
[21] F.Liu,Y.Yarom,Q.Ge,G.Heiser,andR.B.Lee,“Last-LevelCache sium,2014.
Side-ChannelAttacksarePractical,”inS&P’15,2015. [44] Y.Yarom,Q.Ge,F.Liu,R.B.Lee,andG.Heiser,“MappingtheIntel
[22] D. Magenheimer, “Tsc mode how-to,” retrieved on August 13, Last-LevelCache,”CryptologyePrintArchive,Report2015/905,2015.
2016. [Online]. Available: http://xenbits.xen.org/docs/4.3-testing/misc/ [45] T. Ylonen and C. Lonvick, “The secure shell (ssh) protocol
tscmode.txt architecture,”InternetRequestsforComments,RFCEditor,RFC4251,
[23] C.Maurice,N.LeScouarnec,C.Neumann,O.Heen,andA.Francillon, January2006.[Online].Available:https://tools.ietf.org/html/rfc4251
“Reverse Engineering Intel Complex Addressing Using Performance [46] Y. Zhang and M. Reiter, “Du¨ppel: retrofitting commodity operating
Counters,”inRAID,2015. systemstomitigatecachesidechannelsinthecloud,”inCCS’13,2013.
15