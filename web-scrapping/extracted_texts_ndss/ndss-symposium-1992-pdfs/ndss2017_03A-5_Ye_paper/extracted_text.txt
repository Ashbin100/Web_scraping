Cracking Android Pattern Lock in Five Attempts
Guixin Ye†, Zhanyong Tang∗,†, Dingyi Fang†, Xiaojiang Chen†, Kwang In Kim‡, Ben Taylor§, and Zheng Wang∗,§
†School of Information Science and Technology, Northwest University, China
Email: gxye@stumail.nwu.edu.cn, {zytang, dyf, xjchen}@nwu.edu.cn
‡Department of Computer Science, University of Bath, UK
Email: k.kim@bath.ac.uk
§School of Computing and Communications, Lancaster University, UK
Email: {b.d.taylor, z.wang}@lancaster.ac.uk
Abstract—Pattern lock is widely used as a mechanism for Researchers have uncovered a number of ways to crack
authentication and authorization on Android devices. In this Androidpatternlock.Smudgeattacksusetheoilyresiduesleft
paper, we demonstrate a novel video-based attack to reconstruct onthescreentorecoverthepattern[1].However,thisapproach
Android lock patterns from video footage filmed using a mobile relies on the persistence of the smudge which can be easily
phonecamera.Unlikepriorattacksonpatternlock,ourapproach
destroyed by subsequent on-screen activities after unlocking.
doesnotrequirethevideotocaptureanycontentdisplayedonthe
In a recent study, Zhang et al. [34] shows that it is possible
screen. Instead, we employ a computer vision algorithm to track
to infer a locking pattern by analyzing how the WiFi signal is
thefingertipmovementstoinferthepattern.Usingthegeometry
affectedbythefingermotionswhendrawingthepattern.Their
informationextractedfromthetrackedfingertipmotions,ourap-
proachisabletoaccuratelyidentifyasmallnumberof(oftenone) approachisrestrictedtoalimitsetofscenariosdueto:(1)the
candidate patterns to be tested by an adversary. We thoroughly complex setup of the attack and (2) the WiFi signal can be
evaluatedourapproachusing120uniquepatternscollectedfrom disrupted by any moving objects nearby or body movements.
215independentusers,byapplyingittoreconstructpatternsfrom
video footage filmed using smartphone cameras. Experimental Recently,video-basedside-channelattacksareshowntobe
results show that our approach can break over 95% of the effectiveinreconstructingPIN-ortext-basedpasswords.Some
patternsinfiveattemptsbeforethedeviceisautomaticallylocked oftheearlyworkinthisarearelyonvideofootagefilmedusing
by the Android system. We discovered that, in contrast to many a camera directly faced the screen or the keyboard [4, 16].
people’sbelief,complexpatternsdonotofferstrongerprotection Recentworkshowsthatthislimitationcanbeliftedbyexploit-
under our attacking scenarios. This is demonstrated by the fact ingspatial-temporaldynamicsofthehandsduringtyping[23].
that we are able to break all but one complex patterns (with a
Despite the success of video-based attacks on PIN- and text-
97.5% success rate) as opposed to 60% of the simple patterns in
based passwords, no work so far has exploited video-based
thefirstattempt.Sinceourthreatmodeliscommoninday-to-day
side-channels to crack pattern lock. To do so, the attack must
lives, our workr calls for the community to revisit the risks of
address a number of new challenges. These include: How to
using Android pattern lock to protect sensitive information.
map the user’s fingertip movements to a graphical structure
consisting of continuous points instead of discrete keystrokes?
How to transform the fingertip movements tracked from the
I. INTRODUCTION
camera’s perspective to the user’s view point to correctly
Pattern lock is widely used on Android devices to protect reconstructthepattern?Howtocancelthecamerashakeeffect
sensitive information. It is preferred by some users over PIN- thatcansignificantlyaffecttheperformanceoftheattack?How
or text-based passwords, as psychology studies show that the toidentifytwooverlappinglinesegmentsofapattern?Thesize
human brain remembers and recalls visual information better ofthetouch-screenorthepatterngridcanvaryfromonedevice
than numbers and letters [9]. According to a recent study, or one application to the other, how can the algorithm adapt
40% of the Android users use patterns to protect their devices to these changes? These issues make prior work video-based
insteadofaPIN[7].Patternlockisalsousedforauthentication attacks inapplicable. To overcome these challenges requires
–forexample,Alipay,thelargestthird-partyonline-payment creative solutions to be constructed in the new application
platform, uses pattern lock as part of the login authentication. context of pattern lock.
Givenitspervasiveusage,asecuritybreachofthepatternlock
This paper presents a novel approach to crack Android
could lead to serious consequences.
pattern lock using video footage that captures the user’s
fingertip motions when drawing the pattern. Unlike smudge
*Correspondingauthors:ZhanyongTangandZhengWang attacks [1], our approach does not require the video footage
orimagestobecapturedbyacameradirectlyfacedthescreen.
Furthermore,thevideocanbefilmedatadistanceof2meters
Permission to freely reproduce all or part of this paper for noncommercial
purposes is granted provided that copies bear this notice and the full citation fromtheuserinpublicplaces.Suchadistanceislesslikelyto
on the first page. Reproduction for commercial purposes is strictly prohibited raisesuspicioncomparedtoshouldersurfing[21]thatrequires
without the prior written consent of the Internet Society, the first-named author acloserobservationdistancetohaveaclearsightofthecontent
(for reproduction of an entire paper only), and the author’s employer if the
displayed on the screen.
paper was prepared within the scope of employment.
NDSS ’17, 26 February - 1 March 2017, San Diego, CA, USA
Our attack employs a computer vision algorithm to track
Copyright 2017 Internet Society, ISBN 1-891562-46-0
http://dx.doi.org/10.14722/ndss.2017.23130 the fingertip motions from the video. Using the geometryattempts(SectionVI-A).GiventhattheAndroidoperating
system (OS) allows five tries before locking the device,
our attack represents a real threat for pattern lock.
• Identifying New Vulnerabilities: According to a recent
study [8], direct observation techniques, e.g. shoulder
surfing, are considered to be a low risk due to the close
distance between the attacker and the user (in order to
gainaclearsightofthedevicescreen).Asaresult,many
(a) The user was listening to (b) The device screen seen users may underestimate the dangers from using pattern
music and unaware of what fromthevideofilmedin(a). lock in public places. Under our attack, filming can be
washappeningaround. carriedoutatadistanceof2metersfromtheuserandthe
mobile phone camera does not need to directly face the
targetdevice.Suchacamerasettingmakesourattackless
likely to raise suspicion and more likely to success when
compared to direct observation techniques. For instance,
the video can be filmed by an adversary who pretends to
interactwithhisphone,sittingnexttotheuserinapublic
place (see Figure 1). In many similar scenarios, many
users will not be suspicious of the attacker’s behavior.
• New Findings: Our study suggests that complex patterns
(c) The video was recorded (d) The device screen seen
are more vulnerable under video-based attacks (Sec-
fromadistanceof2.5meters. fromthevideofilmedin(c).
tion VI-A). This finding debunks many people’s concep-
tion that more complex patterns give stronger protection.
Therefore, our work sheds new insights on the practical
use of pattern lock.
II. BACKGROUND
A. Android Pattern Lock
Patternlockiswidelyusedtoprotectsensitiveinformation
(e) An outdoor filming (f) The device screen seen
scenario. fromthevideofilmedin(e). and perform authentication on Android touch-screen devices.
To unlock a device protected with pattern lock, the user is
Figure 1. Examples of scenarios in which a mobile phone camera is used
tofilmtheunlockingprocess.Inthesescenarios,thecameradoesnotneedto asked to draw a predefined sequence of connected dots on a
haveaclearsightofthescreen. pattern grid1. Figure 2 (e) shows a pattern which consists of
seven dots on a 3×3 grid. To form a pattern, the user starts
by selecting one dot as the starting point and then swiping
information extracted from the fingertip motions, it then maps over multiple dots of the grid until the fingertip is lifted from
the tracked fingertip locations to a small number of (often just the screen. There are several rules for creating an Android
one) candidate patterns to be tested on the target device. pattern:(1)apatternmustconsistofatleastfourdots;(2)each
dot can only be visited once; and (3) a previously unvisited
We thoroughly evaluate our approach using 120 unique
dot will become visited if it is part of a horizontal, vertical
patterns collected from independent users. We show that our
or diagonal line segment of the pattern. Taking into account
approach is effective in inferring candidate patterns and as
these constraints, the total number of possible patterns on a
a result, an attacker can unlock the target device with a
3×3 grid is 389,112 [29]. Given the large number of possible
success rate of over 95% (up to 97.5%) in five attempts. We
patterns, performing brute-force attacks on Android pattern
demonstrate that, in contrast to many people’s belief, complex
lock is ineffective, because the device will be automatically
patternsdonotprovidestrongerprotectionoversimplepatterns
locked after five failed tries.
underourattack.Accordingtoarecentstudy[18],peopletend
to use complex patterns for important financial applications
suchasonlinebankingandshopping.Ourfindingsuggeststhat B. Threat Model
using pattern lock to protect sensitive information is risky.
In our threat model, we assume an adversary wants to
Contributions The key contribution of this paper is a new access some sensitive information from or to install malware
attackforAndroidpatternlock.Ourattackexploitstechniques on a target device that is protected by pattern lock. This type
developed in the computer vision domain to address the key of attacks is mostly likely to be performed by an attacker who
challenges highlighted above. have physically access to the target device for a short period
of time (e.g. via attending a meeting or a party where the
This paper makes the following specific contributions:
target user presents). To quickly gain access to the device,
the attacker would like to obtain the user’s locking pattern in
• ANewAttack:Thisisthefirstworktoreconstructlocking
advance.
patterns without relying on the content shown on the
screen (Section II-B). Experimental results show that our 1In this paper we use the Android default pattern grid with 3×3 dots,
methodcanbreakover95%ofthelockingpatternsinfive unlessotherwisestated.
2Attacker Our system Attacker
60 60
1 2 30 3 30 4 5
0 0
-30 -30
-60 -60
-60 -30 0 30 60 -60 -30 0 30 60
(a) Video footage (b) Marked tracking areas(c) Fingertip trajectory (d) Transformed trajectory ( e ) Candidate patterns (f) Correct pattern
(camera s perspective) (user s perspective)
Figure2. Overviewoftheattack.Oursystemtakesinavideosegmentthatrecordstheunlockingprocess(a).Theadversaryfirstmarkstwoareasofinterest
on the first video frame (b): one contains the fingertip involved in pattern drawing, and the other contains part of the device. Our system then tries to track
the fingertip’s location w.r.t. to the device. The tracking algorithm produces a fingertip movement trajectory from the camera’s perspective (c) which is then
transformedtotheuser’sperspective(d).Finally,theresultingtrajectoryin(d)ismappedtoseveralcandidatepatterns(e)tobetestedonthetargetdevice(f).
The attack starts from filming how the user unlocks the III. OVERVIEWOFOURATTACK
device. Video recording can be done on-site or ahead of time.
This section gives an overview of our attacking system
The video will then be processed to identify a small number
which analyzes the user’s fingertip movement to infer the
of patterns to be tested on the target device. Because filming
locking pattern. The system takes in a video segment that
canbecarriedoutfromadistanceofasfaras2metersusinga
records the entire unlocking process. It produces a small
mobilephonecameraandthecameradoesnotneedtodirectly
number of candidate patterns to be tested on the target device.
facethetargetdevice,thisactivityoftenwillnotbenoticedby
Figure 2 depicts the five steps of our attack:
theuser.Moreover,giventhatmanyusersusethesamepattern
across devices and applications, the pattern obtained from one 1 FilmingandVideoPreprocessing:Theattackbeginsfrom
device could also be used to break the user’s other devices. filming how the pattern is drawn. The video footage can be
We want to stress that the goal of this paper is to demonstrate filmed at a distance of around 2 meters from the user using
the feasibility of a new attack and the countermeasure is left a mobile phone camera (or 9 meters using a low-end digital
to our future work. singlereflexcamera).Afterrecording,theattackerneedstocut
outavideosegmentthatcontainstheentireunlockingprocess.
Examples of Filming Scenarios Figure 1 illustrates three
We have shown that it is possible to automatically identify
scenarios where filming can be performed without raising
this video segments in some scenarios (Section IV-A). After
suspicion to many users. For all the examples presented in
cutting out the video segment, the attacker is then asked to
Figure 1, the filming camera had a left- or right-front view
mark two areas of interest from one of the video frames: one
angle from the target device and did not directly face the
area consists of the fingertip used to draw the pattern, and the
screen of the target device. Due to the filming distance (2-
other consists of part of the device (see Figure 2 (b)).
3 meters), the recoded video typically does not have a clear
visionofthecontentdisplayedonthescreen.Thisobservation 2 Track Fingertip Locations:Oncetheareasofinterestare
canbeconfirmedbythevideosnapshotplacingalongsideeach highlighted, a computer vision algorithm will be applied to
scenario, where it is impossible to identify the content shown locate the fingertip from each video frame (Section IV-B2).
onthescreen.TheexamplesgiveninFigure1aresomeofthe The algorithm aggregates the successfully tracked fingertip
day-to-day scenarios where security of the user’s device can locations to produce a fingertip movement trajectory. This is
be compromised under our attack. illustrated in Figure 2 (c). Keep in mind that at this stage the
tracked trajectory is presented from the camera’s perspective.
Assumptions Our attack requires the video footage to have
3 Filming Angle Transformation: This step transforms the
a vision of the user’s fingertip that was involved in pattern
trackedfingertiplocationsfromthecamera’sperspectivetothe
drawingaswellaspartofthedevice(e.g.anedgeofaphone).
user’s. We use an edge detection algorithm to automatically
Webelievethisisareasonableassumptionbecauseinpractice
calculate the filming angle which is then used to perform the
manyusersoftendonotfullycovertheirfingersandtheentire
transformation (Section IV-C). For example, Figure 2 (c) will
device when drawing a pattern. This is particularly true when
be transformed to Figure 2 (d) to obtain a fingertip movement
holding a large-screen device by hands. To launch the attack,
trajectory from the user’s perspective.
the attacker needs to know the layout of the grid, e.g. whether
it is a 3×3 or a 6×6 grid. Our approach is to generate a set
4 Identify and Rank Candidate Patterns: In this step, our
ofcandidatepatternsforeachoftheAndroidpatterngridsand
software automatically maps the tracked fingertip movement
the attacker can simply decide which set of candidate patterns
trajectorytoanumberofcandidatepatterns(SectionIV-D).We
to use after seeing the target device (at the time the layout
rank the candidate patterns based on a heuristic described in
of the grid will be available). However, unlike prior work on
SectionIV-D2.Forinstance,thefingertipmovementtrajectory
video-basedattacksonkeystrokebasedauthentication[23],our
in Figure 2 (d) could be mapped to a number of candidate
approach does not require having knowledge of the console’s
patterns shown in Figure 11. We show that our approach
geometry.Inotherwords,thesizeofthescreenortheposition
can reject most patterns to leave no more than five candidate
ofthepatterngridonthescreendoesnotaffecttheaccuracyof
patterns to be tried out on the target device.
ourattack.Wealsoassumethevideodoesnotneedtocapture
any content displayed on the screen. This assumption makes 5 Test Candidate Patterns: In this final step, the attacker
previous video-based attacks on pattern lock [1] inapplicable. tests the candidate patterns on the target device.
3IV. IMPLEMENTATIONDETAILS 1
0.8
A. Video preprocessing
0.6
The first step of our attack is to identify the unlocking 0.4
processfromthevideofootage.Whileallourparticipants(see
0.2
Section V-A) consider this as a straightforward manual task,
0
we developed a simple yet effective heuristic to automatically 1.5 1.6 1.7 1.8
The time interval (s)
detect the video segment in some typical scenarios. Our
heuristic is based on the following observations: (1) before or
after unlocking, users often pause for a few seconds; (2) two
consecutive on-screen operations (e.g. swiping, zooming etc.)
typically expose some spatial-temporal motion characteristics.
In order to test our hypothesis, we have recorded 50 video
streams (each video lasts around 2 minutes) of how ten of
our participants drew patterns. During video recording, our
participants firstly performed some on-screen activities such
as web browsing and gaming for a period of time as they
wished; they then opened up a pattern lock screen to draw a
pattern and continued to perform other on-screen operations
afterwards. For each video stream, we then analyzed frames
that are associated with pattern drawing and those are not.
Figure 3 shows that all our participants paused at least
1.5 seconds before or after pattern drawing due to delay of
the user or the device. We also found that identical on-screen
activities often follow closely. For example, on several occa-
sions our participants had to swipe several times to locate a
programfromtheapplicationlist.Theseconsecutiveon-screen
operations have some spatial-temporal motion characteristics
that are different from pattern drawing. Figure 4 shows the
spatial-temporalmotionstructurefortwogestures,swipingand
zooming,whentheyareperformedonce(a,c,e)andtwice(b,
d,f).Thisdiagramsuggeststhatthespatial-temporalmotionof
twoidenticalon-screenactivitiescontainsoneormorelooping
structures for which pattern drawing does not have.
Our heuristic for identifying the pattern drawing process
is described in Algorithm 1. The input to the algorithm is
a video capturing the unlocking process, and the output of
the algorithm is a time-stamp tuple, <start, end>, which
marks the start and the end of a video segment. To locate
the video segment of pattern drawing, we first filter out on-
screen activities where the fingertip location does not change
within a timeframe of 1.5 seconds (lines 4 and 11). This
allows us to exclude some basic on-screen activities such as
clicking. We use the number of video frames, frameCount, as
a proxy to estimate the time interval between two on-screen
operations.Here,atimeintervalof1.5stranslatesto45frames
or 90 frames when the video was shot at 30 or 60 frames per
second (FPS) respectively. We also use the spatial-temporal
characteristics described above to exclude two consecutive
swiping or zooming gestures (line 8). Finally, we exploit the
observation that users typically pause at least 1.5s before or
after unlocking to locate the start and end points of pattern
drawing (line 19).
Limitations Our heuristic is not perfect. It is likely to fail if
the user was typing using a Swype-like method (i.e. entering
words by sliding a finger from the first letter of a word to its
lastletter)duringvideorecording.Inthiscase,ourmethodwill
identifymultiplevideosegmentsofwhichonemaycontainthe
pattern unlock process. If multiple segments are detected, the
algorithm will ask the user to confirm which video segment
FDC
Figure 3. The cumulative distribution function (CDF) of the time interval
betweenpatterndrawingandotheron-screenactivities.
20 20
10
10
0
0
−10
−10 −20
−20 −30
−40 −20 0 20 40 −50 −25 0 25 50
(a)ahorizontal-swiping (b)twoconsecutively
gesture horizontal-swipinggestures
60 60
30 30
0 0
−30 −30
−60 −60
−20 −10 0 10 20 −40 −20 0 20 40
(c)avertical-swipinggesture (d)twoconsecutively
vertical-swipinggestures
30 −30
15 −15
0 0
−15 15
−3 −0 40 −20 0 20 40 3 −0 40 −20 0 20 40
(e)azoominggesture (f)twoconsecutivezooming
gestures
Figure4. Spatial-temporalcharacteristicsforperforminganon-screengesture
once(a,c,e)andtwice(b,d,f).
to use. In this scenario, the first identified segment is likely to
be the correct one. In practice, an experienced attacker would
waitpatientlytoavoidthiscomplicatedsituationbyfindingthe
right time for filming (e.g. for a screen lock, the time is just
after the device is retrieved). The attacker could also watch
the video to manually cut it to ensure the obtain the correct
video segment. It is worthwhile to mention that automatically
identifying the pattern unlocking process is not central to our
attack because an attacker often can obtain a quality video
input used the manual methods described above. Despite its
limitations, our algorithm can reduce the efforts involved in
some common scenarios.
B. Track fingertip locations
After cutting out the video segment of pattern drawing,
we need to track the finger motions from the video segment.
We achieve this by employing a video tracking algorithm
called Tracking-Learning-Detection (TLD) [15]. This algo-
rithm automatically detects objects defined by a boundary
box. In our case, the objects to be tracked are the user’s
460
30
0
-30
x=265.00 y=364.00 x=275.62 y=324.86 x=310.70 y=278.00
x=156.00 y=454.00 x=156.22 y=456.98 x=157.40 y=437.94 -60
x=109.00 y= -90.00 x= -119.40 y=132.12 x= -153.30 y=159.94
-60 -30 0 30 60
(a)Thefirstvideoframe (b)Amiddlevideoframe (c)Thelastvideoframe (d)Fingertipmovementtrajectory
Figure5. Trackingthefingertipmovementtrajectory.Foreachvideoframe,thesystemtrackstwoareas:onesurroundsthefingertipandtheothercoversthe
edgeofthedevice.Thefingertippositionisdeterminedbycomputingtherelativecoordinatesofthecentralpointsofthetwoareas.Theredpointshighlighted
inthefinalresults(d)arethetouchingpointstrackedfromthethreevideoframes.
Algorithm 1 Unlocking process identification heuristic errors of the detector and updates the detector to avoid these
Input: errors in future frames.
IV: Video footage
frameCount: Pause threshold before or after unlocking The TLD learner automatically extracts features from the
Output: area of interest to build a K-Nearest Neighbor classifier [13]
<start,end>: Start and end of the unlocking video segment which is a part of the detector. In the following frames, the
1: frames[]←getVideoFrames(IV) learner estimates the detection errors and generates new train-
2: LEN ←getFramesLen(frames[]) ing examples (i.e. new appearances of the object) arose from
3: for i=1:LEN −frameCount do object motion to re-train the classifier to avoid these errors.
4: sL ← hasFingertipChanged(frames[i : For each video frame, TLD calculates the tracking confidence
i+frameCount])
and if the confidence is lower than the predefined threshold,
5: if !sL then
the result of this particular frame will be discarded. This
6: sNo=i+frameCount
allows the algorithm to tolerate a certain degree of detection
7: for j =sNo:LEN do
8: if checkLoop(frames[j :LEN]) then errors. Finally, the successfully detected object locations will
9: eNo=i be put onto a single image as the output. Detailed discussion
10: break; of TLD can be found at [15]. Sometimes the algorithm may
11: else if !hasFingertipChanged(frames[j : j + fail to detect the objects in many video frames due to poor
frameCount]) then selectionsofinterestingareas.Ifthishappens,oursystemwill
12: eNo=i ask the user to re-select the areas of interest. We have also
13: break; extendedTLDtoreportwhenafingertippositionisseenonthe
14: end if
footage. This temporal information is recorded as the number
15: end for
ofvideoframesseenwithrespecttothefirstframeofthevideo
16: break;
segment.Thisisusedtoseparatetwopossiblyoverlappingline
17: end if
18: end for segments described in Section IV-D.
19: <start,end>←getTargetVideo(frames[],sNo,eNo)
2)Camera Shake Calibration: By default, the TLD algo-
rithm reports the position of a tracked object with respect to
thetop-leftpixelofthevideoframe.However,videosrecorded
fingertip and an area of the device. These are supplied to the by a hand-held device is not always perfectly steady due to
algorithm by simply highlighting two areas on the first frame camera shake. As a result, the top-left pixel of a video frame
of the video segment (see Figure 2 b). The algorithm tries to may appear in a different location in later frames. This can
localizethefingertipfromeachvideoframeandaggregatesthe drasticallyaffecttheprecisionoffingertiplocalization,leading
successfullytrackedlocationstoproduceafingertipmovement to misidentification of patterns.
trajectory as an output (see Figure 2 c).
Our approach to cancel camera shake is to record the
1)GenerateTheFingertipMovementTrajectory: TheTLD fingertip location with respect to a fixed point of the target
algorithmautomaticallydetectsobjectsbasedontheexamples device. To do so, we track two areas from each video frame.
seen from previous frames. For each tracked object, the algo- Oneareaisanedgeofthedeviceandtheotheristhefingertip.
rithm generates a confidence between 0 and 1. A tracking is Both areas are highlighted on the first frame by the user. The
considered to be successfully if the confidence is greater than location of a successfully tracked fingertip is reported as the
athreshold.Wesetthisthresholdto0.5whichisfoundtogive the relative coordinates of the two center points of the marked
good performance in our initial design experiments using 20 areas. This approach can also be used to calibrate the minor
patterns2. TLD has three modules: (1) a tracker that follows motions of the target device during pattern drawing.
objects across consecutive frames under the assumption that
the frame-to-frame motion is limited and objects are visible; Example: To illustrate how our camera-shake calibration
(2) a detector to fully scan each individual frame to localize methodworks,consideringFigure5wheretwoareasarefirstly
all appearances of the objects; and (3) a learner that estimates marked by two bounding boxes in subfigure (a). Both areas
will then be automatically detected by the TLD algorithm in
2Toprovideafairevaluation,thepatternsusedinallourinitialtestrunsin followingvideoframesasshowninsubfigures(b)and(c).The
thedesignphasearedifferentfromtheonesusedlaterinevaluation. coordinatesofthetwocenterpointsofeachboxarethevalues
5100
100
50
50
0 0
−50 −50
−100 −100
−100 −50 0 50 100 −100 −50 0 50 100
(a)w/ocamerashakecalibration (b)w/camerashakecalibration (c)correctpattern
Figure6. Theresultingfingertipmovementtrajectorieswithout(a)andwith(b)camera-shakecalibration.Thecorrectpatternisshownin(c).Toaidclarity
wehavetransformed(a)and(b)totheuser’sperspective.
Section VI-E, we show that a minor estimation error of the
filming angle has little impact on the attacking success rate.
50 By default, we assume that the pattern grid is presented in
the portrait mode3. If this is not the case, i.e. the pattern grid
100 is shown in the landscape mode, we need to use the shorter

edge of the device to calculate the filming angle. We believe
150 that an attacker interested in a particular target device would
100 200 300 400 have some knowledge of how the pattern grid is presented
under different orientation modes and be able to identify the
Figure7. Filminganglecalculation.Thefilmingangle,θ,istheanglebetween device orientation by watching the video. There are also other
theedgelineofthedeviceandaverticalline.
methods to be used to identify the filming angle [28].
Based on the estimated filming angle, θ, we use the
ofxandy,andtheirrelativepositionsarerepresentedby(cid:52)X followingformulatotransformthetrackedfingertipmovement
and (cid:52)Y. For each frame where both areas are successfully trajectory from the camera’s view point to the user’s:
tracked, we compute the relative coordinates, ((cid:52)X, (cid:52)Y),
which are reported as the location of the tracked fingertip. (cid:20) (cid:21)
(cid:48) cosθ −sinθ
S =TS , T = (1)
Figure 6 shows the results when using TLD to process sinθ cosθ
a video that was filmed with some camera shake effects.
Figure6illustratesthetrackingresultswithout(a)andwith(b) where T is a Transformation Matrix, S(cid:48) is the coordinate
camera-shakecalibration.Toaidclarity,wehaveconvertedthe
of a point of the tracked trajectory, and S is the resulting
trajectories into the user’s perspective. Without camera-shake
coordinate after the transformation. For each video frame, our
calibration, the resulting trajectory is significantly different
algorithmindividuallycalculatesthefilmingangleandperform
from the actual pattern shown in Figure 6 (c). Because of this
the transformation, because the filming angle may change
great difference, using Figure 6 (a) will lead to misidentifica-
across video frames.
tion of candidate patterns. By contrast, Figure 6 (b) generated
withcamera-shakecalibrationismorealikethecorrectpattern.
D. Identify and rank candidate patterns
C. Filming angle transformation In this step, the fingertip movement trajectory will be
mapped to a number of candidate patterns to be tested on
In practice, the filming camera will not directly face the
the target device. The goal of the attack is to exclude as many
target device to avoid raising suspicion by the target user. As
patterns as possible and only leave the most-likely patterns to
a result, the fingertip movement trajectory generated by the
be tried out on the target device. Our approach is to use the
trackingalgorithmwilllookdifferentlyfromtheactualpattern.
geometryinformationofthefingertipmovementtrajectory,i.e.
For example, for the pattern presented in Figure 2 (a), if the
the length and direction of line segments and the number of
videoisfilmedfromtheattacker’sfront-lefttothetargetdevice
turning points, to reject patterns that do not satisfy certain
(i.e. with a filming angle of approximate 45 degrees), we get
criteria. In this section, we first describe how to identify
the trajectory shown in Figure 2 (c). Using this trajectory
overlapping line segments and extract length and direction
without any postprocessing will lead to misidentification of
information before presenting how to use the extracted infor-
candidate patterns. Therefore, we must transform the resulting
mation to identify and rank candidate patterns.
trajectory to the user’s view point. To do so, we need to
estimate the angle between the filming camera and the target 1)Extracting Structure Information: A pattern can be
device. Our approach is described as follows. defined as a collection of line segments where each line
segment has two properties: the length of the line, l, and
We use an edge detection algorithm called Line Segment
the direction of the line, d. We define a pattern, P, as a
Detector (LSD) [12] to detect the longer edge of the device.
The filming angle is the angle between the detected edge 3ThepatterngridoftheAndroidnativepatternlockisalwayspresentedin
line and a vertical line. This is illustrated in Figure 7. In theportraitmoderegardlessoftheorientationofthedevice.
6100 S A S A 16 2 150
S
50
14 15 1 3 4 50
C B 9
0 C B 13 5 0 A B
-50 D E 12 11 9 7 6 -50 1 5 9
-100 D E D 13 C
-100 -50 0 50 100 -100
10 8 -100 -50 0 50 100
(a)trackedfingertipmovement (b)patternexample
(b)numberinglinesegmentofthe
(a)linedirectionnumber trackedtrajectory
Figure8. Thisfigureshowsthetrackedfingertipmovementtrajectory(a)of
apattern(b).PointSon(a)isthethestartingpointandpointsA,B,C,and
Figure10. Allpossiblelinedirectionsfora3×3Androidpatterngrid.
Don(b)representfourturningpoints.
Algorithm 2 Line Segment Identification A specific challenge here is how to separate two overlapping
Input: line segments (see Figure 12 c for an example). It is to note
struct T[]: Temporal information of each tracked location that up to two lines can be overlapped on a pattern grid. The
timeTh:Thresholdofwhethertwolinesegmentsareoverlapping naive linear fitting algorithm would consider two overlapping
Output: segments to be a single line as their points stay close to
tp[] Turning points of fingertip movement.
each other. We overcome this problem by using the temporal
1: for each fingertip movement with temporal sequences T[] do
information (that is recorded by the tracking algorithm) to
2: tpNum=0;
separate two overlapping points. To do so, we visit all tracked
3: struct lines[]←getLines(T[])
pointsofeachlinesegmentgivenbythelinearfittingalgorithm
4: lNum←getLinesNumber(lines[])
5: for i=1:lNum do (line 5) within a timeframe (timeTh) of 20 video frames for a
6: if checkOverlap(lines[i],timeTh) then video of 30 FPS (40 for a video of 60 FPS). For each point,
7: p[tpNum++]←getOverlapPoints(line[i]) we calculate its Euclidean distances to all other points within
8: end if the timeframe. We consider two points to be overlapping if
9: p[tpNum++]←getTurningPoints(line[i]) their distance is less than 5 pixels. For a video shot at 30
10: end for FPS, we consider there exist two overlapping line segments
11: end for if 5 (10 for a 60 FPS video) or more overlapping points in
12: tp[]=p[0:end−1]
the timeframe. Again, these threshold values were determined
throughourinitialdesignexperiments.Finally,weconsiderthe
centerofallpointsastheturningpointofthetwooverlapping
40 26 line segments and use turning point to separate the two lines.
Line 1 Line 2
20 Example: As an example, consider a fingertip movement
timeframes 1110138 trajectory shown in Figure 9 (a). The red rectangle on the
0 25 figure is a timeframe consisting of 20 tracked points. If we
Line 1 12 14 1 zoom in on the timeframe, we get Figure 9 (b) where a point
-20 Line 2 9
is labelled with a frame number according to when the point
Line 3
-40 24 wasseen,startingfrom1fortheearliestpoint.Inthisexample,
-100 -50 0 50 100 90 100 110 there are more than 6 overlapping points within the same
(a)overlappinglines (b)enlargementoftimeframe
timeframe, which are marked by a green circle. We use the
center point (No.10) of the overlapping points as the turning
Figure9. Separatingtwooverlappinglinesegmentsbycheckingthenumber
point to separate the two line segments.
ofoverlappingpointswithinatimeframe.
Extract the Line Length The physical length of a line
collection of line segment prosperities, P = {L,D}. Here segment depends on the sizes of the screen and the pattern
L = {l 1,l 2,··· ,l n} is a collection of the lengths of all line grid, and the space between two touch dots. To ensure our
segments (that are numbered from 1 to n) of the pattern, and approach is independent of the device, we normalize the
D = {d 1,d 2,··· ,d n} is the collection of directions for all physical length of a line segment to the shortest line found on
linesegmentsinL.Algorithm3describeshowP isextracted. the tracked trajectory. For the example shown in Figure 8 (a),
We extract the length and the direction of each line segment the line lengths for segments, SA, AB, BC, CD, and DE, are
fromthetrackedfingertipmovementtrajectoryandstorethem 2l ,l ,2l ,l,2l ,respectively.HeresegmentsABandCDhave
s s s s
into arrays L[] and D[] respectively. the shortest length, l . The physical length of a line segment
s
iscalculatedbycomputingtheEuclideandistancebetweenthe
IdentifyLineSegmentsThefirststepofgeometryinformation
start and the end points of a segment.
extraction is to identify individual line segments from the
trajectory. This can be achieved by finding turning points, the Extract Direction Information In addition to the line length,
start and the end points of the pattern, because two points we also want to know to which direction the fingertip moves.
define a line segment. For example, turning points, A and B, Thisinformationisusefulforinferringwhichdotsareselected
inFigure8definesalinesegment,AB.InAlgorithm2,weuse to unlock the pattern. Figure 10 (a) shows all possible 16
a linear fitting method [17] to discover turning points (line 3). directionsona3×3patterngrid.Thedirectionsarenumbered
7TableI. MAPPINGSFROMLINESLOPESANDFINGERTIP-HORIZONTAL
MOVEMENTSTODIRECTIONNUMBERS
Direction No. 1 2 3 4 5 6 7 8
slope (L → R) +∞ 2 1 1 0 −1 −1 −2 a(1) a(2) a(3) a(4) a(5)
2 2
Direction No. 9 10 11 12 13 14 15 16
slope (R → L) −∞ 2 1 1 0 −1 −1 −2
2 2
Algorithm 3 Candidate Pattern Identification Algorithm
Input: b(1) b(2) b(3) b(4) b(5)
L[]: Relative line length
D[]: Direction number (see Figure 10)
tn: Number of turning points of fingertip trajectory
lengthTh:Thresholdofconsideringtwolinestohavethe
same length c(1) c(2) c(3) c(4) c(5)
directionTh: Threshold of considering two lines to be in
the same direction
Output:
P[]: Candidate patterns
1: for each possible pattern p with tn turning points do d(1) d(2) d(3) d(4) d(5)
2: n←getLineNumber(P[]) Figure11. Possiblemappingsforthetrackedfingertipmovementtrajectory
3: pL[]←getRelativeLength(p) presentedinFigure2(d).
/*Relatvie line length for pattern p*/
4: pD[]←getDirection(p) the relative length threshold, lengthTh, is set to 1.12 and the
5: if match(pL[], L[], lengthTh) then slope threshold, directionTh, is set to 0.25. To determine the
6: if match(pD[], D[], directionTh) then thresholds,wehaveevaluatedarangeofpossiblevaluesinour
7: P[]←p initialdesignexperimentstochosethebestperformingvalues.
8: end if
9: end if Example: We use the pattern depicted in Figure 2 as an
10: end for example to describe our algorithm. Figure 11 gives several
11: P[]←sort(P[]) possiblemappingsforthefingertipmovementtrajectoryshown
inFigure2(d).Forthisparticulart√rajectory,thecollectionsof
lengths and directions are L={l, 2l,l} and D ={5,11,5}
respectively. Any pattern that does not meet L or D should
from 1 to 16 in clockwise. For each line segment of the
not be considered as a candidate pattern for this trajectory.
trackedtrajectory,wecalculateitslineslopeandthehorizontal
For this reason, Figure 11 a(1)–a(5) will be rejected. Take
movementofthefingertip(i.e.left→rightorviceversa).This
Figure 11 a(1) as an example, the line lengths and directions
information will then be checked against Table I to determine √
for all four line segments of this pattern are {l, 5l,l} and
the direction number of the line segment. The horizontal 2
{5,12,5} respectively. It does not meet the expected L or D
movement of the fingertip is determined by first using the
and should be rejected. The patterns presented in b(1)–b(5)
temporal information to find out the start and the end points
and c(1)–c(5) of Figure 11 will also be rejected for the same
of the line and then comparing the horizontal coordinates of
reason.
the two points. The line slope is also computed based on the
coordinatesofthestartandtheendpointsofthelinesegment. Rank Patterns Candidates patterns are then ranked using a
Figure 10 (b) gives the direction number of each tracked line simple heuristic. The heuristic assumes a pattern starting from
segment of a fingertip movement trajectory. leftdotofthegridismorelikelytobethecorrectpatternovera
pattern starting from a right dot. This assumption is supported
2)Map the Tracked Trajectory to Candidate Patterns: In
by recent studies which show that people tend to select a left
thisstep,weusetheextractedgeometryinformationtomapthe
dot as the starting point to construct a pattern [18, 29]. If
fingertip movement trajectory to a small number of candidate
two candidate patterns start from the same dot, we consider
patterns which will then be ranked using a heuristic. This
the pattern with a longer total line length is more likely to
process is described in Algorithm 3.
be the correct pattern. Using these criteria, the five candidate
Identify Candidate Patterns Our implementation simply patterns are ranked in order from subfigures d(1) to d(5) in
enumerates all possible patterns for a given pattern grid to Figure 11. Therefore, an attacker would first try the candidate
identify candidate patterns, starting from the top-left touch pattern presented in Figure 11 d(1). This attempt will lead to
point. We reject patterns that do not meet the requirements a successful attack for the example presented in Figure 2. Our
that the correct pattern is expected to have. The requirements experimental results confirm that this heuristic is effective.
are the number of line segments (this is checked by counting
thenumberofturningpoints),andthelengthandthedirection V. EXPERIMENTALSETUP
foreachlinesegment.Thisisanautomaticprocessperformed
A. Data Collection
byoursoftwaresystemwithoutanyuserinvolvement.Wecon-
sidertwolinesegmentshavingthesamelengthandslopeifthe The patterns used in our evaluation were collected from
difference between them is less than a threshold. Specifically, users who use at least one Android device (a smartphone or
82
1
2 5
2 2
TableII. SCREENSIZESFORTHETESTPHONES
Brands
MI4 Honor7 Note4
Size
Height(cm)×Width(cm) 13.9×6.9 14.3×7.2 15.4×7.9
is given a unique, randomly generated 32-digital number.
(a)linelength (b)line (c)overlapping
Overall, 37.6% of our participants confirmed that they use
intersection lines
patternlockasthescreenlocktoprotecttheirAndroiddevices
Figure12. IllustrationsoftheterminologiesusedinEquation2. on a daily basis; and 33% of those who do not use a pattern
as their screen lock said that they are often required to use
a pattern for authentication by an application like Alipay.
Furthermore, 60% of our participants also indicated that the
pattern they provided is currently being used or have been
used in the past by themselves. Other participants (often those
(a)Examplepatternsbelongtothesimplecategory.
did not use a locking pattern on a daily basis) indicated that
they have provided a pattern which they would like to use if
a locking pattern is required. Based on this information, we
are confident that the patterns we collected represent some of
the real world patterns. Finally, all participants believe that
(b)Examplepatternsbelongtothemediancategory.
a complex pattern provides stronger protection than a simple
counterpart.
B. Pattern Complexity Classification
(c)Examplepatternsbelongtothecomplexcategory. Wequantifythecomplexityofapatternusingthecomplex-
ity (strength) score proposed in [27]. The complexity score,
Figure 13. Examples of patterns collected from our participants. Patterns
CS , of a pattern, P, is defined as:
are grouped into simple, median and complex categories, according to their P
complexityscores.
CS =S ×log (L +I +O ) (2)
P P 2 P P P
where S is the number of connected dots, L is the the
P P
total length of all line segments that form the pattern (see
Figure 12 a), I are the number of intersections (which are
P
also termed as “knight moves” in some prior work [30], see
Figure 12 b) and O are the number of overlapping linear
P
complexityscore: complexityscore: complexityscore: segments (see Figure 12 c). To calculate the line length,
43.8 44.7 46.8
we assume the length between two horizontally or vertically
Figure14. Threemostcomplexpatternsona3×3gridbasedonEquation2. adjunct dots is one. Thus, our method is independent of the
size of the screen and the grid.
a tablet) on a daily basis. To collect the patterns, we have
Intuitively, the more connected dots (S ), line segments
distributed over 1,000 survey forms and collected back 215 P
validforms,resultingin120uniquepatterns4.Ourparticipants (L P), intersections (I P) and overlapping line segments (O P)
that a pattern has, the more complex it is. For example, the
include 95 females and 120 males who were undergraduate or
patternsshowninFigure13(c)usealltheninedotsofthegrid,
postgraduate students at the host university. The majority of
and have at least seven line segments and three intersections.
our participants are in an age group of under 30.
Base on the complexity score, we divide the collected
To collect the patterns, we have conducted a “pen-and-
patterns into three complexity categories: simple, median and
paper” survey by asking participants to fill in an anonymized
complex.Asimplepatternhasascoreoflessthan19,amedian
questionnaire.Thequestionnaireandsurveywereapprovedby
complexpatternhasascorebetween19and33,andacomplex
the research ethics board (REB) of the host institution. We
pattern must have a score greater than 33. This classification
have made sure that our survey complied with strict privacy
gives us roughly 40 patterns per category. Figure 13 gives
regulations. For example, we did not collect any personally
some examples for each category while Figure 15 shows the
identifiable information other than the gender and age group
distribution of these patterns according to their complexity
of the participant. Our participants were well informed on
scores. Based on this definition, the most complex pattern on
the purpose of the study and how the data will be managed
a 3×3 grid has a score of 46.8 (see Figure 14). The complex
and used. The survey forms were distributed as voluntary
scores of the patterns we collected range from 6.4 to 46.8.
homework so that the participants can take the survey form
away to fill in. Users were invited to return the survey
form anonymously within three weeks to a dedicated, locked C. Video Recording and Preprocessing
mailbox,iftheywishtoparticipateinthestudy.Toavoidauser
User Participation We recruited ten postgraduate students
submits multiple copies of the same form, each survey form
(fivemaleandfivefemalestudents)fromNorthwestUniversity
4Available to be downloaded at: https://dx.doi.org/10.17635/lancaster/ to reproduce the 120 patterns (collected from users) and the
researchdata/113. 60 most complex patterns (see Section VI-A) on three target
98
6
4
2
0
6 .3 4 1 3 .0 8 1 9 .8 2 2 6 .5 6 3 3 .3 0 4 0 .0 4
s k
c ol
nr
ett
a p f o
r
e
b
m
u
N
100%
80%
60%
40%
20%
0%
Simple Median Complex
The complexity of pattern locks
C o m p le x ity sc o re
Figure 15. The distribution of complexity scores for the patterns given by
ourparticipants.
mobile phones: a Xiaomi MI4, a Huawei Honor7 and a
Samsung Note4. Table II lists the screen size for each target
mobile phone.
Recording Devices We used three smartphones for video
recording: an Apple iPhone4S, a Xiaomi MI4 and a Meizu2.
Each mobile phone was used to record 40 patterns with
a 1080p HD resolution of 30 FPS under different settings
described as follows.
Video Recording Setup By default, we used the Android 3×
3 native pattern grid, but we evaluated our approach using
other pattern grids with different sizes in Section VI-G. We
recorded each pattern under three filming angles, 45, 90 and
135 degrees, by placing the camera on the left-front, front,
and right-front of the target device respectively. By default,
the video was recorded indoor during daytime under a natural
lightingcondition.InSectionVI-Dweevaluatedourapproach
underdifferentlightingconditionsbothindoorandoutdoor.By
default, videos were recorded at a distance of 2 meters from
the target device and we evaluated the impact of the filming
distance in Section VI-G.
Video Filming Before recording, our participants were given
the opportunity to practice a pattern several times, so that
they can draw the pattern at their natural speed. On average,
this practice session took 10 trails per user per pattern. When
drawing the pattern, some participants sat, while others stood,
some hold the device by hands, while others placed it on a
table. Each pattern was drawn on three target devices and
recordedunderthreefilmingangles.Thus,forthe120patterns
collected from users, we recorded 1,080 videos in total.
Video Preprocessing For each video stream, we used the
algorithm described in Section IV-A to cut out the video
segment of the unlocking process. We left around 200 to 300
milliseconds of the video segment before and after the pattern
unlocking process. To track the fingertip locations, we used
Windows Movie Maker to highlight two areas of interest on
the first frame of the video segment: one area surrounds the
fingertip, and the other contains an edge of the phone (see
Section IV-B2).
Implementation Our prototyped attacking system built upon
a TLD library [14] in Matlab. The developed software ran on
an Intel Core i5 PC with 8GB RAM. The operating system is
Windows 10. Our implementation can be ported onto Android
or Apple iOS systems, which is our future work. On our
evaluation platform, our software takes less than 30 seconds
to process a video to produce candidate patterns.
etar
sseccus
gnikcarC
1 attempt
2 attempts 3 attempts
4 attempts
5 attempts
Figure16. Foreachpatterncategory,thefigureshowsthesuccessrateusing
nomorethan1,2,3,4and5attempts.
VI. EXPERIMENTALRESULTS
In this section, we first present the overall success rate
for cracking the 120 patterns collected from our participants
plus the top 60 most complex patterns on a 3×3 pattern grid.
Ourresultsshowthatourapproachcansuccessfullycrackover
95%ofthepatternsusingnomorethanfiveattempts.Wethen
analyzehowthesuccessrateisaffectedbythefilmingdistance,
filming angles and camera shake. Finally, we demonstrate that
directobservationsleadtopoorperformancebeforeevaluating
our approach on alternative pattern grids.
A. Overall Success Rate
Result 1: We can successfully crack over 95% of the patterns
infiveattemptsandcomplexpatternsarelesssecurecompared
to simple patterns under our attack.
Inthisexperiment,videoswererecordedfromadistanceof
2 meters away from the target device. This mimics a scenario
wheretheadversarysitsatthenexttabletotheuserinapublic
space (e.g. a restaurant). The smartphones used for filming in
this experiment were hand-held. Figure 16 shows the success
rate for cracking different types of patterns within 1, 2, 3, 4
and5attempts.Forallthepatternsusedinthisevaluation,our
approach does not generate more than five candidate patterns.
Forcomplexpatterns,weareabletocrackallexceptone(with
a 97.5% success rate) in the first attempt. For simple and
median patterns, the success rate increases with more tries.
In one attempt, we are able to successfully crack 60% and
87.5% of the simple and median patterns respectively. With
twoattempts,thesuccessrateincreasesto87.5%,and95%for
simple and median patterns respectively. Using five attempts,
weareabletocrackallsimplepatternsandallbutonemedian
patterns. The reason that we failed on one median and one
complexpatternsisbecauseofsomeblurmotionsofthevideo
footage(probablycausedbythevideocompressingalgorithm),
whichleadstomanytrackingfailures.Butweareabletocrack
the same pattern using a video filmed by a different device. It
is important to note that the native Android system allows up
to five failed tries before locking the device [11]. This means,
in practice, our approach is able to successfully crack most
locking patterns.
Another interesting observation is that in contrast to many
people’s intuition, complex patterns do not provide stronger
protection under our attack – as can be seen by the fact
that most of the complex patterns can be cracked in one
attempt. This is because although complex patterns can better
protect the user against direct observation techniques like
shoulder surfing [21], their unique graphical structures help
1040
30
20
10
0
1 2 3 4 5
Number of candidate patterns
snrettap
fo
rebmuN
points on the tracked trajectory, leading to a deteriorative
Simple
Median performanceinidentifyingcandidatepatterns.Thiscanbeseen
Complex fromFigure18wherethequalityoftrackingclearlydecreases
when the filming distance is greater than 3 meters. Nonethe-
less, our approach can achieve a high success rate when the
filmingdistanceiswithin2.5meters.Suchadistanceallowsan
attackertorecordthevideowithoutraisingsuspicionsinmany
day-to-day scenarios (some of these are depicted in Figure 1).
We also evaluated our approach on videos filmed using a
entry-level single-lens reflex (SLR) camera, Nikon D90, with
Figure17. Thedistributionofcandidatepatternsforeachcategory.Nomore a low-end 105mm lens. The SLR camera was placed from a
than5candidatepatternsweregeneratedbyouralgorithm.
distance of 9 meters away from the target device. For this set
TableIII. TRACKINGPRECISIONVSFILMINGDISTANCE
of videos, we are able to achieve the same performance when
compared to using videos filmed by a mobile phone camera
Distance 1 m 2 m 3 m 3.5 m
with a 2-meter filming distance. The further filming distance
fingertip 100% 98.7% 80.9% 68%
is largely due to better video quality brought by the advanced
device edge 100% 99.4% 90.6% 69%
SLR camera and the lens. Therefore, in practice, an attacker
can also use a professional video recording device to launch
our algorithms to narrow the possible options down. This is
the attack from a further distance.
confirmedbyFigure17.Itshowsthatformostmedianandall
complex patterns, our system produces one candidate pattern
– the correct one for most of our test cases. C. Impact of Camera Shake
We also evaluated our approach using the top 60 most Result 3:Ourmethodcantolerateacertaindegreeofcamera
complex patterns (according to Equation 2) on a 3×3 grid. shake in the hand-held mode.
To evaluate our approach on a wide range of patterns, we
excludepatternsthataresimplyarotationtoanalreadychosen In this experiment, we used an IPhone4S smartphone to
pattern. Figure 14 illustrates three highly complex patterns recordhowapatternisdrawnonaHuaweiHonor7phone.This
which have a complexity score between 43.8 and 46.8. The experiment was carried out under three settings: fixed, hand-
threepatternsusealltheninedotsofthegridandhavealarger heldandshaky,wherethefilmingdevicewasrespectivelyfixed
number of line segments, intersections and overlapping lines using a tripod, hand-held, and hand-held but with constant
when compared to simpler patterns. Because of their complex movementsofapproximate2cminthehorizontalorthevertical
graphical structures, remembering these patterns using direct directions. The recording device was placed on the left-front,
observation techniques would be difficult. In this experiment, front,andright-frontofthetargetdevice.Intheexperiment,we
we can crack all the complex patterns in one attempt. This affixed the target device on a table using double-sided tapes.
result reinforces our claim that complex patterns are less
We use a reference point to quantify camera shake. The
security under video-based attacks.
point is the center position of an area of the target device.
The area is marked by a boundary box on the first frame (see
B. Impact of Filming Distances
Figure 5). We calculate the difference (in terms of pixels) of
the locations of the reference point in two consecutive video
Result 2: We can crack over 80% of the patterns in five
frames. We then use the difference to measure the degree of
attempts, if the video was filmed using a smartphone within
camera shake. Figure 20 shows the cumulative distribution
a distance of 2.5 meters away from the target.
function (CDF) of camera shake under the three different
We would like to know how the filming distance affects filming settings. Here, the wider the distribution is, the less
the success rate of the attack. To do so, we used all the 120 steady the filming is. The shaky mode is least stable where
collected patterns and we varied the filming distance from 1 thedifferenceofthereferencepointbetweentwovideoframes
meterto3.5meters.Figure19showshowthecrackingsuccess can be up to 250 pixels.
ratechangesasthefilmingdistanceincreases.Thereareminor
discrepancies in the success rate between this diagram and Figure 21 shows that our approach has the same perfor-
Figure 16 because we used less patterns in this experiment. mance under the hand-held and the fixed modes. The modest
When the filming distance is less than 2 meters, our approach camera sake under the hand-held mode has little impact
can crack all patterns in five attempts. The success rate drops on performance thanks to our camera-shake calibration. We
significantly when the filming distance is greater than 2.5 observe deteriorative performance under the shaky mode, but
meters. Beyond this point, the quality of the video filmed by the performance degradation is modest (80% vs 97% in five
a mobile phone tends to drop significantly with many object attempts). In reality, an attacker would avoid drastic camera
deformations. The degradation of the video quality makes it shake by firmly holding the video recording device.
difficult for the TLD algorithm to successfully track objects
across video frames. This is confirmed by Table III which
D. Impact of Lighting Conditions
shows that the tracking precision for the fingertip and the
device edge drops from around 99% to 68% when the filming Result 4: Low-light has a negative impact on the success rate
distance increases from 2 meters to 3.5 meters. The increased of the attack but our approach can still break over 70% of the
tracking failures result in an increased number of missing patternswhenthevideowasfilmedinalow-lightenvironment.
1170 80 80
35 40 40
0 0 0
−35 −40 −40
−70 −80 −80
−80 −40 0 40 80 −80 −40 0 40 80 −80 −40 0 40 80
(a) (b) (c) (d)
Figure18. Trackedfingertiptrajectories(user’sperspective)forthepatternshownin(d)fromavideofilmedfromadistanceof2m(a),3m(b),and3.5m(c)
respectivelyawayfromthetargetdevice.Thetrackingqualitydecreaseswhenthefilmingdistanceisgreaterthan3m.
100%
80%
60%
40%
20%
0%
1 1.5 2 2.5 3 3.5 Distance(Meter)
etar
sseccus
gnikcarC 1 attempt 2 attempts
3 attempts
4 attempts
5 attempts
Figure19. Impactofthefilmingdistance.
1
0.8
0.6
0.4
0.2
0 −150 −100 −50 0 50 100 150
The distance between video frames
FDC
fixed
hand−held
shaky
Figure 20. The cumulative distribution function (CDF) for different video
recordingmodes.
100%
80%
60%
40%
20%
0%
1 2 3 4 5
The number of sucessfull attempts
etar
sseccus
gnikcarC
TableIV. LIGHTINGCONDITIONS
Scenarios Indoor Indoor Indoor Outdoor
Time nighttime nighttime daytime daytime
LightSource warmLED whitefluorescent sunlight sunlight
LightIntensity(Lux) 55−70 70−100 150–240 500–9500
1 0 0 %
9 0 %
8 0 %
7 0 %
5 5 7 0 1 5 0 -2 4 0 5 0 0 -9 5 0 0
shaky hand−held fixed
Figure21. Impactofcamerashake.Ourapproachhasthesamesuccessrate
under the hand-held and the fixed modes and the performance degradation
undertheshakymodeismodest.
In this experiment, videos were recorded under different
lighting conditions both indoor and outdoor. The experimental
settings are given in Table IV. The light intensity of these
condidtions ranges from 9500 lux (strong light), onto 240 lux
(normallight),and55-70lux(lowlight).Theserepresentsome
of the day-to-day scenarios where filming can take place. For
each setting, we tested all the 120 patterns on a Xiaomi MI4
phone and used an iPhone4S phone to record the video. The
filmingcamerawasplaceontheleft-front,front,andtheright-
front of the target device from a distance of 2 meters.
Figure22showsthatthesuccessrateincreaseswhenvideo
filming were performed in a brighter lighting condition as
the light intensity changes from 55 lux to 9500 lux. This is
et ar
s s e c
c
u s
g
ni
k
c
ar C S im p le M e d ia n C o m p le x
D iffe re n t lig h t c o n d itio n s (L u x )
Figure 22. The cracking success rate within five attempts under different
lightingconditions.
100%
80%
60%
40%
Simple Median Complex 20%
0 degree 5 degrees 10 degrees
Figure23. Impactofestimationerrorsoffilmingangles.
expected as low-light leads to increased video noise, blurred
motions and poor focus, which all have a negative impact on
theTLDalgorithm.Nonetheless,ourattackcanstillcrackover
70% of the patterns in a filming environment of low light.
E. Impact of Filming Angle Estimation
Result 5: Our attack performs well when the error of filming
angle estimation is less than 5 degrees.
Recall that our attack needs to transform the fingertip
movement trajectory to the user’s perspective based on an
estimation of the filming angle (Section IV-C). Because our
filming angle estimation algorithm gives highly accurate re-
sults, we did not find the estimation error to be an issue in
our experiments. Nonetheless, it is worth studying how the
estimation error affects the success rate of our attack. To do
so, we deliberately added an error of 5-10 degrees to the
estimation in this experiment.
Figure 23 shows the results of this experiment. When the
error is less than ±5 degrees, there is little impact on complex
12patterns and no impact at all on simple and median patterns. 50%
However, an estimation error of more than 10 degrees can 40%
significantly affect the success rate. Given such errors, the
30%
resulting trajectory after transformations will be significant
different from the correct pattern. For example, when the 20%
estimation error is 10 degrees from the true value, on average,
10%
0.8, 2.6 and 4.2 line segments per pattern respectively will be
incorrectly labelled for simple, median and complex patterns. 0%
This explains why the success rate for complex patterns drops 1 2 3 4 5
significantlywhenthefilmingangleestimationerrorisgreater Number of attempts
or equal to 10 degrees.
F. Inferring Patterns with Eyes
Result6:Ourattackingmethodologysignificantlyoutperforms
direct observation techniques.
In this experiment, we investigate whether an attacker can
infer the pattern by simply watching the video or through
direct observations. To answer this question, we asked each
of our ten participants to watch 60 videos (where a pattern
wasdrawnbyotherparticipants)toguessthepattern.Weonly
played the video segment during which a pattern is drawn to
the participant (around 3 seconds per video). To familiarize
participants with the process, we played five sample videos
and showed the correct patterns at the end of each video to
our participants before the experiment. Each participant then
had 10 minutes to watch a video and five chances to guess
a pattern. They could adjust the playing speed and replay the
video multiple times as they wished.
Figure 24 (a) shows the success rate of pattern guessing
with bare eyes. Our participants correctly guessed for nearly
half of the simple patterns in five attempts. However, they
found that it is difficult to infer complex patterns with many
linesegments,overlappinglinesandintersections.Thesuccess
rate of guessing complex patterns is less than 10% in five
attempts. This is not a surprising result because although it is
possible to correctly guess patterns with simple structures by
watching the video, doing so for patterns with more complex
structures is much harder.
Wealsoaskedparticipantstodirectlyobservehowapattern
was drawn from a distance of 2 meters away from the target
device.Theintuitionbehindthisevaluationisthathumaneyes
can catch richer information over a digital video camera. The
resultsofthisexperimentareshowninFigure24(b).Ascanbe
seen from the diagram, although the success rate is improved
compared to directly watching the video, the chances for
guessingthecorrectpatternin5attemptsarequitelow.Infact,
thesuccessratesare48.3%,38.3%and11.7%respectivelyfor
simple, median and complex patterns.
G. Evaluation on Other Pattern Grids
Result 7: A pattern grid with more dots provides stronger
protection but our attack can still crack most of the patterns.
There are a few applications (such as CyanLock) and
customized ROMs available to increase the size of the pattern
grid from 3 × 3 to 4 × 4, 5 × 5, and 6 × 6. Although a
3 × 3 grid remains a popular choice (as it is supported by
the native Android OS), it is worth studying whether having
moretouchdotsonapatterngridleadstostrongersecurity.In
etar
sseccus
gnikcarC
Simple
Median
Complex
(a)videowatching
50%
40%
30%
20%
10%
0%
1 2 3 4 5
Number of attempts
etar
sseccus
gnikcarC
Simple
Median
Complex
(b)directobservations
Figure24. Successratesofguessingpatternsthroughwatchingthevideo(a)
ordirectobservations(b).
100%
90%
80%
70%
60%
Simple Median Complex
etar
sseccus
gnikcarC
4*4 5*5 6*6
Figure25. Successratesofourattackfordifferentlockinggrids.
this experiment, we first ranked all possible patterns for each
grid setting in ascending order according to their complexity
scores.Wethenequallydividedthepatternsintothreegroups,
simple, medium and complex, and asked our participants to
randomly select 20 patterns from each group for evaluation.
We report the success rate of our attack within five attempts.
In the experiments, we have adapted our algorithms for each
gridsettingbyadjustingthealgorithmparameters(suchasthe
line direction numbers).
Figure25showsthesuccessrateofourattackfordifferent
grids. Similar to a 3 × 3 grid, our approach achieves a
higher success rate for complex patterns over simple ones.
On average, we can crack 90% of the complex patterns. We
observed that a grid with more dots does provide stronger
protection.Forcomplexpatterns,thesuccessrateofourattack
drops from 95% on a 4 × 4 grid to 87% on a 6 × 6 grid.
For simple patterns, the success rate of our attack drops from
85% on a 4 × 4 grid to 75% on a 6 × 6 grid. This is
because a fingertip trajectory in general could be mapped to
a larger number of candidates on a grid with more dots. For
instance, the pattern shown in Figure 2 (f) can be mapped
to 55 candidate patterns on a 6×6 grid as opposite to 5 on
a 3×3 grid. Overall, our attack can crack over 75% (up to
95%)ofthepatternswithinfiveattempts.Oneofthepurposes
ofintroducingpatterngridswithmoredotsistoallowusersto
13usemorecomplexpatterns.However,thisexperimentsuggests VIII. RELATEDWORK
thatcomplexpatternsremainlesssecurityonthesegridsunder
Our work lies at the intersection between computer vi-
our attack.
sion based attacks and cracking graphical- and touch-based
authentication methods. This work brings together techniques
VII. DISCUSSIONS
developed in the domain of computer vision and motion
A. Potential Countermeasures tracking to develop a new attack.
The success of our attack depends on three factors: (1) Computer Vision-based Attacks No work has targeted using
knowledge of the pattern grid; (2) a decent quality video video footage to crack Android pattern lock and this is the
footageallowingthealgorithmtotrackthefingertipmovement; first to do so. Our work is inspired by the work presented
(3) successfully identifying a video segment that captures the by Shukla et al. [23] on video-based attacks of PIN-based
entire process of pattern drawing. passwords. In addition to addressing the new challenges high-
lighted in Section I, our work differs to their approach in two
For the first factor, the attacker can obtain relevant in- ways. Firstly, we target a different authentication method, i.e.
formation via analyzing a device installed with the same graphical-based passwords, which are fundamentally different
operatingsystemandapplicationsasthetarget.Randomization from PIN-based passwords. Secondly, our approach does not
techniques such as randomized pictures [6, 24] could be a require knowledge of the size of the screen or the grid. Other
solution for the first factor. However, randomization-based work in the area including [33] which attacks PIN-based
solutions often come at the cost of poorer usability. This issue passwords by analyzing how the screen brightness changes
is a major obstruction for this approach to be adopted at a when entering a password. But the subtle changes of the
large scale. Regarding the second factor, there are ways, such screen brightness can be dramatically affected by the lighting
as KALEIDO [35], to prevent unauthorized videotaping by condition.InSectionVI-D,weshowthatourattackiseffective
dynamically changing the colour and brightness of the screen undervariouslightingconditions.Thisrestrictstheapplication
to confuse the filming camera. Furthermore, a non-technical of their approach. There is a body of work using reflections
solution for this aspect would be to educate users to fully to recover information typed by the user [2, 16, 20, 31]. They
cover their fingers when drawing a pattern. But doing this all require having a clear vision of the content displayed on
on a large-screen device could be awkward especially when the screen which is not required by our attack.
the device is held by one hand. For the third factor, the
attacker’s solution depends on the type of the pattern. For a Cracking Graphical-based Passwords Aviv et al. demon-
screen lock, pattern drawing is the first activity (except for strated that it is possible to reconstruct a locking pattern by
receivingaphonecallormakinganemergencycall)whenthe analyzing the oily residues left on the screen [1]. This method
device is retrieved. Therefore, identifying the video segment is highly restricted as oily residues can be messed up by
is straightforward. When the pattern is used by applications, any on-screen activities after pattern drawing. Zhang et al.
we have observed that users typically pause for a few seconds exploit the WiFi signal interferences caused by finger motions
before or after entering the pattern. Therefore, an experienced torecoverpatterns[34].Theirmethodrequiresacomplexsetup
attacker should also be able to identify the video segment and is highly sensitive to moving objects of the environment.
in case our automatic algorithm (presented in Section IV-A) Attacks on Touch-based Authentication Ballard et al. im-
fails to do so. A potential countermeasure is to mix pattern plemented a forgery attack on handwriting authentication [3].
unlockingwithotheron-screenactivities.Forexamples,before Using a small number of training examples, they achieve a
and after pattern drawing, the system can ask the user to type high success rate for this attack. More recently, Serwadda et
in a sentence using a Swype-like method or to draw some al.showthatasimplerobotcanachievehighpenetrationrates
graphicalshapes.Theproblemofthisapproachisthatitcould against touch-based authentication systems by analyzing on-
annoy users by asking them to do more, especially for screen screen gestures including swiping and zooming [22]. In this
unlocking – an activity that is performed many times a day. paper, we present a new, video-based attack for graphical-
based passwords. Research in this area all demonstrates the
B. Implications need for a closer look of the security risks of touch-based
authentication.
While pattern lock is preferable by many users [7], this
workshowsthatitisvulnerableundervideo-basedattacks.Our Study of Android Pattern Lock Uellebenk et al. study how
attack is able to break most patterns in five attempts. Consid- people use Android pattern lock on a daily basis [29]. They
ering Android allows five failed attempts before automatically found that in practice many people only use a small set of
locking the device, our work shows that this default setting is patterns due to the users’ bias in generating patterns. Løge
unsafe. We also demonstrated that, in contrast to many users’ explored the correlation between human’s characteristics (e.g.
perception, complex patterns actually do not provide stronger ages and genders) and the choice of patterns [18]. Her study
protection over simple patterns under our attack. shows that users have a bias in selecting the starting dot to
form a pattern and people tend to use complex patterns for
Itisworthmentioningthatourapproachisonlyoneofthe
sensitive applications.
many attacking methods that researchers have demonstrated.
Examples of these attacks include video-based attacks on MotionTrackingInadditiontoTLD,thereareothermethods
keystroke-based authentication [23, 33], sensor-based attacks proposedinthepastfortrackingobjectmotions.Someofthem
for pattern lock [34]. Authentication methods that combine apply image analysis to track the hand and gesture motions
different authentication methods [10, 19, 25] to constantly from video footage [5, 26, 32]. In this paper we do not seek
checks the user’s identity could be a solution. toadvancethefieldofmotiontracking.Insteadwedemonstrate
14that a new attack can be built using classical motion tracking [11] S. Egelman et al., “Are you ready to lock?” in CCS ’14.
algorithms.Weshowthattheattackpresentedinthisworkcan [12] v. G. R. Grompone et al., “LSD: a fast line segment
be a serious security threat for Android pattern lock. detector with a false detection control.” IEEE PAMI,
2010.
IX. CONCLUSIONS [13] T.HastieandR.Tibshirani,“Discriminantadaptivenear-
est neighbor classification,” IEEE PAMI, 1996.
This paper has presented a novel video-based side-channel
[14] Z. Kalal, “TLD: Tracking-learning-detection,” http://
attackforAndroidpatternlock.Theattackisbasedonavideo
kahlan.eps.surrey.ac.uk/featurespace/tld/.
filmedadistanceof2metersawayfromthetargetdeviceusing [15] Z. Kalal et al., “Tracking-learning-detection,” IEEE
a mobile phone camera. The attack is achieved by employing PAMI, 2012.
a computer vision algorithm to track the fingertip movement [16] M.G.Kuhn,“Compromisingemanations:eavesdropping
from the video, and then using the geometry information of risksofcomputerdisplays,”Ph.D.dissertation,University
the fingertip movement trajectory to identify the most likely of Cambridge, 2002.
patterns to be tested on the target device. Our approach was [17] M. H. Kutner, C. J. Nachtsheim, and J. Neter, “Ap-
evaluated using 120 unique patterns collected from indepen- plied linear regression models (5th ed.),” Technometrics,
dent users as well as some of the most complex patterns. The vol. 26, no. 4, 2004.
experimentalresultsshowthatourattackisabletosuccessfully [18] M.D.Løge,“Tellmewhoyouareandiwilltellyouyour
crack over 90% of the patterns in five attempts. We show unlockpattern,”Master’sthesis,NorwegianUniversityof
that, in contrast to many people’s belief, complex pattern Science and Technology, 2015.
actuallyprovidesweakerprotectionoversimplepatternsunder [19] M. Mannan and P. C. van Oorschot, “Using a personal
our attack. Our study suggests that Android pattern lock is devicetostrengthenpasswordauthenticationfromanun-
vulnerable to video-based side-channel attacks. trusted computer,” in Financial Cryptography and Data
Security. Springer, 2007, pp. 88–103.
ACKNOWLEDGEMENTS [20] R. Raguram et al., “iSpy: automatic reconstruction of
typed input from compromising reflections,” in CCS ’11.
This work was partly supported by the National Natural
[21] J. Rogers, “Please enter your four-digit pin,” Financial
Science Foundation of China (NSFC) through grant agree-
Services Technology, 2007.
ments 61672427, 61672428 and 61572402; and the UK En-
[22] A. Serwadda and V. V. Phoha, “When kids’ toys breach
gineering and Physical Sciences Research Council (EPSRC) mobile phone security,” in CCS ’13.
through grant agreements EP/M01567X/1 (SANDeRs) and [23] D. Shukla et al., “Beware, your hands reveal your se-
EP/M015793/1 (DIVIDEND). The user patterns used to eval- crets!” in CCS ’14.
uate this work are openly available from the Lancaster Uni- [24] H. Siadati et al., “Fortifying android patterns using per-
versity data archive at https://dx.doi.org/10.17635/lancaster/ suasive security framework,” in UBICOMM 2015.
researchdata/113. [25] D. Stefan et al., “Robustness of keystroke-dynamics
based biometrics against synthetic forgeries,” computers
REFERENCES & security, 2012.
[26] B. Stenger et al., “Model-based hand tracking using a
[1] A. J. Aviv et al., “Smudge attacks on smartphone touch
hierarchical bayesian filter,” IEEE PAMI, 2006.
screens,” in 4th USENIX Conference on Offensive Tech-
[27] C. Sun et al., “Dissecting pattern unlock: The effect of
nologies, 2010.
pattern strength meter on pattern selection,” Journal of
[2] M. Backes et al., “Tempest in a teapot: Compromising
Information Security and Applications, 2014.
reflections revisited,” in IEEE S & P ’09.
[28] A. Torralba and A. Oliva, “Depth estimation from image
[3] L.Ballardetal.,“Forgeryqualityanditsimplicationsfor
structure,” IEEE PAMI, 2002.
behavioral biometric security,” IEEE SMC, 2007.
[29] S. Uellenbeck et al., “Quantifying the security of graph-
[4] D. a. Balzarotti, “Clearshot: Eavesdropping on keyboard
ical passwords: The case of android unlock patterns,” in
input from video,” in IEEE S &P ’08.
CCS ’13.
[5] J. Beh et al., “Rule-based trajectory segmentation for
[30] E. von Zezschwitz et al., “Easy to draw, but hard to
modeling hand motion trajectory,” Pattern Recognition,
trace?: On the observability of grid-based (un)lock pat-
2014.
terns,” in CHI ’15.
[6] R. Biddle et al., “Graphical passwords: Learning from
[31] Y. Xu et al., “Seeing double: Reconstructing obscured
thefirsttwelveyears,”ACMComputingSurveys(CSUR),
typed input from repeated compromising reflections,” in
2012.
CCS ’13.
[7] D. V. Bruggen, “Studying the impact of security aware-
[32] M. H. Yang et al., “Extraction of 2d motion trajectories
nesseffortsonuserbehavior,”Ph.D.dissertation,Univer-
and its application to hand gesture recognition,” IEEE
sity of Notre Dame, 2014.
PAMI, 2002.
[8] L. F. Cranor et al., Eds., It’s a Hard Lock Life: A Field
[33] Q.Yueetal.,“Blindrecognitionoftouchedkeys:Attack
Study of Smartphone (Un)Locking Behavior and Risk
and countermeasures,” arXiv preprint arXiv:1403.4829,
Perception.
2014.
[9] A.DeAngelietal.,“Isapicturereallyworthathousand
[34] J.Zhangetal.,“Privacyleakageinmobilesensing:Your
words? exploring the feasibility of graphical authentica-
unlockpasswordscanbeleakedthroughwirelesshotspot
tion systems,” Int. J. Hum.-Comput. Stud., 2005.
functionality,” Mobile Information Systems, 2016.
[10] A. De Luca et al., “Touch me once and I know it’s you!:
[35] L. Zhang et al., “Kaleido: You can watch it but cannot
implicit authentication based on touch screen patterns,”
record it,” in MobiCom ’15.
in CHI ’12.
15