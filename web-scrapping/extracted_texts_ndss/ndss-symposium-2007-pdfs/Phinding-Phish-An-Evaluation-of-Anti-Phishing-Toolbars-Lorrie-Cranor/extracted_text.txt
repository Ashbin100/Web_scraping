Phinding Phish: Evaluating Anti-Phishing Tools
Yue Zhang, Serge Egelman, Lorrie Cranor, and Jason Hong
Carnegie Mellon University
zysxqn@andrew.cmu.edu, {egelman, lorrie, jasonh}@cs.cmu.edu
Abstract dollars are lost each year due to unsuspecting users
entering personal information into fraudulent web
There are currently dozens of freely available tools sites. To respond to this threat, software vendors and
to combat phishing and other web-based scams, many companies with a vested interest in preventing
of which are web browser extensions that warn users phishing attacks have released a variety of “anti-
when they are browsing a suspected phishing site. We phishing tools.” For example, eBay offers a free tool
developed an automated test bed for testing anti- that can positively identify the eBay site, and Google
phishing tools. We used 200 verified phishing URLs offers a free tool aimed at identifying any fraudulent
from two sources and 516 legitimate URLs to test the site [9], [12]. As of September 2006, the free software
effectiveness of 10 popular anti-phishing tools. Only download site Download.com, listed 84 anti-phishing
one tool was able to consistently identify more than tools. Unfortunately, few empirical studies have been
90% of phishing URLs correctly; however, it also performed to examine the effectiveness of these tools.
incorrectly identified 42% of legitimate URLs as phish. Thus, while many anti-phishing tools exist, it is not
The performance of the other tools varied considerably clear how well they actually work.
depending on the source of the phishing URLs. Of Previous studies have examined the extent to which
these remaining tools, only one correctly identified users fall for phishing scams and whether users benefit
over 60% of phishing URLs from both sources. from the information provided by anti-phishing tools.
Performance also changed significantly depending on These studies have shown that most users are likely to
the freshness of the phishing URLs tested. Thus we fall for phishing scams, and that many users ignore
demonstrate that the source of phishing URLs and the warnings provided by anti-phishing tools [7], [8], [13],
freshness of the URLs tested can significantly impact [25]. However, little empirical data is available on the
the results of anti-phishing tool testing. We also accuracy of these tools or on the effectiveness of the
demonstrate that many of the tools we tested were various approaches to detecting phishing sites.
vulnerable to simple exploits. In this paper we describe Towards that end, this paper makes three research
our anti-phishing tool test bed, summarize our contributions. First, we describe the design and
findings, and offer observations about the effectiveness implementation of a test bed for automatically
of these tools as well as ways they might be improved. evaluating anti-phishing tools. Second, we describe the
results of experiments that assess the accuracy of 10
1. Introduction popular anti-phishing tools that use differing
techniques to identify phishing sites. Third, we
describe techniques we developed for circumventing
Over the past few years we have seen an increase in
many of the tools tested. Our paper provides the anti-
“semantic attacks” — computer security attacks that
phishing community with insights into the
exploit human vulnerabilities rather than software
effectiveness of several approaches to combating
vulnerabilities. Phishing is a type of semantic attack in
phishing as well as a methodology for testing anti-
which victims are sent emails that deceive them into
phishing tools.
providing account numbers, passwords, or other
personal information to an attacker. Typical phishing
2. Overview of Anti-Phishing Tools
emails falsely claim to be from a reputable business
where victims might have an account. Victims are
directed to a spoofed web site where they enter There are a variety of methods that can be used to
information such as credit card numbers or Social identify a web page as a phishing site, including
Security Numbers. There were 9,255 unique phishing whitelists (lists of known safe sites), blacklists (lists of
sites reported in June of 2006 alone [1]. Billions of known fraudulent sites), heuristics, and communityratings. The tools examined in this study employ a determination. Additionally, the users themselves are
differing combinations of these methods. We used rated according to their record of correctly identifying
publicly available information provided on the tool phishing sites. Each site’s rating is computed by
download web sites as well as our observations to get a aggregating all ratings given for that site, with each
basic understanding of how each tool functions. user’s rating of a site weighted according to that user’s
reputation. No other heuristics are used in determining
2.1. CallingID Toolbar a site’s rating. Sites determined to be fraudulent are
blocked and users are redirected to an information page
The CallingID Toolbar, shown in Figure 1, boasts and given the option of overriding the block. The
its use of 54 different verification tests in order to Cloudmark Anti-Fraud Toolbar runs on Microsoft
determine the legitimacy of a given site. Like many of Windows 98/NT/2000/XP with Internet Explorer.
the other toolbars, CalingID relies on passive visual After our study began we learned that Cloudmark is no
indicators. These indicators change from green—to longer supporting this toolbar. Cloudmark has since
represent a known-good site; to yellow—to represent a removed this toolbar from their web site. They now
site that is “low risk;” to red—to represent a site that is offer a phishing URL feed for other toolbars and
“high risk,” and therefore probably a phishing site. similar applications and a tool called Cloudmark
Some of the heuristics used include examining the Desktop that works in conjunction with the Microsoft
site’s country of origin, length of registration, Outlook and Microsoft Outlook Express email clients
popularity, user reports, and blacklist data. The and labels phishing emails based on millions of reports
CallingID Toolbar runs on Microsoft Windows from users each day. We have not tested Cloudmark
98/NT/2000/XP with Internet Explorer [2]. Desktop.
2.2. Cloudmark Anti-Fraud Toolbar 2.3. EarthLink Toolbar
The Cloudmark Anti-Fraud Toolbar, shown in Figure The EarthLink Toolbar, shown in Figure 3, appears
2, relies on user ratings [4]. When visiting a site, users to rely on a combination of heuristics, user ratings, and
have the option of reporting the site as good or bad. manual verification. Little information is presented on
Accordingly, the toolbar will display a colored icon for the EarthLink website; however, we used the toolbar
each site visited. Green icons indicate that the site has and observed how it functions. The toolbar allows
been rated as legitimate, red icons indicate that the site users to report suspected phishing sites to EarthLink.
has been determined to be fraudulent, and yellow icons These sites are then verified and added to a blacklist.
indicate that not enough information is known to make The toolbar also appears to examine domain
Figure 1: The CallingID Toolbar indicating a low-risk site.
Figure 2: The Cloudmark Anti-Fraud Toolbar indicating a legitimate site.
Figure 3: The EarthLink Toolbar indicating a legitimate site.registration information such as the owner, age, and option to override the block. The toolbar also gives
country. The toolbar displays a thumb that changes users the ability to report phishing sites, which will
color and position. A green thumbs up represents a then be verified before being blacklisted. The eBay
verified legitimate site, whereas a gray thumbs up Toolbar runs under Microsoft Windows
means that the site is not suspicious, but it has not been 98/ME/NT/2000/XP with Internet Explorer.
verified. The red thumbs down means that a site has
been verified to be fraudulent, whereas the yellow 2.5. Firefox 2
thumbs down means that the site is “questionable.”
Sites determined to be fraudulent are sometimes Firefox 2.0, shown in Figure 5, includes a new
blocked, in which case users are redirected to an feature designed to identify fraudulent web sites.
information page and given the option of overriding Originally, this functionality was an optional extension
the block (and a green thumb is displayed on the for Firefox as part of the Google Safe Browsing
information page). The EarthLink Toolbar runs under Toolbar. URLs are checked against a blacklist, which
Internet Explorer as well as Firefox [10]. Firefox downloads periodically [15]. The feature
displays a popup if it suspects the visited site to be
2.4. eBay Toolbar fraudulent and provides users with a choice of leaving
the site or ignoring the warning. Optionally, the feature
The eBay Tool, shown in Figure 4, uses a can send every URL to Google to determine the
combination of heuristics and blacklists [9]. The likelihood of it being a scam. According to the Google
Account Guard indicator has three modes: green, red, toolbar download site, the toolbar combines “advanced
and gray. The icon is displayed with a green algorithms with reports about misleading pages from a
background when the user visits a site known to be number of sources [12].” We suspect that this means it
operated by eBay (or PayPal). The icon is displayed uses blacklists as well as heuristics. Firefox 2.0 runs on
with a red background when the site is a known Microsoft Windows, Apple Mac OS X, and Linux.
phishing site. The icon is displayed with a gray The Google Safe Browsing Toolbar on which this
background when the site is not operated by eBay and functionality is based runs on Microsoft Internet
not known to be a phishing site. Known phishing sites Explorer under Windows XP/2000 SP3+, or Firefox on
are blocked and a pop-up appears, giving users the most platforms.
Figure 4: The eBay Toolbar at a site not owned by eBay that is not known to be a phishing site.
Figure 5: Firefox 2.0 at a suspected fraudulent site.2.6. GeoTrust TrustWatch Toolbar window. Users also have the option of using this
feature to report suspected phishing sites or to report
GeoTrust’s TrustWatch Tool, shown in Figure 6, that a site has incorrectly been added to the blacklist.
labels sites as green (verified as trusted), yellow (not
verified), or red (verified as fraudulent). GeoTrust 2.8. Netcraft Anti-Phishing Toolbar
works with several third-party reputation services and
certificate authorities to verify sites as trusted. The Netcraft Anti-Phishing Toolbar, shown in
GeoTrust’s web site provides no information about Figure 8, uses several methods to determine the
how TrustWatch determines if a site is fraudulent; legitimacy of a web site. The Netcraft web site
however, we suspect that the company compiles a explains that the toolbar “traps suspicious URLs
blacklist that includes sites reported by users through a containing characters which have no common purpose
button provided on the tool. The toolbar also lets users other than to deceive,” “enforces display of browser
store a custom image or bit of text that is constantly navigation controls (tool & address bar) in all
displayed so that he or she knows that the toolbar is not windows, to defend against pop up windows which
being spoofed. TrustWatch runs on Microsoft attempt to hide the navigational controls,” and “clearly
Windows 98/NT/2000/XP with Internet Explorer [11]. displays sites’ hosting location, including country
helping you to evaluate fraudulent URLs (e.g. the real
2.7. Microsoft Phishing Filter in Windows Citibank.com or Barclays.co.uk sites are unlikely to be
Internet Explorer 7 hosted in the former Soviet Union)” [18]. The Netcraft
toolbar also uses a blacklist, which consists of
The Microsoft Internet Explorer 7 web browser fraudulent sites identified by Netcraft as well as sites
includes a built in phishing filter, shown in Figure 7 submitted by users and verified by the company. When
[17]. The tool largely relies on a blacklist hosted by a user attempts to access a site that is on the blacklist, a
Microsoft. However, it also uses some heuristics when pop-up warning recommends that the access be
it encounters a site that isn’t on the blacklist. When a cancelled, but provides an override option. The toolbar
suspected phishing website is encountered, the user is also displays a risk rating between one and ten as well
redirected to a built in warning message and asked if as the hosting location of the site (gleaned from the
they would like to continue visiting the site or close the registration information for the IP address). Users can
Figure 6: The GeoTrust TrustWatch Toolbar at a verified site.
Figure 7: The Microsoft Phishing Filter in Windows Internet Explorer 7 at a fraudulent web site.
Figure 8: The Netcraft Anti-Phishing Toolbar at a legitimate web site.also use the toolbar to access a more detailed report on recently visited by the user to catch fraudulent web
a web site. The Netcraft Anti-Phishing Toolbar runs on sites that have a similar-looking domain name. Next,
Firefox on most platforms, and on Microsoft Internet the full URL is analyzed to detect obfuscation as well
Explorer under Windows 2000/XP. as non-standard port numbers. Afterwards, the contents
of the page are analyzed, making note of any password
2.9. Netscape Browser 8.1 fields, embedded links, and images. Following this,
SpoofGuard analyzes links in the web page itself using
The Netscape Navigator 8.1 web browser includes a the heuristics described above. Finally, it examines
built in phishing filter, shown in Figure 9 [19]. From images on the web page by hashing them to see if it
our testing, as well as third party reviews, it appears has found identical images on other sites the user has
that this functionality relies solely on a blacklist, which visited. If two identical images are spotted on different
is maintained by AOL and updated frequently [5]. web sites, there is a chance that a fraudulent site has
When a suspected phishing site is encountered, the user copied the images from the legitimate site.
is redirected to a built-in warning page. Users are SpoofGuard computes a score for each web page in
shown the original URL and are asked whether or not the form of a weighted sum of the results of each set of
they would like to proceed. The Netscape Browser runs heuristics. Users can change the weights for each set of
under Microsoft Windows, Linux, and Mac OS X. heuristics in an options menu. If the score surpasses a
certain threshold, the toolbar displays a red icon,
2.10. SpoofGuard warning users that the site is a positively identified
phishing site. If some of the heuristics are triggered but
SpoofGuard, shown in Figure 10, is an anti- not enough to exceed the threshold, the icon turns
phishing toolbar developed at Stanford University [2]. yellow to indicate that it cannot make a determination
Unlike the other tools described here, SpoofGuard does about the site. If none of the heuristics are triggered,
not use whitelists or blacklists. Instead, the toolbar the icon turns green to indicate a safe site. SpoofGuard
employs a series of heuristics to identify phishing runs on Microsoft Windows 98/NT/2000XP with
pages. The toolbar first checks the current domain Internet Explorer [2].
name and compares it with sites that have been
Figure: 9 Netscape 8.1 web browser at a fraudulent web site.
Figure 10: SpoofGuard at a legitimate web site.3. Anti-Phishing Tool Evaluation conclusively whether any tools were using the phishing
feeds we tried. After experimenting with feeds that
We conducted a series of experiments designed to consisted of mostly phishing sites that had already
investigate the accuracy of anti-phishing tools. Our been taken down, we obtained access to a feed of
first experiment involved manually evaluating five of phishing URLs provided by an email filtering vendor.
the tools described above. This gave us a feel for the Each tool was tested with 50 confirmed phishing URLs
behavior and effectiveness of the various tools, but identified within the previous 36 hours. Because we
proved labor intensive and posed significant logistical generally did not receive more than 20 new phishing
difficulties. As a result, we developed an automated URLs each day, we conducted the study during three
testing system and used it to conduct our subsequent separate sessions over a two-week period.
experiments. Using our automated testing system, we
were able to test how each of 10 tools responded to a 3.2. Design and Implementation of an
set of URLs multiple times over a 24 hour period, Automated Anti-Phishing Test Bed
allowing us to observe the effect of blacklist updates
and of phishing sites being taken down. Our first experiment was very labor intensive,
making this method infeasible for evaluating larger
3.1. Manual Evaluation of Anti-Phishing Tools data sets across longer periods of time. Therefore, we
developed an automated test bed for evaluating the
Our first experiment was conducted using five effectiveness of anti-phishing tools. This test bed will
laptops to simultaneously test five anti-phishing tools. facilitate the evaluation of new approaches to phish
One experimenter was assigned to each laptop. The detection and the examination of long-term phishing
experimenters manually entered URLs to be tested into trends, giving the anti-phishing community a clearer
web browsers running on each laptop, and then picture of how much progress we are making towards
observed and recorded the results. This was a slow and automatically detecting phishing sites. Figure 11 shows
labor-intensive process. the high-level system architecture. Our system includes
Once phishing web sites are identified, they are a task manager and a set of workers, each of which is
often taken down quickly. According to the Anti- responsible for evaluating a single tool. Our automated
Phishing Working Group (APWG), the average time anti-phishing test bed is currently implemented in C#
that a phishing site stays online is 4.5 days [1], though and is comprised of 2000 lines of code. Our
our experience suggests that many are taken down implementation also makes use of freely available
within hours. Therefore, it was critical to find a source .NET components, including Compare Images [23],
of freshly reported phishing sites to test in our which checks if two images are identical.
experiment. We also tried to find a source that was not
used by any of the tools we were testing for updating Step 1 – Retrieve Potential Phishing Sites. First, the
their blacklist, although it was difficult to determine task manager obtains a set of phishing URLs to test
Figure 11: High-level system architecture for our anti-phishing evaluation test bed. The Task
Manager (1) gets an updated list of URLs from a phishing feed, and then (2) sends that URL to a set
of Workers. Each worker (3) retrieves a web page and checks whether the web page was labeled as
a phishing scam or not, and (4) sends the result back to the Task Manager, which aggregates all of
the results. The Task Manager and Workers are grouped together because they can be run on the
same machine or on separate machines.against. We experimented with automating this process image-based approach for workers to check a given
by extracting URLs from a feed of validated phishing tool. Each tool has several known states (e.g., a red
URLs or by using our own heuristics to select phishing icon if it has detected a phishing site and a green icon
URLs from a feed of unvalidated phishing email if it has not), and each tool can be set up to be in a
messages.1 We found that by the time phishing URLs known location in the web browser. Thus, we simply
are validated and distributed on a phishing feed, they capture screenshots of the tools beforehand and
tend not to be very fresh and many of the sites have compare relevant portions of those images to
been taken down. Furthermore, some phishing tools screenshots of the current state of the tool. The primary
update their blacklists using data from validated advantage of this image-based approach is that it works
phishing feeds. Unvalidated phishing URLs or email for all tools regardless of the programming language in
messages are a better source for fresh phishing URLs; which the tool was written, whether or not the tool
however, use of these sources requires that phishing provides an explicit API, and what web browser is
URLs be manually selected and validated. This process being used.
can be partially automated. However, if heuristics are
used to select valid phishing URLs, phishing sites that Step 4 – Task Manager Aggregates Results. In the
cannot be identified using those heuristics may be fourth step, the task manager aggregates all of the
excluded from the test and thus the results may be results from the workers and tallies overall statistics,
biased in favor of tools that use heuristics similar to the including true positives, true negatives, false positives,
selection heuristics. In order to get large numbers of false negatives, and sites that no longer exist.
very fresh phishing URLs without bias we decided to
manually select and validate phishing URLs from a 3.3. Evaluation of Anti-Phishing Tools
phishing feed and repository, using automated tools
only to extract URLs from suspected phishing
We used our automated anti-phishing test bed to
messages and remove those we had already seen. For
evaluate 10 anti-phishing tools. We tested the built in
our experiments, we labeled a site as a phishing scam
phishing filters in Microsoft Internet Explorer
only if it impersonates a known brand. This means, for
7.0.5700.6, Netscape Navigator 8.1.2., and Firefox 2.0.
example, that we did not include e-commerce sites that
We used Internet Explorer 6 to test the following tools:
might rip you off, or web sites for fictitious companies
CallingID 1.5.0.150, Cloudmark 1.0, EarthLink
that conduct identity theft by tricking prospective
3.3.44.0, eBay 2.3.2.0, Netcraft 1.7.0, TrustWatch
employees into submitting their resumes.
3.0.4.0.1.2, and SpoofGuard.
We began our experiment using FireFox 1.5.0.6 to
Step 2 – Send URL to Workers. In the second step,
test Google Toolbar 2.1. However when Firefox 2.0
the task manager sends each URL to a set of workers,
was released it included the Safe Browsing feature
each of which is running a separate tool. The workers
from the Google Toolbar, and we found that when the
can be run on the same machine as the task manager or
Google Toolbar was configured with its default
on separate machines. However, running workers on
settings it produced the same results as FireFox 2.0
the same machine can be problematic when testing
configured with the “Ask Google” option. Thus, we
multiple tools that work with the same web browser, as
decided to continue our experiment using Firefox 2.0
the tests should be run with only one tool installed in
instead of the Google Toolbar. We also tested McAfee
the web browser at a time. Virtual machines can reduce
SiteAdvisor 1.7.0.53 in the early part of our
the number of test machines needed.
experiment, but removed it from the experiment when
it became apparent that it does not actually detect
Step 3 – Worker Evaluates Potential Phishing Site. phishing URLs.2 After removing McAfee SiteAdvisor
In the third step, each worker downloads the specified
from our experiment, we added CallingID. Thus we
web page, examines whether its tool has labeled the
did not test CallingID on the complete set of phishing
web page as phishing or not, and returns that value
URLs.
back to the task manager. Workers retrieve web pages
using the Tor anonymity network [24], thus making it
harder for phishing operators to observe that we are 2 The McAfee web site claimed that SiteAdvisor protects
against “online scams,” however; a company representative
evaluating their sites. We have developed a simple
explained that claim refers to protection against long-
running online scams such as greencard lotteries, and not
1 Phishing email messages often contain multiple links, some the more transient phishing attacks. McAfee has a premium
of which lead to fraudulent sites and some of which lead to product, SiteAdvisor Plus, that does provide phishing
legitimate sites. protection. However, we have not yet tested this product.We configured all tools with their default settings. We compiled a list of 516 legitimate URLs to test
However, we tested Firefox 2.0 with the default setting for false positives. The URLs were compiled from the
(which uses a blacklist, downloaded approximately following sources:
every 30 minutes) and with the “Ask Google” option
(which sends every URL visited to Google for testing) • 416 URLs were taken from the list of 500
and report these results separately. The Task Manager legitimate URLs compiled by 3Sharp and published
was run on a 1.6GHZ Toshiba Portege M200 in a September 2006 report [22] (the remaining 84
Notebook. The Workers were run on an IBM 1.6GHz URLs tested by 3Sharp were no longer active).
ThinkPad T42 Notebook and a 1.7 GHz Compaq
Presario v2000 Notebook. • 35 URLs were compiled by selecting the log-in
On November 4-5, 2006 we tested 100 phishing pages of sites that are often attacked by phishers,
URLs extracted from the list of unvalidated phishing such as www.citibank.com and www.paypal.com.
reports on phishtank.com. We visited phishtank.com These pages were selected to see whether tools can
every six hours and retrieved all new suspected distinguish phishing site from the legitimate sites
phishing URLs that had been submitted within the they commonly spoof.
previous six hours. We manually verified that they
were phishing sites and that the sites were still online.3 • 35 URLs were compiled by selecting the most
We extracted 100 confirmed, active phishing URLs popular web pages reported by Alexa Web Search.
and examined each URL within six hours of its being These pages were selected to see whether tools
posted on phishtank.com. label frequently-visited pages correctly.
On November 21 and 27, 2006 we tested 100
phishing URLs extracted from the APWG feed of • 30 pages were compiled by selecting random pages
reported phishing emails. We downloaded new from http://random.yahoo.com/fast/ryl, and
messages from the feed every two hours and manually manually verifying that they are legitimate. These
identified and verified active phishing URLs from pages were selected to see whether tools label
these messages. We extracted 100 confirmed, active random legitimate URLs correctly.
phishing URLs and examined each URL within two
hours of its being received on our APWG feed. 3.3.1. Catch Rate. The most important function of an
Each URL was tested against each tool within one anti-phishing tool is to accurately and conspicuously
hour of extraction. In addition, each URL was tested identify phishing web sites that users visit. Since not
against all tools except SpoofGuard 1, 2, 12, and 24 all of the tools provide the same types of indicators, we
hours later. By testing each URL multiple times we had to come up with a standard way of measuring
were able to observe blacklist updates as well as how accuracy. Some of the tools provide binary indicators
long it took for phishing sites to be taken down. (i.e. either that site is phishing or it is not), while some
During preliminary testing, we observed that tools use a ternary system (i.e. a site can be phishing,
SpoofGuard treats all re-visited URLs as legitimate, not phishing, or unknown). We count only positive
even if it initially identified them as phishing. Thus, identification of phishing as a “catch.” Most of the
SpoofGuard failed to identify any URLs as phishing tools we tested have only one form of positive
URLs on the second and later visits. We discovered identification. However, IE7 and EarthLink can either
that if we cleared the web browser history before warn or block when they identify phish, so we count
testing each URL this problem goes away. However, as either as a catch. We do not count “unvalidated”
SpoofGuard’s determination is based only on heuristics ratings or other uncertain ratings as a catch.4 We define
and not on blacklists, SpoofGuard’s assessment does “catch rate” (or true positive rate) as the number of
not change over time. Thus we decided to test phishing sites positively identified by a tool out of the
SpooGuard only once on each URL. The apparent total number of active phishing sites visited, with sites
change in accuracy of SpoofGuard over time in our that had been taken down at the time of testing
reported results is due entirely to some of the phishing removed from the denominator. The rationale here is
web sites being taken down. that it makes no difference whether a tool identifies a
taken-down site as a phishing site, since a site that has
3 Phishtank.com also provides a feed of phishing URLs that been taken down does no harm to the user.
have been verified by users. We manually selected URLs
from those submitted rather than using the feed in order to 4 One previous study counted other warning indicators, such
get fresher URLs and to reduce the chance of using a feed as TrustWatch’s yellow “not verified” indicator as catches
that was being used by one of the tools being tested. [22].Table 1, Figure 12, and Figure 13 show the able to identify 50-60% of phishing sites initially and
percentage of phishing sites correctly identified over 70-75% of phishing sites after 24 hours. Firefox,
time using the phishtank.com and APWG URLs. After TrustWatch, Netscape, CallingID, and CloudMark all
24 hours, 70 of the phishtank.com URLs and 67 of the identified less than 50% of phishing sites initially.
APWG URLs remained active. The performance of the TrustWatch and Firefox improved to over 65% after 24
tools varies considerably depending on the source of hours, while Netscape, CallingID, and CloudMark
the URLs used for testing. Some tools performed improved but still remained under 50% after 24 hours.
significantly better with URLs from one source or the eBay identified 52% of phishing sites initially, and did
other, but none of the tools we tested performed well not improve over the 24-hour testing period.
across the board. SpoofGuard had a consistently high Our results indicate that the source of phishing
catch rate of over 90%, but also had a 42% false URLs can have a major impact on test results. Neither
positive rate. Of the other tools we tested, only IE7 had of the sources we used lend themselves to use as
a catch rate better than 60% with both sources, but it completely automated feeds, and none of the tools we
still missed 25% of the APWG phishing URLs and tested was able to correctly identify all of the phishing
32% of the phishtank.com phishing URLs. URLs from either of the feeds. Therefore we do not
When we tested the tools with phishtank.com URLs, believe that any of the tools were updating their
SpoofGuard, EarthLink, and Netcraft performed best at blacklists automatically from either of these sources
identifying phishing sites initially. A chi-square test directly. However, the APWG feed includes data from
(p=0.01) demonstrated that SpoofGuard performed multiple sources, and some of the tools might update
significantly better than Netcraft. However, we did not their blacklists using data from some of them. In
find a statistically significant difference between addition, phishtank.com has a validated phishing URL
EarthLink and Netcraft, or SpoofGuard and EarthLink feed that includes a subset of the URLs that we
at the initial time period. Google, Cloudmark, and IE7 validated ourselves. It is likely that some of the tested
also did well. TrustWatch was able to only identify tools use this feed to update their blacklists. We also
about half the phishing sites tested, while eBay observed that some types of phishing attacks appeared
identified 28% and Netscape identified 8%. more frequently in one source than the other. For
When we tested the tools with the APWG URLs, example, spoofs of eBay-owned brands appeared more
SpoofGuard was able to identify 96% of the phishing often in the APWG feed. Finally, we checked the
sites. The next best tool, IE7, identified only 75% of APWG feed more frequently than we checked
the phishing sites initially, and 85% after 24 hours had phishtank.com, and thus we believe the APWG URLs
passed. Netcraft, Firefox/Google, and EarthLink, were to be fresher than the phishtank.com URLs.
PhishTank APWG
Time since
URL 0 hours 1 hour 2 hours 12 hours 24 hours 0 hours 1 hour 2 hours 12 hours 24 hours
extraction
CallingID NA NA NA NA NA 23 (23%) 26 (26%) 25 (27%) 30 (38%) 24 (36%)
Cloudmark 68 (68%) 68 (68%) 68 (69%) 64 (67%) 47 (67%) 22 (22%) 24 (24%) 21 (22%) 25 (31%) 25 (37%)
EarthLink 83 (83%) 83 (83%) 81 (82%) 78 (84%) 59 (84%) 54 (54%) 53 (54%) 51 (54%) 51 (64%) 47 (70%)
eBay 28 (28%) 28 (28%) 26 (27%) 24 (26%) 18 (26%) 52 (52%) 52 (53%) 51 (54%) 43 (54%) 35 (52%)
IE7 68 (68%) 68 (68%) 67 (68%) 62 (67%) 47 (67%) 75 (75%) 74 (75%) 72 (77%) 67 (84%) 58 (87%)
Firefox NA NA NA NA NA 28 (28%) 50 (50%) 51 (54%) 47 (59%) 44 (66%)
Firefox/
70 (70%) 70 (70%) 70 (71%) 71 (76%) 59 (84%) 53 (53%) 54 (55%) 56 (60%) 56 (70%) 49 (73%)
Google
Netcraft 77 (77%) 77 (77%) 73 (74%) 69 (74%) 56 (80%) 60 (60%) 59 (60%) 57 (61%) 62 (78%) 49 (73%)
Netscape 8 (8%) 10 (10%) 10 (10%) 9 (10%) 15 (21%) 31 (31%) 31 (31%) 32 (34%) 37 (46%) 30 (45%)
SpoofGuard 91 (91%) 91 (91%) 89 (91%) 85 (91%) 64 (91%) 96 (96%) 95 (96%) 90 (96%) 78 (98%) 65 (97%)
TrustWatch 49 (49%) 49 (49%) 48 (49%) 45 (48%) 36 (51%) 44 (44%) 43 (43%) 44 (47%) 45 (56%) 45 (67%)
ActiveURLs 100 100 98 93 70 100 99 94 80 67
Table 1: Number of phishing sites correctly identified by anti-phishing tools.
Note, SpoofGuard!s catch rate is estimated after time 0.Figure 12: Catch rate of each tool over time using phishtank.com URLs.
Note that SpoofGuard!s catch rate is estimated after time 0.
Figure 13: Catch rate of each tool over time using APWG URLs.
Note that SpoofGuard!s catch rate is estimated after time 0.phishtank.com URLs APWG URLs
Time since URL 1 hour 2 hours 12 24 1 hour 2 hours 12 24
extraction hours hours hours hours
CallingID N/A N/A N/A N/A 3 0 6 0
Cloudmark 0 1 0 0 2 0 5 2
EarthLink 0 0 0 0 0 0 3 1
eBay 0 0 0 0 1 0 2 0
Firefox N/A N/A N/A N/A 23 3 1 5
Firefox/Google 0 1 4 5 1 5 3 3
IE7 0 1 0 0 0 0 2 1
Netcraft 0 1 0 4 0 4 10 0
Netscape 2 0 0 7 0 1 10 0
SpoofGuard 0 0 0 0 0 0 0 0
TrustWatch 0 0 0 0 0 1 5 9
Active URLs 100 98 93 70 99 94 80 67
Table 2: Number of phishing sites initially identified incorrectly that were
later identified correctly by anti-phishing tools.
As Table 2 shows, most phishing sites are detected least one tool at time 0. For 85% of the APWG
quickly by the tools we tested, but some are detected phishing URLs we tested, at least three tools identified
after several hours or even a day or more after they them correctly when they were first tested, and at least
appear in phishing emails. Some tools improved more five tools identified them correctly after 24 hours. For
than others as our experiment progressed. When using 85% of the phishtank.com URLs, at least four tools
phishtank.com URLs, only five of the tools were able identified them correctly when they were first tested,
to correctly identify phishing sites in later tests that and at least five tools identified them correctly after 24
they incorrectly identified initially. The changes in hours. It was rare, even after 24 hours for eight or more
accuracy observed for the other tools are due entirely tools to identify a URL correctly. Some phishing URLs
to some of the phishing sites being taken down. When were missed by one of the better tools but caught by
using APWG URLs, all tools except SpoofGuard were another, or even caught by one of the tools that did not
able to correctly identify phishing sites in later tests perform well overall.
that they incorrectly identified initially. The larger
changes over time observed when using the APWG 3.3.2. False Positive Rates. While the catch rate for
URLs are likely due to the APWG URLs being fresher real phishing sites is the paramount concern, caution
than the phishtank.com URLs. The biggest needs to be taken with regard to false positives. False
improvement was seen with Firefox, which correctly positives pose a major usability problem for any
identified 23 APWG phishing sites after 1 hour that it security software. If a user is continually alerted to a
had missed initially. As we were testing Firefox we pending a danger (in this case phishing) even when the
observed that it initially missed a large number of sites user knows no such danger exists, he or she is most
until it automatically downloaded the latest version of likely to disable or ignore the tool that is creating the
its blacklist. This suggests that Firefox test results alerts. Thus, while a phishing tool must identify
(without the “ask Google” option) are likely to vary phishing sites, it should also be careful to not identify
depending on how recently the blacklist has been legitimate web pages as phishing.
downloaded. Each tool was tested against 516 legitimate URLs.
Interestingly, we also saw that some of the tools SpoofGuard erroneously labeled 42% of these URLs as
initially made a correct identification of a phishing site phishing. In addition it reported that it was unsure
and later reversed themselves. We observed this only about an additional 50% of these URLs. The only other
once or twice with most of the tools, but we observed tools to falsely identify any URLs as phishing sites
Netcraft make an incorrect reversal 11 times. were EarthLink and Cloudmark (which misidentified
In general, the differing approaches taken by the 1% of the legitimate sites), and CallingID (which
tools resulted in their catching different sets of phish. misidentified 2% of the legitimate sites). CallingID,
All but one URL from each data set was caught by at Cloudmark, EarthLink, and TrustWatch were alsounsure of a large number of sites. The false positives We were interested in whether visiting a web site
results are summarized in Table 3. Overall, false through a content distribution network (CDN) would
positives do not appear to be a major problem for most provide sufficient obfuscation.
of the tools we tested. We tested the CDN attack using the Coral Project
CDN [6]. The Coral Project is a content distribution
Falsely Unsure network that runs on top of PlanetLab, which
identified as dynamically routes HTTP traffic through any of 260
phishing servers located around the world [21]. These servers
CallingID 10 (2%) 177 (34%) primarily reside at academic or research institutions.
Cloudmark 5 (1%) 497 (96%) To use Coral, one simply appends “.nyud.net:8090” to
EarthLink 5 (1%) 493 (96%) a given URL’s domain name portion. Thus, all URLs
eBay 0 (0%) 0 (0%) passed through Coral appear to be on the .nyud.net
Firefox 0 (0%) 0 (0%) domain. We re-examined some of the URLs that had
Firefox/Google 0 (0%) 0 (0%) been identified by a tool as fraudulent, this time
IE7 0 (0%) 0 (0%) passing them through Coral. Some of the tools failed to
Netcraft 0 (0%) 0 (0%) properly identify any of the URLs as fraudulent when
Netscape 0 (0%) 0 (0%) they were passed through Coral. Figure 14 shows a
SpoofGuard 218 (42%) 256 (50%) comparison of the TrustWatch Tool visiting a phishing
TrustWatch 0 (0%) 256 (50%) site with and without the use of Coral. As can be seen,
Table 3: Number of legitimate sites (out of 516 the original phishing URL causes the tool to display a
tested) falsely identified as phishing sites by red warning. When the URL is run through Coral,
anti-phishing tools TrustWatch says that the site is now unverified. This
exploit works on Cloudmark, Google, TrustWatch,
Netcraft, and Netscape.
4. Tool Exploits
As would be expected, this exploit did not work on
the SpoofGuard tool. Since SpoofGuard does not use a
As we tested the five tools in this study, we got a
blacklist, nothing can be gained by causing the URL to
feel for how they identified fraudulent sites and
hash to a different value or appear to come from a
developed some ideas for exploiting them. We describe
different domain name. In fact, this particular exploit
two of these potential exploits here, as well as ways the
caused SpoofGuard to perform better. One of the
vulnerable tools could be modified to protect against
heuristics that SpoofGuard checks is whether the
them.
destination web site is running on a non-standard port.
For this particular exploit to work with Coral, the
4.1. Content Distribution Networks
destination web site must be running on port 80 (the
standard HTTP port). However, after running the URL
Nine of the ten tools we examined appear to rely on
through Coral, the URL will now point to port 8090 on
blacklists. Some of the tools take the entire URL into
a PlanetLab server, thus triggering this heuristic from
account, possibly by using a hash or pattern matching.
within SpoofGuard.
Other tools seem to make their decision based on
While this vulnerability is worrisome, it should be
information that is known about the domain name or IP
fairly easy to address either by blacklisting CDNs or,
block where the site is hosted. Thus, by obfuscating the
preferably, by checking for blacklisted URLs that
URL or forcing it to be routed through another domain
appear as sub-strings of the URL being checked.
name, an attacker might be able to convince the tool
that a blacklisted site is really a non-blacklisted site.
Figure 14: Demonstration of the CDN attack on the TrustWatch tool. The top screenshot shows TrustWatch
correctly labeling a site as a phishing scam. The bottom screenshot shows how redirecting that same scam
through the Coral CDN causes the same site to be labeled incorrectly.4.2. Page Load Attack the tool could fill these spaces with warnings (e.g.
replacing incomplete images with images of warnings).
While SpoofGuard was not susceptible to the CDN
attack mentioned in Section 4.1, we were able to 5. Conclusions and Future Work
discover an exploit to which it was vulnerable.
SpoofGuard examines the content on a web site when We conclude with our observations on tool
making a determination about whether or not the site is performance, testing methodology, and user interfaces,
fraudulent. It must therefore wait for the entire web as well as some directions for future work.
page to load before it can make a decision. This was
confirmed during our tests when we noticed that while 5.1. Tool Performance
a page was loading, SpoofGuard would display a
yellow icon (indicating that it cannot determine
Overall, we found that the anti-phishing tools that
whether or not the site is fraudulent). After all content
were examined in this study left a lot to be desired.
on the web page had loaded, only then might the icon
SpoofGuard did a very good job at identifying
change to either red or green. We hypothesized that if a
fraudulent sites, but it also incorrectly identified a large
page took an extremely long time to load, the indicator
fraction of legitimate sites as fraudulent. The
would remain yellow for a dangerously long period of
performance of the other tools varied considerably
time; a minute or two are more than adequate for a user
depending on the source of the phishing URLs. Of
to enter authentication information on a given phishing
these other tools, only IE7 was able to correctly
page.
identify over 60% of phishing URLs from both
To test this, we constructed a simple PHP script and
sources, but it still missed 25% of the APWG phishing
mirrored a phishing site that SpoofGuard had
URLs and 32% of the phishtank.com phishing URLs.
previously identified. This PHP script consisted of five
Half the tools we tested could correctly identify less
lines that created a GIF header. Upon sending the GIF
than half the phishing sites. Many of the tools we
header, the script would then enter an infinite loop,
tested were vulnerable to some simple exploits as well.
transmitting one byte per second. We placed this image
Our experiments also suggest that there is no single
on the phishing site and visited it using SpoofGuard.
technique that will always outperform others for
We found that since the web page would take an
identifying phishing web sites. Most of the tools we
infinite amount of time to load, SpoofGuard would
tested used blacklists, but only half of them were able
never display anything other than the yellow icon
to identify the majority of phishing web sites. We do
(which it displays on most non-phishing sites anyway).
not know the size of the blacklists used by each tool,
From the user’s perspective, the entire web page would
nor do we know what heuristics are used by any of the
appear to be rendered. Only savvy users would be able
tools other than SpoofGuard. We suspect that the tools
to tell that the page is still loading, but it is unclear if
that performed best use larger and more frequently
even they would find this suspicious. Thus, any
updated blacklists. They may also use heuristics that
phishing page can be easily altered to prevent
allow them to detect phishing sites that have not yet
SpoofGuard from warning users.
been put on their blacklist.
eBay was the only other tool on which we were
The only tool we tested that is known to make no
able to demonstrate this attack (by hosting our own
use of blacklists was SpoofGuard. While it was able to
spoofed PayPal site). However, without the ability to
identify the majority of phishing sites using only
add our script to sites identified as phishing by the
heuristics, it still missed some phishing sites and it had
other tools we were unable to test their vulnerability to
a very high false positive rate. SpoofGuard could
this attack.
potentially be improved through the use of a whitelist,
This vulnerability is quite simple to fix. A default
which would prevent the problems that occurred when
timeout needs to be added to vulnerable tools so that
phishing sites were visited before their corresponding
they will stop loading a web page once the timeout
legitimate sites. The whitelist would not necessarily
occurs. They should then evaluate the portion of the
need to be extremely large or updated frequently to be
page that has been received to determine the risk of it
effective.
being a phishing site. This timeout needs to be short
The success of a blacklist relies on massive
enough that users will be unable to submit information
amounts of data being collected at frequent intervals.
to the web page before the tool can evaluate it. One
Relying solely on heuristics requires that the software
way of ensuring this is by not displaying the web page
is designed with the foresight to prevent
until the tool has had a chance to make a
circumvention. In this study we were able to exploit
determination. Additionally, if the timeout has expired
and some of the content on the page has failed to load,both techniques, which leads us to believe that a URL on the first tool and the last tool. If we were to
combination of techniques is necessary. use a fresher source of phishing URLs and attempt to
Some of the tools that rely on blacklists send the more precisely monitor the speed of blacklist updates,
URLs requested by a user to a central blacklist server, it would be important to test all tools simultaneously
which may raise privacy concerns and could on separate computers. Close to simultaneous testing
potentially impact browser performance (however, we could also be achieved using virtual machines.
did not observe perceptible performance impacts in our We conducted all of our tests using the tools’
testing). We observed that Firefox performed poorly default configuration options, except for Firefox,
when the blacklist has not been downloaded recently. which we also tested using the “Ask Google” option. It
On the other hand, even after the blacklist was updated, would also be interesting to test tools with multiple
when we configured Firefox to send every URL to configuration options to observe the impact these
Google it was able to identify an additional 6% of options have on tool accuracy and false positives.
phishing sites. However, each additional option requires an additional
“worker” in the automated test bed.
5.2. Testing Methodology
5.3. User Interfaces
Testing anti-phishing tools is a time consuming and
difficult process. In order for results to be comparable, Prior research has focused on user studies of new
multiple tools need to be tested on the same set of anti-phishing solutions, not on solutions that are in
URLs within a short time frame, and URLs are only widespread use. Literature on the usability of popular
useful for testing purposes while they are fresh. anti-phishing solutions is scarce at best. Since our
Although we were able to automate much of the study only measured the technical accuracy of ten
testing process, we still found the process of popular anti-phishing tools, we have only anecdotal
identifying phishing URLs to test to be problematic. evidence of their usability.
Ideally tools should be tested with URLs extracted Eight of the ten tools examined employed
from phishing messages immediately after those indicators based on red and green color schemes.
messages arrive in users’ mailboxes. However, it takes Green represents a legitimate site, and red represents a
time for phishing messages to be identified and positively identified phishing site. Seven of the ten
propagated through phish feeds. We were able to tools also use a yellow or gray indicator to indicate that
collect URLs fresh enough that the sites had not yet nothing conclusive is known about the site. Given the
been taken down, but we were unable to determine predominance of red/green color blindness, this may be
how fresh the URLs we tested actually were. However, a poor choice unless the colored indicator includes
given the small number of improvements we saw in other readily noticeable cues.
tool performance over the 24 hour period after we Besides colored indicators, several tools use popup
began testing each URL, we suspect that most of the dialog boxes to warn when a site has been identified as
URLs we tested were at least several hours old, and fraudulent. While the IE7, eBay, Firefox, Netscape,
thus had already made their way onto many of the and Netcraft dialog boxes block the phishing site
blacklists. In order to test the speed at which tools are unless the user overrides the block, the SpoofGuard
able to identify phishing sites and add them to their dialog box contains “yes” and “no” buttons with which
blacklists we would need a fresher source of phishing to dismiss it. Regardless of which button is pressed, the
URLs. web page remains open. Previous studies have shown
Ideally, all tools would be tested in parallel. that when presented with dialog boxes containing
However, this would require a separate computer for buttons with which to dismiss them, most users will
each tool to be tested. We did not have the resources to simply dismiss the boxes without reading them [14].
do this, so we ran multiple “worker” processes on each When Firefox encounters a site that it has positively
test computer and did some manual loading and identified as phishing, it darkens the page to draw
unloading of tools.5 As a result, there was a difference attention to a dialog box. IE7, Netscape and
of as much as 1 hour between the testing of a particular Cloudmark do not even display the page, instead they
show a different page where the user is given the
choice of displaying the suspected phishing site or
5 Initially we had planned to use virtual machines to alleviate
closing the window. eBay’s tool puts a red warning
the need to load and unload tools and allow our testing of
box at the top of the suspected phishing site, but does
each tool to proceed almost simultaneously. However, this
ended up being unworkable due to the limitations of our not interact with the user in any meaningful way. The
test bed computers and network. TrustWatch, SpoofGuard, and CallingID tools do not
present the user with any indications beyond thered/green/yellow icons. User testing is needed to better [4] Cloudmark, Inc. Accessed: September 5, 2006.
understand how users react to each style of warning. http://www.cloudmark.com/desktop/download/.
Based on our cursory review, all of the tools [5] Computer Crime Research Center. “Netscape: Anti-
examined appear to have some usability problems. We Phishing Bundled.” February 2, 2005. Accessed:
believe that it is important for these problems to be November 9, 2006. http://www.crime-
research.org/news/02.02.2005/938/.
resolved if these tools are to be effective. An anti-
phishing tool could identify all fraudulent web sites [6] The Coral Content Distribution Network. Accessed:
June 13, 2006. http://www.coralcdn.org/.
without any false positives, but if it has usability
[7] Dhamija, R., Tygar, J.D., and Hearst, M. 2006. Why
problems, users might still fall victim to fraud.
phishing works. In Proceedings of the SIGCHI
Future anti-phishing tool studies should also
Conference on Human Factors in Computing Systems
include usability testing. A technically sound tool is of
(Montreal, Quebec, Canada, April 22 - 28, 2006). New
little use if users are unsure of what it is trying to
York: ACM Press, 2006.
communicate to them. Previous research has examined
[8] Downs, Julie S., Mandy Holbrook, and Lorrie Cranor,
the effectiveness of several techniques for informing
“Decision Strategies and Susceptibility to Phishing,” in
users about phishing [25]. However, it did not evaluate Proceedings of The 2006 Symposium on Usable Privacy
the effectiveness of pop-up warnings, or the difference and Security, Pittsburgh, PA 12-14 July 2006.
in user reaction upon seeing a warning versus having a [9] eBay, Inc. Using eBay Tool’s Account Guard.
web site blocked. Accessed: June 13, 2006.
Usability problems plague all varieties of http://pages.eBay.com/help/confidence/account-
software—security software in particular. For an anti- guard.html.
phishing tool, poor usability could mean the difference [10] EarthLink, Inc. EarthLink Tool. Accessed: November 9,
between correctly steering someone away from a 2006. http://www.earthlink.net/software/free/tool/.
phishing site and having them ignore the warnings only [11] GeoTrust, Inc. TrustWatch Tool. Accessed: June 13,
to become a victim of identity theft. 2006. http://tool.trustwatch.com/tour/v3ie/tool-v3ie-
tour-overview.html.
6. Acknowledgments [12] Google, Inc. Google Safe Browsing for Firefox.
Accessed: June 13, 2006.
http://www.google.com/tools/firefox/safebrowsing/.
Thanks to Joseph Schwartz for his assistance
[13] Jagatic, T., Johnson, N., Jakobsson, M., Menczer, F.
conducting our preliminary studies and to the other
Social Phishing. Commun. ACM. To appear.
members of the Supporting Trust Decisions project for
http://www.indiana.edu/phishing/social-network-
their feedback. This work was supported in part by experiment/phishing-preprint.pdf
National Science Foundation under grant CCF- [14] Jendricke, U, D. Gerd tom Markotten, "Usability Meets
0524189, and by the Army Research Office grant Security - The Identity-Manager As Your Personal
number DAAD19-02-1-0389. The views and Security Assistant for The Internet," in Proceedings of
conclusions contained in this document are those of the The 16th Annual Computer Security Applications
authors and should not be interpreted as representing Conference (ACSAC'00), 2000.
the official policies, either expressed or implied, of the [15] Kerner, Sean Michael. 2006. Firefox 2.0 Bakes in Anti-
National Science Foundation or the U.S. government. Phish Antidote. InternetNews.
http://www.internetnews.com/dev-
news/article.php/3609816.
7. References
[16] McAfee, Inc. McAfee SiteAdvisor. Accessed:
[1] Anti-Phishing Working Group. Phishing Activity
November 9, 2006. http://www.siteadvisor.com/.
Trends Report. June, 2006.
[17] Microsoft Corporation. Internet Explorer 7. Accessed:
http://www.antiphishing.org/reports/apwg_report_june_
November 9, 2006.
06.pdf.
http://www.microsoft.com/windows/ie/default.mspx.
[2] CallingID, Ltd. Accessed: December 1, 2006.
[18] Netcraft. Netcraft Anti-Phishing Tool. Accessed: June
http://www.callingid.com/DesktopSolutions/CallingIDT
13, 2006. http://tool.netcraft.com/.
oolbar.aspx.
[19] Netscape Communications Corp. “Security Center.”
[3] Chou, Neil, Robert Ledesma, Yuka Teraguchi, Dan
Accessed: November 9, 2006.
Boneh and John C. Mitchell, “Client-Side Defense
http://browser.netscape.com/ns8/product/security.jsp.
against Web-Based Identity Theft,” in Proceedings of
The 11th Annual Network and Distributed System [20] Phelps, Thomas A., and Robert Wilensky. “Robust
Security Symposium (NDSS '04), San Diego, CA Hyperlinks and Locations,” D-Lib Magazine,
February, 2004. July/August 2000.
http://crypto.stanford.edu/SpoofGuard/webspoof.pdf. [21] The PlanetLab Consortium. PlanetLab: Home.
Accessed: June 13, 2006. http://www.planet-lab.org/.[22] Robichaux, Paul. 2006. Gone Phishing: Evaluating [24] Tor: An Anonymous Internet Communication System.
Anti-Phishing Tools for Windows. 3Sharp Technical Accessed: September 7, 2006. http://tor.eff.org/.
Report. [25] Wu, Min, Robert C. Miller, and Simson L. Garfinkel,
http://www.3sharp.com/projects/antiphishing/gone- “Do Security Tools Actually Prevent Phishing
phishing.pdf Attacks?” in Proceedings of the SIGCHI Conference on
[23] Rouse, Mark. Comparing Images using GDI+. Human Factors in Computing Systems, (Montreal,
Accessed: September 9, 2006. Quebec, Canada, April 22 - 28, 2006), 601-610. New
http://www.codeproject.com/dotnet/comparingimages.asp. York: ACM Press, 2006.