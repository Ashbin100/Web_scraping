Trust Negotiation with Hidden Credentials, Hidden Policies, and Policy Cycles ∗
KeithB.Frikken JiangtaoLi MikhailJ.Atallah
DepartmentofComputer Science,PurdueUniversity,WestLafayette,Indiana
{kbf,jtli,mja}@cs.purdue.edu
Abstract a substantial extension of the state-of-the-art in privacy-
preservingtrustnegotiations.
InanopenenvironmentsuchastheInternet,thedecision
tocollaboratewithastranger(e.g.,bygrantingaccesstoa
resource)isoftenbasedonthecharacteristics(ratherthan
1 Introduction
theidentity)oftherequester,viadigitalcredentials: Access
isgrantedifAlice’scredentialssatisfyBob’saccesspolicy.
Whereasinthepastaccessdecisionswerebasedonthe
Theliteraturecontainsmanyexampleswhereprotectingthe
identityoftheentityrequestingaresource,inopensystems
credentials and the access control policies is useful, and
suchastheInternet,thisapproachisineffectivewhenthere-
therearenumerousprotocolsthatachievethis. Inmanyof
sourceownerandtherequesterbelongtodifferentsecurity
theseschemes,theserverdoesnotlearnwhethertheclient
domains that are controlled by different authorities, possi-
obtained access (e.g., to a message, or a service via an e-
blyunknowntoeachother. Onealternativeistousedigital
ticket). Aconsequenceofthispropertyisthattheclientcan
credentialsforsatisfyingaccesscontrolpolicies[3,12,21].
useallofhercredentialswithoutfearof“probing”attacks
Digitalcredentialsaredigitallysignedassertionsaboutthe
bytheserver,becausetheservercannotgleaninformation
credential owner by a credential issuer. Each digital cre-
aboutwhichcredentialstheclienthas(whenthispropertyis
dential contains an attribute (or set of attributes) about the
lacking,theliteratureusesaframeworkwheretheveryuse
owner.Thedecisiontograntaccesstoaresourceisbasedon
ofacredentialissubjecttoapolicyspecifictothatcreden-
theattributesintherequester’scredentials,suchascitizen-
tial). Themainresultofthispaperisaprotocolfornegoti-
ship, security clearance, employment, group membership,
atingtrustbetweenAliceandBobwithoutrevealingeither
creditstatus,etc.
credentialsorpolicies,wheneachcredentialhasitsownac-
Atypicalscenarioforaccessingaresourceusingdigital
cesspolicyassociatedwithit(e.g.,“atop-secretclearance
credentialsisfortherequester,Alice,tosendherrequestto
credentialcanonlybeusedwhentheotherpartyisagov-
theresourceowner,Bob. Bobthenrespondswiththepolicy
ernment employee and has a top-secret clearance”). Our
that governs access to that resource. If Alice’s credentials
protocol carries out this privacy-preserving trust negotia-
satisfyBob’spolicy,shesendstheappropriatecredentialsto
tion between Alice and Bob, while enforcing each creden-
Bob. After Bob receives the credentials and verifies them,
tial’spolicy(therebyprotectingsensitivecredentials). Note
hegrantsAliceaccesstotheresource. Observethat,inthis
that there can be a deep nesting of dependencies between
scenario, Alice learns Bob’s policy and Bob learns Alice’s
credential policies, and that there can be (possibly over-
credentials. Suchastrategyisstraightforwardandefficient,
lapping) policy cycles of these dependencies. Our result
however it is unacceptable if the credentials or the access
is not achieved through the routine use of standard tech-
controlpoliciesareconsideredtobesensitiveinformation.
niques to implement, in this framework, one of the known
Clearly,itisadvantageousfortherequestertoprotecther
strategies for trust negotiations (such as the “eager strat-
credentials,asrevealingthemmayviolateherpersonalpri-
egy”). Rather, this paper uses novel techniques to imple-
vacy.Themotivationforhidingthepolicyisnotnecessarily
ment a non-standard trust negotiation strategy specifically
protectionfromaneviladversary.Itcouldsimplybethede-
suitedtothisframework(andinfactunusableoutsideofthis
sire to prevent legitimate users from “gaming” the system
framework, as will become clear). Our work is therefore
– e.g., changing their behavior based on their knowledge
∗Portions of this work were supported by Grants IIS-0325345, IIS- ofthepolicy(whichcanrenderaneconomically-motivated
0219560,IIS-0312357,andIIS-0242421fromtheNationalScienceFoun- policylesseffective).Thisisparticularlyimportantforpoli-
dation,ContractN00014-02-1-0364fromtheOfficeofNavalResearch,by
cies that are not incentive-compatible in economic terms
sponsorsoftheCenterforEducationandResearchinInformationAssur-
anceandSecurity,andbyPurdueDiscoveryPark’se-enterpriseCenter. (e.g., they suffer from perverse incentives in that they re-
1wardthewrongkindsofbehavior,suchasfree-loading).Or such situations, the client may understandably have legiti-
itcouldbethatthepolicyisacommercialsecret–e.g.,Bob mateconcernsaboutusingcredentialsthatshedeemssensi-
has pioneered a novel way of doing business, and knowl- tive – in fact the client may be required to protect certain
edge of the policy would compromise Bob’s strategy and credentials (e.g., a top-secret clearance credential). This
inviteunwelcomeimitators.Finally,aprocessthathidesAl- poses a problem for the previous schemes, which require
ice’scredentialsfromBobisultimatelynotonlytoAlice’s the client’s ability to use all of her credential set. There-
advantagebutalsotoBob’s: Bobnolongerneedstoworry fore, there isaneed foratrustnegotiation systemthatcan
about rogue insiders in his organization illicitly leaking or mitigatetheseconcerns.
sellingAlice’sprivateinformation,andmayevenlowerhis In traditional trust negotiation [30, 32, 25, 34, 33, 29]
liabilityinsuranceratesasaresult. Privacy-preservationis the notion of sensitive credential protection has been well
a win-win proposition, one that is appealing even if Alice studied (see Section 3). In these schemes, each sensitive
andBobarehonestandtrustworthyentities. credentialhasanaccesscontrolpolicy–acredentialisused
Fortheseandothersimilarreasons,therehasbeenasub- (or revealed) only when the other party satisfies the policy
stantial amount of recent work [17, 6, 14] on performing forthatcredential.ThisdoesnotpreventSCALP,butitdoes
this type of attribute-based access control while protect- allowtheusertocontrolthepotentialleakageofhercreden-
ing Alice’s credentials and Bob’s policies. One assump- tials. Theschemesin[14,17,6]didnotrevealcredentials
tion of these schemes is that the resource owner does not butcouldnothandlepoliciesforcredentials(i.e.,theydealt
learn whether the requester obtained access. When this is with the easier special case where each credential’s access
thecase,therequestercanuseallofhercredentialswithout controlpolicywasunconditionally“true”). Thepresentpa-
regardtotheirsensitivitylevel,astheseschemesdonotleak per is the first to combine the techniques for hidden cre-
therequester’scredentialstotheserviceprovider.However, dentialswiththenotionofpoliciesforsensitivecredentials.
this“resourceownerdoesnotlearn”propertymaynothold Thesecredentialpolicieshavetobeconsideredsensitiveas
inpracticeforthefollowingtworeasons: well,becauseotherwisetheserver(orclient)cangamethe
systeminmanyways. Forexample,iftheclientknowsthe
1. Inmanyscenarios,theservergrantsaccesstoservices accesscontrolpoliciesfortheserver’scredentialsthenshe
rather than messages. Thus, for certain types of ser- willknowthepathofleastresistancetounlockcertaincre-
vices, the server has to know whether the client got dentialsandthusshewillbeabletoprobemoreeasily.
access to the services. In fact there are audit and ac- Therestofthispaperisorganizedasfollows. Webegin
counting requirements that cause many organizations withadetaileddescriptionofourcontributionsinSection2.
torequirelearningwhetheraccesstookplace. Wereviewtrustnegotiationandproposeanewdefinitionof
trust negotiation that supports policy cycles in Section 3.
2. Eveniftheserveroffersmessagesratherthanservices,
Next,weformallyintroduceourapproachtotrustnegotia-
messagerequestsarenotindependentinmostsystems.
tion in Section 4, and then we review some cryptographic
For example, suppose a client requests message M ,
1 tools in Section 5. We present our protocol for privacy-
which contains a hyperlink to message M , and that
2 preservingtrustnegotiationinSection6.Wegiveefficiency
same client subsequently requests M a few minutes
2 improvementsforourbaseschemeinsection7. Wegivea
later;althoughtheserverdoesnotlearnforcertainthat
sketchoftheproofofsecurityinSection8. Wediscussthe
theclientsuccessfullyobtainedM ,inferencescanbe
1 relatedworkinSection9,andweconcludeinSection10.
made.
2 OurContributions
Fortheabovereasons,theservercouldlearnwhetherthe
clientobtainedaccess. Thismayseemlikeaninsignificant
bitofinformation,butsincetheservercansethispolicyto Weintroduceaprotocolforprivacy-preservingtrustne-
beanarbitraryfunction,thisenablestheservertoprobethe gotiation, where the client and server each input a set of
clientforsensitivecredentials. Forexample,theservermay credentials along with an access control policy for each of
intentionallysethisaccesscontrolpolicytobe“onlypeople theircredentials. Theprotocoldeterminesthesetofusable
with top-secret clearance can access the resource”. When credentialsbetweentheclientandtheserver,andthenwill
theclientobtainsaccess,theserverlearnsimmediatelythat processtheresourceorservicerequestbasedontheclient’s
theclienthasatop-secretclearancecredential. usablecredentials. Acredentialisusableifitsaccesscon-
ThisSensitiveCredentiAlLeakageProblem(SCALP)is trolpolicyhasbeensatisfiedbytheotherparty. Ourproto-
not due to any flaw or weakness in the previous protocols coliscomplicatedbythefactthat: (1)thepoliciesforsen-
(e.g.,[17,6,14])butratherexistsinanysituationwherethe sitivecredentialsmaythemselvesbesensitiveandtherefore
server can link transactions to the same client and has ar- cannotberevealed,(2)theclientshouldnotlearninforma-
bitraryfreedomwhencreatingtheaccesscontrolpolicy. In tion about which of her credentials or the server’s creden-tialsareusable,and(3)theservershouldnotlearninforma- consistsofasequenceofcredentialexchanges. Trustises-
tionaboutwhichofhiscredentialsortheclient’scredentials tablished if the initially requested resource is granted and
are usable. The rationale for requirement (1) was given in all policies for disclosed credentials are satisfied [30, 32].
theprevioussection. Requirements(2)and(3)arebecause, In this case, the negotiation between the client and server
iftheclientorserverweretolearnwhichofitscredentials isasuccessfulnegotiation, andotherwise, itisafailed ne-
are usable, then this would reveal more information about gotiation. Wegivetheformaldefinitionfortraditionaltrust
the other party’s credential set and thus facilitate probing negotiationasfollows:
attacks. Thetechnicalcontributionsofthispaperinclude:
Definition1(TraditionalTrustNegotiation) Let C and
S
P (C andP )bethesetsofcredentialsandpoliciespos-
1. Wedevelopanewprivacy-preservingtrustnegotiation S C C
sessed by a negotiating server (client). The negotiation is
protocolandseveralnovelcryptographicprotocolsfor
initiated by a request for s ∈ C 1 from the client. The
carryingitout. Oneofthechallengesisthedistinction S
goal of trust negotiation is to find a credential disclosure
betweenhavingacredentialandbeingabletousethat
sequence(c ,...,c = s),wherec ∈ C ∪C ,andsuch
credential(whenitsaccesscontrolpolicyhasbeensat- 1 n i S C
thatforeachc ,1 ≤ i ≤ n,thepolicyforc issatisfiedby
isfied), while requiring that “not having” a credential i i
thecredentialsalreadydisclosed,i.e.,φ (S c )=1. If
beindistinguishablefrom“havingbutbeingunableto ci j<i j
theclientandserverfindacredentialdisclosuresequence,
use”acredential.
thenegotiationsucceeds,otherwise,itfails.
2. We propose a reverse eager trust negotiation strat-
The sequence of disclosed credentials depends on the
egy (denoted as RE strategy) that handles arbitrary
decisions of each party; these decisions are referred to as
policy cycles, whereas the existing traditional trust-
a strategy. A strategy controls which credentials are dis-
negotiationstrategies(suchastheeagerstrategy[30])
closed,whentodisclosethem,andwhentoterminateane-
are inherently unable to handle such cycles (even if
gotiation [34]. Several negotiation strategies are proposed
these strategies were properly implemented in this
in [30, 32, 34]. For example, in the eager strategy [30],
framework).
two parties take turns disclosing a credential to the other
sideassoonastheaccesscontrolpolicyforthatcredential
3 TrustNegotiation: ReviewandDiscussion is satisfied. For the reader unfamiliar with the eager strat-
egy,wedescribeitinmoredetailinAppendixA. Although
the cryptographic contributions of this paper will make it
Intrustnegotiation [30,32,25,34,28,33,29],thedis-
possible to implement the eager strategy in the framework
closure of a credential s is controlled by an access con-
considered,wedonotpursuethisapproachbecauseitfails
trolpolicyp thatspecifiestheprerequisiteconditionsthat
s
to handle policy cycles. In fact, if there is a policy cycle,
must be satisfied in order for credential s to be disclosed.
the trust negotiation will fail under Definition 1. We now
Typically, the prerequisite conditions are a set of creden-
propose a new definition of trust negotiation that supports
tials C ⊆ C, where C is the set of all credentials. As
policycycles.
in [30, 32, 25, 34, 33], the policies in this paper are mod-
eled using propositional formulas. Each policy p s takes Definition2(Cycle-TolerantTrustNegotiation) Let C
S
the form s ← φ s(c 1,...,c k) where c 1,...,c k ∈ C and andP
S
(C
C
andP C)bethesetsofcredentialsandpolicies
φ s(c 1,...,c k) is a normal formula consisting of literals possessedbyanegotiatingserver(client). Thenegotiation
c i, the Boolean operators ∨ and ∧, and parentheses (if is initiated by a request for s ∈ C from the client. The
S
needed). In this paper, s is referred to as the target of p s, negotiationbetweentheclientandserversucceedsifthere
and φ s(c 1,...,c k) is referred to as the policy function of exists usable credential sets U
S
⊆ C
S
and U
C
⊆ C
C
for
p s. theserverandclientrespectively,suchthat(1)s ∈ U ,(2)
S
Given a setof credentials C′ ⊆ C and a policy function ∀c ∈ U , φ (U ) = 1, and (3) ∀c ∈ U , φ (U ) = 1.
S c C C c S
φ s(c 1,...,c k),wedenoteφ s(C′)asthevalueofthenormal Otherwise,thenegotiationfails.
formulaφ (x ,...,x )wherex =1ifandonlyifc ∈C′
s 1 k i i
(otherwise x = 0). For example, if φ = (c ∧c )∨c , Note that the above definition allows for many possible
i s 1 2 3
then φ s({c 1,c 2,c 4}) = 1 and φ s({c 1,c 4}) = 0. Policy U C,U S solution pairs, and does not capture any notion of
p is satisfied by a set of credentials C′ ⊆ C if and only minimality for such pairs: Some solution pair may be a
s
if φ (C′) = 1. During trust negotiation, one can disclose propersubsetofsomeotherpair,andeitherofthemiscon-
s
credentialsifφ (C′) = 1whereC′ isthesetofcredentials sideredacceptable. Thisisfineintheframeworkofthispa-
s
thatshehasreceivedfromtheotherparty. per,becauseattheendofthenegotiationnothingisrevealed
A trust negotiation protocol is normally initiated by a 1Forsimplicity,wemodelservicesasacredential. Inordertoobtain
clientrequestingaresourcefromaserver. Thenegotiation s,theclienthastohavecredentialsthatsatisfyφs.aboutthespecificU ,U pair,i.e.,neitherpartycandistin- becauseofthe“optimism”oftheREstrategy(inthatacre-
C S
guishwhichpairwasresponsibleforaccessorwhetherthat dentialistentativelyusable,untilprovenotherwise),cycles
pairwasminimalornot.Italsoimpliesthatthetrustnegoti- nolongercauseaproblem,becausea“self-reinforcing”cy-
ationstrategywedesignneednotmakeanyparticulareffort cle’scredentialswillremainusable2(whereasitdeadlocked
atzeroinginonaparticularpair(e.g.,aminimalone). intheeagerstrategy).ThisREstrategy(thedetailsofwhich
aregivenlater)ismadepossiblebythefactthatwecarryout
Example1 Supposetheclientandserverhavethefollow-
the iterative process in a doubly blinded form, so that nei-
ingpolicies:
therpartylearnsanything(notonlyabouttheotherparty’s
Client Server credentials, but also about their use policies for these cre-
p :c ←s p :s←c ∨(c ∧c ) dentials). The RE strategy and blinded evaluations work
c1 1 2 s 5 2 4
p :c ←s ∧s p :s ←c handinhand: Theformerisuselesswithoutthelatter,and
c2 2 2 3 s1 1 6
p :c ←s p :s ←c itshouldnotbeusedoutsideofthisparticularframework.
c3 3 6 s2 2 1
p :c ←true p :s ←c Therestofthissectiongivesamoreprecisepresentation
c4 4 s3 3 4
byfirstintroducingthenotationthatwillbeusedthroughout
where s denotes the server’s service, {s,s 1,s 2,s 3} denote therestofthepaper, thendefiningourproblemandgiving
the set of server’s credentials, {c 1,c 2,c 3,c 4} denotes the amoredetailedoverviewofourapproach.
setoftheclient’scredentials. UnderDefinition1,thenego-
tiation between the client and server would fail as there is 4.1 NotationandDefinitions
a policy cycle between c and s , and there exists no cre-
1 2
dentialdisclosuresequenceendingwiths. However,under Before describing the details of our approach, it is nec-
Definition2,thenegotiationsucceeds,asU C ={c 1,c 2,c 4} essarytogiveamoreformalnotationthantheintuitiveter-
andU S ={s,s 2,s 3}isasolutionpair. minologyoftheprevioussection.
Clearly, if the trust negotiation between the client and • We use s to denote the server’s service or resource
server can succeed in Definition 1, it will also succeed in thattheclientrequests. Withoutlossofgenerality,we
Definition2,butnotvice-versa(e.g.,seeExample1).Inthe modelsasacredential.
nextsection,wedescribeareverseeager(RE)strategythat
• WeuseC (resp.,C )todenotethesetoftheclient’s
efficiently determines whether the negotiation can succeed C S
(resp., the server’s) hidden credentials. We use n
(underDefinition2)givenC , P , C , andP . Then, we C
S S C C
and n to denote the size of C and C , respectively.
willgiveaprivacy-preservingtrustnegotiationprotocolthat S C S
securely implements the RE strategy without revealing C Referring to Example 1, C C = {c 1,c 2,c 3,c 4} and
S
n =4.
and P to the client and without revealing C and P to C
S C C
theserver.
• WeuseP (resp.,P )todenotethesetoftheclient’s
C S
(resp.,server’s)policies.
4 OurApproach
• WeuseR(p )todenotethesetofcredentialsrelevant
i
to(i.e.,thatappearin)thepolicyfunctionofthepolicy
Webeginthissectionwithanintuitive,informalpresen-
p . Forexample,ifthepolicyfunctionforp takesthe
tationofourapproach. Theeagerstrategyfortrustnegotia- i i
formofφ (c ,...,c ),thenR(p )={c ,...,c }.
tionscanbethoughtofasoneof“progressivelyincrement- i 1 k i 1 k
ingtheusableset”: Thesetofusablecredentialsisinitially • We use R(P ) (resp. R(P )) to denote the union
C S
settotheunconditionallyusablecredentials,andeachiter- of all the R(p )’s over all p in P (resp. P ), i.e.,
i i C S
ation adds to it credentials that have just (in that iteration) R(P ) = S R(p ). Weusem andm tode-
C pi∈P
C
i C S
become known to be usable. It is, in other words, a con- notethesizeofR(P )andR(P ), respectively. Re-
C S
servative approach, whose motto is that a credential is not ferringtoExample1,R(P )={c ,c ,c ,c ,c }and
S 1 2 4 5 6
usableunlessprovedotherwise: Theiterativeprocessstops m =5.
S
whennomorecredentialsareaddedtotheusableset. This
• WeuseU (resp.,U )todenotethesetoftheclient’s
conservatism of the eager approach is also why using that C S
(resp., the server’s) credentials whose policies are
strategy would lead us to deadlock on cycles. Our over-
presumed to have been satisfied (i.e., these are the
allstrategyistheopposite,andcanbeviewedasa“reverse
currently-believedusablecredentials);asstatedearlier,
eager”strategy:Initiallyallcredentialsaretemporarilycon-
these sets will decrease from one iteration to another.
sideredtobeusable,andeachiterationdecreasesthesetof
Initially, U = C andU = C , andthroughoutthe
usable credentials (of course the decrease is achieved im- C C S S
iterativeprocesswehaveU ⊆C andU ⊆C .
plicitly,soasnottoviolateprivacy–moreontheseimple- C C S S
mentation details is given in the next section). Note that, 2SeeSection4.4forproof4.2 ProblemDefinition theotherparty). Afterthis,thenegotiatorblindlydecreases
theirownlocalpresumed-usablecredentialsetaccordingly.
Thegoalofthispaperistodevelopasolutionsuchthat RecallthatweuseU (U )todenotethesetoftheclient’s
C S
the client and server are able to learn whether trust can be (server’s)credentialsthatarepresumedusable,i.e.,atapar-
establishedwithouteitherpartyrevealingtotheotherparty ticular stage of the iterative process, for each credential in
anything about their own private credentials and policies U (U ),thecorrespondingusabilitypolicyiscurrentlysat-
C S
(other than, unavoidably, what can be deduced from the isfied(althoughitmayceasetobesoinafutureiteration).
computed answer). We formalize the privacy-preserving WepresenttheREstrategyinFigure1.
trustnegotiationproblemasfollows.
reverse-eager-strategy(C,P,U )
O
Problem1 TheserverinputsC
S
andP
S
andtheclientin-
C: thelocalcredentialsofthisparty.
putsC C,P C,andarequestfortheserver’sservices. Inthe
P: thelocalpoliciesofthisparty.
end,boththeclientandserverlearnwhethertheclient’sac-
U : thecredentialsusedbytheotherparty.
O
cesstoscanbegrantedbasedontheircredentialsandpoli-
Output:
cies, without revealing their sensitive credentials and poli-
U: thelocalcredentialsthatcanbeused.
cies to the other party. In other words, they want to know
Procedure:
whetherthetrustnegotiationbetweentheclientandserver
U =C;
succeedsunderDefinition2withoutleakingotherinforma-
Foreachcredentialc∈C
tion,exceptforn C,n S,m C,andm S.
letc’spolicybep :c←φ ;
c c
ifφ (U )=0,thenU =U −{c};
Having stated the problem, we will now discuss the in- c O
returnU.
formationrevealedbytheprotocol. Thevaluesn andn
C S
reveal the number of credentials that the client and server
respectively have and the values m C and m S reveal the Figure1.PseudocodefortheREstrategy
size of all policies for all credentials for the client and the
server.Wedonotviewthisasaproblembecausetheparties
Our approach to privacy-preserving trust negotiation is
canpadtheirlistortheirpolicieswithdummycredentials.
toimplementtheREstrategyinasecureway. Wegivethe
Wenowlistthesecuritypropertiesrequiredofasolution(a
high-leveldescriptionofourprotocolinFigure2. Init,the
moredetailedversionisgiveninSection8).
server first initializes U . Then the client and server run a
S
secureversionoftheREstrategyprotocoltoupdateU and
1. Correctness: If trust can be successfully negotiated, C
U iterativelyfornrounds,wheren=min(n ,n )(recall
thenboththeclientandservershouldoutputtruewith S C S
that the trust negotiation using the eager strategy takes at
overwhelmingprobabilityiftheyfollowtheprotocol.
mostnrounds). Intheend,ifs ∈ U (i.e.,scanbeused),
S
2. Robustnessagainstmaliciousadversaries: Ifthetrust thenegotiationsucceeds,otherwise,itfails.
negotiationfails,thenboththeclientandservershould
outputfalseevenifoneoftheparticipantsismalicious privacy-preserving-trust-nego(s,C ,P ,C ,P )
C C S S
(i.e.,behavesarbitrarily)withoverwhelmingprobabil- Output:
ity. trueorfalse
Procedure:
3. Privacy-preservation: The client and server should
InitializeU ;
S
notlearnanythingabouttheotherparty’sprivateinput
Fori=1,...,min(n ,n )
C S
(credentials and policies) or intermediate results (us-
U =reverse-eager-strategy(C ,P ,U );
C C C S
able credential sets), other than what can be deduced
U =reverse-eager-strategy(C ,P ,U );
S S S C
fromtheyes/nooutcomeofthenegotiation.
Ifs∈U ,outputtrue,otherwise,outputfalse.
S
4.3 OverviewofOurApproach
Figure 2. High-level description of privacy-
As described earlier, our overall strategy for privacy- preservingtrustnegotiation
preservingtrustnegotiationistheREstrategy. Duringeach
round of the RE strategy, a negotiator blindly (i.e., with-
out actually learning the outcome) checks which of their Clearly, U and U should not be known to either the
C S
presumed-usablelocalcredentialsareinfactnotusable(ac- clientortheserver. ThusU andU needtobemaintained
C S
cording to whether the policy for it has ceased to be satis- in such a way that the values of U and U : (1) are un-
C S
fiedbasedonthethenewpresumed-usablecredentialsetof known to the client and server and (2) cannot be modifiedbyamaliciousclientorserver. WemaintainU C inthefol- 2. during iteration i − 1, C X,i−1 is computed
lowingsplitway: Foreachc∈C C,theclientgeneratestwo based on C X,i−2 and C X¯,i−2, i.e., C X,i−1 =
random numbers r c[0] and r c[1], and the server learns one f X(C X,i−2,C X¯,i−2);
of them, denoted as r . If c ∈ U , then r = r [1], oth-
c C c c
erwise r = r [0]. The client does not learn which value 3. bytheinductionhypothesiswehaveC X,i−1 ⊆C X,i−2,
c c
the server obtains, and so by splitting U in this way, the andC X¯,i−1 ⊆C X¯,i−2
C
clientdoesnotlearnU C. Furthermore, theserverdoesnot The above facts (1), (2), and (3), together with the
learnanythingaboutU C,asthevaluesheobtainsfromthe monotonicityofthefunctionf X,implythatC
X,i
⊆C X,i−1.
clientlookrandomtohim.WemaintainU inananalogous (cid:3)
S
way. Ourprotocolwillkeepthisformofsplittingasanin- Acorollaryoftheabovelemmaisthat,toprovethecor-
variantthroughallitssteps. Thisdoesnotsolveallprivacy rectnessofRE, itsufficestoshowthatforeverycredential
problemsofthenegotiation,butitwillbeoneoftheguiding cofpartyX,cisunusableifandonlyifthereissomeitera-
principlesofourprotocol. tioniafterwhichc∈/ C . Thenextlemmaprovesthe“if”
X,i
part. RecallthatC(X)denotethecorrectusablecredentials
4.4 ProofofREStrategy forX.
Lemma2 Foreveryi,wehaveC(X)⊆C .
We now provide a proof of the correctness of the RE X,i
strategy for trust negotiations. That is, we prove that at Proof: By induction on i. The basis, i = 0, is trivial
theendoftheREnegotiationeveryunusablecredentialhas because C = C . For the inductive step, i > 0, we
X,0 X
been markedassuch(theother credentials correctlyretain assume that credential c was removed by iteration i (i.e.,
theirinitiallabelof“usable”). SonotonlydoesREnotpro- that c ∈ C X,i−1 and c ∈/ C X,i), and we show that it must
duce a minimal usable credential set pair C C,C S, in fact it thenbethecasethatc∈/ C(X). Observethat
willproduceamaximalpairinthesensethateverycreden-
tial(whetheressentialornot)iskeptusableunlessmarked 1. c∈/ f X(C X,i−1,C X¯,i−1);
otherwise. Asstatedearlier,thisisjustifiedbytheindistin-
2. bytheinductionhypothesis,wehaveC(X) ⊆ C X,i−1
guishabilitytoeitherpartyofanytwosolutionpairs. andC(X¯)⊆C X¯,i−1.
Throughout this section, we use C , X ∈ {C,S}, to
X,i
denotetheusablecredentialsetoftheclient(ifX = C)or Theabove(1)and(2),togetherwiththemonotonicityof
oftheserver(ifX = S)afteriterationioftheREnegotia- f X, imply that c ∈/ f X(C(X),C(X¯)), i.e., that c ∈/ C(X).
tionhascompleted. WeuseC todenotetheinitial(prior (cid:3)
X,0
toiteration1)usablecredentialset(whichequalsC ). We The above lemma proved that every c removed by the
X
useX¯ todenote{C,S}−X. RE negotiation deserves to be removed (the “if” part). To
Letting C(X) denote the correct usable credentials for complete the proof, we need to prove the “only if” part:
X, our goal is therefore to prove that, after the last itera- Thateveryunusablecredentialwilleventuallybemarkedas
tion i of the RE negotiation, we have C = C(X) and suchbytheREnegotiation. Thatis,weneedtoprovethat
X,i
C X¯,i = C(X¯). Note that C X,i = f X(C X,i−1,C X¯,i−1) for everyc∈/ C(X)will,forsomei,beremovedbyiterationi.
some monotonic function f . (Although in fact C de- Thisisprovedinthenextlemma.
X Xi
pends only on C X¯,i−1 and not on C X,i−1, it does no harm
Lemma3 For every c ∈/ C(X), there is an iteration i for
to give a more general proof, as we do below, for the case
whenitcandependonboth.)
whichc∈C X,i−1andc∈/ C X,i.
Thenextlemmaprovestheintuitivefactthataniteration Proof:Foreverycredentialc,letthelevelofcbedefined
icannotcauseanunusablecredentialtobecomeusable. asfollows:
Lemma1 C
X,i
⊆C X,i−1,fori=1,2,.... • Ifcisunconditionallyusablethenlevel(c)=1.
• Iftheusabilitypolicyforcisp thenlevel(c) = 1+
c
Proof: Byinductiononi. Forthebasisoftheinduction,
max{level(v):v ∈R(p )}. (RecallthatR(p )isthe
c c
i = 1, the claim trivially holds because, prior to iteration
setofcredentialsrelevanttopolicyp .)
c
1,allthecredentialsofeachpartyareintheirinitialusable
set C . We now turn our attention to the inductive step, We claim that a credential c ∈/ C(X) is removed after
X,0
i>1. Observethat atmostlevel(c)iterations, i.e., thatforsomei ≤ level(c)
we have c ∈ C X,i−1 and c ∈/ C X,i. This is established by
1. during iteration i, C X,i is computed based on C X,i−1 a straightforward induction on level(c), whose details we
andC X¯,i−1,i.e.,C
X,i
=f X(C X,i−1,C X¯,i−1); omit. (cid:3)5 ReviewofCryptographicToolsandHidden 5.3 ScrambledCircuitEvaluation
CredentialsSystem
Thescrambledcircuitevaluationprotocolwasdeveloped
by Yao [31]. This protocol involves a generator and an
5.1 Identity-basedencryption
evaluator, in which the evaluator has private input x and
the generator has private input y, and they want to jointly
TheconceptofIdentity-BaseEncryption(IBE)wasfirst computef(x,y)withoutrevealingtheirprivateinputstothe
proposed by Shamir [26] in 1984, however the first usable otherparty.
IBEsystemswerediscoveredonlyrecently[5,9]. AnIBE In the scrambled circuit evaluation protocol, the gener-
schemeisspecifiedbyfollowingfouralgorithms: ator builds a circuit for computing f, constructs a scram-
bled version of the circuit, and then sends the scrambled
1. Setup:APrivateKeyGenerator(PKG)takesasecurity circuit to the evaluator for evaluation. In a scrambled cir-
parameter k and generates system parameters params cuit,eachwireisassociatedwithtworandomnumbers,one
and a master secret s. params is public, whereas s is correspondsto0andtheotherto1. Beforetheevaluation,
privatetoPKG. the evaluator uses oblivious transfer to obtain the random
values for the input wires corresponding to each bit of her
2. Extract: GivenanyarbitraryID ∈ {0,1}∗, PKGuses privateinputx. Duringtheevaluation,theevaluatorlearns
params, s, and ID to compute the corresponding pri- exactly one random value for each internal wire, yet she
vatekeydID. doesn’tknowwhetheritcorrespondsto0or1. Finallythe
evaluatorsendstheoutcomeoftheevaluationtothegener-
3. Encrypt: Ittakesparams,IDandplaintextM asinput ator,whorecoversthefinalresult.
andreturnsciphertextC. The scrambled circuit evaluation protocol is secure
againstsemi-honestadversariesandhasbeenimplemented
4. Decrypt:Ittakesparams,dIDandciphertextCasinput
by Malkhi et al. in [22]. Let γ be a security parameter, ρ
andreturnsthecorrespondingplaintextM.
bethecostofa1-out-of-2oblivioustransfer,assumingthe
circuittocomputef isans-input,t-gateBoolean2-arycir-
AnIBEschemeenablesBobtoencryptamessageusing cuit,thecostofthescramblecircuitprotocolisO(ρs+γt).
Alice’sIDasthepublickey, andthusavoidsobtainingthe Whenthesizeofthecircuitislineartothesizeoftheinput,
public key from Alice or a directory. Boneh and Franklin thecostoftheprotocolisO(ρs).
proposed an IBE scheme from the Weil pairing [5]. Their
schemeissecureagainstadaptivechosenciphertextattacks. 5.4 Reviewofhiddencredentialssystem
5.2 HomomorphicEncryption The hidden credentials system was proposed by Holt et
al. [17, 6]. In that system, there is a trusted Credential
Authority(CA)whoissuescredentialsforusersinthesys-
Ahomomorphicencryptionscheme[23,24,10,11]isan
encryptionschemeinwhichtheplaintextsaretakenfroma
tem3. Each user in the system is assigned a unique nym,
groupG,andgiventheencryptionsoftwogroupelements
wherenymcouldbeeitherarealnameorapseudonym. A
hiddencredentialisadigitallysignedassertionaboutanat-
onecanefficientlycomputeaencryptionoftheirsum. Usu-
tributeofacredentialholderbytheCA.Roughlyspeaking,
ally this computation involves a modular multiplication of
the encryptions, let G = Z where M is a large integer, givenanIBEscheme,ahiddencredentialcredforusername
M
wehaveE(a)·E(b)=E(a+bmodM). Itiseasytosee nym and attribute attr is the private key corresponding to
thatE(a)c =E(c·amodM). thestringnym||attr.
We now give a simple example of how Alice accesses
Damga˚rd and Jurik [11] recently proposed a homomor-
Bob’sresourceusingthehiddencredentials.SupposeBob’s
phicencryptionschemeinwhichalluserscanusethesame
resourceM hasanaccesspolicywhichstatesthatM should
RSA modulus N when generating key pairs. Under the
onlybeaccessedbystudents. Alicehasastudentcredential
Decisional Composite Residuosity assumption and Deci-
cred, i.e., cred.nym = Alice and cred.attr = student.
sion Diffie-Hellman assumption, the Damga˚rd-Jurik cryp-
ToaccessM,AlicesendsherusernameAlicetoBob. Bob
tosystem [11] is semantically secure. The semantic secu-
respondswithI(M,Alice||student),theIBEencryptionof
rity property guarantees that an eavesdropper cannot learn
M usingidentityAlice||student. Aliceuseshercredential
anyinformationaboutafromE(a). Moreprecisely,given
credtodecryptI(M,Alice||student)andobtainsM. Note
two arbitrary message m and m , the random variables
0 1
representingthetwohomomorphicencryptionsE(m 0)and 3ItispossibletosupportmultipleCAsinthehiddencredentialssys-
E(m 1)arecomputationallyindistinguishable. tem[17].Forsimplicity,weassumethereisonlyoneCA.that Bob does not learn whether Alice possesses a student Input: Bobhasnvalueshy ,y ,...,y i. Alicehasn
1 2 n
credentialfromtheaboveinteraction. valueshx ,x ,...,x iandhastworandomnumbers
1 2 n
t andt .
0 1
6 Protocol for Privacy-Preserving Trust Ne-
Output: Boblearnst ifandonlyifthere∃i∈[1..n]
1
gotiation suchthatx =y ,andlearnst otherwise.Alicelearns
i i 0
nothing.
6.1 BuildingBlocks
Figure4.Inputandoutputofequalitytestfor
We now describe two building blocks, one for blinded
arrayelements
policy evaluation, the other for equality test for array ele-
ments.Thesebuildingblockswilllaterbeusedinthesecure
REstrategyprotocol.
quirementtoO(ρn)(thatisofindependentinterest)inSec-
tion7.
6.1.1 Blindedpolicyevaluation
The goal of the blinded policy evaluation is for Bob to 6.2 SecureREStrategyProtocol
evaluate Alice’s policy without learning her policy. Alice
shouldlearnnothingaboutBob’sinputnortheoutputofthe The goal of the secure RE strategy protocol is to se-
evaluation. Wedefinetheinputandoutputforthisblinded curely implement the RE strategy in Figure 1. We denote
policyevaluationinFigure3. the participants of this protocol by Alice and Bob, where
AliceiseithertheclientortheserverandBobistheoppo-
Input: Alice has a private policy function φ : site role. In this section, we introduce a protocol to com-
{0,1}k → {0,1}, two random numbers t
0
and t 1, pute secure-reverse-eager-strategy(C A,P A,C B,U B) (the
andkpairsofvalues{r [0],r [1]},...,{r [0],r [1]}. items subscripted by A are Alice’s values and those sub-
1 1 k k
Bobhaskvaluesr 1,...,r k wherer i ∈{r i[0],r i[1]}. scripted by B are Bob’s values), where the output is U A
in the split-formdescribed earlier. The careful reader may
Output: Bob learns t ? ? . Alice notice a discrepancy between this and the RE strategy de-
φ(r1=r1[1],...,rk=rk[1])
learnsnothing. fined earlier. Note that in this case U represents an array
B
of Boolean values marking which credentials are usable,
whereas in the previous case it represented the actual cre-
Figure 3. Input and output of blinded policy
dentials. A credentials c of Alice’s is not usable if Bob’s
evaluation
usablecredentialsdonotsatisfyAlice’susabilitypolicyfor
c. Figure5describesthisprotocol.
The protocol for blinded policy evaluation was given IntuitonofCorrectness/Security: InStep 1ofthe proto-
in [14], for details see Appendix B. In most cases, it re- col,Bobwilllearnt [1]ifhehascredentialc andhecanuse
i i
quiresapolynomialamountofcommunication, andworks it,andotherwisehelearnst [0].Notethatthesevalueswere
i
forafamilyofpolicyfunctions. generated by Alice. The first part of this (i.e., Bob has c )
i
iscapturedbythevaluex;thatis,Bobisabletoobtainxif
andonlyifhehasc . Furthermore,ifBob’scredentialb is
6.1.2 Equalitytestforarrayelements i j
c ,thend =xinStep1b.Thesecondpartofthis(i.e.,Bob
i j
Inanequalitytestforarrayelements,Alicehasaprivatear- canusec )iscapturedbythesetU ;thatis,Alicewillhave
i B
ray hx ,...,x iand Bob has a private array hy ,...,y i. rB[1]ifBobcanusec canshewillhaverB[0]otherwise.
1 n 1 n i i i
Theywanttolearnwhetherthereexistsanindexisuchthat Puttingthesepiecestogetherimpliesthat”b equalsc and
j i
x = y . The result of the equality test is known to nei- Bob can use b ” if and only if x+rB[dB] = d +rB[1].
i i j j j j j
therAlicenorBob. Wedefinetheinputandoutputforthis Thustheequalitytestforarraryelementsprotocolcomputes
protocolinFigure4. thedesiredvalue.
This equality test can be implemented by a scrambled InStep2oftheprotocolAliceandBoblearntheirshares
circuit evaluation protocol [31, 22]. The protocol requires ofU ,thatisAlicewilllearnapair(rA[0],rA[1])andBob
A i i
O(ρ2n) communication and computation, where ρ is the willlearnrA[1]ifandonlyifAlicecanusecredentiala and
i i
maximumbit-lengthofeachx andy orthesecuritypara- hewilllearnrA[0]otherwise. NotethatAlicecanusecre-
i i i
mater(whicheverislarger). Wegiveanefficiencyimprove- dentiala onlyifBob’susablecredential(computedinStep
i
mentthatreducesthatcommunicationandcomputationre- 1) satisfies Alice’s policy for a . However, this is exactly
iInput: Bobinputs: (1)asetofcredentials,C ,whichwedenotebyb ,...,b and(2)hisshareofU ,which
B 1 n B
wedenotebyorderedpairs(rB[0],rB[1]),...,(rB[0],rB[1]). Aliceinputs: (1)asetofcredentials,C ,which
1 1 n n A
wedenotebya ,...,a ,(2)asetofpoliciesforthesecredentials,P ,whichwedenotebyp ,...,p ,and(3)
1 m A 1 m
hershareofU ,whichwedenotebyrB[dB],...,rB[dB](notedB is1ifBobcanuseb andis0otherwise).
B 1 1 n n i i
Output: Alice learns her share of the updated U which is denoted by ordered pairs
A
(rA[0],rA[1]),...,(rA[0],rA[1]). Bob learns his share of the updated U which is denoted by
1 1 m m A
rA[dA],...,rA[dA],wheredA =p (U ).
1 1 m m i i B
ProtocolSteps:
1. DeterminewhichcredentialsinAlice’spoliciesBobhasandcanuse:SupposethatthecredentialsinR(P )
A
arec ,...,c . Alicerandomlygenerateskorderedpairs: (t [0],t [1]),...,(t [0],t [1]). Foreachcreden-
1 k 1 1 k k
tialc ,AliceandBobengageinthefollowingsteps:
i
(a) Alicepicksarandomnumberx,andsendsm=I(x,c )(theIBEencryptionofxbasedonthehidden
i
credentialc )toBob.
i
(b) Bobdecryptsmusingeachofhishiddencredentials,andobtainsd ,...,d ,whered =I−1(m,b ).
1 n i i
(c) Alice creates a vector~a = hx+rB[dB],...,x+rB[dB]i and Bob creates a vector~a = hd +
1 1 1 n n 2 1
rB[1],...,d +rB[1]i. AliceandBobengageinanequalitytestprotocolforarrayelementswhere
1 n n
theyeachinputtheirownarrayandAliceinputst [0]andt [1]. Attheendoftheprotocol,Bobobtains
i i
t [x ]. Notethatx is1ifandonlyifc ∈ U andBobhasc (thatisBobcanusethecredentialand
i i i i B i
heactuallyhasit)andis0otherwise.
2. ComputeU : Foreachcredentiala ,AliceandBobengageinthefollowingsteps:
A i
(a) Alicerandomlygeneratesanorderedpair(rA[0],rA[1]).
i i
(b) Alice and Bob securely evaluate p using blinded policy evaluation. Alice inputs
i
p ,(rA[0],rA[1]),{(t [0],t [1]),...,(t [0],t [1])} and Bob inputs {t [x ],...,t [x ]}. At the end
i i i 1 1 k k 1 1 k k
oftheprotocolBobobtainsrA[dA].
1 1
3. Alice and Bob produce U : Alice learns (rA[0],rA[1]),...,(rA[0],rA[1]) and Bob learns
A 1 1 m m
rA[dA],...,rA[dA]
1 1 m m
Figure5.SecureREstrategyprotocolsecure-reverse-eager-strategy(C ,P ,C ,U )
A A B B
whattheblindedpolicyevaluationinStep2does. scribetheprotocolinFigure6.
Proof of Correctness/Security: A more detailed proof Intuition of Correctness/Security: In Step 1 of the pro-
sketchisgiveninSection8. tocol, the server sets its set of usable credentials to all of
itscredentials(recallthattheREstrategyprotocolassumes
CostanalysisSteps1(a)-1(c)areperformedk times. Step
everything is usable initially and that things are removed
1(c)requiresO(nρ2)(whereρisasecurityparameter)com-
fromthisset).
munication.ThusStep1requiresO(knρ2)communication,
In Step 2 of the protocol, the client and the server take
butthiscanbereducedtoO(knρ)iftheprotocolinSection
turnsupdatingtheirusablecredentialsetsbasedontheother
7.1isusedforStep1(c). Assumingthatthepoliciescanbe
party’s usable set. Once a set ceases to change then the
computedwithcircuitsthatarelinearinthenumberofcre-
usable sets will cease changing and we will have com-
dentials, Step 2 requires O(mkρ) communication. Now k
puted the maximal usable credential set. Note that since
ism ,nisn ,andmisn ,andsothisprotocolrequires
A B A we are assuming monotonic policies this will take at most
O(m ρ(n +n ))communication(assumingpoliciescan
A A B min{n ,n }roundstocomputethisset.
C S
becomputedbyacircuitofsizelinearinthenumberofbits
Finally, as we model the service as a credential s , the
oftheirinputs). 1
clientwillhaverS[1]afterStep3ifandonlyifs isinthe
1 1
U .
S
6.3 Privacy-Preserving Trust Negotiation Proto-
col Proof of Correctness/Security: A more detailed proof
sketchisgiveninSection8.
We now “put the pieces together” and give the overall Cost analysis Step 2 of the protocol is executed
protocol for privacy-preserving trust negotiation. We de- min{n ,n }(callthisvaluen)times. Anindividualexe-
C SInput: TheclienthasC andP . TheserverhasC (callthesecredentialss ,...,s )andP . Furthermore,
C C S 1 nS S
s istheservicethattheclientrequested.
1
Output: Ifthetrustnegotiationbetweentheclientandservercansucceed,thenboththeclientandserveroutput
true,otherwise,theyoutputfalse.
ProtocolSteps:
1. InitializeU . Foreachcredentials ∈C ,theserverpickstworandomnumbers{rS[0],rS[1]}. Theserver
S i S i i
sendsrS[1]totheclient. TheclientcallsthisvaluerS[x ]
i i i
2. Fori=1,...,min(n ,n ):
C S
(a) The client and server run the secure RE strategy protocol (Figure 5) to obtain U =
C
secure-reverse-eager-strategy(C ,P ,C ,U )insplitform.
C C S S
(b) The server and client run the secure RE protocol (Figure 5) to obtain U =
S
secure-reverse-eager-strategy(C ,P ,C ,U )insplitform.
S S C C
3. Output result. To determine whether s ∈ U , the server sends a hash of rS[1] to the client. The client
1 S 1
checksifthehashofrS[x ]matchesthisvalue; ifitisamatchthentheclientprovesthistotheserverby
1 1
sendingrS[x ]totheserver(andbothpartiesoutputtrue),andifitisnotamatchtheclientterminatesthe
1 1
protocol(andbothpartiesoutputfalse).
Figure6.Privacy-preservingtrustnegotiationprotocol
cutionrequiresO(ρ(m +m )(n +n ))communication sets cease changing is not a good idea. Another option is
C S C S
andthustheprotocolrequiresO(nρ(m +m )(n +n )) tolimitthenumberofroundstosomereasonableconstant.
C S C S
communication. Thisdoesnothaveprivacyproblems,butitcouldcausethe
negotiation to succeed where it would not have succeeded
underDefinition2oftrustnegotiation. However,ifthereis
7 EfficiencyImprovements
domain-specificknowledgethatboundsthelongestcreden-
tialchain,thenthisisaviableoption.
7.1 A more efficient equality test for array ele-
ments
8 SecurityProofs
Inthissection,weintroduceamoreefficientprotocolfor
theequalitytestforarrayelements. Thisprotocolisrelated Inthisappendixwediscussthesecurityofourprotocols.
totheprotocolproposedby[13]forsecuresetintersection. We first define what is meant by security. We then briefly
Figure7introducesthisprotocol. Notethatthisprotocolre- (duetopageconstraints)sketchcomponentsoftheproofof
quiresonlyO(nρ+ρ2)communication(insteadofO(nρ2) security.
communication). We give the proof sketch of correctness
andsecurityinSection8. 8.1 DefinitionofSecurity
7.2 Reducingthenumberofrounds The security definition we use is similar to the stan-
dard model from the secure multi-party computation liter-
Apossiblecriticismofourprotocolfortrustnegotiation ature [15, 7]. The security of our protocol is analyzed by
isthatitrequiresO(min{n ,n })rounds.TheREstrategy comparingwhatanadversarycandoinourprotocolagainst
C S
requiresthismanyroundsintheworstcase,butinpractice whatanadversarycandoinanidealimplementationwitha
itrequiresmuchless(itrequiresroundsproportionaltothe trustedoracle. Specifically,wewillshowourprotocolisno
length of the longest policy chain). Our protocol can be worsethanthisidealmodelbyshowingthatforanyadver-
modifiedtostopassoonastheusablecredentialsetscease sary in our model there is an adversary in the ideal model
changing. However, this is not recommended as it would thatisessentiallyequivalent. Thusiftheidealmodelisac-
leakadditionalinformation,andthisinformationallowsfor ceptable(intermsofsecurity),thenourprotocolsmustalso
additionalprobing. Forexample,ifthenegotiationrequires beacceptable.
5 rounds then both parties can deduce that the other party Defining the ideal model for private trust negotiation is
does not satisfy at least 4 of their credentials. Thus, from tricky. First, the ideal model has to be defined such that
aprivacystandpointterminatingaftertheusablecredential there are no “violations of security” that are achievable inInputandOutput: SeeFigure4.
ProtocolSteps:
1. AliceandBobbothchoosesemanticallysecurehomomorphicencryptionschemesE andE thatsharea
A B
modulusM andexchangepublicparameters.
2. Alice creates a polynomial P that encodes the x values where the constant coefficient is 1 (which can be
donesincethisarithmeticismodular). InotherwordsshefindsapolynomialP(x)=η nxn+η n−1xn−1+
···+η x+1whereP(x )=0forallx . ShesendstoBobE (η ),...,E (η ).
1 i i A n A 1
3. Bobchoosesavaluek uniformlyfromZ⋆ . Foreachy , Bobchoosesavalueq uniformlyfromZ⋆
B M i B,i M
andhecomputes(E (P(y )))qB,iE (k +y )=E (q P(y )+k +y )(callthisvalueE (α )). Bob
A i A B i A B,i i B i A i
sendstoAliceE (α ),...,E (α ),E (k ).
A 1 A n B B
4. Alicedecryptsthevaluestoobtainα ,...,α . Shethencomputesx −α ,...,x −α Shechecksfor
1 n 1 i n n
duplicatevalues,andifthereareduplicatesshereplacesallextraoccurrencesofavaluebyarandomvalue.
Alicechoosesavaluek uniformlyfromZ⋆ . Foreachofthevaluesx −α shechoosesq uniformly
A M i i A,i
fromZ M⋆ andthenshecomputes(E B(k B)E B(x i−α i))qAiE B(k A)=E B((x i+k
B
−α i)q A,i+k A)(we
willcallthisvalueE (β )). AlicesendstoBobE (β ),...,E (β ).
B i B 1 B n
5. Bobdecryptsthevaluestoobtainβ ,...,β . BobthencreatesapolynomialQthatencodesthesevalues
1 n
wheretheconstantcoefficientis1. InotherwordsBobfindsapolynomialQ(x) = γ nxn +γ n−1xn−1 +
···+γ x+1whereQ(β )=0forallβ . BobsendstoAliceE (γ ),...,E (γ ).
1 i i B n B 1
6. Alice chooses two values k and q uniformly from Z⋆ and computes E (Q(k )q +k) and sends this
A M B A A
valuetoBob.
7. Bobdecryptsthisvaluetoobtaink′. AliceandBobengageinascrambledcircuitevaluationofanequality
circuitwhereAliceisthegeneratorwithinputkandshesetstheencodingsfortheoutputwiretot forthe
0
negativeencodingandtot forthepositiveencodingandBobistheevaluatorwithinputk′.
1
Figure7.SecureEqualityTestforArrayElements.
this ideal model; otherwise, there could be “violations of cificcredentialbecomesunusable. Theoraclewillsimulate
security” in our protocols. Furthermore, the ideal model theREstrategyusingtheaccesscontrolpoliciesdefinedby
must be defined in such a way as to allow useful trust ne- each party’s control algorithm. At the end of the negotia-
gotiation to take place; otherwise it and our protocols will tiontheoraclewillinformtheclientandtheserverwhether
not be useful. This is further complicated by the fact that accessisgranted. Duetopagelimitationswedonotdiscuss
the RE strategy does not make sense in a non-private set- theaboveidealmodelinmoredetail.
ting(asonecannotrevokeknowledgefromanotherparty).
Thus we define a fictitious environment where the parties 8.2 SketchoftheSecurityProof
have”chronicamensia”abouttheotherparty’scredentials.
InsuchanenvironmenttheREstrategyisplausible,andso
Wewillnowsketchpartoftheproof. Asitistoolengthy
ouridealmodelsimulatesthisenvironment.
toincludeinfulldetail,wefocusonlyononespecificaspect
We now informally define an ideal model implementa- ofthesystem. WefocusontheSecureReverseEagerstrat-
tionofourscheme. IntheidealmodeltheclientsendsC egy protocol (which is the key component of our system).
C
andP tothetrustedoracle, andtheserversendsC , P , We first show that if Alice is honest, then Bob cannot in-
C S S
andstotheoracle. WemodelP andP asarbitraryPPT fluencetheoutcomeoftheprotocolssothatheunrightfully
C S
algorithms. Thesealgorithmswillsimulatetheparties’be- keepsoneofAlice’scredentialsusable.
haviorduringtheREstrategy.Thusthesealgorithmsshould
beviewedascontrolalgorithmsthat: (1)definewhichcre- Lemma4 InthesecureREstrategyprotocol(Figure5): If
dentialstouseduringeachround,(2)definetheaccesscon- Alice is honest and after the protocol a specific credential
trol policies (which we model as PPT algorithms over the a (with policy p ) is in U , then Bob has a credential set
i i A
otherparty’scurrentlyusablecredentials)foritscredentials C suchthatp (C )istrue.
B i B
during each round, and (3) can force the oracle to termi-
nate. We stress that these algorithms cannot do the above Proof: Because step 2 is done by SCE and Alice is an
operationsbaseduponthestateofthenegotiation. Forex- honestgenerator,byLemma5allthatwemustshowisthat
ample,theycannotforcetheoracletoterminatewhenaspe- afterstep1,Boblearnst [1]onlywhenhehascredentiala .
i iBy way of contradiction, suppose Bob does not have cre- 1. Bobdoesnothavec : InStep1boftheprotocol,Bob
i
dentiala ,andthathelearnst [1]inStep1c. ByLemmas6 willnotlearnthevaluex,andthustherewillnotbea
i i
and7,Bobonlylearnst [1]whenthereisamatchinthear- match in Step 1c (with very high probability). Since
i
rayscreatedbyAliceandBobinStep1c.Ifthereisamatch, there is no match in the array, Bob will learn t [0],
i
thenBobmustbeabletolearnxwithanon-negligibleprob- whichiscorrect.
ability,butthisimpliesthathecaninverttheIBEencryption 2. Bob has c but cannot use it. Suppose b = c and
i j i
withnon-negligibleprobability,butthiscontradictsthatthe AlicehasrB[0]. Inthiscase,d =x,butBob’svector
j j
IBEencryptionschemeissecure. (cid:3) entrywillbex+rB[1]andAlice’swillbex+rB[0].
j j
Since there is no match in the array, Bob will learn
Lemma5 In scrambled circuit evaluation: If the genera-
t [0],whichiscorrect.
i
torishonestandtheevaluatorlearnsatmostoneencoding
3. Bobhasc andcanuseit. Supposeb = c andAlice
i j i
for each input wire, then the evaluator learns at most one hasrB[1]. Inthiscase,d =x,butBob’svectorentry
encoding for the output wire; furthermore this encoding is j j
willbex+rB[1]andAlice’swillbex+rB[1]. Since
thecorrectvalue. j j
thereisamatchinthearray,Bobwilllearnt [1],which
i
iscorrect.
Proof: We omit the details of this lemma, but similar
lemmasareassumedintheliterature (cid:3). Instep2oftheprotocol,AliceandBobsecurelyevaluate
p based upon which credentials are in U . If p (U ) is
i B i B
Lemma6 Inthecircuit-versionoftheequalitytestforar- true, then Bob will learn rA[1] (signifying that Alice can
i
ray elements: If Alice is honest, Bob learns t
1
only when use a i) and otherwise he will learn r iA[0] (signifying that
thereisanindexisuchthatx
i
=y i. Alicecannotusea i). (cid:3)
Proof: SinceAliceisthegeneratorofthecircuitandis
9 RelatedWork
honest,Bobwillinputasetofyvaluesandwilllearnt only
1
when one of his y values matches one of Alice’s x values
Our work is originally motivated from the existing au-
(byLemma5). (cid:3)
tomated trust negotiation literature [4, 30, 25, 34, 33,
Lemma7 In the other version (Figure 7) of the equality 29] whose goal is to enable trust establishment between
test for array elements: If Alice is honest, Bob learns t strangers in a decentralized or open environment, such as
1
onlywhenthereisanindexisuchthatx =y . theInternet. Intrustnegotiation,eachpartyestablishesac-
i i
cesscontrolpoliciestoregulatenotonlythegrantingofre-
Proof: By way of contradiction, suppose Bob learns t sources,butalsothedisclosureofcredentials(andpossibly
1
andthereisnomatchintheirarrays. InStep7ofthepro- policies) to others. A negotiation begins when a party re-
tocol Bob must know the value k (by Lemma 5). Thus in quests access to a resource that is protected by an access
Step5oftheprotocol,Bobmustbeabletogenerateanon- control policy. The negotiation process consists of a se-
zeropolynomialofdegreenthathask asaroot, butthis quence of cautious and iterative exchanges of credentials
A
impliesheknowsk withnon-negligibleprobability. This and possibly access control policies. In successful nego-
A
impliesthatinStep3,Bobcangeneratevaluesα ,...,α tiations, disclosed credentials eventually satisfy the access
1 n
suchthatthereisanα valuethatisx +k . Thisimplies controlpolicesofthedesiredresource. Asecurityrequire-
i B
Bobknowsx withnon-negligibleprobability,andthisim- ment for trust negotiation is that no credential should be
i
pliesthatthereisamatchinthearrays. (cid:3) disclosedunlessitsaccesscontrolpolicyhasbeensatisfied.
The above only shows one part of the proof. We must Theconceptofprivacyprotectionintheprevioustrustnego-
alsoshowthatifAliceishonest,Bobcannotlearnwhether tiationschemesdiffersfromtheoneinourscheme.Inexist-
hemadeaspecificcredentialusable(hecanforceacreden- ingtrustnegotiationschemes, aresource(e.g., aservice, a
tial to be unusable, but this has limited impact). Further- credential,orapolicy)isrevealedanddeliveredtotheother
more, we must show that if Bob is honest that Alice does party,whenthepolicyforthesourcehasbeensatisfied. In
not learn which of her credentials are usable (other than our framework, neither the credentials nor the policies are
what can be deduced from her policies; i.e., a globally us- revealedtotheotherparty,evenwhenthepoliciesforthere-
ablecredentialwilldefinitelybeusable). Theseproofswill sourceandthecredentialsaresatisfied. Furthermore,allof
be in the full version of the paper. We now show that the theintermediateresultsofthenegotiationremainunknown
protocoliscorrect,thatisifthepartiesarehonest,thenthe toeachparticipant. Thus, ourschemeoffersbetterprivacy
correctusablesetiscomputed. protectionthantheexistingschemes.
Proof:Instep1oftheprotocol,Boblearnsavaluet [x ] Recent work on using cryptographic protocols for trust
i i
wherex is1ifBobhascredentialc andcanuseit. There negotiation includes hidden credentials [17, 6, 14], secret
i i
are3casestoconsider: handshakes [2], oblivious signature based envelope [20],oblivious attribute certificates [18, 19], and policy-based on Security and Privacy, pages 164–173. IEEE Computer
cryptography [1]. In these protocols, Alice has some pri- SocietyPress,May1996.
vatecredentials(orattributevalues),Bobhasapolicy(that [4] P. Bonatti and P. Samarati. Regulating service access and
informationreleaseontheweb. InProceedingsofthe7th
may or may not be private), Alice and/or Bob want to de-
ACMConferenceonComputerandCommunicationsSecu-
termines whether Alice’s credentials satisfy Bob’s policy.
rity(CCS-7),pages134–143.ACMPress,Nov.2000.
While these protocols are useful in general and can be in-
[5] D.BonehandM.Franklin. Identity-BasedEncryptionfrom
tegratedintotrustnegotiationsystemsasvaluablebuilding
the Weil Pairing. In Proceedings of Crypto 2001, volume
blocks,noneoftheprotocolsaddresstheSCALPproblem, 2139ofLectureNotesinComputerScience,pages213–229.
i.e.,Alice’scredentialsarenotprotectedbyanyofherpoli- Springer,2001.
ciesinthoseprotocols. Therefore,ourworkissubstantially [6] R. Bradshaw, J. Holt, and K. Seamons. Concealing com-
differentfromthisotherwork. plexpolicieswithhiddencredentials.InProceedingsof11th
OurproblemiscloselyrelatedtoSecureFunctionEval- ACMConferenceonComputerandCommunicationsSecu-
rity,Oct.2004.
uation (SFE) [31, 16, 15]. In SFE, Alice has an input
[7] R.Canetti. Securityandcompositionofmultipartycrypto-
x, Bob has an input y, Alice and Bob want to compute
graphic protocols. Journal of Cryptology, 13(1):143–202,
f(x,y), where f is public to both of them. Elegant gen-
2000.
eral constructions have been developed to solve any SFE [8] R.Canetti,Y.Ishai,R.Kumar,M.K.Reiter,R.Rubinfeld,
problems [31, 16, 8]. Our paper uses two-party SFE tech- andR.N.Wright.Selectiveprivatefunctionevaluationwith
niques, however, it is not a routine usage of these tech- applicationstoprivatestatistics.InProceedingsofthetwen-
niquesbecause(1)wehadtofirstproposeasuitableoverall tieth annual ACM symposium on Principles of distributed
strategyforthenegotiation(i.e.,what“overallglobalfunc- computing,pages293–304.ACMPress,2001.
[9] C. Cocks. An identity based encryption scheme based on
tion”tocomputeinthefirstplace); and(2)inthestandard
quadraticresidues. In8thIMAInternationalConferenceon
SFEproblems,neitherparty’sinputsarecertified,butinour
Cryptography and Coding, volume 2260, pages 360–363.
problem, someoftheinputsareverifiedoff-linebyathird
Springer,Dec.2001.
party (recall that Alice and Bob input their credentials is- [10] I.Damga˚rdandM.Jurik. Ageneralisation,asimplification
suedbytheCAinsteadofdirectlyprovidingtheirattributes andsomeapplicationsofpaillier’sprobabilisticpublic-key
totheprotocol),andverifyingthecredentialsusingthegen- system. InPKC’01: Proceedingsofthe4thInternational
eralsolutionstoSFEisexpensive. WorkshoponPracticeandTheoryinPublicKeyCryptogra-
phy,pages119–136.Springer,2001.
[11] I.Damga˚rdandM.Jurik. Alength-flexiblethresholdcryp-
10 Conclusion
tosystemwithapplications. InProceedingsofthe8thAus-
tralasianConferenceonInformationSecurityandPrivacy,
Inthispaper,wegaveanefficientprotocolforAliceand volume2727ofLectureNotesinComputerScience,pages
Bobtonegotiatetrust,suchthatAlicedoesnotlearnBob’s 350–364.Springer,2003.
credentialsandpolicies,andBobdoesnotlearnAlice’scre- [12] C. Ellison, B. Frantz, B. Lampson, R. Rivest, B. Thomas,
dentials and policies. The only information they learn is and T. Ylonen. SPKI certificate theory. IETF RFC 2693,
Sept.1999.
whether the trust between them can be established, or in
[13] M.J.Freedman,K.Nissim,andB.Pinkas. Efficientprivate
other words, whether Alice is eligible for Bob’s service or
matchingandsetintersection. InAdvancesinCryptology:
resource.Ourworkisasubstantialextensionofthestate-of-
EUROCRYPT’04, volume3027ofLectureNotesinCom-
the-artinprivacy-preservingtrustnegotiations. Thedetails
puterScience,pages1–19.Springer,2004.
of our work contain technical results of independent inter- [14] K.B.Frikken,M.J.Atallah,andJ.Li.Hiddenaccesscontrol
est,suchasthesecureprotocolforanequalitytestforarray policieswithhiddencredentials. InProceedingsofthe3rd
elements. ACM Workshop on Privacy in the Electronic Society, Oct.
2004.
[15] O.Goldreich. TheFoundationsofCryptography—Volume
References
2. CambridgeUniversityPress,May2004.
[16] O. Goldreich, S. Micali, and A. Wigderson. How to play
[1] W. Bagga and R. Molva. Policy-based cryptography and anymentalgame. InProceedingsofthenineteenthannual
applications. InProceedingsofthe9thInternationalCon- ACM conference on Theory of computing, pages 218–229,
ferenceonFinancialCryptographyandDataSecurity,Feb. May1987.
2005. [17] J.E.Holt,R.W.Bradshaw,K.E.Seamons,andH.Orman.
[2] D.Balfanz,G.Durfee,N.Shankar,D.Smetters,J.Staddon, Hiddencredentials. InProceedingsofthe2ndACMWork-
andH.-C.Wong.Secrethandshakesfrompairing-basedkey shoponPrivacyintheElectronicSociety,Oct.2003.
agreements. In Proceedings of the IEEE Symposium and [18] J.LiandN.Li. OACerts:Obliviousattributecertificates. In
SecurityandPrivacy,pages180–196,May2003. Proceedings of the 3rd Conference on Applied Cryptogra-
[3] M.Blaze, J.Feigenbaum, andJ.Lacy. Decentralizedtrust phyandNetworkSecurity(ACNS),volume3531ofLecture
management. InProceedingsofthe1996IEEESymposium NotesinComputerScience.Springer,June2005.[19] J.LiandN.Li. Policy-hidingaccesscontrolinopenenvi- [34] T.Yu,M.Winslett,andK.E.Seamons.Interoperablestrate-
ronment. InProceedingsofthe24ndACMSymposiumon giesinautomatedtrustnegotiation.InProceedingsofthe8th
PrinciplesofDistributedComputing(PODC).ACMPress, ACMConferenceonComputerandCommunicationsSecu-
July2005. rity(CCS-8),pages146–155.ACMPress,Nov.2001.
[20] N.Li,W.Du,andD.Boneh. Oblivioussignature-baseden-
velope. In Proceedings of the 22nd ACM Symposium on
A TheEagerStrategy
PrinciplesofDistributedComputing(PODC).ACMPress,
July2003.
[21] N.Li,J.C.Mitchell,andW.H.Winsborough. Designofa Inthisappendixwereviewtheeagerstrategy[30]. Re-
role-basedtrustmanagementframework. InProceedingsof callthatthegoaloftheeagerstrategyistocomputeacre-
the2002IEEESymposiumonSecurityandPrivacy, pages
dentialdisclosuresequencethatcontainstherequestedser-
114–130.IEEEComputerSocietyPress,May2002.
vice. In the eager strategy, each negotiator iteratively ex-
[22] D. Malkhi, N. Nisan, B. Pinkas, and Y. Sella. Fairplay
ecutes the pseudo-code in Figure 8. The negotiation suc-
– secure two-party computation system. In Proceedings
of the 13th USENIX Security Symposium, pages 287–302. ceeds if s appears in the output (i.e., s ∈ M), and it fails
USENIX,2004. ifthesizeofthecredentialdisclosuresequencedoesnotin-
[23] T.Okamoto,S.Uchiyama,andE.Fujisaki. Epoc: Efficient crement after one round of execution (i.e., M = ∅). Note
probabilisticpublic-keyencryption. InIEEEP1363:Proto- that any negotiation using the eager strategy takes at most
colsfromotherfamiliesofpublic-keyalgorithms,Nov.1998. min(n ,n )rounds,wheren andn arethesizesofC
S C S C S
[24] P. Paillier. Public-key cryptosystems based on composite
andC , respectively. Thefollowingisanexampleoftrust
degreeresiduosityclasses. InAdvancesinCryptology:EU- C
negotiationusingtheeagerstrategy.
ROCRYPT’99,volume1592ofLectureNotesinComputer
Science,pages223–238.Springer,1999.
[25] K.E.Seamons,M.Winslett,andT.Yu.Limitingthedisclo- TheEagerStrategy(D,C,P,s)
sureofaccesscontrolpoliciesduringautomatedtrustnego- D ={c 1,...,c k}: thecredentialdisclosuresequence.
tiation. InProceedingsoftheSymposiumonNetworkand C: thelocalcredentialsofthisparty.
DistributedSystemSecurity(NDSS’01),February2001. P: thelocalpoliciesofthisparty.
[26] A. Shamir. Identity-based cryptosystems and signature
s: theservicetowhichaccesswasoriginallyrequested.
schemes.InAdvancesinCryptology:CRYPTO’84,volume
Output:
196 of Lecture Notes in Computer Science, pages 47–53.
M: thesetofnewreleasedcredentials.
Springer,1984.
Pre-condition:
[27] L. G. Valiant. Universal circuits (preliminary report). In
STOC’76: ProceedingsoftheeighthannualACMsympo- shasnotbeendisclosed.
sium on Theory of computing, pages 196–203, New York, Procedure:
NY,USA,1976.ACMPress. M=∅;
[28] W.H.WinsboroughandN.Li.Towardspracticalautomated Foreachcredentialc∈C
trustnegotiation. InProceedingsoftheThirdInternational letc’spolicybep :c←φ ;
c c
WorkshoponPoliciesforDistributedSystemsandNetworks
ifφ (D)=1,thenM=M∪{c};
c
(Policy2002),pages92–103.IEEEComputerSocietyPress,
M=M−D;
June2002.
returnM.
[29] W. H. Winsborough and N. Li. Safety in automated trust
negotiation. InProceedingsoftheIEEESymposiumonSe-
curityandPrivacy,pages147–160,May2004.
Figure8.PseudocodefortheEagerStrategy
[30] W.H.Winsborough,K.E.Seamons,andV.E.Jones. Auto-
matedtrustnegotiation.InDARPAInformationSurvivability
ConferenceandExposition,volumeI,pages88–102.IEEE
Press,Jan.2000. Example2 Supposetheclientandserverhavethefollow-
[31] A.C.Yao. Howtogenerateandexchangesecrets. InPro- ingpolicies:
ceedings of the 27th IEEE Symposium on Foundations of
ComputerScience,pages162–167.IEEEComputerSociety Client Server
Press,1986. p :c ←s p :s←c ∨(c ∧c )
[32] T. Yu, X. Ma, and M. Winslett. Prunes: An efficient and
c1 1 1 s 5 2 4
p :c ←s ∧s p :s ←c
completestrategyfortrustnegotiationovertheinternet. In
c2 2 2 3 s1 1 4
p :c ←s ∨s p :s ←c
Proceedingsofthe7thACMConferenceonComputerand c3 3 1 2 s2 2 1
p :c ←true p :s ←true
Communications Security (CCS-7), pages 210–219. ACM c4 4 s3 3
Press,Nov.2000.
where s denotes the server’s service, {s,s ,s ,s } denote
[33] T.YuandM.Winslett. Unifiedschemeforresourceprotec- 1 2 3
tioninautomatedtrustnegotiation. InProceedingsofIEEE the set of server’s credentials, {c 1,c 2,c 3,c 4} denotes the
SymposiumonSecurityandPrivacy,pages110–122.IEEE set of the client’s credentials. Using the eager strategy,
ComputerSocietyPress,May2003. the client begins by revealing credential c , as the policy
4function for c is true (thus it is trivially satisfied). The secondhalfofthevalues,thefunctionW a ∧
4 i∈S1 i
serverthendisclosess (whichcanberevealedfreely)and W a .
3 i∈S2 i
s (whichrequirestheearlierreceiptofc ). Theexchange
1 4
of credentials continues as the final disclosure sequence is
{c ,s ,s ,c ,c ,s ,c ,s}. Note that all policies for dis-
4 1 3 1 3 2 2
closedcredentialshavebeensatisfied.
B ProtocolforBlindedPolicyEvaluation
Figure9describeshowtoachieveblindedpolicyevalua-
tion,whichisanaturalextensionofYao’scircuitsimulation
protocol[31].
1. Alice constructs a circuit C that computes her
policy(several“usefulcircuits”aredescribedbe-
low)thatusesther valuesasinputsandthathas
i
an output wire with two encodings: t for true
1
and t for false. She sends the encodings of the
0
circuit’sgatestoBob(notethathealreadyhasin-
putencodings).
2. Bobevaluatesthecircuitandlearnstheencoding
fortheoutputwire.
Figure9.BlindedPolicyEvaluationProtocol
The protocol for Blinded Policy Evaluation uses a cir-
cuittoevaluatethepolicy. Thisrevealsthetopologyofthe
circuittotheevaluator(whichrevealssomeinformationto
theevaluator). However,onecanbuildatopologythatcov-
ers a large class of functions; this can be achieved in sev-
eralwaysincluding:(1)buildingatopologythatcanhandle
manyusefulfunctions,(2)usingauniversalcircuit[27],and
(3)usingasinglen-arygateforarbitraryfunctionality(this
latter option requires exponential communication). There
areseveralinterestingcircuittopologieswithsizelinearin
thenumberofinputstothecircuit,including:
1. Itiseasytoconstructanobliviouscomparisoncircuit
(i.e.,onethatcancompute=,6=,>,<,≥,and≤with-
outrevealingwhichcomparisonisdone)withsizepro-
portionaltothenumberofbitsinthevalues.
2. A binary tree of oblivious gates (with inputs
a ,...,a )canbeusedtocomputemanyusefulfunc-
1 n
tions(withoutrevealingwhichfunctionisbeingcom-
puted)including:
(a) Vn a ,Wn a ,Ln a ,etc.
i=1 i i=1 i i=1 i
(b) ForanysubsetofthevaluesS,V a ,W a ,
i∈S i i∈S i
L a ,etc.
i∈S i
(c) Other functions like: for a subset S of the first
1
half of the values and another subset S of the
2